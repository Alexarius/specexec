{"msg_type": "config", "gen_type": "SpecExecBase", "model_0": "Qwen/Qwen2.5-0.5B", "model_1": "Qwen/Qwen2.5-14B", "temperature": 0.6, "max_n_beams": "128", "max_beam_len": "32", "top_p": 0.9, "max_new_tokens": 32, "max_budget": "16, 32, 64, 128, 256, 512, 1024, 2048", "max_branch_width": "32", "branching": null, "min_log_prob": null, "replacement": false, "n_tests": 1000, "seed": 0, "dataset": "oasst", "timestamp": "2025-03-25 09:24:54", "date": "250325", "hostname": "orin", "commit": "none", "offload": false, "device": "Orin"}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 9.8, "tree_w": 3, "tree_size": 16, "t0": 0.762, "t1": 0.364, "tft": 2.5301, "input_0": 40, "input_1": 17, "min_CLP": -3.64, "draft_iters": 10.8, "mem_use": 33.68, "gen_rate": 8.8, "speed": 7.79, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.5143, "t1": 0.31, "tft": 1.9685, "input_0": 32, "input_1": 17, "min_CLP": -3.62, "draft_iters": 7.4, "mem_use": 35.21, "gen_rate": 5.0, "speed": 6.07, "text": "\"You are correct. I apologize fo"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.5211, "t1": 0.3144, "tft": 1.7914, "input_0": 43, "input_1": 17, "min_CLP": -3.17, "draft_iters": 7.6, "mem_use": 36.13, "gen_rate": 4.0, "speed": 4.79, "text": "\"I'm sorry, but I'm not able to "}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 6.4, "tree_w": 3, "tree_size": 16, "t0": 0.518, "t1": 0.334, "tft": 0.8684, "input_0": 42, "input_1": 17, "min_CLP": -2.82, "draft_iters": 7.4, "mem_use": 33.85, "gen_rate": 6.8, "speed": 8.0, "text": "\"Certainly! Here's a Python scri"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 5.4, "tree_w": 4, "tree_size": 16, "t0": 0.4567, "t1": 0.3433, "tft": 1.1692, "input_0": 39, "input_1": 17, "min_CLP": -3.34, "draft_iters": 6.4, "mem_use": 33.7, "gen_rate": 3.0, "speed": 3.76, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 0.686, "t1": 0.314, "tft": 2.3089, "input_0": 47, "input_1": 17, "min_CLP": -2.83, "draft_iters": 10.0, "mem_use": 36.26, "gen_rate": 6.8, "speed": 6.81, "text": "Certainly! Here\\'s a potential o"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.5233, "t1": 0.3, "tft": 2.3471, "input_0": 44, "input_1": 17, "min_CLP": -3.11, "draft_iters": 7.7, "mem_use": 36.83, "gen_rate": 5.8, "speed": 7.08, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.5157, "t1": 0.3129, "tft": 2.8567, "input_0": 42, "input_1": 17, "min_CLP": -3.0, "draft_iters": 7.6, "mem_use": 38.98, "gen_rate": 4.6, "speed": 5.5, "text": "\"Sure, let's dive deeper into at"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 0.5571, "t1": 0.3071, "tft": 2.0145, "input_0": 43, "input_1": 17, "min_CLP": -3.17, "draft_iters": 8.1, "mem_use": 36.45, "gen_rate": 4.9, "speed": 5.61, "text": "\"Sure, here is a list of the leg"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.54, "t1": 0.3, "tft": 1.7032, "input_0": 48, "input_1": 17, "min_CLP": -3.01, "draft_iters": 7.8, "mem_use": 35.8, "gen_rate": 6.2, "speed": 7.34, "text": "There are many beginner-friendly"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.4, "tree_w": 6, "tree_size": 16, "t0": 0.5075, "t1": 0.3063, "tft": 1.0717, "input_0": 36, "input_1": 17, "min_CLP": -4.01, "draft_iters": 7.4, "mem_use": 34.35, "gen_rate": 4.4, "speed": 5.38, "text": "Here is your code:\\n``If thou ar"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 0.5986, "t1": 0.3143, "tft": 1.9762, "input_0": 42, "input_1": 17, "min_CLP": -3.07, "draft_iters": 8.7, "mem_use": 36.2, "gen_rate": 5.1, "speed": 5.63, "text": "Here\\'s a shorter version:\\n\\n\"F"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 0.702, "t1": 0.328, "tft": 1.5349, "input_0": 46, "input_1": 17, "min_CLP": -2.81, "draft_iters": 10.2, "mem_use": 35.4, "gen_rate": 7.6, "speed": 7.38, "text": "Sure, here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.7, "tree_w": 4, "tree_size": 16, "t0": 0.8767, "t1": 0.36, "tft": 1.1674, "input_0": 52, "input_1": 17, "min_CLP": -4.02, "draft_iters": 12.7, "mem_use": 33.68, "gen_rate": 12.0, "speed": 9.72, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.5, "t1": 0.3056, "tft": 2.4169, "input_0": 41, "input_1": 17, "min_CLP": -3.31, "draft_iters": 7.3, "mem_use": 36.8, "gen_rate": 4.0, "speed": 4.96, "text": "\"While it's true that spaced rep"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.9, "tree_w": 3, "tree_size": 16, "t0": 0.7586, "t1": 0.3643, "tft": 0.9363, "input_0": 52, "input_1": 17, "min_CLP": -3.07, "draft_iters": 10.9, "mem_use": 34.01, "gen_rate": 4.6, "speed": 4.07, "text": "The minimum upload speed recomme"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 0.6917, "t1": 0.35, "tft": 1.2986, "input_0": 44, "input_1": 17, "min_CLP": -2.83, "draft_iters": 10.0, "mem_use": 33.7, "gen_rate": 6.8, "speed": 6.55, "text": "\"Sure, I can explain Fermat's La"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 8.8, "tree_w": 5, "tree_size": 16, "t0": 0.68, "t1": 0.356, "tft": 0.825, "input_0": 45, "input_1": 17, "min_CLP": -3.94, "draft_iters": 9.8, "mem_use": 33.67, "gen_rate": 9.0, "speed": 8.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.4914, "t1": 0.32, "tft": 1.2316, "input_0": 41, "input_1": 17, "min_CLP": -3.48, "draft_iters": 7.1, "mem_use": 34.21, "gen_rate": 4.9, "speed": 5.99, "text": "D-theanine is the less common fo"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.545, "t1": 0.35, "tft": 1.0951, "input_0": 39, "input_1": 17, "min_CLP": -3.33, "draft_iters": 7.8, "mem_use": 33.68, "gen_rate": 5.3, "speed": 5.96, "text": "What is the Balfour Declaration?"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 20, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.405, "t1": 0.33, "tft": 1.1324, "input_0": 34, "input_1": 17, "min_CLP": -3.82, "draft_iters": 5.8, "mem_use": 34.52, "gen_rate": 3.3, "speed": 4.54, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.375, "t1": 0.305, "tft": 0.8055, "input_0": 28, "input_1": 17, "min_CLP": -3.54, "draft_iters": 5.5, "mem_use": 33.68, "gen_rate": 3.5, "speed": 5.18, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.612, "t1": 0.308, "tft": 1.8635, "input_0": 51, "input_1": 17, "min_CLP": -3.03, "draft_iters": 9.0, "mem_use": 36.05, "gen_rate": 7.4, "speed": 8.06, "text": "For an asymmetric bimodal distri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.4575, "t1": 0.3312, "tft": 0.9019, "input_0": 37, "input_1": 17, "min_CLP": -3.35, "draft_iters": 6.6, "mem_use": 33.75, "gen_rate": 4.2, "speed": 5.37, "text": "1. Understanding the Question: T"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.435, "t1": 0.319, "tft": 1.497, "input_0": 33, "input_1": 17, "min_CLP": -3.57, "draft_iters": 6.3, "mem_use": 34.71, "gen_rate": 3.4, "speed": 4.51, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.2, "tree_w": 3, "tree_size": 16, "t0": 0.77, "t1": 0.3475, "tft": 0.8838, "input_0": 48, "input_1": 17, "min_CLP": -3.77, "draft_iters": 11.2, "mem_use": 33.72, "gen_rate": 10.0, "speed": 8.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.3738, "t1": 0.3275, "tft": 1.3839, "input_0": 32, "input_1": 17, "min_CLP": -3.76, "draft_iters": 5.4, "mem_use": 34.38, "gen_rate": 4.1, "speed": 5.89, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 22, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.6083, "t1": 0.3633, "tft": 0.8786, "input_0": 43, "input_1": 17, "min_CLP": -3.09, "draft_iters": 8.8, "mem_use": 34.24, "gen_rate": 3.7, "speed": 3.78, "text": "\"You're welcome! It was a pleasu"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.13, "t1": 0.32, "tft": 2.03, "input_0": 50, "input_1": 17, "min_CLP": -4.12, "draft_iters": 17.0, "mem_use": 36.19, "gen_rate": 17.0, "speed": 11.74, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.0, "tree_w": 4, "tree_size": 16, "t0": 0.745, "t1": 0.345, "tft": 0.7473, "input_0": 45, "input_1": 17, "min_CLP": -3.96, "draft_iters": 11.0, "mem_use": 33.73, "gen_rate": 9.5, "speed": 8.71, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.4786, "t1": 0.3043, "tft": 1.1941, "input_0": 43, "input_1": 17, "min_CLP": -3.24, "draft_iters": 7.0, "mem_use": 34.42, "gen_rate": 5.1, "speed": 6.57, "text": "Yes, Into the Breach is a game o"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.0, "tree_w": 6, "tree_size": 16, "t0": 0.347, "t1": 0.319, "tft": 1.3609, "input_0": 33, "input_1": 17, "min_CLP": -3.65, "draft_iters": 5.0, "mem_use": 34.83, "gen_rate": 3.4, "speed": 5.08, "text": "[ANSWER]: It seems like there is"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 0.5175, "t1": 0.3512, "tft": 1.0653, "input_0": 36, "input_1": 17, "min_CLP": -3.52, "draft_iters": 7.5, "mem_use": 34.18, "gen_rate": 4.0, "speed": 4.61, "text": "Freyja, dear goddess, we pray to"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.3755, "t1": 0.3082, "tft": 1.5699, "input_0": 35, "input_1": 17, "min_CLP": -3.52, "draft_iters": 5.5, "mem_use": 35.82, "gen_rate": 3.1, "speed": 4.52, "text": "Vegetarian cheese is a great opt"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.42, "t1": 0.3029, "tft": 1.5787, "input_0": 38, "input_1": 17, "min_CLP": -3.22, "draft_iters": 6.1, "mem_use": 35.86, "gen_rate": 4.6, "speed": 6.32, "text": "When choosing an ISP package, th"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 0.5586, "t1": 0.3129, "tft": 3.0257, "input_0": 43, "input_1": 17, "min_CLP": -3.31, "draft_iters": 8.3, "mem_use": 38.58, "gen_rate": 5.1, "speed": 5.89, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.4929, "t1": 0.3357, "tft": 1.2672, "input_0": 36, "input_1": 17, "min_CLP": -3.55, "draft_iters": 7.1, "mem_use": 33.71, "gen_rate": 4.7, "speed": 5.7, "text": "\"I'm sorry, but I cannot answer "}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.4218, "t1": 0.3545, "tft": 1.4134, "input_0": 34, "input_1": 17, "min_CLP": -3.88, "draft_iters": 6.1, "mem_use": 34.23, "gen_rate": 2.9, "speed": 3.75, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 7.1, "tree_w": 5, "tree_size": 16, "t0": 0.5467, "t1": 0.3111, "tft": 2.1258, "input_0": 38, "input_1": 17, "min_CLP": -3.31, "draft_iters": 8.1, "mem_use": 36.61, "gen_rate": 3.8, "speed": 4.41, "text": "Sure, I can definitely try to ac"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 0.635, "t1": 0.34, "tft": 1.4733, "input_0": 49, "input_1": 17, "min_CLP": -3.34, "draft_iters": 9.2, "mem_use": 34.64, "gen_rate": 8.0, "speed": 8.2, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 33, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.3338, "t1": 0.3354, "tft": 0.7439, "input_0": 30, "input_1": 17, "min_CLP": -3.94, "draft_iters": 4.8, "mem_use": 33.93, "gen_rate": 2.5, "speed": 3.79, "text": "\"I am not to be controlled by me"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.6, "tree_w": 5, "tree_size": 16, "t0": 0.384, "t1": 0.303, "tft": 1.9032, "input_0": 35, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.6, "mem_use": 36.43, "gen_rate": 3.6, "speed": 5.26, "text": "\"Thank you for your feedback. I "}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.2, "tree_w": 5, "tree_size": 16, "t0": 0.616, "t1": 0.312, "tft": 2.2402, "input_0": 33, "input_1": 17, "min_CLP": -3.5, "draft_iters": 9.2, "mem_use": 36.85, "gen_rate": 7.6, "speed": 8.2, "text": "[INST] I am not sure. I am looki"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.9, "tree_w": 4, "tree_size": 16, "t0": 0.5414, "t1": 0.3343, "tft": 1.5947, "input_0": 48, "input_1": 17, "min_CLP": -2.9, "draft_iters": 7.9, "mem_use": 35.2, "gen_rate": 4.7, "speed": 5.38, "text": "Determining the \"best\" SAST tool"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 13, "tree_h": 7.7, "tree_w": 3, "tree_size": 16, "t0": 0.5933, "t1": 0.33, "tft": 1.5042, "input_0": 44, "input_1": 17, "min_CLP": -3.46, "draft_iters": 8.7, "mem_use": 34.46, "gen_rate": 4.3, "speed": 4.72, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.11, "t1": 0.37, "tft": 1.5172, "input_0": 57, "input_1": 17, "min_CLP": -3.61, "draft_iters": 16.5, "mem_use": 34.19, "gen_rate": 16.5, "speed": 11.15, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.6257, "t1": 0.3643, "tft": 0.9604, "input_0": 53, "input_1": 17, "min_CLP": -3.27, "draft_iters": 9.0, "mem_use": 33.71, "gen_rate": 5.9, "speed": 5.91, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 6.4, "tree_w": 6, "tree_size": 16, "t0": 0.4977, "t1": 0.3169, "tft": 2.7099, "input_0": 36, "input_1": 17, "min_CLP": -3.63, "draft_iters": 7.4, "mem_use": 39.12, "gen_rate": 2.5, "speed": 3.03, "text": "Certainly! Let\\'s try this:\\n\\nT"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.3427, "t1": 0.3182, "tft": 1.3833, "input_0": 32, "input_1": 17, "min_CLP": -3.9, "draft_iters": 4.9, "mem_use": 35.44, "gen_rate": 3.3, "speed": 4.96, "text": "Thank you for listening, Agent. "}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.3745, "t1": 0.3427, "tft": 1.1044, "input_0": 32, "input_1": 17, "min_CLP": -3.69, "draft_iters": 5.4, "mem_use": 34.47, "gen_rate": 3.4, "speed": 4.7, "text": "\"Alright, I hope you understand."}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 0.6283, "t1": 0.3583, "tft": 0.962, "input_0": 45, "input_1": 17, "min_CLP": -3.21, "draft_iters": 9.2, "mem_use": 33.99, "gen_rate": 6.7, "speed": 6.75, "text": "\u70b9\u51fb\u7387 (CTR) \u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u4e3b\u9898"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.08, "t1": 0.335, "tft": 1.8048, "input_0": 63, "input_1": 17, "min_CLP": -3.16, "draft_iters": 16.0, "mem_use": 35.86, "gen_rate": 9.5, "speed": 6.72, "text": "F-centers, also known as color c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.4883, "t1": 0.3317, "tft": 1.4017, "input_0": 39, "input_1": 17, "min_CLP": -3.43, "draft_iters": 7.2, "mem_use": 35.08, "gen_rate": 5.8, "speed": 7.11, "text": "Sure, here are some more histori"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.4271, "t1": 0.3286, "tft": 1.6641, "input_0": 38, "input_1": 17, "min_CLP": -3.09, "draft_iters": 6.1, "mem_use": 35.42, "gen_rate": 5.0, "speed": 6.61, "text": "Yes, it is possible for technolo"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 36, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.3885, "t1": 0.3562, "tft": 0.9153, "input_0": 31, "input_1": 17, "min_CLP": -3.78, "draft_iters": 5.5, "mem_use": 33.88, "gen_rate": 2.8, "speed": 3.73, "text": "\"People all over the world wear "}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.4122, "t1": 0.3067, "tft": 1.9135, "input_0": 35, "input_1": 17, "min_CLP": -3.66, "draft_iters": 6.0, "mem_use": 36.29, "gen_rate": 3.8, "speed": 5.26, "text": "Sure, here is a pitch deck for F"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 42, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.499, "t1": 0.314, "tft": 2.555, "input_0": 36, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.4, "mem_use": 37.53, "gen_rate": 4.2, "speed": 5.16, "text": "You are correct, and I apologize"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.4871, "t1": 0.3157, "tft": 2.4991, "input_0": 39, "input_1": 17, "min_CLP": -3.22, "draft_iters": 7.1, "mem_use": 37.69, "gen_rate": 4.6, "speed": 5.73, "text": "\"Yes, for a complete beginner wi"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.5, "tree_w": 2, "tree_size": 16, "t0": 0.9125, "t1": 0.335, "tft": 1.8519, "input_0": 52, "input_1": 17, "min_CLP": -2.64, "draft_iters": 13.5, "mem_use": 35.35, "gen_rate": 10.0, "speed": 8.03, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.4529, "t1": 0.3414, "tft": 1.2917, "input_0": 34, "input_1": 17, "min_CLP": -3.73, "draft_iters": 6.6, "mem_use": 33.7, "gen_rate": 5.3, "speed": 6.65, "text": "Best way to form a new habit is "}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 2, "tree_size": 16, "t0": 0.99, "t1": 0.3233, "tft": 1.8523, "input_0": 62, "input_1": 17, "min_CLP": -2.72, "draft_iters": 14.7, "mem_use": 36.12, "gen_rate": 14.7, "speed": 11.15, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.9, "tree_w": 7, "tree_size": 16, "t0": 0.402, "t1": 0.309, "tft": 2.331, "input_0": 31, "input_1": 17, "min_CLP": -3.99, "draft_iters": 5.9, "mem_use": 36.94, "gen_rate": 3.4, "speed": 4.8, "text": "[The general nods to his army, a"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.368, "t1": 0.325, "tft": 1.1885, "input_0": 35, "input_1": 17, "min_CLP": -3.64, "draft_iters": 5.3, "mem_use": 34.65, "gen_rate": 3.2, "speed": 4.62, "text": "Thank you for the feedback! Reme"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.425, "t1": 0.3313, "tft": 1.2896, "input_0": 38, "input_1": 17, "min_CLP": -3.46, "draft_iters": 6.1, "mem_use": 34.37, "gen_rate": 4.2, "speed": 5.62, "text": "The proof-of-stake (PoS) concept"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.7, "tree_w": 8, "tree_size": 16, "t0": 0.33, "t1": 0.3291, "tft": 1.1033, "input_0": 28, "input_1": 17, "min_CLP": -3.79, "draft_iters": 4.7, "mem_use": 34.49, "gen_rate": 3.0, "speed": 4.55, "text": "Adolph Hitler was not the only p"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.4586, "t1": 0.3086, "tft": 2.1144, "input_0": 38, "input_1": 17, "min_CLP": -3.16, "draft_iters": 6.7, "mem_use": 36.56, "gen_rate": 4.7, "speed": 6.15, "text": "Sure, I can explain how to use v"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.4688, "t1": 0.31, "tft": 2.2778, "input_0": 39, "input_1": 17, "min_CLP": -3.47, "draft_iters": 6.9, "mem_use": 37.06, "gen_rate": 4.1, "speed": 5.3, "text": "\"I'm sorry, but I'm not able to "}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 3, "tree_size": 16, "t0": 0.5583, "t1": 0.3017, "tft": 2.0416, "input_0": 51, "input_1": 17, "min_CLP": -3.19, "draft_iters": 8.2, "mem_use": 36.29, "gen_rate": 5.5, "speed": 6.4, "text": "\"Implementing two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 7.5, "tree_w": 4, "tree_size": 16, "t0": 0.5833, "t1": 0.3583, "tft": 0.8384, "input_0": 44, "input_1": 17, "min_CLP": -3.34, "draft_iters": 8.5, "mem_use": 34.11, "gen_rate": 7.0, "speed": 7.43, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.4187, "t1": 0.3437, "tft": 1.5269, "input_0": 36, "input_1": 17, "min_CLP": -3.39, "draft_iters": 6.0, "mem_use": 33.7, "gen_rate": 4.2, "speed": 5.58, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 11.2, "tree_w": 2, "tree_size": 16, "t0": 0.818, "t1": 0.318, "tft": 2.1324, "input_0": 49, "input_1": 17, "min_CLP": -2.68, "draft_iters": 12.2, "mem_use": 36.52, "gen_rate": 9.0, "speed": 7.92, "text": "Sure, here is the updated table "}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.4333, "t1": 0.35, "tft": 0.809, "input_0": 34, "input_1": 17, "min_CLP": -3.77, "draft_iters": 6.2, "mem_use": 33.66, "gen_rate": 3.6, "speed": 4.53, "text": "The city of Berlin was establish"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.125, "t1": 0.32, "tft": 2.1673, "input_0": 57, "input_1": 17, "min_CLP": -3.69, "draft_iters": 17.0, "mem_use": 36.01, "gen_rate": 17.0, "speed": 11.74, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.5, "tree_w": 4, "tree_size": 16, "t0": 0.5788, "t1": 0.3138, "tft": 1.9669, "input_0": 43, "input_1": 17, "min_CLP": -3.06, "draft_iters": 8.5, "mem_use": 35.83, "gen_rate": 4.2, "speed": 4.76, "text": "Sure, here are some of the main "}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.41, "t1": 0.3167, "tft": 0.8035, "input_0": 32, "input_1": 17, "min_CLP": -4.03, "draft_iters": 6.0, "mem_use": 33.67, "gen_rate": 2.7, "speed": 3.68, "text": "Where does pornography come from"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.145, "t1": 0.38, "tft": 0.8899, "input_0": 51, "input_1": 17, "min_CLP": -3.21, "draft_iters": 17.0, "mem_use": 33.99, "gen_rate": 17.0, "speed": 11.14, "text": "You can visit at The World Clock"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.4311, "t1": 0.3422, "tft": 0.8934, "input_0": 36, "input_1": 17, "min_CLP": -3.61, "draft_iters": 6.2, "mem_use": 34.07, "gen_rate": 3.9, "speed": 5.01, "text": "It depends. If you drop food on "}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 31, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.61, "t1": 0.3683, "tft": 0.7947, "input_0": 42, "input_1": 17, "min_CLP": -3.01, "draft_iters": 8.8, "mem_use": 33.79, "gen_rate": 5.2, "speed": 5.29, "text": "def solve_task():\\n    eggs = 12"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.8, "tree_w": 4, "tree_size": 16, "t0": 0.668, "t1": 0.332, "tft": 1.3491, "input_0": 48, "input_1": 17, "min_CLP": -3.2, "draft_iters": 9.8, "mem_use": 34.54, "gen_rate": 7.2, "speed": 7.2, "text": "Sure! One of the most well-known"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.5029, "t1": 0.34, "tft": 0.9143, "input_0": 40, "input_1": 17, "min_CLP": -3.37, "draft_iters": 7.3, "mem_use": 34.11, "gen_rate": 5.1, "speed": 6.11, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 7.3, "tree_w": 5, "tree_size": 16, "t0": 0.5745, "t1": 0.3573, "tft": 0.8429, "input_0": 36, "input_1": 17, "min_CLP": -3.3, "draft_iters": 8.3, "mem_use": 33.82, "gen_rate": 3.0, "speed": 3.23, "text": "Here\\'s an announcement tweet fo"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.4075, "t1": 0.3425, "tft": 1.7038, "input_0": 38, "input_1": 17, "min_CLP": -3.59, "draft_iters": 5.9, "mem_use": 34.43, "gen_rate": 4.5, "speed": 6.0, "text": "Sexual selection can also affect"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.48, "t1": 0.3033, "tft": 1.5613, "input_0": 39, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.0, "mem_use": 35.47, "gen_rate": 5.5, "speed": 7.02, "text": "Sure, here are some ways AI assi"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.0, "tree_w": 4, "tree_size": 16, "t0": 0.7375, "t1": 0.31, "tft": 1.9771, "input_0": 42, "input_1": 17, "min_CLP": -3.56, "draft_iters": 11.0, "mem_use": 36.5, "gen_rate": 10.0, "speed": 9.56, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.47, "t1": 0.3, "tft": 1.3747, "input_0": 40, "input_1": 17, "min_CLP": -3.22, "draft_iters": 6.9, "mem_use": 34.98, "gen_rate": 4.6, "speed": 6.02, "text": "The scp command is specific to U"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 13.0, "tree_w": 2, "tree_size": 16, "t0": 0.9433, "t1": 0.33, "tft": 1.736, "input_0": 55, "input_1": 17, "min_CLP": -2.7, "draft_iters": 14.0, "mem_use": 35.62, "gen_rate": 11.7, "speed": 9.17, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.466, "t1": 0.347, "tft": 0.8149, "input_0": 36, "input_1": 17, "min_CLP": -3.47, "draft_iters": 6.7, "mem_use": 33.73, "gen_rate": 3.2, "speed": 3.93, "text": "It is not illegal to keep a doll"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.9, "tree_w": 4, "tree_size": 16, "t0": 0.61, "t1": 0.3486, "tft": 1.1718, "input_0": 43, "input_1": 17, "min_CLP": -3.43, "draft_iters": 8.9, "mem_use": 34.01, "gen_rate": 4.9, "speed": 5.07, "text": "Sydney is the largest city in Au"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 12.7, "tree_w": 3, "tree_size": 16, "t0": 0.9267, "t1": 0.36, "tft": 0.9489, "input_0": 45, "input_1": 17, "min_CLP": -4.06, "draft_iters": 13.7, "mem_use": 34.31, "gen_rate": 13.7, "speed": 10.64, "text": "\"[INST] 5 second rule is a dange"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 17, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.3657, "t1": 0.3229, "tft": 0.8757, "input_0": 32, "input_1": 17, "min_CLP": -3.67, "draft_iters": 5.3, "mem_use": 33.99, "gen_rate": 2.4, "speed": 3.53, "text": "\"I'm glad you liked it! If you w"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.745, "t1": 0.3475, "tft": 1.3202, "input_0": 46, "input_1": 17, "min_CLP": -3.93, "draft_iters": 11.0, "mem_use": 33.76, "gen_rate": 10.0, "speed": 9.16, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.4278, "t1": 0.3422, "tft": 0.8604, "input_0": 36, "input_1": 17, "min_CLP": -3.83, "draft_iters": 6.1, "mem_use": 33.74, "gen_rate": 3.9, "speed": 5.05, "text": "Walking around the world is a hy"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 3, "tree_size": 16, "t0": 0.71, "t1": 0.326, "tft": 2.3017, "input_0": 54, "input_1": 17, "min_CLP": -2.81, "draft_iters": 10.4, "mem_use": 35.47, "gen_rate": 6.6, "speed": 6.36, "text": "\"Sure, I can explain that in lay"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.5, "tree_w": 4, "tree_size": 16, "t0": 0.7175, "t1": 0.335, "tft": 0.8348, "input_0": 46, "input_1": 17, "min_CLP": -3.97, "draft_iters": 10.5, "mem_use": 33.74, "gen_rate": 10.0, "speed": 9.48, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.7467, "t1": 0.3467, "tft": 1.1766, "input_0": 53, "input_1": 17, "min_CLP": -2.72, "draft_iters": 11.0, "mem_use": 34.04, "gen_rate": 11.0, "speed": 10.06, "text": "In Godot Engine 3.x, you can wri"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 8.4, "tree_w": 5, "tree_size": 16, "t0": 0.644, "t1": 0.342, "tft": 0.8952, "input_0": 37, "input_1": 17, "min_CLP": -3.84, "draft_iters": 9.4, "mem_use": 33.71, "gen_rate": 8.0, "speed": 8.11, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.4075, "t1": 0.3225, "tft": 0.9031, "input_0": 38, "input_1": 17, "min_CLP": -3.88, "draft_iters": 5.9, "mem_use": 34.02, "gen_rate": 4.0, "speed": 5.47, "text": "Ah, young one, the path to becom"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.5, "tree_w": 7, "tree_size": 16, "t0": 0.3855, "t1": 0.3327, "tft": 1.1479, "input_0": 31, "input_1": 17, "min_CLP": -3.58, "draft_iters": 5.5, "mem_use": 33.88, "gen_rate": 2.9, "speed": 4.03, "text": "A gas-operated rifle is a type o"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.5062, "t1": 0.31, "tft": 1.069, "input_0": 41, "input_1": 17, "min_CLP": -3.75, "draft_iters": 7.4, "mem_use": 34.12, "gen_rate": 5.1, "speed": 6.27, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.4167, "t1": 0.2978, "tft": 2.2063, "input_0": 37, "input_1": 17, "min_CLP": -3.57, "draft_iters": 6.1, "mem_use": 36.95, "gen_rate": 3.9, "speed": 5.44, "text": "I understand. A more robust solu"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.4767, "t1": 0.3211, "tft": 0.9102, "input_0": 36, "input_1": 17, "min_CLP": -3.21, "draft_iters": 6.9, "mem_use": 34.18, "gen_rate": 3.9, "speed": 4.89, "text": "Yes, it is generally considered "}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.5, "tree_w": 6, "tree_size": 16, "t0": 0.44, "t1": 0.299, "tft": 2.0826, "input_0": 34, "input_1": 17, "min_CLP": -3.83, "draft_iters": 6.5, "mem_use": 37.05, "gen_rate": 3.5, "speed": 4.73, "text": "Xin ch\u00e0o! T\u00f4i c\u00f3 th\u1ec3 gi\u00fap g\u00ec cho"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 15.0, "tree_w": 1, "tree_size": 16, "t0": 1.07, "t1": 0.3333, "tft": 1.1065, "input_0": 55, "input_1": 17, "min_CLP": -2.69, "draft_iters": 16.0, "mem_use": 34.55, "gen_rate": 16.0, "speed": 11.36, "text": "I checked, the story of British "}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.4986, "t1": 0.3086, "tft": 1.0887, "input_0": 39, "input_1": 17, "min_CLP": -3.05, "draft_iters": 7.3, "mem_use": 34.07, "gen_rate": 5.4, "speed": 6.72, "text": "Sure, here\\'s an example to help"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.5067, "t1": 0.3133, "tft": 1.6166, "input_0": 42, "input_1": 17, "min_CLP": -3.54, "draft_iters": 7.3, "mem_use": 35.49, "gen_rate": 6.0, "speed": 7.31, "text": "In order to compile a list of th"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.3636, "t1": 0.3027, "tft": 1.1438, "input_0": 31, "input_1": 17, "min_CLP": -3.86, "draft_iters": 5.3, "mem_use": 34.03, "gen_rate": 3.2, "speed": 4.77, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.5112, "t1": 0.2975, "tft": 1.9534, "input_0": 39, "input_1": 17, "min_CLP": -3.2, "draft_iters": 7.5, "mem_use": 36.05, "gen_rate": 4.0, "speed": 4.95, "text": "\"To acquire revenue from custome"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.3462, "t1": 0.2975, "tft": 1.3376, "input_0": 34, "input_1": 17, "min_CLP": -3.56, "draft_iters": 5.0, "mem_use": 34.65, "gen_rate": 4.0, "speed": 6.21, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 3, "tree_size": 16, "t0": 0.735, "t1": 0.3125, "tft": 0.911, "input_0": 51, "input_1": 17, "min_CLP": -3.21, "draft_iters": 10.8, "mem_use": 34.19, "gen_rate": 9.2, "speed": 8.85, "text": "Certainly! Here is an essay on h"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.3, "tree_w": 3, "tree_size": 16, "t0": 0.5733, "t1": 0.3367, "tft": 1.2675, "input_0": 43, "input_1": 17, "min_CLP": -3.22, "draft_iters": 8.3, "mem_use": 34.33, "gen_rate": 6.2, "speed": 6.78, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 14, "new_tokens": 35, "tree_h": 3.3, "tree_w": 11, "tree_size": 16, "t0": 0.295, "t1": 0.315, "tft": 1.6518, "input_0": 23, "input_1": 17, "min_CLP": -4.65, "draft_iters": 4.3, "mem_use": 35.59, "gen_rate": 2.5, "speed": 4.1, "text": "\"Sure, here's a poem in Quenya t"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 18, "new_tokens": 34, "tree_h": 3.8, "tree_w": 8, "tree_size": 16, "t0": 0.3417, "t1": 0.3528, "tft": 1.2743, "input_0": 28, "input_1": 17, "min_CLP": -3.96, "draft_iters": 4.8, "mem_use": 33.71, "gen_rate": 1.9, "speed": 2.73, "text": "I am a model trained by Meta, no"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.464, "t1": 0.327, "tft": 1.1052, "input_0": 38, "input_1": 17, "min_CLP": -3.21, "draft_iters": 6.7, "mem_use": 33.75, "gen_rate": 3.8, "speed": 4.81, "text": "The error in the code is that th"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.368, "t1": 0.318, "tft": 1.2822, "input_0": 31, "input_1": 17, "min_CLP": -3.63, "draft_iters": 5.3, "mem_use": 35.13, "gen_rate": 3.6, "speed": 5.25, "text": "The message left by the past you"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 0.5187, "t1": 0.3325, "tft": 1.2153, "input_0": 43, "input_1": 17, "min_CLP": -3.22, "draft_iters": 7.5, "mem_use": 34.36, "gen_rate": 4.2, "speed": 5.0, "text": "Certainly! In Python, the `@` sy"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.6, "tree_w": 3, "tree_size": 16, "t0": 0.5913, "t1": 0.3125, "tft": 1.169, "input_0": 46, "input_1": 17, "min_CLP": -3.17, "draft_iters": 8.6, "mem_use": 34.48, "gen_rate": 4.8, "speed": 5.25, "text": "\"One way to achieve this would b"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.417, "t1": 0.295, "tft": 1.9314, "input_0": 37, "input_1": 17, "min_CLP": -3.44, "draft_iters": 6.1, "mem_use": 36.27, "gen_rate": 3.7, "speed": 5.21, "text": "\"It's important to be cautious w"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 8.0, "tree_w": 5, "tree_size": 16, "t0": 0.6075, "t1": 0.3075, "tft": 0.8625, "input_0": 38, "input_1": 17, "min_CLP": -3.19, "draft_iters": 9.0, "mem_use": 34.26, "gen_rate": 8.5, "speed": 9.31, "text": "Absolutely! Here\\'s the updated "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.5, "tree_w": 1, "tree_size": 16, "t0": 1.0475, "t1": 0.335, "tft": 2.1404, "input_0": 56, "input_1": 17, "min_CLP": -1.91, "draft_iters": 15.5, "mem_use": 35.62, "gen_rate": 10.0, "speed": 7.21, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.3978, "t1": 0.3311, "tft": 0.8073, "input_0": 37, "input_1": 17, "min_CLP": -3.45, "draft_iters": 5.7, "mem_use": 33.69, "gen_rate": 3.8, "speed": 5.19, "text": "Yes, as an AI language model, I "}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 9.0, "tree_w": 4, "tree_size": 16, "t0": 0.684, "t1": 0.356, "tft": 1.0162, "input_0": 43, "input_1": 17, "min_CLP": -4.11, "draft_iters": 10.0, "mem_use": 33.91, "gen_rate": 8.4, "speed": 8.08, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.4764, "t1": 0.3318, "tft": 0.8643, "input_0": 37, "input_1": 17, "min_CLP": -3.69, "draft_iters": 6.9, "mem_use": 34.16, "gen_rate": 3.0, "speed": 3.71, "text": "\"Thank you, I'm always here to h"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.9, "tree_w": 7, "tree_size": 16, "t0": 0.4038, "t1": 0.32, "tft": 1.4954, "input_0": 32, "input_1": 17, "min_CLP": -3.98, "draft_iters": 5.9, "mem_use": 35.73, "gen_rate": 4.6, "speed": 6.4, "text": "Thou art the sun that doth shine"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.4929, "t1": 0.3414, "tft": 1.0736, "input_0": 41, "input_1": 17, "min_CLP": -3.13, "draft_iters": 7.1, "mem_use": 34.33, "gen_rate": 5.1, "speed": 6.17, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.0, "tree_w": 7, "tree_size": 16, "t0": 0.4143, "t1": 0.35, "tft": 1.1161, "input_0": 32, "input_1": 17, "min_CLP": -3.82, "draft_iters": 6.0, "mem_use": 33.73, "gen_rate": 5.1, "speed": 6.72, "text": "Sure, here are some words to exp"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.5, "tree_w": 4, "tree_size": 16, "t0": 0.5887, "t1": 0.3438, "tft": 1.1034, "input_0": 44, "input_1": 17, "min_CLP": -3.13, "draft_iters": 8.5, "mem_use": 33.71, "gen_rate": 4.0, "speed": 4.29, "text": "\"Presidents' Day, also known as "}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 29, "tree_h": 4.7, "tree_w": 7, "tree_size": 16, "t0": 0.3944, "t1": 0.3567, "tft": 0.8302, "input_0": 30, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.7, "mem_use": 34.01, "gen_rate": 3.2, "speed": 4.28, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.5988, "t1": 0.3488, "tft": 1.3686, "input_0": 43, "input_1": 17, "min_CLP": -2.94, "draft_iters": 8.8, "mem_use": 34.81, "gen_rate": 4.0, "speed": 4.22, "text": "Yes, the US National Reconnaissa"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 14, "new_tokens": 36, "tree_h": 3.9, "tree_w": 8, "tree_size": 16, "t0": 0.3429, "t1": 0.3329, "tft": 0.8174, "input_0": 27, "input_1": 17, "min_CLP": -4.09, "draft_iters": 4.9, "mem_use": 34.09, "gen_rate": 2.6, "speed": 3.81, "text": "Why did the college student in S"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.397, "t1": 0.354, "tft": 0.803, "input_0": 32, "input_1": 17, "min_CLP": -3.57, "draft_iters": 5.7, "mem_use": 34.16, "gen_rate": 3.4, "speed": 4.53, "text": "\"Well then, it's a pleasure to m"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.3991, "t1": 0.3555, "tft": 1.0378, "input_0": 34, "input_1": 17, "min_CLP": -3.64, "draft_iters": 5.7, "mem_use": 33.71, "gen_rate": 3.1, "speed": 4.09, "text": "Yes, the ATF has been involved i"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 34, "tree_h": 3.4, "tree_w": 8, "tree_size": 16, "t0": 0.3085, "t1": 0.3285, "tft": 1.1587, "input_0": 29, "input_1": 17, "min_CLP": -4.29, "draft_iters": 4.4, "mem_use": 34.4, "gen_rate": 2.6, "speed": 4.11, "text": "\"oh my gosh, seriously? that\\'s "}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.3982, "t1": 0.3436, "tft": 0.8702, "input_0": 32, "input_1": 17, "min_CLP": -3.48, "draft_iters": 5.7, "mem_use": 33.83, "gen_rate": 3.3, "speed": 4.41, "text": "There is a chance that your mayo"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.4044, "t1": 0.3133, "tft": 1.2865, "input_0": 36, "input_1": 17, "min_CLP": -3.58, "draft_iters": 5.9, "mem_use": 35.05, "gen_rate": 3.8, "speed": 5.25, "text": "Certainly! Here are some recomme"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.415, "t1": 0.313, "tft": 0.7678, "input_0": 35, "input_1": 17, "min_CLP": -3.8, "draft_iters": 6.0, "mem_use": 34.15, "gen_rate": 3.4, "speed": 4.68, "text": "\"No, I won't. I'm just an AI lan"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.55, "t1": 0.3283, "tft": 1.7464, "input_0": 46, "input_1": 17, "min_CLP": -2.97, "draft_iters": 8.0, "mem_use": 35.35, "gen_rate": 5.3, "speed": 6.06, "text": "\"If you're a beginner hiker look"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.43, "t1": 0.333, "tft": 0.9123, "input_0": 32, "input_1": 17, "min_CLP": -3.72, "draft_iters": 6.2, "mem_use": 34.11, "gen_rate": 3.4, "speed": 4.47, "text": "\"Open Assistant: Get ready to ex"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.4367, "t1": 0.3178, "tft": 0.887, "input_0": 35, "input_1": 17, "min_CLP": -3.37, "draft_iters": 6.3, "mem_use": 34.0, "gen_rate": 4.2, "speed": 5.59, "text": "\"Sure, here's a simple diagram t"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 0.565, "t1": 0.2967, "tft": 1.8595, "input_0": 48, "input_1": 17, "min_CLP": -3.2, "draft_iters": 8.3, "mem_use": 36.34, "gen_rate": 5.8, "speed": 6.76, "text": "\"The issue you're experiencing i"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.399, "t1": 0.334, "tft": 0.8608, "input_0": 36, "input_1": 17, "min_CLP": -3.91, "draft_iters": 5.7, "mem_use": 33.7, "gen_rate": 3.4, "speed": 4.63, "text": "Yes, you can use tools like PyPy"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.414, "t1": 0.333, "tft": 0.8159, "input_0": 31, "input_1": 17, "min_CLP": -3.91, "draft_iters": 6.0, "mem_use": 34.24, "gen_rate": 3.6, "speed": 4.81, "text": "The question is not about how th"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.4875, "t1": 0.365, "tft": 1.0087, "input_0": 40, "input_1": 17, "min_CLP": -3.58, "draft_iters": 7.0, "mem_use": 33.87, "gen_rate": 4.4, "speed": 5.13, "text": "This matters because the brownin"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.5217, "t1": 0.335, "tft": 0.961, "input_0": 46, "input_1": 17, "min_CLP": -3.35, "draft_iters": 7.5, "mem_use": 33.71, "gen_rate": 5.7, "speed": 6.62, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4433, "t1": 0.2967, "tft": 1.7071, "input_0": 38, "input_1": 17, "min_CLP": -3.36, "draft_iters": 6.4, "mem_use": 35.78, "gen_rate": 3.8, "speed": 5.1, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.3442, "t1": 0.3342, "tft": 0.942, "input_0": 31, "input_1": 17, "min_CLP": -3.73, "draft_iters": 4.9, "mem_use": 33.67, "gen_rate": 3.0, "speed": 4.41, "text": "\"Yes, a thumb war can be conside"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 7, "tree_size": 16, "t0": 0.4462, "t1": 0.3625, "tft": 1.183, "input_0": 37, "input_1": 17, "min_CLP": -3.73, "draft_iters": 6.4, "mem_use": 33.75, "gen_rate": 4.0, "speed": 4.95, "text": "The third verse of Rick Astley\\'"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.8, "tree_w": 4, "tree_size": 16, "t0": 0.4617, "t1": 0.3, "tft": 2.2261, "input_0": 38, "input_1": 17, "min_CLP": -3.13, "draft_iters": 6.8, "mem_use": 37.01, "gen_rate": 5.3, "speed": 6.97, "text": "As of my last knowledge update i"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.4263, "t1": 0.3238, "tft": 1.3733, "input_0": 36, "input_1": 17, "min_CLP": -3.82, "draft_iters": 6.2, "mem_use": 35.01, "gen_rate": 4.4, "speed": 5.83, "text": "I apologize for any confusion. A"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.5157, "t1": 0.3457, "tft": 0.8707, "input_0": 42, "input_1": 17, "min_CLP": -3.81, "draft_iters": 7.4, "mem_use": 33.97, "gen_rate": 4.7, "speed": 5.47, "text": "Sure, there are many resources a"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.479, "t1": 0.346, "tft": 1.0856, "input_0": 39, "input_1": 17, "min_CLP": -3.35, "draft_iters": 6.9, "mem_use": 33.94, "gen_rate": 3.3, "speed": 4.0, "text": "In the United States, committing"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.391, "t1": 0.332, "tft": 1.2274, "input_0": 34, "input_1": 17, "min_CLP": -3.48, "draft_iters": 5.6, "mem_use": 33.71, "gen_rate": 3.6, "speed": 4.98, "text": "The theory of sexual selection, "}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.4275, "t1": 0.3163, "tft": 1.1828, "input_0": 35, "input_1": 17, "min_CLP": -3.81, "draft_iters": 6.2, "mem_use": 34.52, "gen_rate": 4.5, "speed": 6.04, "text": "Sure thing! Here is an ASCII dra"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 28, "tree_h": 10.3, "tree_w": 3, "tree_size": 16, "t0": 0.7633, "t1": 0.3133, "tft": 1.6605, "input_0": 52, "input_1": 17, "min_CLP": -3.93, "draft_iters": 11.3, "mem_use": 34.54, "gen_rate": 9.3, "speed": 8.64, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.52, "t1": 0.3033, "tft": 2.8028, "input_0": 42, "input_1": 17, "min_CLP": -3.1, "draft_iters": 7.7, "mem_use": 37.04, "gen_rate": 5.3, "speed": 6.46, "text": "\"Sure, here's a shortened versio"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.8, "tree_w": 4, "tree_size": 16, "t0": 0.7275, "t1": 0.315, "tft": 0.8035, "input_0": 42, "input_1": 17, "min_CLP": -4.06, "draft_iters": 10.8, "mem_use": 33.72, "gen_rate": 10.0, "speed": 9.6, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.3682, "t1": 0.3227, "tft": 0.9366, "input_0": 34, "input_1": 17, "min_CLP": -3.58, "draft_iters": 5.3, "mem_use": 34.28, "gen_rate": 3.0, "speed": 4.35, "text": "Berlin is known for its creative"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.7, "tree_w": 3, "tree_size": 16, "t0": 0.6714, "t1": 0.3471, "tft": 0.9, "input_0": 46, "input_1": 17, "min_CLP": -2.86, "draft_iters": 9.7, "mem_use": 33.75, "gen_rate": 5.0, "speed": 4.91, "text": "Sure, here\\'s a Python script th"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.1, "t1": 0.315, "tft": 1.7881, "input_0": 55, "input_1": 17, "min_CLP": -2.29, "draft_iters": 16.5, "mem_use": 36.27, "gen_rate": 16.5, "speed": 11.62, "text": "## Vegetarian\\n Sausage, Peppers"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.3958, "t1": 0.3358, "tft": 0.8104, "input_0": 32, "input_1": 17, "min_CLP": -3.49, "draft_iters": 5.7, "mem_use": 33.67, "gen_rate": 3.0, "speed": 4.11, "text": "The task requires me to provide "}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.532, "t1": 0.302, "tft": 2.4795, "input_0": 43, "input_1": 17, "min_CLP": -3.08, "draft_iters": 7.8, "mem_use": 35.95, "gen_rate": 6.4, "speed": 7.66, "text": "Here are some steps that the own"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.41, "t1": 0.3256, "tft": 0.805, "input_0": 36, "input_1": 17, "min_CLP": -3.4, "draft_iters": 5.9, "mem_use": 33.68, "gen_rate": 3.6, "speed": 4.83, "text": "As an AI assistant, I am here to"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 5.4, "tree_w": 6, "tree_size": 16, "t0": 0.4458, "t1": 0.3258, "tft": 0.8959, "input_0": 35, "input_1": 17, "min_CLP": -4.14, "draft_iters": 6.4, "mem_use": 33.66, "gen_rate": 2.7, "speed": 3.45, "text": "\u300c\u6211\u4eca\u5929\u65e9\u4e0a\u5403\u4e86\u65e9\u9910\u3002\u300d\\n<|im_start|>user\\n"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.614, "t1": 0.308, "tft": 0.8461, "input_0": 43, "input_1": 17, "min_CLP": -3.19, "draft_iters": 9.0, "mem_use": 33.82, "gen_rate": 6.6, "speed": 7.16, "text": "\"Sure, I'd be happy to share an "}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.435, "t1": 0.3412, "tft": 1.5737, "input_0": 38, "input_1": 17, "min_CLP": -3.57, "draft_iters": 6.2, "mem_use": 34.87, "gen_rate": 4.0, "speed": 5.16, "text": "In the 1950s, the quality of lif"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 9.6, "tree_w": 5, "tree_size": 16, "t0": 0.726, "t1": 0.372, "tft": 0.8331, "input_0": 42, "input_1": 17, "min_CLP": -3.85, "draft_iters": 10.6, "mem_use": 33.77, "gen_rate": 8.8, "speed": 7.99, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.5155, "t1": 0.3555, "tft": 0.8247, "input_0": 37, "input_1": 17, "min_CLP": -3.42, "draft_iters": 7.5, "mem_use": 33.97, "gen_rate": 3.1, "speed": 3.55, "text": "In reStructuredText (rst), to cr"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.436, "t1": 0.342, "tft": 1.0197, "input_0": 36, "input_1": 17, "min_CLP": -3.58, "draft_iters": 6.3, "mem_use": 34.31, "gen_rate": 3.2, "speed": 4.12, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.4933, "t1": 0.3667, "tft": 1.0036, "input_0": 43, "input_1": 17, "min_CLP": -3.61, "draft_iters": 7.0, "mem_use": 33.86, "gen_rate": 4.0, "speed": 4.66, "text": "\"I'm a goddess of love, beauty, "}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.3, "tree_w": 3, "tree_size": 16, "t0": 0.6383, "t1": 0.3517, "tft": 1.4346, "input_0": 45, "input_1": 17, "min_CLP": -2.74, "draft_iters": 9.3, "mem_use": 35.07, "gen_rate": 6.7, "speed": 6.74, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.4944, "t1": 0.3622, "tft": 0.7729, "input_0": 36, "input_1": 17, "min_CLP": -3.45, "draft_iters": 7.1, "mem_use": 33.75, "gen_rate": 3.8, "speed": 4.41, "text": "As a helpful assistant, I must r"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 0.5933, "t1": 0.33, "tft": 1.2889, "input_0": 44, "input_1": 17, "min_CLP": -3.08, "draft_iters": 8.7, "mem_use": 34.59, "gen_rate": 5.5, "speed": 5.96, "text": "\"Microwave ovens became a common"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.5388, "t1": 0.3637, "tft": 0.9265, "input_0": 39, "input_1": 17, "min_CLP": -3.35, "draft_iters": 7.8, "mem_use": 33.86, "gen_rate": 4.6, "speed": 5.13, "text": "[Answer] Pros and Cons of Loweri"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.0, "tree_w": 3, "tree_size": 16, "t0": 0.8225, "t1": 0.365, "tft": 1.0419, "input_0": 49, "input_1": 17, "min_CLP": -3.7, "draft_iters": 12.0, "mem_use": 33.69, "gen_rate": 9.5, "speed": 8.01, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.5014, "t1": 0.3143, "tft": 2.8252, "input_0": 42, "input_1": 17, "min_CLP": -3.14, "draft_iters": 7.4, "mem_use": 37.98, "gen_rate": 4.7, "speed": 5.77, "text": "\"If you rejected the offer to dr"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 0.5943, "t1": 0.3714, "tft": 0.801, "input_0": 43, "input_1": 17, "min_CLP": -3.06, "draft_iters": 8.6, "mem_use": 33.99, "gen_rate": 4.6, "speed": 4.74, "text": "When approaching a technical pro"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.1, "tree_w": 5, "tree_size": 16, "t0": 0.5571, "t1": 0.3414, "tft": 1.6371, "input_0": 41, "input_1": 17, "min_CLP": -3.39, "draft_iters": 8.1, "mem_use": 34.86, "gen_rate": 5.6, "speed": 6.19, "text": "If we assume that the journey ar"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.384, "t1": 0.307, "tft": 1.7061, "input_0": 35, "input_1": 17, "min_CLP": -3.63, "draft_iters": 5.6, "mem_use": 36.14, "gen_rate": 3.2, "speed": 4.62, "text": "To prevent spiders from spawning"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.5, "tree_w": 6, "tree_size": 16, "t0": 0.454, "t1": 0.358, "tft": 0.9934, "input_0": 33, "input_1": 17, "min_CLP": -4.01, "draft_iters": 6.5, "mem_use": 33.97, "gen_rate": 3.4, "speed": 4.2, "text": "\"What do you call a broke colleg"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.5537, "t1": 0.3563, "tft": 0.8975, "input_0": 42, "input_1": 17, "min_CLP": -3.62, "draft_iters": 8.0, "mem_use": 34.01, "gen_rate": 4.1, "speed": 4.52, "text": "\"You're welcome! I'm here to hel"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 5, "tree_size": 16, "t0": 0.5286, "t1": 0.3614, "tft": 1.285, "input_0": 41, "input_1": 17, "min_CLP": -3.14, "draft_iters": 7.7, "mem_use": 34.48, "gen_rate": 5.0, "speed": 5.62, "text": "Certainly! There are several 3D "}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 3, "tree_size": 16, "t0": 0.815, "t1": 0.3525, "tft": 1.4209, "input_0": 45, "input_1": 17, "min_CLP": -3.51, "draft_iters": 12.0, "mem_use": 33.99, "gen_rate": 8.0, "speed": 6.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.4089, "t1": 0.3389, "tft": 1.2451, "input_0": 36, "input_1": 17, "min_CLP": -3.84, "draft_iters": 5.9, "mem_use": 34.67, "gen_rate": 3.6, "speed": 4.76, "text": "The transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.615, "t1": 0.3633, "tft": 0.819, "input_0": 38, "input_1": 17, "min_CLP": -3.32, "draft_iters": 9.0, "mem_use": 34.01, "gen_rate": 5.5, "speed": 5.63, "text": "\"Sure, here's a text that would "}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4429, "t1": 0.3657, "tft": 0.7983, "input_0": 32, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.4, "mem_use": 33.74, "gen_rate": 4.7, "speed": 5.82, "text": "Pieces of a reinforcement learni"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 0.9667, "t1": 0.3667, "tft": 0.8348, "input_0": 49, "input_1": 17, "min_CLP": -3.52, "draft_iters": 14.3, "mem_use": 33.7, "gen_rate": 13.3, "speed": 10.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 22, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 0.5867, "t1": 0.3133, "tft": 2.6294, "input_0": 49, "input_1": 17, "min_CLP": -3.22, "draft_iters": 8.7, "mem_use": 37.96, "gen_rate": 7.3, "speed": 8.16, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.485, "t1": 0.3475, "tft": 0.9154, "input_0": 42, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.0, "mem_use": 33.84, "gen_rate": 4.6, "speed": 5.55, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.49, "t1": 0.3333, "tft": 1.8015, "input_0": 37, "input_1": 17, "min_CLP": -3.42, "draft_iters": 7.2, "mem_use": 35.36, "gen_rate": 5.5, "speed": 6.66, "text": "While carbon crystals, such as d"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.528, "t1": 0.335, "tft": 1.3397, "input_0": 41, "input_1": 17, "min_CLP": -3.39, "draft_iters": 7.7, "mem_use": 35.13, "gen_rate": 3.3, "speed": 3.83, "text": "The \"chkdsk\" command will automa"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.764, "t1": 0.358, "tft": 0.8157, "input_0": 54, "input_1": 17, "min_CLP": -2.96, "draft_iters": 11.0, "mem_use": 33.97, "gen_rate": 6.6, "speed": 5.89, "text": "To approach this problem using c"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.4256, "t1": 0.3589, "tft": 0.9261, "input_0": 32, "input_1": 17, "min_CLP": -3.59, "draft_iters": 6.1, "mem_use": 33.78, "gen_rate": 4.1, "speed": 5.25, "text": "\"I'm sorry, but I cannot provide"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 10.8, "tree_w": 4, "tree_size": 16, "t0": 0.8, "t1": 0.3525, "tft": 0.941, "input_0": 44, "input_1": 17, "min_CLP": -3.8, "draft_iters": 11.8, "mem_use": 33.76, "gen_rate": 10.8, "speed": 9.34, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.55, "t1": 0.34, "tft": 1.3897, "input_0": 44, "input_1": 17, "min_CLP": -3.09, "draft_iters": 8.0, "mem_use": 34.76, "gen_rate": 6.8, "speed": 7.66, "text": "As an AI language model, I can d"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.4722, "t1": 0.3678, "tft": 0.8311, "input_0": 33, "input_1": 17, "min_CLP": -3.61, "draft_iters": 6.8, "mem_use": 34.09, "gen_rate": 3.8, "speed": 4.5, "text": "Q: What is time?\\nA:\\n\\nTime, as"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 11.3, "tree_w": 3, "tree_size": 16, "t0": 0.8329, "t1": 0.3386, "tft": 1.5005, "input_0": 47, "input_1": 17, "min_CLP": -3.48, "draft_iters": 12.3, "mem_use": 35.4, "gen_rate": 5.7, "speed": 4.89, "text": "Here are the feminine words from"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.4378, "t1": 0.3456, "tft": 1.0159, "input_0": 34, "input_1": 17, "min_CLP": -3.43, "draft_iters": 6.3, "mem_use": 34.32, "gen_rate": 3.9, "speed": 4.97, "text": "\"One can draw many conclusions a"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 6.2, "tree_w": 6, "tree_size": 16, "t0": 0.5, "t1": 0.363, "tft": 0.853, "input_0": 34, "input_1": 17, "min_CLP": -3.64, "draft_iters": 7.2, "mem_use": 34.17, "gen_rate": 3.4, "speed": 3.95, "text": "The ATF has been involved in var"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.4286, "t1": 0.3443, "tft": 0.9324, "input_0": 39, "input_1": 17, "min_CLP": -3.31, "draft_iters": 6.1, "mem_use": 33.91, "gen_rate": 4.7, "speed": 6.1, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 1, "tree_size": 16, "t0": 0.93, "t1": 0.3233, "tft": 1.9978, "input_0": 51, "input_1": 17, "min_CLP": -1.98, "draft_iters": 14.0, "mem_use": 36.69, "gen_rate": 14.0, "speed": 11.18, "text": "Chapter 4: The Aftermath\\n\\nWith"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 1, "tree_size": 16, "t0": 0.9367, "t1": 0.3233, "tft": 2.6131, "input_0": 49, "input_1": 17, "min_CLP": -2.31, "draft_iters": 14.0, "mem_use": 36.62, "gen_rate": 14.0, "speed": 11.11, "text": "\"Once upon a time, in the fair c"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 3.5, "tree_w": 8, "tree_size": 16, "t0": 0.3127, "t1": 0.3409, "tft": 0.7482, "input_0": 26, "input_1": 17, "min_CLP": -4.17, "draft_iters": 4.5, "mem_use": 33.7, "gen_rate": 3.4, "speed": 5.13, "text": "In the twilight of the day,\\nA g"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 11.2, "tree_w": 2, "tree_size": 16, "t0": 0.84, "t1": 0.36, "tft": 1.2308, "input_0": 51, "input_1": 17, "min_CLP": -3.03, "draft_iters": 12.2, "mem_use": 34.85, "gen_rate": 10.8, "speed": 9.0, "text": "Certainly, I can add information"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 0.696, "t1": 0.334, "tft": 1.5522, "input_0": 49, "input_1": 17, "min_CLP": -2.94, "draft_iters": 10.2, "mem_use": 35.3, "gen_rate": 6.8, "speed": 6.6, "text": "\"I apologize for any confusion I"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 3, "tree_size": 16, "t0": 0.835, "t1": 0.365, "tft": 0.9408, "input_0": 47, "input_1": 17, "min_CLP": -3.15, "draft_iters": 12.2, "mem_use": 33.68, "gen_rate": 9.2, "speed": 7.71, "text": "\"To normalize a vector, you need"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.417, "t1": 0.35, "tft": 0.8988, "input_0": 32, "input_1": 17, "min_CLP": -4.0, "draft_iters": 6.0, "mem_use": 33.97, "gen_rate": 3.3, "speed": 4.31, "text": "Freyja: I will not. I am not you"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 4, "tree_size": 16, "t0": 0.5917, "t1": 0.3217, "tft": 1.7844, "input_0": 41, "input_1": 17, "min_CLP": -2.82, "draft_iters": 8.7, "mem_use": 35.55, "gen_rate": 5.5, "speed": 6.03, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 8.4, "tree_w": 4, "tree_size": 16, "t0": 0.646, "t1": 0.356, "tft": 0.8642, "input_0": 42, "input_1": 17, "min_CLP": -3.25, "draft_iters": 9.4, "mem_use": 33.91, "gen_rate": 8.6, "speed": 8.59, "text": "The task is asking you to explai"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 0.586, "t1": 0.344, "tft": 1.3807, "input_0": 44, "input_1": 17, "min_CLP": -2.89, "draft_iters": 8.6, "mem_use": 35.25, "gen_rate": 6.6, "speed": 7.11, "text": "\"Certainly, here's a more organi"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.8, "tree_w": 7, "tree_size": 16, "t0": 0.4, "t1": 0.3387, "tft": 0.8252, "input_0": 35, "input_1": 17, "min_CLP": -3.71, "draft_iters": 5.8, "mem_use": 33.71, "gen_rate": 4.0, "speed": 5.41, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 13.0, "tree_w": 1, "tree_size": 16, "t0": 0.9433, "t1": 0.3533, "tft": 0.8192, "input_0": 49, "input_1": 17, "min_CLP": -3.93, "draft_iters": 14.0, "mem_use": 33.72, "gen_rate": 14.0, "speed": 10.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.4612, "t1": 0.3488, "tft": 0.9074, "input_0": 38, "input_1": 17, "min_CLP": -3.34, "draft_iters": 6.6, "mem_use": 34.36, "gen_rate": 4.0, "speed": 4.94, "text": "\"Sure, I can do both! Here's a b"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.4857, "t1": 0.3086, "tft": 1.1494, "input_0": 35, "input_1": 17, "min_CLP": -3.55, "draft_iters": 7.1, "mem_use": 34.59, "gen_rate": 4.7, "speed": 5.95, "text": "Thank you! I apologize for the m"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 0.515, "t1": 0.315, "tft": 1.0101, "input_0": 49, "input_1": 17, "min_CLP": -3.46, "draft_iters": 7.5, "mem_use": 33.7, "gen_rate": 4.5, "speed": 5.44, "text": "The AK-47 is a type of assault r"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.55, "t1": 0.3425, "tft": 0.8237, "input_0": 42, "input_1": 17, "min_CLP": -3.08, "draft_iters": 8.0, "mem_use": 34.04, "gen_rate": 4.6, "speed": 5.18, "text": "\"To copy a directory of files fr"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 3, "tree_size": 16, "t0": 0.7133, "t1": 0.3283, "tft": 1.4291, "input_0": 46, "input_1": 17, "min_CLP": -2.51, "draft_iters": 10.5, "mem_use": 35.42, "gen_rate": 5.7, "speed": 5.44, "text": "1. Statistics modeling is applyi"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.3, "tree_w": 3, "tree_size": 16, "t0": 0.5767, "t1": 0.3683, "tft": 0.8029, "input_0": 42, "input_1": 17, "min_CLP": -3.17, "draft_iters": 8.3, "mem_use": 34.03, "gen_rate": 5.5, "speed": 5.83, "text": "Here are some tips to help you s"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4471, "t1": 0.3529, "tft": 1.2582, "input_0": 39, "input_1": 17, "min_CLP": -3.4, "draft_iters": 6.4, "mem_use": 34.52, "gen_rate": 4.7, "speed": 5.9, "text": "While there is no harm in lettin"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.3436, "t1": 0.3345, "tft": 0.7943, "input_0": 31, "input_1": 17, "min_CLP": -3.93, "draft_iters": 4.9, "mem_use": 34.17, "gen_rate": 3.1, "speed": 4.56, "text": "I see, to make it more personal "}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 7.8, "tree_w": 5, "tree_size": 16, "t0": 0.6067, "t1": 0.3333, "tft": 0.9552, "input_0": 40, "input_1": 17, "min_CLP": -3.6, "draft_iters": 8.8, "mem_use": 34.28, "gen_rate": 7.2, "speed": 7.63, "text": "The output should be in English "}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 19, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.3413, "t1": 0.34, "tft": 0.896, "input_0": 29, "input_1": 17, "min_CLP": -3.76, "draft_iters": 4.9, "mem_use": 33.68, "gen_rate": 2.4, "speed": 3.49, "text": "I am thinking about how to provi"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.4338, "t1": 0.3263, "tft": 0.8331, "input_0": 39, "input_1": 17, "min_CLP": -3.94, "draft_iters": 6.2, "mem_use": 33.69, "gen_rate": 4.2, "speed": 5.61, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.508, "t1": 0.354, "tft": 1.0657, "input_0": 36, "input_1": 17, "min_CLP": -3.55, "draft_iters": 7.4, "mem_use": 34.22, "gen_rate": 6.4, "speed": 7.43, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.4937, "t1": 0.3287, "tft": 0.814, "input_0": 39, "input_1": 17, "min_CLP": -3.13, "draft_iters": 7.1, "mem_use": 33.99, "gen_rate": 4.4, "speed": 5.33, "text": "Certainly! Below is an example o"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 2, "tree_size": 16, "t0": 1.0433, "t1": 0.3733, "tft": 0.8555, "input_0": 54, "input_1": 17, "min_CLP": -3.71, "draft_iters": 15.3, "mem_use": 33.78, "gen_rate": 15.3, "speed": 10.83, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.4111, "t1": 0.3433, "tft": 0.8655, "input_0": 36, "input_1": 17, "min_CLP": -3.27, "draft_iters": 5.9, "mem_use": 33.74, "gen_rate": 3.6, "speed": 4.72, "text": "This is due to several factors t"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.6, "tree_w": 6, "tree_size": 16, "t0": 0.4575, "t1": 0.3588, "tft": 0.8918, "input_0": 35, "input_1": 17, "min_CLP": -3.66, "draft_iters": 6.6, "mem_use": 34.3, "gen_rate": 4.4, "speed": 5.36, "text": "\"The significance of the Windows"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.5, "tree_w": 5, "tree_size": 16, "t0": 0.3791, "t1": 0.3091, "tft": 2.2506, "input_0": 33, "input_1": 17, "min_CLP": -3.57, "draft_iters": 5.5, "mem_use": 37.34, "gen_rate": 3.0, "speed": 4.37, "text": "\"Using your neighbor's gas to he"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.3275, "t1": 0.3017, "tft": 1.8179, "input_0": 29, "input_1": 17, "min_CLP": -3.6, "draft_iters": 4.8, "mem_use": 36.11, "gen_rate": 2.7, "speed": 4.24, "text": "\"I see! It's possible that our p"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.4045, "t1": 0.3136, "tft": 1.0063, "input_0": 33, "input_1": 17, "min_CLP": -3.66, "draft_iters": 5.9, "mem_use": 34.36, "gen_rate": 3.3, "speed": 4.55, "text": "To build a Dyson sphere, a civil"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 10.8, "tree_w": 3, "tree_size": 16, "t0": 0.8, "t1": 0.3525, "tft": 0.8954, "input_0": 45, "input_1": 17, "min_CLP": -3.99, "draft_iters": 11.8, "mem_use": 33.7, "gen_rate": 11.5, "speed": 10.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 28, "tree_h": 3.9, "tree_w": 6, "tree_size": 16, "t0": 0.34, "t1": 0.3344, "tft": 0.8308, "input_0": 31, "input_1": 17, "min_CLP": -3.66, "draft_iters": 4.9, "mem_use": 33.68, "gen_rate": 3.1, "speed": 4.59, "text": "I can speak German. I have learn"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.497, "t1": 0.352, "tft": 0.8641, "input_0": 41, "input_1": 17, "min_CLP": -3.72, "draft_iters": 7.2, "mem_use": 33.89, "gen_rate": 3.3, "speed": 3.88, "text": "Certainly! As a helpful assistan"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.4238, "t1": 0.3437, "tft": 1.3088, "input_0": 35, "input_1": 17, "min_CLP": -3.54, "draft_iters": 6.1, "mem_use": 34.76, "gen_rate": 4.0, "speed": 5.2, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.612, "t1": 0.324, "tft": 1.7792, "input_0": 45, "input_1": 17, "min_CLP": -3.08, "draft_iters": 9.0, "mem_use": 35.35, "gen_rate": 6.8, "speed": 7.27, "text": "Yes, AI image generators like St"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.37, "t1": 0.3445, "tft": 0.841, "input_0": 29, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.3, "mem_use": 33.74, "gen_rate": 3.0, "speed": 4.2, "text": "Sure, here are some haikus for d"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 42, "tree_h": 6.1, "tree_w": 6, "tree_size": 16, "t0": 0.487, "t1": 0.357, "tft": 1.47, "input_0": 33, "input_1": 17, "min_CLP": -3.74, "draft_iters": 7.1, "mem_use": 34.11, "gen_rate": 4.2, "speed": 4.97, "text": "     o\\n     /|\\\\\\n     / \\\\\\n  "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 3, "tree_size": 16, "t0": 0.7667, "t1": 0.3267, "tft": 0.8308, "input_0": 50, "input_1": 17, "min_CLP": -3.83, "draft_iters": 11.3, "mem_use": 33.7, "gen_rate": 11.3, "speed": 10.36, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.48, "t1": 0.35, "tft": 1.103, "input_0": 39, "input_1": 17, "min_CLP": -3.76, "draft_iters": 7.0, "mem_use": 34.05, "gen_rate": 4.7, "speed": 5.68, "text": "Yes, there is a true, most ethic"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.408, "t1": 0.337, "tft": 1.1004, "input_0": 35, "input_1": 17, "min_CLP": -3.36, "draft_iters": 5.9, "mem_use": 33.97, "gen_rate": 3.2, "speed": 4.3, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.395, "t1": 0.3042, "tft": 1.8047, "input_0": 35, "input_1": 17, "min_CLP": -3.6, "draft_iters": 5.8, "mem_use": 36.03, "gen_rate": 2.8, "speed": 3.93, "text": "\"Alright, let's get started! Fir"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.8, "tree_w": 4, "tree_size": 16, "t0": 0.7325, "t1": 0.315, "tft": 0.7835, "input_0": 43, "input_1": 17, "min_CLP": -4.33, "draft_iters": 10.8, "mem_use": 33.86, "gen_rate": 10.2, "speed": 9.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.4757, "t1": 0.3086, "tft": 2.0059, "input_0": 39, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.0, "mem_use": 36.72, "gen_rate": 4.6, "speed": 5.83, "text": "\"I'm sorry, but I cannot fulfill"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.2, "tree_w": 8, "tree_size": 16, "t0": 0.3609, "t1": 0.3418, "tft": 0.8253, "input_0": 31, "input_1": 17, "min_CLP": -3.75, "draft_iters": 5.2, "mem_use": 33.73, "gen_rate": 3.1, "speed": 4.39, "text": "Sure, here is an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.5071, "t1": 0.36, "tft": 1.1624, "input_0": 41, "input_1": 17, "min_CLP": -3.07, "draft_iters": 7.3, "mem_use": 33.69, "gen_rate": 4.7, "speed": 5.44, "text": "\"HTML (Hypertext Markup Language"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.3, "tree_w": 3, "tree_size": 16, "t0": 0.6433, "t1": 0.3533, "tft": 0.839, "input_0": 47, "input_1": 17, "min_CLP": -2.93, "draft_iters": 9.3, "mem_use": 33.71, "gen_rate": 5.7, "speed": 5.7, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 17, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.416, "t1": 0.332, "tft": 0.8506, "input_0": 33, "input_1": 17, "min_CLP": -3.33, "draft_iters": 6.0, "mem_use": 34.08, "gen_rate": 3.4, "speed": 4.57, "text": "The image is protected by copyri"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 0.9667, "t1": 0.3367, "tft": 0.9559, "input_0": 51, "input_1": 17, "min_CLP": -3.24, "draft_iters": 14.3, "mem_use": 33.7, "gen_rate": 13.0, "speed": 10.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.5, "tree_w": 2, "tree_size": 16, "t0": 0.8525, "t1": 0.345, "tft": 1.6543, "input_0": 57, "input_1": 17, "min_CLP": -3.55, "draft_iters": 12.5, "mem_use": 34.76, "gen_rate": 8.0, "speed": 6.68, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.3642, "t1": 0.3283, "tft": 1.0999, "input_0": 31, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.2, "mem_use": 34.47, "gen_rate": 2.7, "speed": 3.85, "text": "Alright, that makes sense. In th"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.3427, "t1": 0.3427, "tft": 0.8162, "input_0": 29, "input_1": 17, "min_CLP": -3.82, "draft_iters": 4.9, "mem_use": 34.31, "gen_rate": 3.0, "speed": 4.38, "text": "\"Ah, but that's the thing, I don"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 14, "new_tokens": 36, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.3671, "t1": 0.3371, "tft": 1.2594, "input_0": 32, "input_1": 17, "min_CLP": -3.59, "draft_iters": 5.3, "mem_use": 35.03, "gen_rate": 2.6, "speed": 3.65, "text": "\"That sounds like a very powerfu"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 30, "tree_h": 3.3, "tree_w": 9, "tree_size": 16, "t0": 0.3023, "t1": 0.3354, "tft": 0.8193, "input_0": 26, "input_1": 17, "min_CLP": -3.9, "draft_iters": 4.3, "mem_use": 33.67, "gen_rate": 2.3, "speed": 3.61, "text": "Here is an ASCII art of a cat:\\n"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.3936, "t1": 0.3382, "tft": 0.8349, "input_0": 34, "input_1": 17, "min_CLP": -3.66, "draft_iters": 5.6, "mem_use": 33.99, "gen_rate": 3.2, "speed": 4.35, "text": "Sure, here are some of the names"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.478, "t1": 0.328, "tft": 1.5515, "input_0": 40, "input_1": 17, "min_CLP": -3.44, "draft_iters": 7.0, "mem_use": 34.74, "gen_rate": 6.8, "speed": 8.44, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.3517, "t1": 0.3275, "tft": 0.9995, "input_0": 31, "input_1": 17, "min_CLP": -3.69, "draft_iters": 5.1, "mem_use": 33.79, "gen_rate": 2.7, "speed": 3.92, "text": "Motion Matching is a computer gr"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.5, "tree_w": 2, "tree_size": 16, "t0": 0.98, "t1": 0.335, "tft": 1.7421, "input_0": 56, "input_1": 17, "min_CLP": -2.14, "draft_iters": 14.5, "mem_use": 35.41, "gen_rate": 9.2, "speed": 7.04, "text": "\"Certainly! Here's an updated ve"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 0.5183, "t1": 0.3517, "tft": 0.8557, "input_0": 40, "input_1": 17, "min_CLP": -3.21, "draft_iters": 7.5, "mem_use": 33.74, "gen_rate": 5.8, "speed": 6.69, "text": "Sure, I can explain how to imple"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.3492, "t1": 0.3392, "tft": 0.8543, "input_0": 27, "input_1": 17, "min_CLP": -4.03, "draft_iters": 5.0, "mem_use": 34.12, "gen_rate": 2.8, "speed": 4.0, "text": "\u300c\u671b\u3080\u300d(nozomu) is the Japanese wor"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.6, "tree_w": 5, "tree_size": 16, "t0": 0.5143, "t1": 0.3157, "tft": 1.8656, "input_0": 41, "input_1": 17, "min_CLP": -3.38, "draft_iters": 7.6, "mem_use": 35.42, "gen_rate": 4.9, "speed": 5.84, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.4062, "t1": 0.3038, "tft": 1.5242, "input_0": 40, "input_1": 17, "min_CLP": -3.61, "draft_iters": 5.9, "mem_use": 35.85, "gen_rate": 4.2, "speed": 5.97, "text": "\"Paul Allen's plane collection i"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.4156, "t1": 0.3156, "tft": 1.5564, "input_0": 38, "input_1": 17, "min_CLP": -3.35, "draft_iters": 6.0, "mem_use": 35.29, "gen_rate": 3.9, "speed": 5.33, "text": "Certainly, here is an example of"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 0.7, "t1": 0.3525, "tft": 0.8979, "input_0": 46, "input_1": 17, "min_CLP": -3.55, "draft_iters": 10.2, "mem_use": 33.77, "gen_rate": 9.0, "speed": 8.56, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.5, "tree_w": 5, "tree_size": 16, "t0": 0.4462, "t1": 0.3425, "tft": 1.106, "input_0": 38, "input_1": 17, "min_CLP": -3.44, "draft_iters": 6.5, "mem_use": 34.4, "gen_rate": 4.0, "speed": 5.07, "text": "As an artificial intelligence la"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 0.5957, "t1": 0.3743, "tft": 1.5936, "input_0": 46, "input_1": 17, "min_CLP": -3.51, "draft_iters": 8.6, "mem_use": 33.8, "gen_rate": 4.9, "speed": 5.01, "text": "The main methods employed by car"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.8, "tree_w": 3, "tree_size": 16, "t0": 0.7325, "t1": 0.3675, "tft": 1.0288, "input_0": 40, "input_1": 17, "min_CLP": -3.69, "draft_iters": 10.8, "mem_use": 33.69, "gen_rate": 8.5, "speed": 7.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.4, "tree_w": 5, "tree_size": 16, "t0": 0.5757, "t1": 0.36, "tft": 1.2258, "input_0": 36, "input_1": 17, "min_CLP": -3.26, "draft_iters": 8.4, "mem_use": 34.52, "gen_rate": 4.6, "speed": 4.88, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 8.1, "tree_w": 4, "tree_size": 16, "t0": 0.625, "t1": 0.3388, "tft": 1.4558, "input_0": 49, "input_1": 17, "min_CLP": -3.3, "draft_iters": 9.1, "mem_use": 35.32, "gen_rate": 5.8, "speed": 5.96, "text": "\"There is no way to completely s"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.3383, "t1": 0.2975, "tft": 2.185, "input_0": 34, "input_1": 17, "min_CLP": -3.65, "draft_iters": 4.9, "mem_use": 36.25, "gen_rate": 3.0, "speed": 4.72, "text": "Multi-track drifting is an inter"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.475, "t1": 0.3213, "tft": 1.6689, "input_0": 41, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.9, "mem_use": 34.83, "gen_rate": 4.2, "speed": 5.34, "text": "\"It is theoretically possible fo"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 12.7, "tree_w": 2, "tree_size": 16, "t0": 0.92, "t1": 0.3333, "tft": 1.6824, "input_0": 49, "input_1": 17, "min_CLP": -3.68, "draft_iters": 13.7, "mem_use": 34.66, "gen_rate": 13.7, "speed": 10.91, "text": "\"My love, you're the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.3, "tree_w": 6, "tree_size": 16, "t0": 0.5011, "t1": 0.3289, "tft": 1.5065, "input_0": 33, "input_1": 17, "min_CLP": -3.73, "draft_iters": 7.3, "mem_use": 34.44, "gen_rate": 3.6, "speed": 4.28, "text": "In Japanese, \"love\" is \"\u611b (ai)\","}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4471, "t1": 0.3343, "tft": 0.8069, "input_0": 41, "input_1": 17, "min_CLP": -3.51, "draft_iters": 6.4, "mem_use": 33.98, "gen_rate": 4.7, "speed": 6.04, "text": "Some of the best universities fo"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.4, "t1": 0.3225, "tft": 0.9567, "input_0": 35, "input_1": 17, "min_CLP": -3.29, "draft_iters": 5.8, "mem_use": 33.67, "gen_rate": 4.0, "speed": 5.53, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.5, "tree_w": 2, "tree_size": 16, "t0": 0.9275, "t1": 0.3475, "tft": 0.8544, "input_0": 53, "input_1": 17, "min_CLP": -2.92, "draft_iters": 13.5, "mem_use": 33.81, "gen_rate": 8.2, "speed": 6.47, "text": "\"Here's a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.0, "tree_w": 5, "tree_size": 16, "t0": 0.545, "t1": 0.3367, "tft": 1.2442, "input_0": 37, "input_1": 17, "min_CLP": -3.64, "draft_iters": 8.0, "mem_use": 34.92, "gen_rate": 5.8, "speed": 6.61, "text": "1. Financial stress: One way to "}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.3918, "t1": 0.3373, "tft": 0.8227, "input_0": 35, "input_1": 17, "min_CLP": -3.42, "draft_iters": 5.6, "mem_use": 33.67, "gen_rate": 3.2, "speed": 4.37, "text": "Hello! I am an AI language model"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.5, "tree_w": 3, "tree_size": 16, "t0": 0.64, "t1": 0.305, "tft": 1.8185, "input_0": 46, "input_1": 17, "min_CLP": -3.09, "draft_iters": 9.5, "mem_use": 36.34, "gen_rate": 8.0, "speed": 8.47, "text": "One example of where you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 0.535, "t1": 0.3325, "tft": 0.7928, "input_0": 46, "input_1": 17, "min_CLP": -3.53, "draft_iters": 7.8, "mem_use": 33.96, "gen_rate": 4.5, "speed": 5.19, "text": "Yes, you are correct. Hairy bitt"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 33, "tree_h": 4.0, "tree_w": 8, "tree_size": 16, "t0": 0.35, "t1": 0.3377, "tft": 0.9213, "input_0": 33, "input_1": 17, "min_CLP": -3.97, "draft_iters": 5.0, "mem_use": 33.75, "gen_rate": 2.5, "speed": 3.69, "text": "The name of the Windows XP defau"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.5575, "t1": 0.31, "tft": 1.8351, "input_0": 41, "input_1": 17, "min_CLP": -3.24, "draft_iters": 8.2, "mem_use": 35.95, "gen_rate": 4.8, "speed": 5.47, "text": "Certainly, here are some open so"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 0.6317, "t1": 0.3633, "tft": 0.8341, "input_0": 44, "input_1": 17, "min_CLP": -3.05, "draft_iters": 9.2, "mem_use": 33.74, "gen_rate": 6.0, "speed": 6.03, "text": "\"To use software defined radio ("}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4362, "t1": 0.32, "tft": 1.3018, "input_0": 37, "input_1": 17, "min_CLP": -3.62, "draft_iters": 6.4, "mem_use": 34.44, "gen_rate": 4.4, "speed": 5.79, "text": "\"No, there is no most ethical re"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 8.2, "tree_w": 3, "tree_size": 16, "t0": 0.623, "t1": 0.33, "tft": 1.6453, "input_0": 39, "input_1": 17, "min_CLP": -4.12, "draft_iters": 9.2, "mem_use": 35.31, "gen_rate": 3.6, "speed": 3.78, "text": "1. m\u00eb (pronounced \"me\")\\n2. mele"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 6, "tree_size": 16, "t0": 0.465, "t1": 0.3225, "tft": 1.0169, "input_0": 40, "input_1": 17, "min_CLP": -3.44, "draft_iters": 6.8, "mem_use": 33.99, "gen_rate": 4.1, "speed": 5.25, "text": "\"Sure, I'd be happy to! Here's a"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.42, "t1": 0.304, "tft": 2.0568, "input_0": 35, "input_1": 17, "min_CLP": -3.41, "draft_iters": 6.2, "mem_use": 36.75, "gen_rate": 3.4, "speed": 4.69, "text": "I apologize for the incorrect in"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.3943, "t1": 0.34, "tft": 0.805, "input_0": 37, "input_1": 17, "min_CLP": -3.62, "draft_iters": 5.7, "mem_use": 33.71, "gen_rate": 4.6, "speed": 6.19, "text": "\"In reStructuredText (rst), you "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 3, "tree_size": 16, "t0": 0.7, "t1": 0.32, "tft": 1.6867, "input_0": 55, "input_1": 17, "min_CLP": -2.91, "draft_iters": 10.3, "mem_use": 35.7, "gen_rate": 5.5, "speed": 5.39, "text": "\"Sure, here's an example code fo"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 3, "tree_size": 16, "t0": 0.7667, "t1": 0.3567, "tft": 1.2787, "input_0": 54, "input_1": 17, "min_CLP": -3.74, "draft_iters": 11.3, "mem_use": 33.69, "gen_rate": 11.0, "speed": 9.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.6, "tree_w": 7, "tree_size": 16, "t0": 0.32, "t1": 0.312, "tft": 0.8034, "input_0": 31, "input_1": 17, "min_CLP": -3.88, "draft_iters": 4.6, "mem_use": 34.14, "gen_rate": 3.3, "speed": 5.23, "text": "\"That's a very difficult questio"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.7, "tree_w": 6, "tree_size": 16, "t0": 0.4483, "t1": 0.31, "tft": 2.927, "input_0": 35, "input_1": 17, "min_CLP": -3.57, "draft_iters": 6.7, "mem_use": 39.27, "gen_rate": 5.7, "speed": 7.45, "text": "\"Yes, I'd be happy to! Here's a "}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.4114, "t1": 0.3214, "tft": 1.2858, "input_0": 32, "input_1": 17, "min_CLP": -3.85, "draft_iters": 6.0, "mem_use": 34.51, "gen_rate": 4.9, "speed": 6.64, "text": "0 A lawyer that works for the go"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.36, "t1": 0.3038, "tft": 1.9314, "input_0": 35, "input_1": 17, "min_CLP": -3.6, "draft_iters": 5.2, "mem_use": 36.37, "gen_rate": 4.0, "speed": 6.04, "text": "As a business professional, it i"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.1, "tree_w": 6, "tree_size": 16, "t0": 0.3522, "t1": 0.3178, "tft": 1.2405, "input_0": 33, "input_1": 17, "min_CLP": -3.65, "draft_iters": 5.1, "mem_use": 34.74, "gen_rate": 3.6, "speed": 5.3, "text": "1. External factors: If there ar"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 14, "new_tokens": 34, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.3329, "t1": 0.3471, "tft": 0.8155, "input_0": 28, "input_1": 17, "min_CLP": -3.8, "draft_iters": 4.8, "mem_use": 34.02, "gen_rate": 2.4, "speed": 3.57, "text": "```python\\ndef inspirational_mon"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.5229, "t1": 0.3086, "tft": 2.5637, "input_0": 41, "input_1": 17, "min_CLP": -3.07, "draft_iters": 7.7, "mem_use": 36.5, "gen_rate": 5.3, "speed": 6.34, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.4767, "t1": 0.34, "tft": 0.8601, "input_0": 39, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.0, "mem_use": 34.2, "gen_rate": 3.6, "speed": 4.34, "text": "\"To determine the most cost-effe"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.5517, "t1": 0.3083, "tft": 2.1024, "input_0": 45, "input_1": 17, "min_CLP": -3.24, "draft_iters": 8.2, "mem_use": 36.17, "gen_rate": 5.5, "speed": 6.4, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.5033, "t1": 0.3517, "tft": 1.0144, "input_0": 38, "input_1": 17, "min_CLP": -3.22, "draft_iters": 7.3, "mem_use": 33.73, "gen_rate": 5.5, "speed": 6.44, "text": "\"Certainly! Here's an implementa"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 0.8767, "t1": 0.33, "tft": 1.153, "input_0": 59, "input_1": 17, "min_CLP": -3.29, "draft_iters": 13.0, "mem_use": 34.45, "gen_rate": 13.0, "speed": 10.8, "text": "\"The laws for nudity in Wyoming "}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 8.8, "tree_w": 5, "tree_size": 16, "t0": 0.6625, "t1": 0.3325, "tft": 0.856, "input_0": 41, "input_1": 17, "min_CLP": -3.83, "draft_iters": 9.8, "mem_use": 34.17, "gen_rate": 9.0, "speed": 9.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.52, "t1": 0.3475, "tft": 0.8632, "input_0": 41, "input_1": 17, "min_CLP": -3.2, "draft_iters": 7.6, "mem_use": 33.77, "gen_rate": 4.1, "speed": 4.76, "text": "\"To create a smooth Snake game i"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.44, "t1": 0.3143, "tft": 1.2957, "input_0": 38, "input_1": 17, "min_CLP": -3.39, "draft_iters": 6.4, "mem_use": 34.65, "gen_rate": 5.0, "speed": 6.61, "text": "\"It's important to remember that"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 8.1, "tree_w": 4, "tree_size": 16, "t0": 0.6129, "t1": 0.3071, "tft": 2.2345, "input_0": 45, "input_1": 17, "min_CLP": -3.27, "draft_iters": 9.1, "mem_use": 36.25, "gen_rate": 5.4, "speed": 5.88, "text": "Certainly, here is a list of som"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.5129, "t1": 0.3229, "tft": 0.9167, "input_0": 41, "input_1": 17, "min_CLP": -3.43, "draft_iters": 7.6, "mem_use": 33.88, "gen_rate": 5.7, "speed": 6.82, "text": "The total travel time would be 2"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.5, "tree_w": 2, "tree_size": 16, "t0": 0.785, "t1": 0.3575, "tft": 0.9824, "input_0": 59, "input_1": 17, "min_CLP": -3.38, "draft_iters": 11.5, "mem_use": 33.79, "gen_rate": 8.8, "speed": 7.67, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.4291, "t1": 0.3536, "tft": 0.9651, "input_0": 35, "input_1": 17, "min_CLP": -3.53, "draft_iters": 6.2, "mem_use": 33.69, "gen_rate": 3.3, "speed": 4.18, "text": "Yes, I am capable of answering a"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.41, "t1": 0.3025, "tft": 2.5192, "input_0": 39, "input_1": 17, "min_CLP": -3.32, "draft_iters": 6.0, "mem_use": 37.46, "gen_rate": 4.6, "speed": 6.51, "text": "\"TypeScript is a superset of Jav"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 8, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.3775, "t1": 0.32, "tft": 1.0998, "input_0": 35, "input_1": 17, "min_CLP": -3.87, "draft_iters": 5.5, "mem_use": 33.81, "gen_rate": 2.0, "speed": 2.87, "text": "The name of the fourth kid is Mi"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.39, "t1": 0.3229, "tft": 1.2211, "input_0": 30, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.7, "mem_use": 34.84, "gen_rate": 4.6, "speed": 6.41, "text": "[INST] 1. Build a mob grinder. T"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.406, "t1": 0.303, "tft": 1.9257, "input_0": 33, "input_1": 17, "min_CLP": -3.62, "draft_iters": 6.0, "mem_use": 36.61, "gen_rate": 3.2, "speed": 4.5, "text": "It depends on the type of bread "}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.4529, "t1": 0.3471, "tft": 0.7864, "input_0": 39, "input_1": 17, "min_CLP": -3.37, "draft_iters": 6.6, "mem_use": 33.94, "gen_rate": 4.7, "speed": 5.9, "text": "\"Yes, you are on the right track"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 9.2, "tree_w": 4, "tree_size": 16, "t0": 0.682, "t1": 0.314, "tft": 1.1024, "input_0": 40, "input_1": 17, "min_CLP": -3.61, "draft_iters": 10.2, "mem_use": 34.44, "gen_rate": 9.0, "speed": 9.02, "text": "\"You're welcome!\\n[INST] Can you"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.5057, "t1": 0.3214, "tft": 1.9657, "input_0": 44, "input_1": 17, "min_CLP": -2.97, "draft_iters": 7.4, "mem_use": 36.19, "gen_rate": 5.3, "speed": 6.4, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.485, "t1": 0.323, "tft": 1.3832, "input_0": 38, "input_1": 17, "min_CLP": -3.4, "draft_iters": 7.1, "mem_use": 34.57, "gen_rate": 3.4, "speed": 4.2, "text": "The television was invented by a"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.5, "t1": 0.3062, "tft": 2.1246, "input_0": 43, "input_1": 17, "min_CLP": -3.28, "draft_iters": 7.4, "mem_use": 36.89, "gen_rate": 4.1, "speed": 5.13, "text": "By trying these methods, you sho"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.2, "tree_w": 6, "tree_size": 16, "t0": 0.425, "t1": 0.323, "tft": 1.3884, "input_0": 38, "input_1": 17, "min_CLP": -3.57, "draft_iters": 6.2, "mem_use": 35.22, "gen_rate": 3.3, "speed": 4.41, "text": "The multiple days on which Chris"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.5, "tree_w": 6, "tree_size": 16, "t0": 0.3809, "t1": 0.3245, "tft": 1.0548, "input_0": 35, "input_1": 17, "min_CLP": -3.64, "draft_iters": 5.5, "mem_use": 34.26, "gen_rate": 3.1, "speed": 4.37, "text": "\"Oh, you're right! I am an AI an"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.8, "tree_w": 3, "tree_size": 16, "t0": 0.522, "t1": 0.306, "tft": 2.1449, "input_0": 42, "input_1": 17, "min_CLP": -3.18, "draft_iters": 7.8, "mem_use": 36.07, "gen_rate": 6.4, "speed": 7.69, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 0.6225, "t1": 0.3125, "tft": 0.849, "input_0": 38, "input_1": 17, "min_CLP": -3.93, "draft_iters": 9.2, "mem_use": 33.88, "gen_rate": 8.5, "speed": 9.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 31, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 0.57, "t1": 0.3211, "tft": 1.249, "input_0": 38, "input_1": 17, "min_CLP": -3.6, "draft_iters": 8.4, "mem_use": 34.5, "gen_rate": 3.4, "speed": 3.86, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 4.3, "tree_w": 7, "tree_size": 16, "t0": 0.3658, "t1": 0.31, "tft": 1.5397, "input_0": 30, "input_1": 17, "min_CLP": -4.04, "draft_iters": 5.3, "mem_use": 33.97, "gen_rate": 3.0, "speed": 4.44, "text": "\"Oh, you're a broke college stud"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 3, "tree_size": 16, "t0": 0.666, "t1": 0.324, "tft": 0.8039, "input_0": 46, "input_1": 17, "min_CLP": -2.92, "draft_iters": 9.8, "mem_use": 33.99, "gen_rate": 6.4, "speed": 6.47, "text": "The distance to Sagittarius A*, "}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.6, "tree_w": 8, "tree_size": 16, "t0": 0.318, "t1": 0.335, "tft": 1.0233, "input_0": 27, "input_1": 17, "min_CLP": -4.03, "draft_iters": 4.6, "mem_use": 34.37, "gen_rate": 3.3, "speed": 5.05, "text": "Google Authenticator is a mobile"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.4314, "t1": 0.3386, "tft": 1.4602, "input_0": 38, "input_1": 17, "min_CLP": -3.39, "draft_iters": 6.3, "mem_use": 34.15, "gen_rate": 4.9, "speed": 6.3, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.4267, "t1": 0.3411, "tft": 0.8061, "input_0": 36, "input_1": 17, "min_CLP": -3.19, "draft_iters": 6.2, "mem_use": 33.92, "gen_rate": 4.4, "speed": 5.78, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 4, "tree_size": 16, "t0": 0.6925, "t1": 0.35, "tft": 0.9176, "input_0": 43, "input_1": 17, "min_CLP": -4.19, "draft_iters": 10.2, "mem_use": 33.77, "gen_rate": 10.2, "speed": 9.81, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.0, "tree_w": 5, "tree_size": 16, "t0": 0.5467, "t1": 0.34, "tft": 0.8668, "input_0": 42, "input_1": 17, "min_CLP": -3.32, "draft_iters": 8.0, "mem_use": 33.8, "gen_rate": 3.9, "speed": 4.38, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.4562, "t1": 0.35, "tft": 0.8952, "input_0": 37, "input_1": 17, "min_CLP": -3.8, "draft_iters": 6.6, "mem_use": 33.72, "gen_rate": 4.1, "speed": 5.12, "text": "[INST] Write a whitepaper for ou"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.485, "t1": 0.32, "tft": 1.2422, "input_0": 37, "input_1": 17, "min_CLP": -3.26, "draft_iters": 7.2, "mem_use": 34.89, "gen_rate": 5.3, "speed": 6.62, "text": "In that case, you can use your l"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.4762, "t1": 0.3287, "tft": 0.9516, "input_0": 40, "input_1": 17, "min_CLP": -3.27, "draft_iters": 6.9, "mem_use": 33.68, "gen_rate": 4.0, "speed": 4.97, "text": "In Python, the \"@\" symbol has tw"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.4786, "t1": 0.3429, "tft": 1.1465, "input_0": 38, "input_1": 17, "min_CLP": -3.71, "draft_iters": 7.0, "mem_use": 33.69, "gen_rate": 4.6, "speed": 5.55, "text": "ChatGPT is an AI language model "}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.0, "tree_w": 6, "tree_size": 16, "t0": 0.4109, "t1": 0.3364, "tft": 0.9015, "input_0": 31, "input_1": 17, "min_CLP": -3.6, "draft_iters": 6.0, "mem_use": 33.99, "gen_rate": 3.0, "speed": 4.01, "text": "Hello, I am a psychologist and I"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.465, "t1": 0.3325, "tft": 0.813, "input_0": 40, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.8, "mem_use": 33.73, "gen_rate": 4.0, "speed": 5.03, "text": "Certainly! Here\\'s an example of"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.4967, "t1": 0.3233, "tft": 1.3012, "input_0": 39, "input_1": 17, "min_CLP": -3.15, "draft_iters": 7.3, "mem_use": 34.42, "gen_rate": 5.3, "speed": 6.47, "text": "\"Sure, I'd be happy to explain e"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 4.7, "tree_w": 5, "tree_size": 16, "t0": 0.3867, "t1": 0.3017, "tft": 2.2694, "input_0": 36, "input_1": 17, "min_CLP": -3.45, "draft_iters": 5.7, "mem_use": 36.91, "gen_rate": 4.0, "speed": 5.81, "text": "Sure, I can try to understand yo"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.499, "t1": 0.341, "tft": 1.1188, "input_0": 42, "input_1": 17, "min_CLP": -3.24, "draft_iters": 7.2, "mem_use": 34.23, "gen_rate": 3.5, "speed": 4.17, "text": "Decorators and wrapping function"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 37, "tree_h": 3.6, "tree_w": 7, "tree_size": 16, "t0": 0.315, "t1": 0.3183, "tft": 1.3138, "input_0": 26, "input_1": 17, "min_CLP": -3.93, "draft_iters": 4.6, "mem_use": 35.34, "gen_rate": 3.1, "speed": 4.87, "text": "That\\'s not how it works. You do"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 17, "tree_h": 6.1, "tree_w": 7, "tree_size": 16, "t0": 0.4844, "t1": 0.3467, "tft": 1.318, "input_0": 35, "input_1": 17, "min_CLP": -3.94, "draft_iters": 7.1, "mem_use": 34.22, "gen_rate": 1.9, "speed": 2.27, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.0, "tree_w": 3, "tree_size": 16, "t0": 0.6038, "t1": 0.3112, "tft": 2.2988, "input_0": 44, "input_1": 17, "min_CLP": -3.07, "draft_iters": 9.0, "mem_use": 37.09, "gen_rate": 4.5, "speed": 4.91, "text": "Sure, here are some simple code "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 3, "tree_size": 16, "t0": 0.5717, "t1": 0.3533, "tft": 5.2335, "input_0": 44, "input_1": 17, "min_CLP": -2.93, "draft_iters": 8.5, "mem_use": 43.09, "gen_rate": 5.5, "speed": 5.96, "text": "\"Certainly! Here's an example of"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.6, "tree_w": 4, "tree_size": 16, "t0": 0.6457, "t1": 0.3286, "tft": 1.717, "input_0": 42, "input_1": 17, "min_CLP": -3.3, "draft_iters": 9.6, "mem_use": 35.45, "gen_rate": 4.9, "speed": 4.97, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 0.5433, "t1": 0.365, "tft": 0.771, "input_0": 45, "input_1": 17, "min_CLP": -3.22, "draft_iters": 7.8, "mem_use": 33.73, "gen_rate": 5.8, "speed": 6.42, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.5, "tree_w": 4, "tree_size": 16, "t0": 0.71, "t1": 0.33, "tft": 0.9345, "input_0": 39, "input_1": 17, "min_CLP": -3.32, "draft_iters": 10.5, "mem_use": 33.85, "gen_rate": 9.2, "speed": 8.89, "text": "[INST] ### Instruction:\\nIn Type"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.4856, "t1": 0.3144, "tft": 2.011, "input_0": 34, "input_1": 17, "min_CLP": -3.37, "draft_iters": 7.2, "mem_use": 36.62, "gen_rate": 3.7, "speed": 4.58, "text": "Sure! I can help you come up wit"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.4862, "t1": 0.355, "tft": 1.1053, "input_0": 38, "input_1": 17, "min_CLP": -3.66, "draft_iters": 7.0, "mem_use": 33.79, "gen_rate": 4.0, "speed": 4.75, "text": "In 1950, the world was quite dif"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 0.5471, "t1": 0.3114, "tft": 2.8842, "input_0": 48, "input_1": 17, "min_CLP": -3.01, "draft_iters": 8.1, "mem_use": 38.76, "gen_rate": 5.0, "speed": 5.82, "text": "\"Creating your own stable diffus"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.5, "tree_w": 5, "tree_size": 16, "t0": 0.5817, "t1": 0.33, "tft": 0.7664, "input_0": 41, "input_1": 17, "min_CLP": -3.61, "draft_iters": 8.5, "mem_use": 34.13, "gen_rate": 6.2, "speed": 6.79, "text": "The order is: 1. Casing, 2. Moth"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.425, "t1": 0.3383, "tft": 0.942, "input_0": 38, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.2, "mem_use": 33.98, "gen_rate": 5.3, "speed": 6.98, "text": "\"Carnegie Mellon's robotics prog"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.4, "tree_w": 7, "tree_size": 16, "t0": 0.3713, "t1": 0.3325, "tft": 0.9028, "input_0": 34, "input_1": 17, "min_CLP": -3.88, "draft_iters": 5.4, "mem_use": 34.04, "gen_rate": 4.5, "speed": 6.37, "text": "I will be more free, more honest"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 4, "tree_size": 16, "t0": 0.652, "t1": 0.318, "tft": 1.4721, "input_0": 50, "input_1": 17, "min_CLP": -3.18, "draft_iters": 9.6, "mem_use": 35.39, "gen_rate": 6.6, "speed": 6.79, "text": "The primary components of a PC t"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 7.4, "tree_w": 4, "tree_size": 16, "t0": 0.578, "t1": 0.359, "tft": 0.829, "input_0": 40, "input_1": 17, "min_CLP": -3.41, "draft_iters": 8.4, "mem_use": 34.11, "gen_rate": 3.5, "speed": 3.74, "text": "Yes, it is true that the US Nati"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.4767, "t1": 0.3508, "tft": 0.9479, "input_0": 37, "input_1": 17, "min_CLP": -3.34, "draft_iters": 6.9, "mem_use": 34.28, "gen_rate": 2.8, "speed": 3.33, "text": "Here is a recipe you can try usi"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.486, "t1": 0.349, "tft": 0.976, "input_0": 38, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.1, "mem_use": 34.34, "gen_rate": 3.5, "speed": 4.19, "text": "One way to see the stars more cl"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.4155, "t1": 0.3055, "tft": 1.9377, "input_0": 39, "input_1": 17, "min_CLP": -3.4, "draft_iters": 6.1, "mem_use": 36.27, "gen_rate": 3.0, "speed": 4.16, "text": "Here are some YouTube channels t"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.0, "tree_w": 4, "tree_size": 16, "t0": 0.7367, "t1": 0.3233, "tft": 0.8026, "input_0": 39, "input_1": 17, "min_CLP": -4.06, "draft_iters": 11.0, "mem_use": 33.69, "gen_rate": 10.7, "speed": 10.06, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.7, "tree_w": 3, "tree_size": 16, "t0": 0.67, "t1": 0.36, "tft": 0.8773, "input_0": 46, "input_1": 17, "min_CLP": -2.9, "draft_iters": 9.7, "mem_use": 33.83, "gen_rate": 4.9, "speed": 4.71, "text": "Given two matrices A and B which"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 37, "tree_h": 4.0, "tree_w": 6, "tree_size": 16, "t0": 0.3442, "t1": 0.3125, "tft": 1.4364, "input_0": 31, "input_1": 17, "min_CLP": -3.73, "draft_iters": 5.0, "mem_use": 35.26, "gen_rate": 3.1, "speed": 4.7, "text": "\"Statistical modeling, it's the "}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.13, "t1": 0.325, "tft": 2.686, "input_0": 66, "input_1": 17, "min_CLP": -2.89, "draft_iters": 17.0, "mem_use": 36.43, "gen_rate": 17.0, "speed": 11.68, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 4.0, "tree_w": 6, "tree_size": 16, "t0": 0.34, "t1": 0.28, "tft": 1.1409, "input_0": 35, "input_1": 17, "min_CLP": -3.89, "draft_iters": 5.0, "mem_use": 33.67, "gen_rate": 4.0, "speed": 6.38, "text": "The current date is [insert curr"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.4956, "t1": 0.3411, "tft": 1.292, "input_0": 42, "input_1": 17, "min_CLP": -3.41, "draft_iters": 7.2, "mem_use": 35.14, "gen_rate": 3.8, "speed": 4.52, "text": "\"Yes, that's a great approach as"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 36, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.3423, "t1": 0.3385, "tft": 0.8325, "input_0": 32, "input_1": 17, "min_CLP": -3.8, "draft_iters": 4.9, "mem_use": 34.04, "gen_rate": 2.8, "speed": 4.07, "text": "\"Hey, that's so not true! Techno"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.6, "tree_w": 3, "tree_size": 16, "t0": 0.588, "t1": 0.358, "tft": 0.9515, "input_0": 47, "input_1": 17, "min_CLP": -3.17, "draft_iters": 8.6, "mem_use": 33.73, "gen_rate": 6.4, "speed": 6.77, "text": "Variance is a statistical measur"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.5033, "t1": 0.36, "tft": 0.8414, "input_0": 37, "input_1": 17, "min_CLP": -3.14, "draft_iters": 7.2, "mem_use": 34.08, "gen_rate": 3.8, "speed": 4.38, "text": "\"Sure! I'd be happy to help you "}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 0.582, "t1": 0.324, "tft": 0.8917, "input_0": 43, "input_1": 17, "min_CLP": -3.43, "draft_iters": 8.6, "mem_use": 33.67, "gen_rate": 6.4, "speed": 7.07, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.6, "tree_w": 5, "tree_size": 16, "t0": 0.5122, "t1": 0.3333, "tft": 1.2514, "input_0": 40, "input_1": 17, "min_CLP": -3.29, "draft_iters": 7.6, "mem_use": 34.99, "gen_rate": 3.8, "speed": 4.46, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.6, "tree_w": 3, "tree_size": 16, "t0": 0.7214, "t1": 0.3657, "tft": 0.8693, "input_0": 43, "input_1": 17, "min_CLP": -2.96, "draft_iters": 10.6, "mem_use": 33.86, "gen_rate": 5.0, "speed": 4.59, "text": " Bob has two sons, John and Jay."}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.4, "tree_w": 3, "tree_size": 16, "t0": 0.772, "t1": 0.334, "tft": 0.7947, "input_0": 51, "input_1": 17, "min_CLP": -3.1, "draft_iters": 11.4, "mem_use": 34.24, "gen_rate": 6.8, "speed": 6.17, "text": "The oceans in the world are:\\n1."}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 4.5, "tree_w": 5, "tree_size": 16, "t0": 0.378, "t1": 0.323, "tft": 1.0484, "input_0": 35, "input_1": 17, "min_CLP": -3.4, "draft_iters": 5.5, "mem_use": 34.48, "gen_rate": 3.7, "speed": 5.28, "text": "One way to get started is to res"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.3, "tree_w": 3, "tree_size": 16, "t0": 0.7043, "t1": 0.3471, "tft": 0.9828, "input_0": 44, "input_1": 17, "min_CLP": -2.92, "draft_iters": 10.3, "mem_use": 33.9, "gen_rate": 5.4, "speed": 5.18, "text": "# Import the necessary libraries"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4386, "t1": 0.3314, "tft": 1.3883, "input_0": 34, "input_1": 17, "min_CLP": -3.4, "draft_iters": 6.4, "mem_use": 34.99, "gen_rate": 4.7, "speed": 6.12, "text": "A DLL (Dynamic Link Library) is "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.3914, "t1": 0.3271, "tft": 0.9155, "input_0": 33, "input_1": 17, "min_CLP": -3.59, "draft_iters": 5.7, "mem_use": 34.14, "gen_rate": 5.1, "speed": 7.16, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.7, "tree_w": 7, "tree_size": 16, "t0": 0.3282, "t1": 0.3382, "tft": 0.8891, "input_0": 31, "input_1": 17, "min_CLP": -4.04, "draft_iters": 4.7, "mem_use": 33.68, "gen_rate": 2.9, "speed": 4.35, "text": "The Infinite Banking Concept, al"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 19, "tree_h": 4.2, "tree_w": 6, "tree_size": 16, "t0": 0.36, "t1": 0.314, "tft": 0.849, "input_0": 33, "input_1": 17, "min_CLP": -3.71, "draft_iters": 5.2, "mem_use": 33.79, "gen_rate": 3.8, "speed": 5.66, "text": "def test_cypress_docker_screensh"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.7, "tree_w": 6, "tree_size": 16, "t0": 0.4567, "t1": 0.3367, "tft": 0.8191, "input_0": 32, "input_1": 17, "min_CLP": -3.97, "draft_iters": 6.7, "mem_use": 33.94, "gen_rate": 5.3, "speed": 6.74, "text": "They are not on a higher moral l"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 1, "tree_size": 16, "t0": 0.9833, "t1": 0.3433, "tft": 1.1045, "input_0": 54, "input_1": 17, "min_CLP": -2.72, "draft_iters": 14.7, "mem_use": 34.45, "gen_rate": 14.7, "speed": 11.03, "text": "I have an almost irrational hatr"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.5017, "t1": 0.325, "tft": 1.3833, "input_0": 40, "input_1": 17, "min_CLP": -3.51, "draft_iters": 7.3, "mem_use": 35.29, "gen_rate": 5.5, "speed": 6.66, "text": "\"Certainly, I'd be happy to help"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.3, "tree_w": 4, "tree_size": 16, "t0": 0.4957, "t1": 0.3086, "tft": 1.7069, "input_0": 41, "input_1": 17, "min_CLP": -3.1, "draft_iters": 7.3, "mem_use": 35.82, "gen_rate": 5.3, "speed": 6.57, "text": "There are several languages that"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.7, "tree_w": 5, "tree_size": 16, "t0": 0.3933, "t1": 0.3311, "tft": 0.8618, "input_0": 36, "input_1": 17, "min_CLP": -3.41, "draft_iters": 5.7, "mem_use": 34.28, "gen_rate": 3.8, "speed": 5.22, "text": "All of the AI tools for 2D anima"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.464, "t1": 0.351, "tft": 0.8555, "input_0": 37, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.7, "mem_use": 34.14, "gen_rate": 3.3, "speed": 4.07, "text": "That is because I am an AI, and "}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.4367, "t1": 0.3356, "tft": 0.9067, "input_0": 37, "input_1": 17, "min_CLP": -3.6, "draft_iters": 6.3, "mem_use": 34.36, "gen_rate": 3.9, "speed": 5.03, "text": "\"I can understand why you might "}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 0.5337, "t1": 0.335, "tft": 1.4219, "input_0": 45, "input_1": 17, "min_CLP": -3.4, "draft_iters": 7.8, "mem_use": 34.37, "gen_rate": 4.2, "speed": 4.91, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 36, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.3977, "t1": 0.3615, "tft": 0.8647, "input_0": 34, "input_1": 17, "min_CLP": -3.74, "draft_iters": 5.7, "mem_use": 33.79, "gen_rate": 2.8, "speed": 3.65, "text": "\"Sure, I'll give it a try!\\n\\nNa"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.5333, "t1": 0.33, "tft": 1.6171, "input_0": 43, "input_1": 17, "min_CLP": -3.43, "draft_iters": 7.8, "mem_use": 35.45, "gen_rate": 5.3, "speed": 6.17, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.0, "tree_w": 5, "tree_size": 16, "t0": 0.4788, "t1": 0.34, "tft": 1.0787, "input_0": 35, "input_1": 17, "min_CLP": -3.97, "draft_iters": 7.0, "mem_use": 33.94, "gen_rate": 4.6, "speed": 5.64, "text": "Hippocentro\\n[INST] What are the"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.0, "tree_w": 4, "tree_size": 16, "t0": 0.68, "t1": 0.3525, "tft": 1.1275, "input_0": 50, "input_1": 17, "min_CLP": -3.94, "draft_iters": 10.0, "mem_use": 33.77, "gen_rate": 9.0, "speed": 8.73, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.3758, "t1": 0.3508, "tft": 0.8783, "input_0": 31, "input_1": 17, "min_CLP": -3.61, "draft_iters": 5.4, "mem_use": 34.25, "gen_rate": 2.7, "speed": 3.67, "text": "\"I am an AI language model, so I"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.3955, "t1": 0.3045, "tft": 2.1013, "input_0": 34, "input_1": 17, "min_CLP": -3.38, "draft_iters": 5.8, "mem_use": 35.95, "gen_rate": 3.1, "speed": 4.4, "text": "When creating new images, the in"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.1, "tree_w": 7, "tree_size": 16, "t0": 0.356, "t1": 0.34, "tft": 1.4162, "input_0": 33, "input_1": 17, "min_CLP": -3.85, "draft_iters": 5.1, "mem_use": 34.72, "gen_rate": 3.2, "speed": 4.59, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.495, "t1": 0.3312, "tft": 1.4726, "input_0": 38, "input_1": 17, "min_CLP": -3.45, "draft_iters": 7.2, "mem_use": 35.14, "gen_rate": 4.0, "speed": 4.84, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.5, "tree_w": 4, "tree_size": 16, "t0": 0.7775, "t1": 0.33, "tft": 0.8199, "input_0": 39, "input_1": 17, "min_CLP": -4.0, "draft_iters": 11.5, "mem_use": 33.72, "gen_rate": 10.2, "speed": 9.27, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.3, "tree_w": 4, "tree_size": 16, "t0": 0.6217, "t1": 0.3133, "tft": 3.3345, "input_0": 41, "input_1": 17, "min_CLP": -3.11, "draft_iters": 9.3, "mem_use": 38.42, "gen_rate": 6.0, "speed": 6.42, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.54, "t1": 0.326, "tft": 1.262, "input_0": 41, "input_1": 17, "min_CLP": -3.35, "draft_iters": 8.0, "mem_use": 34.85, "gen_rate": 6.4, "speed": 7.38, "text": "To transform other text words or"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.0, "tree_w": 3, "tree_size": 16, "t0": 0.74, "t1": 0.35, "tft": 1.2128, "input_0": 50, "input_1": 17, "min_CLP": -2.79, "draft_iters": 11.0, "mem_use": 34.71, "gen_rate": 6.3, "speed": 5.81, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.562, "t1": 0.336, "tft": 1.4406, "input_0": 44, "input_1": 17, "min_CLP": -3.08, "draft_iters": 8.2, "mem_use": 33.74, "gen_rate": 6.4, "speed": 7.1, "text": "\"## How Adolf Hitler Took Over G"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.4725, "t1": 0.3375, "tft": 1.079, "input_0": 39, "input_1": 17, "min_CLP": -3.68, "draft_iters": 6.9, "mem_use": 34.08, "gen_rate": 5.0, "speed": 6.18, "text": "\"Sure! Here's another one:\\n\\nWh"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4467, "t1": 0.3589, "tft": 0.8132, "input_0": 35, "input_1": 17, "min_CLP": -3.41, "draft_iters": 6.4, "mem_use": 33.7, "gen_rate": 4.3, "speed": 5.37, "text": "There are currently several know"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.1, "tree_w": 6, "tree_size": 16, "t0": 0.4111, "t1": 0.3078, "tft": 2.8764, "input_0": 33, "input_1": 17, "min_CLP": -3.68, "draft_iters": 6.1, "mem_use": 38.48, "gen_rate": 3.7, "speed": 5.1, "text": "I apologize for not fully unders"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.5, "tree_w": 5, "tree_size": 16, "t0": 0.45, "t1": 0.3536, "tft": 1.0215, "input_0": 37, "input_1": 17, "min_CLP": -4.03, "draft_iters": 6.5, "mem_use": 33.78, "gen_rate": 2.9, "speed": 3.62, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.4, "tree_w": 6, "tree_size": 16, "t0": 0.37, "t1": 0.3211, "tft": 3.8351, "input_0": 33, "input_1": 17, "min_CLP": -3.69, "draft_iters": 5.4, "mem_use": 40.68, "gen_rate": 4.0, "speed": 5.78, "text": "Thank you for the explanation an"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 14, "new_tokens": 34, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.3993, "t1": 0.34, "tft": 1.2779, "input_0": 33, "input_1": 17, "min_CLP": -3.72, "draft_iters": 5.8, "mem_use": 34.96, "gen_rate": 2.4, "speed": 3.29, "text": "Spritesla is the first and final"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.4614, "t1": 0.3571, "tft": 0.9237, "input_0": 35, "input_1": 17, "min_CLP": -3.38, "draft_iters": 6.7, "mem_use": 33.81, "gen_rate": 4.6, "speed": 5.59, "text": "The human genome is the complete"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.505, "t1": 0.3713, "tft": 0.8322, "input_0": 41, "input_1": 17, "min_CLP": -3.46, "draft_iters": 7.2, "mem_use": 33.68, "gen_rate": 4.6, "speed": 5.27, "text": "\"Two-factor authentication (2FA)"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.4978, "t1": 0.3678, "tft": 0.8286, "input_0": 35, "input_1": 17, "min_CLP": -3.44, "draft_iters": 7.2, "mem_use": 33.92, "gen_rate": 4.0, "speed": 4.62, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.6217, "t1": 0.3433, "tft": 0.8584, "input_0": 50, "input_1": 17, "min_CLP": -3.49, "draft_iters": 9.0, "mem_use": 34.22, "gen_rate": 6.7, "speed": 6.93, "text": "Here are a few examples of popul"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 3, "tree_size": 16, "t0": 0.688, "t1": 0.312, "tft": 1.7229, "input_0": 51, "input_1": 17, "min_CLP": -2.79, "draft_iters": 10.2, "mem_use": 35.82, "gen_rate": 6.6, "speed": 6.6, "text": "Certainly! Here are some hardwar"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.5171, "t1": 0.3586, "tft": 1.489, "input_0": 41, "input_1": 17, "min_CLP": -3.17, "draft_iters": 7.6, "mem_use": 34.94, "gen_rate": 4.6, "speed": 5.22, "text": "\"The physical characteristics of"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.2, "tree_w": 4, "tree_size": 16, "t0": 0.7625, "t1": 0.35, "tft": 0.8054, "input_0": 44, "input_1": 17, "min_CLP": -3.79, "draft_iters": 11.2, "mem_use": 33.86, "gen_rate": 10.0, "speed": 8.98, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 8.1, "tree_w": 4, "tree_size": 16, "t0": 0.6089, "t1": 0.3178, "tft": 2.0023, "input_0": 38, "input_1": 17, "min_CLP": -3.11, "draft_iters": 9.1, "mem_use": 36.48, "gen_rate": 4.1, "speed": 4.43, "text": "\"Here's the same example with co"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.4671, "t1": 0.3314, "tft": 1.8301, "input_0": 36, "input_1": 17, "min_CLP": -3.78, "draft_iters": 6.9, "mem_use": 34.96, "gen_rate": 4.6, "speed": 5.72, "text": "Lo siento, Linkin Park no tiene "}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 10.2, "tree_w": 4, "tree_size": 16, "t0": 0.7625, "t1": 0.3725, "tft": 0.8065, "input_0": 43, "input_1": 17, "min_CLP": -3.92, "draft_iters": 11.2, "mem_use": 33.7, "gen_rate": 10.5, "speed": 9.26, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 30, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.5271, "t1": 0.3671, "tft": 0.9549, "input_0": 39, "input_1": 17, "min_CLP": -3.0, "draft_iters": 7.6, "mem_use": 33.78, "gen_rate": 4.3, "speed": 4.79, "text": "\"```markdown\\nHere is an example"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.4091, "t1": 0.3491, "tft": 1.3057, "input_0": 34, "input_1": 17, "min_CLP": -3.58, "draft_iters": 5.9, "mem_use": 34.8, "gen_rate": 3.3, "speed": 4.33, "text": "\"I'm a little confused by your r"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.4178, "t1": 0.3178, "tft": 1.7058, "input_0": 34, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.1, "mem_use": 35.75, "gen_rate": 3.9, "speed": 5.29, "text": "You can use the spread operator "}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.4575, "t1": 0.3525, "tft": 0.8701, "input_0": 39, "input_1": 17, "min_CLP": -3.47, "draft_iters": 6.6, "mem_use": 34.3, "gen_rate": 4.0, "speed": 4.96, "text": "\"Sure! Here's a basic training p"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.4, "tree_w": 5, "tree_size": 16, "t0": 0.3778, "t1": 0.3367, "tft": 1.2529, "input_0": 34, "input_1": 17, "min_CLP": -3.28, "draft_iters": 5.4, "mem_use": 34.77, "gen_rate": 3.6, "speed": 4.97, "text": "My assumption that the second ba"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.48, "t1": 0.36, "tft": 0.8189, "input_0": 41, "input_1": 17, "min_CLP": -3.33, "draft_iters": 6.9, "mem_use": 33.69, "gen_rate": 3.7, "speed": 4.35, "text": "JavaScript can be used for both "}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.2, "tree_w": 4, "tree_size": 16, "t0": 0.7575, "t1": 0.355, "tft": 0.9508, "input_0": 37, "input_1": 17, "min_CLP": -3.49, "draft_iters": 11.2, "mem_use": 33.68, "gen_rate": 10.2, "speed": 9.22, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 44, "tree_h": 8.8, "tree_w": 4, "tree_size": 16, "t0": 0.6678, "t1": 0.3644, "tft": 1.1761, "input_0": 45, "input_1": 17, "min_CLP": -3.44, "draft_iters": 9.8, "mem_use": 34.39, "gen_rate": 4.9, "speed": 4.74, "text": "[INST] Give me 5 words that are "}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.6, "tree_w": 7, "tree_size": 16, "t0": 0.385, "t1": 0.365, "tft": 1.0532, "input_0": 29, "input_1": 17, "min_CLP": -4.0, "draft_iters": 5.6, "mem_use": 33.81, "gen_rate": 3.3, "speed": 4.39, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 3.6, "tree_w": 7, "tree_size": 16, "t0": 0.3192, "t1": 0.3425, "tft": 0.7852, "input_0": 30, "input_1": 17, "min_CLP": -3.91, "draft_iters": 4.6, "mem_use": 33.81, "gen_rate": 3.0, "speed": 4.52, "text": "Here\\'s a poem for your Valentin"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.6, "tree_w": 5, "tree_size": 16, "t0": 0.522, "t1": 0.352, "tft": 0.852, "input_0": 39, "input_1": 17, "min_CLP": -3.37, "draft_iters": 7.6, "mem_use": 33.78, "gen_rate": 6.6, "speed": 7.55, "text": "\"I'd be happy to help you with y"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.413, "t1": 0.31, "tft": 2.8294, "input_0": 35, "input_1": 17, "min_CLP": -3.47, "draft_iters": 6.1, "mem_use": 38.53, "gen_rate": 3.2, "speed": 4.42, "text": "\"Thank you for providing the sce"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.5389, "t1": 0.3078, "tft": 2.0018, "input_0": 41, "input_1": 17, "min_CLP": -3.09, "draft_iters": 8.0, "mem_use": 36.19, "gen_rate": 4.3, "speed": 5.12, "text": "Sure! So, Fermat\\'s Last Theorem"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.4, "tree_w": 3, "tree_size": 16, "t0": 0.638, "t1": 0.336, "tft": 1.535, "input_0": 50, "input_1": 17, "min_CLP": -2.95, "draft_iters": 9.4, "mem_use": 34.61, "gen_rate": 7.4, "speed": 7.61, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 4, "tree_size": 16, "t0": 0.4686, "t1": 0.3257, "tft": 1.227, "input_0": 42, "input_1": 17, "min_CLP": -3.3, "draft_iters": 6.9, "mem_use": 34.78, "gen_rate": 4.6, "speed": 5.74, "text": "From polar bears, we can learn a"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.42, "t1": 0.3125, "tft": 1.6593, "input_0": 36, "input_1": 17, "min_CLP": -3.42, "draft_iters": 6.1, "mem_use": 35.82, "gen_rate": 4.1, "speed": 5.63, "text": "Lemon wedges are simply small sl"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 19, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.33, "t1": 0.3225, "tft": 0.9196, "input_0": 30, "input_1": 17, "min_CLP": -3.86, "draft_iters": 4.8, "mem_use": 33.87, "gen_rate": 2.4, "speed": 3.64, "text": "\"[INST] Oh, hi! Sorry I'm late. "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.4325, "t1": 0.3375, "tft": 0.9217, "input_0": 40, "input_1": 17, "min_CLP": -3.47, "draft_iters": 6.2, "mem_use": 33.83, "gen_rate": 4.1, "speed": 5.35, "text": "\"Don't worry, it's okay to feel "}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.4783, "t1": 0.3083, "tft": 1.2272, "input_0": 38, "input_1": 17, "min_CLP": -3.45, "draft_iters": 7.0, "mem_use": 33.71, "gen_rate": 5.7, "speed": 7.21, "text": "`npm init` will create a package"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.5157, "t1": 0.3043, "tft": 1.8313, "input_0": 44, "input_1": 17, "min_CLP": -3.11, "draft_iters": 7.6, "mem_use": 35.28, "gen_rate": 5.3, "speed": 6.45, "text": "There are a few examples of citi"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4375, "t1": 0.3062, "tft": 1.4722, "input_0": 37, "input_1": 17, "min_CLP": -3.59, "draft_iters": 6.4, "mem_use": 34.81, "gen_rate": 4.2, "speed": 5.73, "text": "Freeman Dyson has been known to "}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.435, "t1": 0.315, "tft": 0.8692, "input_0": 40, "input_1": 17, "min_CLP": -3.25, "draft_iters": 6.3, "mem_use": 33.67, "gen_rate": 3.7, "speed": 4.92, "text": "Certainly! I can write code in s"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.5157, "t1": 0.3143, "tft": 1.1763, "input_0": 42, "input_1": 17, "min_CLP": -3.52, "draft_iters": 7.6, "mem_use": 34.41, "gen_rate": 5.0, "speed": 6.01, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 6.2, "tree_w": 6, "tree_size": 16, "t0": 0.4909, "t1": 0.3427, "tft": 1.2493, "input_0": 33, "input_1": 17, "min_CLP": -3.61, "draft_iters": 7.2, "mem_use": 35.0, "gen_rate": 2.9, "speed": 3.48, "text": "\"Sure, here are the full lyrics "}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 7.6, "tree_w": 5, "tree_size": 16, "t0": 0.586, "t1": 0.349, "tft": 1.0828, "input_0": 37, "input_1": 17, "min_CLP": -3.72, "draft_iters": 8.6, "mem_use": 34.03, "gen_rate": 3.6, "speed": 3.86, "text": "1.    Work pressure and job inse"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.405, "t1": 0.3338, "tft": 0.8933, "input_0": 37, "input_1": 17, "min_CLP": -3.54, "draft_iters": 5.9, "mem_use": 33.7, "gen_rate": 4.1, "speed": 5.59, "text": "\"Here's the definition of self-a"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.4478, "t1": 0.3278, "tft": 0.7957, "input_0": 34, "input_1": 17, "min_CLP": -3.53, "draft_iters": 6.6, "mem_use": 34.26, "gen_rate": 4.1, "speed": 5.29, "text": "Tensorflow and PyTorch are both "}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.6, "tree_w": 5, "tree_size": 16, "t0": 0.6486, "t1": 0.3243, "tft": 1.31, "input_0": 45, "input_1": 17, "min_CLP": -3.45, "draft_iters": 9.6, "mem_use": 34.7, "gen_rate": 5.1, "speed": 5.28, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 5.5, "tree_w": 6, "tree_size": 16, "t0": 0.445, "t1": 0.32, "tft": 1.0272, "input_0": 39, "input_1": 17, "min_CLP": -3.71, "draft_iters": 6.5, "mem_use": 34.37, "gen_rate": 3.0, "speed": 3.94, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.13, "t1": 0.32, "tft": 2.7184, "input_0": 59, "input_1": 17, "min_CLP": -2.7, "draft_iters": 17.0, "mem_use": 36.5, "gen_rate": 17.0, "speed": 11.76, "text": "\"L'Hopital's rule is a mathemati"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.4644, "t1": 0.3056, "tft": 2.553, "input_0": 39, "input_1": 17, "min_CLP": -3.52, "draft_iters": 6.9, "mem_use": 38.05, "gen_rate": 3.6, "speed": 4.62, "text": "\"I don't have personal experienc"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.1, "tree_w": 5, "tree_size": 16, "t0": 0.4825, "t1": 0.3038, "tft": 1.307, "input_0": 41, "input_1": 17, "min_CLP": -3.4, "draft_iters": 7.1, "mem_use": 35.07, "gen_rate": 4.0, "speed": 5.09, "text": "\"It's great that you're motivate"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 7.6, "tree_w": 3, "tree_size": 16, "t0": 0.5829, "t1": 0.3271, "tft": 1.4779, "input_0": 41, "input_1": 17, "min_CLP": -3.21, "draft_iters": 8.6, "mem_use": 35.46, "gen_rate": 6.0, "speed": 6.59, "text": "While all the reasons for the ne"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 6.6, "tree_w": 4, "tree_size": 16, "t0": 0.52, "t1": 0.354, "tft": 1.0068, "input_0": 40, "input_1": 17, "min_CLP": -3.48, "draft_iters": 7.6, "mem_use": 33.7, "gen_rate": 6.8, "speed": 7.78, "text": "The main difference between sets"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.4883, "t1": 0.3367, "tft": 1.3845, "input_0": 41, "input_1": 17, "min_CLP": -3.31, "draft_iters": 7.2, "mem_use": 35.03, "gen_rate": 5.5, "speed": 6.67, "text": "To calculate the number of days "}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 8.2, "tree_w": 6, "tree_size": 16, "t0": 0.62, "t1": 0.31, "tft": 0.838, "input_0": 39, "input_1": 17, "min_CLP": -3.95, "draft_iters": 9.2, "mem_use": 33.87, "gen_rate": 8.4, "speed": 9.04, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 5.8, "tree_w": 5, "tree_size": 16, "t0": 0.4717, "t1": 0.3517, "tft": 0.784, "input_0": 38, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.8, "mem_use": 33.75, "gen_rate": 5.8, "speed": 7.08, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4429, "t1": 0.3543, "tft": 1.1167, "input_0": 37, "input_1": 17, "min_CLP": -3.56, "draft_iters": 6.4, "mem_use": 33.74, "gen_rate": 4.7, "speed": 5.92, "text": "To farm experience quickly in Mi"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 25, "tree_h": 4.7, "tree_w": 5, "tree_size": 16, "t0": 0.39, "t1": 0.3233, "tft": 0.8216, "input_0": 37, "input_1": 17, "min_CLP": -3.61, "draft_iters": 5.7, "mem_use": 33.69, "gen_rate": 4.2, "speed": 5.83, "text": "Hello, I am Freyja, the Norse Go"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 15, "tree_h": 9.0, "tree_w": 4, "tree_size": 16, "t0": 0.67, "t1": 0.315, "tft": 1.2548, "input_0": 47, "input_1": 17, "min_CLP": -3.08, "draft_iters": 10.0, "mem_use": 34.95, "gen_rate": 7.5, "speed": 7.63, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.616, "t1": 0.348, "tft": 1.0268, "input_0": 44, "input_1": 17, "min_CLP": -3.39, "draft_iters": 9.0, "mem_use": 34.08, "gen_rate": 6.8, "speed": 7.07, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.2, "tree_w": 3, "tree_size": 16, "t0": 0.5483, "t1": 0.315, "tft": 3.0457, "input_0": 41, "input_1": 17, "min_CLP": -3.0, "draft_iters": 8.2, "mem_use": 39.13, "gen_rate": 6.0, "speed": 6.94, "text": "Yes, the degree of sexual dimorp"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.7, "tree_w": 6, "tree_size": 16, "t0": 0.3929, "t1": 0.32, "tft": 0.772, "input_0": 35, "input_1": 17, "min_CLP": -3.64, "draft_iters": 5.7, "mem_use": 34.21, "gen_rate": 4.6, "speed": 6.39, "text": "Large language models require a "}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.4, "t1": 0.3275, "tft": 0.8579, "input_0": 38, "input_1": 17, "min_CLP": -3.77, "draft_iters": 5.8, "mem_use": 33.78, "gen_rate": 4.2, "speed": 5.87, "text": "\"Sure, here's a joke for you:\\n\\"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.4, "tree_w": 5, "tree_size": 16, "t0": 0.5075, "t1": 0.3387, "tft": 0.7583, "input_0": 41, "input_1": 17, "min_CLP": -3.23, "draft_iters": 7.4, "mem_use": 33.99, "gen_rate": 4.4, "speed": 5.17, "text": "\"Sure, here's a eulogy that capt"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.4056, "t1": 0.3156, "tft": 1.5759, "input_0": 37, "input_1": 17, "min_CLP": -3.41, "draft_iters": 5.9, "mem_use": 35.46, "gen_rate": 3.6, "speed": 4.93, "text": "\"I don't have any specific quest"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.443, "t1": 0.332, "tft": 0.9129, "input_0": 36, "input_1": 17, "min_CLP": -3.65, "draft_iters": 6.4, "mem_use": 33.86, "gen_rate": 3.3, "speed": 4.27, "text": "\"Yes, I am an AI language model "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 10.2, "tree_w": 3, "tree_size": 16, "t0": 0.76, "t1": 0.325, "tft": 0.8653, "input_0": 39, "input_1": 17, "min_CLP": -4.03, "draft_iters": 11.2, "mem_use": 33.84, "gen_rate": 11.0, "speed": 10.17, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.8, "tree_w": 4, "tree_size": 16, "t0": 0.4644, "t1": 0.3344, "tft": 0.9593, "input_0": 38, "input_1": 17, "min_CLP": -3.43, "draft_iters": 6.8, "mem_use": 33.67, "gen_rate": 3.7, "speed": 4.58, "text": "Mars is known for its reddish co"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 16, "new_tokens": 32, "tree_h": 3.4, "tree_w": 10, "tree_size": 16, "t0": 0.3, "t1": 0.3094, "tft": 1.8716, "input_0": 25, "input_1": 17, "min_CLP": -4.25, "draft_iters": 4.4, "mem_use": 35.89, "gen_rate": 2.0, "speed": 3.29, "text": "In Quenya, \"I love you\" can be t"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 4, "tree_size": 16, "t0": 0.515, "t1": 0.3467, "tft": 1.1779, "input_0": 46, "input_1": 17, "min_CLP": -3.49, "draft_iters": 7.5, "mem_use": 33.75, "gen_rate": 5.3, "speed": 6.17, "text": "The book \"Harry Potter and the D"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.4138, "t1": 0.325, "tft": 1.0846, "input_0": 35, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.0, "mem_use": 34.3, "gen_rate": 4.4, "speed": 5.93, "text": "\"The ATF is a law enforcement ag"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 3, "tree_size": 16, "t0": 0.5957, "t1": 0.3814, "tft": 0.8425, "input_0": 42, "input_1": 17, "min_CLP": -3.24, "draft_iters": 8.6, "mem_use": 33.75, "gen_rate": 4.9, "speed": 4.98, "text": "No, there is no known formula th"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.9, "tree_w": 6, "tree_size": 16, "t0": 0.4088, "t1": 0.3325, "tft": 0.8635, "input_0": 36, "input_1": 17, "min_CLP": -3.59, "draft_iters": 5.9, "mem_use": 34.19, "gen_rate": 4.1, "speed": 5.56, "text": "\"I'm happy to help! As a baby si"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 11, "tree_h": 7.0, "tree_w": 4, "tree_size": 16, "t0": 0.5433, "t1": 0.3333, "tft": 0.8786, "input_0": 38, "input_1": 17, "min_CLP": -3.3, "draft_iters": 8.0, "mem_use": 33.87, "gen_rate": 3.7, "speed": 4.21, "text": "Before Canberra, the capital of "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 16.0, "tree_w": 1, "tree_size": 16, "t0": 1.14, "t1": 0.375, "tft": 1.1053, "input_0": 48, "input_1": 17, "min_CLP": -2.11, "draft_iters": 17.0, "mem_use": 34.05, "gen_rate": 17.0, "speed": 11.2, "text": "write a eulogy for my 100 year o"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.4857, "t1": 0.3114, "tft": 1.9871, "input_0": 39, "input_1": 17, "min_CLP": -3.47, "draft_iters": 7.1, "mem_use": 36.27, "gen_rate": 4.9, "speed": 6.1, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.0, "tree_w": 7, "tree_size": 16, "t0": 0.348, "t1": 0.341, "tft": 0.8674, "input_0": 32, "input_1": 17, "min_CLP": -4.02, "draft_iters": 5.0, "mem_use": 33.87, "gen_rate": 3.2, "speed": 4.63, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 13.3, "tree_w": 2, "tree_size": 16, "t0": 0.9567, "t1": 0.3533, "tft": 1.3918, "input_0": 52, "input_1": 17, "min_CLP": -2.39, "draft_iters": 14.3, "mem_use": 35.15, "gen_rate": 14.3, "speed": 10.91, "text": "Let vector A be a vector with it"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.6114, "t1": 0.3286, "tft": 0.9508, "input_0": 45, "input_1": 17, "min_CLP": -3.09, "draft_iters": 9.0, "mem_use": 33.73, "gen_rate": 5.0, "speed": 5.31, "text": "Certainly! Here are some issues "}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.392, "t1": 0.347, "tft": 0.8639, "input_0": 31, "input_1": 17, "min_CLP": -4.01, "draft_iters": 5.6, "mem_use": 33.78, "gen_rate": 3.4, "speed": 4.61, "text": "I am a powerful mage, and I have"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 4, "tree_size": 16, "t0": 0.5817, "t1": 0.3633, "tft": 0.8426, "input_0": 41, "input_1": 17, "min_CLP": -3.09, "draft_iters": 8.5, "mem_use": 33.73, "gen_rate": 5.7, "speed": 6.01, "text": "\"L'Hopital's Rule is a mathemati"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.54, "t1": 0.3383, "tft": 1.0217, "input_0": 41, "input_1": 17, "min_CLP": -3.33, "draft_iters": 7.8, "mem_use": 34.3, "gen_rate": 6.5, "speed": 7.42, "text": "Variance is closely related to s"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.2, "tree_w": 7, "tree_size": 16, "t0": 0.4245, "t1": 0.3391, "tft": 1.2646, "input_0": 29, "input_1": 17, "min_CLP": -3.8, "draft_iters": 6.2, "mem_use": 34.59, "gen_rate": 2.9, "speed": 3.81, "text": "\"Find Your Inner Calm with Hippo"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.3, "tree_w": 6, "tree_size": 16, "t0": 0.4333, "t1": 0.3256, "tft": 1.0352, "input_0": 35, "input_1": 17, "min_CLP": -3.51, "draft_iters": 6.3, "mem_use": 34.38, "gen_rate": 3.7, "speed": 4.83, "text": "To see the best starry sky in th"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.8, "tree_w": 5, "tree_size": 16, "t0": 0.5389, "t1": 0.3478, "tft": 0.8179, "input_0": 39, "input_1": 17, "min_CLP": -3.52, "draft_iters": 7.8, "mem_use": 33.73, "gen_rate": 3.7, "speed": 4.13, "text": "\"Certainly! Here's a top 10 list"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4444, "t1": 0.3333, "tft": 1.2683, "input_0": 34, "input_1": 17, "min_CLP": -3.48, "draft_iters": 6.4, "mem_use": 34.28, "gen_rate": 3.8, "speed": 4.85, "text": "\"If the two dropped eggs landed "}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.2, "tree_w": 5, "tree_size": 16, "t0": 0.49, "t1": 0.3167, "tft": 0.8661, "input_0": 39, "input_1": 17, "min_CLP": -3.18, "draft_iters": 7.2, "mem_use": 34.15, "gen_rate": 5.8, "speed": 7.24, "text": "There are many ways to cope with"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.5, "t1": 0.308, "tft": 2.2142, "input_0": 40, "input_1": 17, "min_CLP": -3.28, "draft_iters": 7.4, "mem_use": 37.21, "gen_rate": 3.7, "speed": 4.58, "text": "1. Establish clear objectives an"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 4, "tree_size": 16, "t0": 0.4486, "t1": 0.29, "tft": 1.7891, "input_0": 39, "input_1": 17, "min_CLP": -3.41, "draft_iters": 6.6, "mem_use": 35.89, "gen_rate": 4.6, "speed": 6.19, "text": "It depends on your needs and pre"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.4, "tree_w": 6, "tree_size": 16, "t0": 0.4429, "t1": 0.3329, "tft": 0.7992, "input_0": 37, "input_1": 17, "min_CLP": -3.41, "draft_iters": 6.4, "mem_use": 33.68, "gen_rate": 4.7, "speed": 6.08, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.7, "tree_w": 5, "tree_size": 16, "t0": 0.5271, "t1": 0.3471, "tft": 0.8122, "input_0": 41, "input_1": 17, "min_CLP": -4.19, "draft_iters": 7.7, "mem_use": 33.93, "gen_rate": 5.1, "speed": 5.88, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.7, "tree_w": 4, "tree_size": 16, "t0": 0.4511, "t1": 0.3178, "tft": 4.0998, "input_0": 39, "input_1": 17, "min_CLP": -3.22, "draft_iters": 6.7, "mem_use": 40.72, "gen_rate": 3.6, "speed": 4.62, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.4, "tree_w": 4, "tree_size": 16, "t0": 0.5071, "t1": 0.3143, "tft": 1.3312, "input_0": 42, "input_1": 17, "min_CLP": -3.32, "draft_iters": 7.4, "mem_use": 34.11, "gen_rate": 5.1, "speed": 6.24, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 10.2, "tree_w": 4, "tree_size": 16, "t0": 0.7575, "t1": 0.325, "tft": 0.7725, "input_0": 49, "input_1": 17, "min_CLP": -4.12, "draft_iters": 11.2, "mem_use": 33.81, "gen_rate": 11.0, "speed": 10.13, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.443, "t1": 0.361, "tft": 0.8506, "input_0": 35, "input_1": 17, "min_CLP": -3.44, "draft_iters": 6.3, "mem_use": 33.81, "gen_rate": 3.3, "speed": 4.11, "text": "Sure, I can help with that! In W"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4378, "t1": 0.3022, "tft": 1.8051, "input_0": 41, "input_1": 17, "min_CLP": -3.45, "draft_iters": 6.4, "mem_use": 36.36, "gen_rate": 3.7, "speed": 4.96, "text": "\"I'm sorry if my previous respon"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.8, "tree_w": 3, "tree_size": 16, "t0": 0.598, "t1": 0.342, "tft": 1.0543, "input_0": 43, "input_1": 17, "min_CLP": -3.45, "draft_iters": 8.8, "mem_use": 34.23, "gen_rate": 6.4, "speed": 6.78, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 14.0, "tree_w": 2, "tree_size": 16, "t0": 1.0, "t1": 0.3367, "tft": 1.2977, "input_0": 50, "input_1": 17, "min_CLP": -3.99, "draft_iters": 15.0, "mem_use": 34.42, "gen_rate": 15.0, "speed": 11.22, "text": "\"What is the airspeed velocity o"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 43, "tree_h": 7.8, "tree_w": 4, "tree_size": 16, "t0": 0.5975, "t1": 0.3487, "tft": 0.8252, "input_0": 45, "input_1": 17, "min_CLP": -3.09, "draft_iters": 8.8, "mem_use": 34.02, "gen_rate": 5.4, "speed": 5.67, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.4192, "t1": 0.3392, "tft": 1.6073, "input_0": 32, "input_1": 17, "min_CLP": -3.82, "draft_iters": 6.1, "mem_use": 34.26, "gen_rate": 2.8, "speed": 3.75, "text": "\"Attention bias, it's the star,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.9, "tree_w": 6, "tree_size": 16, "t0": 0.472, "t1": 0.345, "tft": 0.8232, "input_0": 32, "input_1": 17, "min_CLP": -3.71, "draft_iters": 6.9, "mem_use": 34.05, "gen_rate": 3.5, "speed": 4.27, "text": "The state of the cat is not know"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.1, "tree_w": 5, "tree_size": 16, "t0": 0.4167, "t1": 0.3022, "tft": 1.7332, "input_0": 37, "input_1": 17, "min_CLP": -3.36, "draft_iters": 6.1, "mem_use": 36.05, "gen_rate": 3.9, "speed": 5.41, "text": "\"Based on your symptoms and the "}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 6.8, "tree_w": 4, "tree_size": 16, "t0": 0.542, "t1": 0.354, "tft": 1.0362, "input_0": 42, "input_1": 17, "min_CLP": -3.08, "draft_iters": 7.8, "mem_use": 33.81, "gen_rate": 6.4, "speed": 7.14, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 5.4, "tree_w": 5, "tree_size": 16, "t0": 0.4433, "t1": 0.3489, "tft": 0.8576, "input_0": 36, "input_1": 17, "min_CLP": -3.58, "draft_iters": 6.4, "mem_use": 33.83, "gen_rate": 4.0, "speed": 5.04, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfEn"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 15, "new_tokens": 32, "tree_h": 4.3, "tree_w": 6, "tree_size": 16, "t0": 0.3707, "t1": 0.344, "tft": 1.0519, "input_0": 32, "input_1": 17, "min_CLP": -3.69, "draft_iters": 5.3, "mem_use": 33.8, "gen_rate": 2.1, "speed": 2.98, "text": "F-centers, short for Farbzentren"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 22, "tree_h": 8.0, "tree_w": 4, "tree_size": 16, "t0": 0.6067, "t1": 0.37, "tft": 2.7849, "input_0": 50, "input_1": 17, "min_CLP": -3.29, "draft_iters": 9.0, "mem_use": 38.34, "gen_rate": 7.3, "speed": 7.53, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.4113, "t1": 0.3138, "tft": 1.48, "input_0": 36, "input_1": 17, "min_CLP": -3.35, "draft_iters": 6.0, "mem_use": 35.43, "gen_rate": 4.8, "speed": 6.56, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 5, "tree_size": 16, "t0": 0.4125, "t1": 0.3362, "tft": 0.7898, "input_0": 38, "input_1": 17, "min_CLP": -3.41, "draft_iters": 6.0, "mem_use": 34.23, "gen_rate": 4.0, "speed": 5.34, "text": "\"I don't think AI assistants wil"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 5, "tree_size": 16, "t0": 0.4643, "t1": 0.3071, "tft": 2.0829, "input_0": 41, "input_1": 17, "min_CLP": -3.38, "draft_iters": 6.9, "mem_use": 36.15, "gen_rate": 4.6, "speed": 5.92, "text": "Breeding animals in Minecraft is"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 39, "tree_h": 5.1, "tree_w": 7, "tree_size": 16, "t0": 0.4145, "t1": 0.3055, "tft": 1.8699, "input_0": 34, "input_1": 17, "min_CLP": -3.82, "draft_iters": 6.1, "mem_use": 36.11, "gen_rate": 3.5, "speed": 4.93, "text": "Die Zementindustrie ist in Deuts"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.4533, "t1": 0.3111, "tft": 1.4703, "input_0": 37, "input_1": 17, "min_CLP": -3.37, "draft_iters": 6.7, "mem_use": 35.43, "gen_rate": 3.8, "speed": 4.94, "text": "I apologize, but I cannot provid"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 4.6, "tree_w": 6, "tree_size": 16, "t0": 0.3833, "t1": 0.3308, "tft": 1.2943, "input_0": 30, "input_1": 17, "min_CLP": -3.63, "draft_iters": 5.6, "mem_use": 34.47, "gen_rate": 2.8, "speed": 3.85, "text": "It depends on where you found it"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 4, "tree_size": 16, "t0": 0.622, "t1": 0.352, "tft": 1.0091, "input_0": 41, "input_1": 17, "min_CLP": -3.5, "draft_iters": 9.2, "mem_use": 34.06, "gen_rate": 6.4, "speed": 6.58, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u5e7e\u7bc7\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1a\\n\\n1. Vasw"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 0.88, "t1": 0.3533, "tft": 0.8718, "input_0": 55, "input_1": 17, "min_CLP": -2.57, "draft_iters": 13.0, "mem_use": 33.87, "gen_rate": 10.7, "speed": 8.66, "text": "\"Here's a function in JavaScript"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.6, "tree_w": 4, "tree_size": 16, "t0": 0.585, "t1": 0.3312, "tft": 1.5239, "input_0": 42, "input_1": 17, "min_CLP": -3.22, "draft_iters": 8.6, "mem_use": 35.14, "gen_rate": 4.5, "speed": 4.9, "text": "It is generally illegal to be na"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 3.8, "tree_w": 7, "tree_size": 16, "t0": 0.3345, "t1": 0.3327, "tft": 0.87, "input_0": 29, "input_1": 17, "min_CLP": -3.87, "draft_iters": 4.8, "mem_use": 34.26, "gen_rate": 2.9, "speed": 4.37, "text": "How about you write it down on a"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.3, "tree_w": 5, "tree_size": 16, "t0": 0.4344, "t1": 0.31, "tft": 1.4832, "input_0": 41, "input_1": 17, "min_CLP": -3.49, "draft_iters": 6.3, "mem_use": 35.14, "gen_rate": 3.7, "speed": 4.93, "text": "\"The optimal thickness of mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.3, "tree_w": 4, "tree_size": 16, "t0": 0.5667, "t1": 0.3383, "tft": 1.3116, "input_0": 41, "input_1": 17, "min_CLP": -3.3, "draft_iters": 8.3, "mem_use": 34.52, "gen_rate": 6.2, "speed": 6.82, "text": "In that case, if you live in a E"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 5, "tree_size": 16, "t0": 0.515, "t1": 0.345, "tft": 0.9777, "input_0": 41, "input_1": 17, "min_CLP": -3.66, "draft_iters": 7.5, "mem_use": 33.79, "gen_rate": 5.3, "speed": 6.22, "text": "\"def generate_nicks(num_nicks):\\"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 4, "tree_size": 16, "t0": 0.5529, "t1": 0.3457, "tft": 1.2149, "input_0": 39, "input_1": 17, "min_CLP": -3.23, "draft_iters": 8.1, "mem_use": 34.19, "gen_rate": 5.0, "speed": 5.56, "text": "Yes, the Balfour Declaration was"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.0, "tree_w": 2, "tree_size": 16, "t0": 0.87, "t1": 0.33, "tft": 1.5843, "input_0": 52, "input_1": 17, "min_CLP": -2.92, "draft_iters": 13.0, "mem_use": 34.95, "gen_rate": 11.3, "speed": 9.45, "text": "\"Canciones felices:\\n1. \u00ab(I Can'"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.8, "tree_w": 2, "tree_size": 16, "t0": 0.7925, "t1": 0.355, "tft": 0.8627, "input_0": 48, "input_1": 17, "min_CLP": -2.78, "draft_iters": 11.8, "mem_use": 33.89, "gen_rate": 9.5, "speed": 8.27, "text": "Here is a table of the average t"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 10.7, "tree_w": 3, "tree_size": 16, "t0": 0.7933, "t1": 0.3417, "tft": 0.9738, "input_0": 49, "input_1": 17, "min_CLP": -2.75, "draft_iters": 11.7, "mem_use": 34.28, "gen_rate": 7.5, "speed": 6.59, "text": "Oh, I apologize! Here is the cor"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 25, "tree_h": 4.9, "tree_w": 5, "tree_size": 16, "t0": 0.4022, "t1": 0.31, "tft": 1.1698, "input_0": 32, "input_1": 17, "min_CLP": -3.58, "draft_iters": 5.9, "mem_use": 34.65, "gen_rate": 2.8, "speed": 3.89, "text": "Sure, how about this: \"A heart\\'"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.2, "tree_w": 4, "tree_size": 16, "t0": 0.4938, "t1": 0.305, "tft": 1.5947, "input_0": 42, "input_1": 17, "min_CLP": -3.04, "draft_iters": 7.2, "mem_use": 35.41, "gen_rate": 4.2, "speed": 5.33, "text": "\"Building a reinforcement learni"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.4325, "t1": 0.3275, "tft": 1.1798, "input_0": 39, "input_1": 17, "min_CLP": -3.7, "draft_iters": 6.2, "mem_use": 33.9, "gen_rate": 4.1, "speed": 5.44, "text": "Frank-Walter Steinmeier (born 28"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.0, "tree_w": 3, "tree_size": 16, "t0": 0.6775, "t1": 0.33, "tft": 0.7939, "input_0": 46, "input_1": 17, "min_CLP": -3.9, "draft_iters": 10.0, "mem_use": 33.82, "gen_rate": 8.8, "speed": 8.7, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 5.6, "tree_w": 5, "tree_size": 16, "t0": 0.4462, "t1": 0.3025, "tft": 2.7244, "input_0": 39, "input_1": 17, "min_CLP": -3.37, "draft_iters": 6.6, "mem_use": 37.93, "gen_rate": 4.8, "speed": 6.34, "text": "1. **Discovery:**\\n   - Identify"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.2, "tree_w": 5, "tree_size": 16, "t0": 0.4275, "t1": 0.3312, "tft": 1.1324, "input_0": 33, "input_1": 17, "min_CLP": -3.65, "draft_iters": 6.2, "mem_use": 33.72, "gen_rate": 4.0, "speed": 5.26, "text": "[END]\\nThe many-worlds interpret"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 4, "tree_size": 16, "t0": 0.7325, "t1": 0.3675, "tft": 0.9586, "input_0": 37, "input_1": 17, "min_CLP": -3.64, "draft_iters": 10.8, "mem_use": 33.68, "gen_rate": 9.2, "speed": 8.4, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 45, "tree_h": 6.3, "tree_w": 5, "tree_size": 16, "t0": 0.4886, "t1": 0.3014, "tft": 2.4756, "input_0": 39, "input_1": 17, "min_CLP": -3.51, "draft_iters": 7.3, "mem_use": 37.93, "gen_rate": 6.4, "speed": 8.15, "text": "\"Hey there! How can I help you t"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.4763, "t1": 0.3112, "tft": 1.6081, "input_0": 40, "input_1": 17, "min_CLP": -3.34, "draft_iters": 7.0, "mem_use": 35.73, "gen_rate": 4.2, "speed": 5.4, "text": "\u2022 Make it a part of your daily r"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 35, "tree_h": 4.8, "tree_w": 6, "tree_size": 16, "t0": 0.4, "t1": 0.3292, "tft": 1.1732, "input_0": 33, "input_1": 17, "min_CLP": -3.57, "draft_iters": 5.8, "mem_use": 34.98, "gen_rate": 2.7, "speed": 3.7, "text": "You are correct, my apologies. T"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.8, "tree_w": 8, "tree_size": 16, "t0": 0.3975, "t1": 0.3362, "tft": 0.9169, "input_0": 30, "input_1": 17, "min_CLP": -3.81, "draft_iters": 5.8, "mem_use": 33.87, "gen_rate": 4.0, "speed": 5.45, "text": "noted\\n[INST] What about the wea"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 4, "tree_size": 16, "t0": 0.5271, "t1": 0.3514, "tft": 1.067, "input_0": 38, "input_1": 17, "min_CLP": -3.09, "draft_iters": 7.7, "mem_use": 33.89, "gen_rate": 4.6, "speed": 5.2, "text": "In the context of the game \"Into"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 4, "tree_size": 16, "t0": 0.4863, "t1": 0.3175, "tft": 1.5073, "input_0": 37, "input_1": 17, "min_CLP": -3.43, "draft_iters": 7.1, "mem_use": 34.7, "gen_rate": 4.2, "speed": 5.27, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 4, "tree_size": 16, "t0": 0.66, "t1": 0.328, "tft": 1.5923, "input_0": 42, "input_1": 17, "min_CLP": -3.12, "draft_iters": 9.8, "mem_use": 35.23, "gen_rate": 6.4, "speed": 6.49, "text": "\"Here's a more concise version o"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 14, "tree_h": 4.2, "tree_w": 5, "tree_size": 16, "t0": 0.3575, "t1": 0.2925, "tft": 1.15, "input_0": 32, "input_1": 17, "min_CLP": -3.41, "draft_iters": 5.2, "mem_use": 34.65, "gen_rate": 3.5, "speed": 5.37, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 1, "tree_size": 16, "t0": 1.095, "t1": 0.355, "tft": 1.1541, "input_0": 56, "input_1": 17, "min_CLP": -2.65, "draft_iters": 16.5, "mem_use": 34.76, "gen_rate": 16.5, "speed": 11.39, "text": "\"Of all the joys in life that I "}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.2, "tree_w": 4, "tree_size": 16, "t0": 0.555, "t1": 0.3233, "tft": 0.9947, "input_0": 42, "input_1": 17, "min_CLP": -3.49, "draft_iters": 8.2, "mem_use": 34.16, "gen_rate": 6.3, "speed": 7.2, "text": "The airspeed velocity of a Europ"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 5, "tree_size": 16, "t0": 0.4629, "t1": 0.3286, "tft": 1.3753, "input_0": 41, "input_1": 17, "min_CLP": -3.41, "draft_iters": 6.7, "mem_use": 34.12, "gen_rate": 4.6, "speed": 5.78, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.8, "tree_w": 4, "tree_size": 16, "t0": 0.4667, "t1": 0.3117, "tft": 1.4049, "input_0": 44, "input_1": 17, "min_CLP": -3.29, "draft_iters": 6.8, "mem_use": 35.44, "gen_rate": 5.3, "speed": 6.85, "text": "\"You're welcome! If the command "}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.6, "tree_w": 4, "tree_size": 16, "t0": 0.4478, "t1": 0.3122, "tft": 1.6618, "input_0": 38, "input_1": 17, "min_CLP": -3.44, "draft_iters": 6.6, "mem_use": 35.36, "gen_rate": 3.8, "speed": 4.98, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.8, "tree_w": 3, "tree_size": 16, "t0": 0.59, "t1": 0.308, "tft": 2.309, "input_0": 44, "input_1": 17, "min_CLP": -3.43, "draft_iters": 8.8, "mem_use": 36.82, "gen_rate": 6.4, "speed": 7.12, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.3, "tree_w": 2, "tree_size": 16, "t0": 0.83, "t1": 0.3667, "tft": 0.9317, "input_0": 54, "input_1": 17, "min_CLP": -3.45, "draft_iters": 12.3, "mem_use": 33.68, "gen_rate": 11.0, "speed": 9.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 3.9, "tree_w": 7, "tree_size": 16, "t0": 0.3382, "t1": 0.3291, "tft": 1.4998, "input_0": 29, "input_1": 17, "min_CLP": -4.01, "draft_iters": 4.9, "mem_use": 34.6, "gen_rate": 3.0, "speed": 4.5, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 5.6, "tree_w": 6, "tree_size": 16, "t0": 0.4487, "t1": 0.3087, "tft": 1.7894, "input_0": 34, "input_1": 17, "min_CLP": -3.5, "draft_iters": 6.6, "mem_use": 36.49, "gen_rate": 4.8, "speed": 6.28, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 6, "tree_size": 16, "t0": 0.5038, "t1": 0.3562, "tft": 0.9163, "input_0": 35, "input_1": 17, "min_CLP": -3.73, "draft_iters": 7.4, "mem_use": 34.19, "gen_rate": 4.1, "speed": 4.8, "text": "The contrarian nature of sufferi"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 16, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.0, "tree_w": 4, "tree_size": 16, "t0": 0.4733, "t1": 0.3067, "tft": 1.3848, "input_0": 43, "input_1": 17, "min_CLP": -3.19, "draft_iters": 7.0, "mem_use": 35.04, "gen_rate": 5.5, "speed": 7.03, "text": "I apologize for the confusion. U"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 16, "max_branch_width": 32, "gen_rate": 5.42, "gen_rate_micro": 4.59, "gen_speed": 5.978, "gen_speed_micro": 5.59, "t0": 0.5344, "t1": 0.3327, "input_0": 39.7, "input_1": 17.0, "tree_size": 16.0, "tree_w": 4.7, "tree_h": 6.8, "prompt_len": 298.0, "min_CLP": -3.45, "mem_use": 43.09, "exp_time": 4066.2}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.9, "tree_w": 12, "tree_size": 32, "t0": 0.414, "t1": 0.344, "tft": 1.1099, "input_0": 69, "input_1": 33, "min_CLP": -4.46, "draft_iters": 5.9, "mem_use": 33.77, "gen_rate": 3.5, "speed": 4.61, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 0.6817, "t1": 0.3283, "tft": 1.7376, "input_0": 80, "input_1": 33, "min_CLP": -3.93, "draft_iters": 10.0, "mem_use": 35.31, "gen_rate": 5.7, "speed": 5.61, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.8, "tree_w": 9, "tree_size": 32, "t0": 0.66, "t1": 0.3287, "tft": 1.8268, "input_0": 78, "input_1": 33, "min_CLP": -4.15, "draft_iters": 9.8, "mem_use": 36.22, "gen_rate": 4.0, "speed": 4.04, "text": "1. Minecraft: Minecraft is a gam"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.4, "tree_w": 6, "tree_size": 32, "t0": 0.72, "t1": 0.368, "tft": 0.993, "input_0": 112, "input_1": 33, "min_CLP": -3.72, "draft_iters": 10.4, "mem_use": 33.95, "gen_rate": 8.2, "speed": 7.53, "text": "```python\\ndef calculate_derivat"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.8, "tree_w": 7, "tree_size": 32, "t0": 0.6088, "t1": 0.3787, "tft": 1.254, "input_0": 95, "input_1": 33, "min_CLP": -3.96, "draft_iters": 8.8, "mem_use": 33.79, "gen_rate": 4.6, "speed": 4.69, "text": "Sure, I can definitely help you "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 0.5886, "t1": 0.3214, "tft": 2.9338, "input_0": 86, "input_1": 33, "min_CLP": -3.95, "draft_iters": 8.6, "mem_use": 36.35, "gen_rate": 5.0, "speed": 5.48, "text": "1. Introduction: Define what \"li"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 6, "tree_size": 32, "t0": 0.688, "t1": 0.33, "tft": 2.3951, "input_0": 97, "input_1": 33, "min_CLP": -3.61, "draft_iters": 10.2, "mem_use": 36.92, "gen_rate": 6.4, "speed": 6.29, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 7, "tree_size": 32, "t0": 0.5883, "t1": 0.3333, "tft": 2.9189, "input_0": 91, "input_1": 33, "min_CLP": -3.97, "draft_iters": 8.7, "mem_use": 39.07, "gen_rate": 5.5, "speed": 5.96, "text": "To attract the right customers, "}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.4, "tree_w": 7, "tree_size": 32, "t0": 0.64, "t1": 0.324, "tft": 2.0455, "input_0": 103, "input_1": 33, "min_CLP": -3.89, "draft_iters": 9.4, "mem_use": 36.54, "gen_rate": 7.8, "speed": 8.08, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.2, "tree_w": 7, "tree_size": 32, "t0": 0.5633, "t1": 0.3283, "tft": 2.0268, "input_0": 81, "input_1": 33, "min_CLP": -3.92, "draft_iters": 8.2, "mem_use": 35.93, "gen_rate": 5.7, "speed": 6.37, "text": "There are many hobby options tha"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 54, "tree_h": 8.1, "tree_w": 14, "tree_size": 32, "t0": 0.6256, "t1": 0.3711, "tft": 1.4942, "input_0": 62, "input_1": 33, "min_CLP": -4.88, "draft_iters": 9.1, "mem_use": 34.44, "gen_rate": 6.0, "speed": 6.01, "text": "Here is your code:\\n``\"Speak, me"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 10.3, "tree_w": 7, "tree_size": 32, "t0": 0.7629, "t1": 0.3386, "tft": 2.7622, "input_0": 91, "input_1": 33, "min_CLP": -4.02, "draft_iters": 11.3, "mem_use": 36.29, "gen_rate": 5.6, "speed": 5.05, "text": "Here\\'s a shorter version of the"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.8, "tree_w": 5, "tree_size": 32, "t0": 0.875, "t1": 0.35, "tft": 1.6306, "input_0": 125, "input_1": 33, "min_CLP": -3.5, "draft_iters": 12.8, "mem_use": 35.49, "gen_rate": 9.2, "speed": 7.55, "text": "Sure! Here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 17.0, "tree_w": 10, "tree_size": 32, "t0": 1.21, "t1": 0.365, "tft": 1.2181, "input_0": 106, "input_1": 33, "min_CLP": -4.53, "draft_iters": 18.0, "mem_use": 33.77, "gen_rate": 16.0, "speed": 10.15, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 8, "tree_size": 32, "t0": 0.6043, "t1": 0.3271, "tft": 2.4223, "input_0": 91, "input_1": 33, "min_CLP": -3.88, "draft_iters": 8.9, "mem_use": 36.89, "gen_rate": 4.7, "speed": 5.06, "text": "\"If you're finding it difficult "}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 7, "tree_size": 32, "t0": 0.714, "t1": 0.368, "tft": 1.4738, "input_0": 92, "input_1": 33, "min_CLP": -3.93, "draft_iters": 10.4, "mem_use": 34.11, "gen_rate": 6.8, "speed": 6.29, "text": "To stream at 720p 30fps to Twitc"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 13.2, "tree_w": 6, "tree_size": 32, "t0": 0.975, "t1": 0.3875, "tft": 1.2922, "input_0": 105, "input_1": 33, "min_CLP": -3.38, "draft_iters": 14.2, "mem_use": 33.79, "gen_rate": 10.2, "speed": 7.53, "text": "\"Sure, Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 15.3, "tree_w": 8, "tree_size": 32, "t0": 1.0767, "t1": 0.3733, "tft": 0.9083, "input_0": 78, "input_1": 33, "min_CLP": -4.5, "draft_iters": 16.0, "mem_use": 33.77, "gen_rate": 16.3, "speed": 11.26, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 11.6, "tree_w": 7, "tree_size": 32, "t0": 0.8657, "t1": 0.3314, "tft": 1.2658, "input_0": 109, "input_1": 33, "min_CLP": -4.32, "draft_iters": 12.6, "mem_use": 34.3, "gen_rate": 6.1, "speed": 5.13, "text": "\"D-theanine is the less common f"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 7.2, "tree_w": 8, "tree_size": 32, "t0": 0.5689, "t1": 0.34, "tft": 1.5781, "input_0": 82, "input_1": 33, "min_CLP": -4.34, "draft_iters": 8.2, "mem_use": 33.78, "gen_rate": 4.0, "speed": 4.39, "text": "\"The Balfour Declaration was a l"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 23, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.538, "t1": 0.32, "tft": 1.4058, "input_0": 97, "input_1": 33, "min_CLP": -4.51, "draft_iters": 7.8, "mem_use": 34.62, "gen_rate": 4.6, "speed": 5.36, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 6.0, "tree_w": 9, "tree_size": 32, "t0": 0.48, "t1": 0.315, "tft": 0.8118, "input_0": 80, "input_1": 33, "min_CLP": -4.23, "draft_iters": 7.0, "mem_use": 33.77, "gen_rate": 3.5, "speed": 4.4, "text": "Hello, how can I help you today?"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 0.6917, "t1": 0.33, "tft": 2.3001, "input_0": 95, "input_1": 33, "min_CLP": -3.84, "draft_iters": 10.2, "mem_use": 36.14, "gen_rate": 6.2, "speed": 6.02, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.0, "tree_w": 7, "tree_size": 32, "t0": 0.7567, "t1": 0.34, "tft": 0.9205, "input_0": 107, "input_1": 33, "min_CLP": -3.85, "draft_iters": 11.0, "mem_use": 33.84, "gen_rate": 6.7, "speed": 6.08, "text": "Certainly! The process of genera"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.1, "tree_w": 10, "tree_size": 32, "t0": 0.5567, "t1": 0.3178, "tft": 1.5016, "input_0": 78, "input_1": 33, "min_CLP": -4.46, "draft_iters": 8.1, "mem_use": 34.8, "gen_rate": 3.7, "speed": 4.19, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.4, "tree_w": 7, "tree_size": 32, "t0": 0.58, "t1": 0.372, "tft": 0.8944, "input_0": 94, "input_1": 33, "min_CLP": -4.12, "draft_iters": 8.4, "mem_use": 33.81, "gen_rate": 7.0, "speed": 7.35, "text": "Nietzsche\\'s philosophical ideas"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.8, "tree_w": 11, "tree_size": 32, "t0": 0.4044, "t1": 0.34, "tft": 1.6486, "input_0": 65, "input_1": 33, "min_CLP": -4.55, "draft_iters": 5.8, "mem_use": 34.48, "gen_rate": 3.8, "speed": 5.09, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 17, "tree_h": 11.5, "tree_w": 6, "tree_size": 32, "t0": 0.8525, "t1": 0.3825, "tft": 1.0189, "input_0": 93, "input_1": 33, "min_CLP": -3.69, "draft_iters": 12.5, "mem_use": 34.34, "gen_rate": 4.2, "speed": 3.44, "text": "\"You're welcome! It was my pleas"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 22.0, "tree_w": 4, "tree_size": 32, "t0": 1.51, "t1": 0.3667, "tft": 2.4356, "input_0": 94, "input_1": 33, "min_CLP": -4.35, "draft_iters": 22.7, "mem_use": 36.28, "gen_rate": 18.0, "speed": 9.6, "text": "\"La, la, la, la, la, la, la, la,"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 0.632, "t1": 0.368, "tft": 0.8333, "input_0": 87, "input_1": 33, "min_CLP": -4.37, "draft_iters": 9.2, "mem_use": 33.82, "gen_rate": 6.8, "speed": 6.8, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 12.8, "tree_w": 6, "tree_size": 32, "t0": 0.935, "t1": 0.34, "tft": 1.3184, "input_0": 122, "input_1": 33, "min_CLP": -3.86, "draft_iters": 13.8, "mem_use": 34.52, "gen_rate": 10.5, "speed": 8.24, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 9, "tree_size": 32, "t0": 0.58, "t1": 0.3537, "tft": 1.4901, "input_0": 88, "input_1": 33, "min_CLP": -4.93, "draft_iters": 8.4, "mem_use": 34.92, "gen_rate": 4.4, "speed": 4.69, "text": "[Mathematical questions]: {How c"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.3, "tree_w": 10, "tree_size": 32, "t0": 0.506, "t1": 0.34, "tft": 1.067, "input_0": 76, "input_1": 33, "min_CLP": -4.34, "draft_iters": 7.3, "mem_use": 34.28, "gen_rate": 3.3, "speed": 3.9, "text": "In the name of love and fertilit"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 0.6083, "t1": 0.3267, "tft": 1.8468, "input_0": 88, "input_1": 33, "min_CLP": -4.07, "draft_iters": 8.8, "mem_use": 35.95, "gen_rate": 5.5, "speed": 5.89, "text": "There are a few substitutes for "}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 0.5414, "t1": 0.3314, "tft": 1.9683, "input_0": 87, "input_1": 33, "min_CLP": -4.02, "draft_iters": 7.9, "mem_use": 35.99, "gen_rate": 4.9, "speed": 5.57, "text": "When choosing an ISP package, th"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.5, "tree_w": 3, "tree_size": 32, "t0": 1.625, "t1": 0.37, "tft": 3.1354, "input_0": 117, "input_1": 33, "min_CLP": -3.48, "draft_iters": 24.5, "mem_use": 38.67, "gen_rate": 24.0, "speed": 12.02, "text": "Selenium is a more established a"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.42, "t1": 0.3718, "tft": 1.3609, "input_0": 65, "input_1": 33, "min_CLP": -4.68, "draft_iters": 6.0, "mem_use": 33.8, "gen_rate": 3.4, "speed": 4.25, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 5.4, "tree_w": 14, "tree_size": 32, "t0": 0.4425, "t1": 0.3383, "tft": 1.9062, "input_0": 66, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.4, "mem_use": 34.33, "gen_rate": 2.7, "speed": 3.41, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 0.5983, "t1": 0.33, "tft": 2.3917, "input_0": 84, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.8, "mem_use": 36.7, "gen_rate": 5.3, "speed": 5.73, "text": "Of course, I can try to act like"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 0.58, "t1": 0.344, "tft": 1.4973, "input_0": 89, "input_1": 33, "min_CLP": -3.93, "draft_iters": 8.4, "mem_use": 34.73, "gen_rate": 6.4, "speed": 6.93, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.4, "tree_w": 14, "tree_size": 32, "t0": 0.378, "t1": 0.35, "tft": 0.883, "input_0": 60, "input_1": 33, "min_CLP": -4.74, "draft_iters": 5.4, "mem_use": 34.03, "gen_rate": 3.5, "speed": 4.81, "text": "Foolish mortal. I will not bow t"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 24.5, "tree_w": 4, "tree_size": 32, "t0": 1.665, "t1": 0.39, "tft": 2.0449, "input_0": 108, "input_1": 33, "min_CLP": -3.2, "draft_iters": 25.0, "mem_use": 36.52, "gen_rate": 18.5, "speed": 9.01, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 21.5, "tree_w": 4, "tree_size": 32, "t0": 1.47, "t1": 0.345, "tft": 2.265, "input_0": 127, "input_1": 33, "min_CLP": -3.84, "draft_iters": 22.0, "mem_use": 36.94, "gen_rate": 22.5, "speed": 12.41, "text": "\"Certainly! It sounds like you a"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.7, "tree_w": 7, "tree_size": 32, "t0": 0.6686, "t1": 0.34, "tft": 1.8012, "input_0": 102, "input_1": 33, "min_CLP": -4.02, "draft_iters": 9.7, "mem_use": 35.29, "gen_rate": 5.0, "speed": 4.97, "text": "Choosing the \"best\" SAST tool de"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 12.0, "tree_w": 4, "tree_size": 32, "t0": 0.87, "t1": 0.35, "tft": 1.643, "input_0": 116, "input_1": 33, "min_CLP": -3.88, "draft_iters": 13.0, "mem_use": 34.55, "gen_rate": 7.0, "speed": 5.74, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 16.7, "tree_w": 7, "tree_size": 32, "t0": 1.2044, "t1": 0.3911, "tft": 1.8707, "input_0": 87, "input_1": 33, "min_CLP": -4.5, "draft_iters": 17.7, "mem_use": 34.29, "gen_rate": 3.7, "speed": 2.3, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.555, "t1": 0.365, "tft": 1.3245, "input_0": 83, "input_1": 33, "min_CLP": -3.96, "draft_iters": 8.0, "mem_use": 33.8, "gen_rate": 5.8, "speed": 6.36, "text": "To check your system drive (usua"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 51, "tree_h": 15.8, "tree_w": 6, "tree_size": 32, "t0": 1.11, "t1": 0.342, "tft": 2.9819, "input_0": 99, "input_1": 33, "min_CLP": -4.16, "draft_iters": 16.8, "mem_use": 39.22, "gen_rate": 10.2, "speed": 7.01, "text": "\"Alright, I'll try to amp up the"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 6.4, "tree_w": 13, "tree_size": 32, "t0": 0.5027, "t1": 0.3473, "tft": 1.6976, "input_0": 59, "input_1": 33, "min_CLP": -4.62, "draft_iters": 7.4, "mem_use": 35.53, "gen_rate": 3.1, "speed": 3.64, "text": "I saw it, I saw the abomination "}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.3, "tree_w": 11, "tree_size": 32, "t0": 0.5029, "t1": 0.3429, "tft": 1.233, "input_0": 75, "input_1": 33, "min_CLP": -4.27, "draft_iters": 7.3, "mem_use": 34.56, "gen_rate": 5.0, "speed": 5.92, "text": "\"I hope you understand. I'm alwa"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 54, "tree_h": 11.6, "tree_w": 8, "tree_size": 32, "t0": 0.864, "t1": 0.38, "tft": 0.9687, "input_0": 96, "input_1": 33, "min_CLP": -3.98, "draft_iters": 12.6, "mem_use": 34.08, "gen_rate": 10.8, "speed": 8.68, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898\u3002 "}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 21.5, "tree_w": 4, "tree_size": 32, "t0": 1.515, "t1": 0.355, "tft": 2.1643, "input_0": 146, "input_1": 33, "min_CLP": -3.64, "draft_iters": 22.5, "mem_use": 35.99, "gen_rate": 17.0, "speed": 9.09, "text": "F-centers are crystallographic d"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 7, "tree_size": 32, "t0": 0.794, "t1": 0.338, "tft": 1.78, "input_0": 112, "input_1": 33, "min_CLP": -3.76, "draft_iters": 11.6, "mem_use": 35.18, "gen_rate": 6.8, "speed": 6.0, "text": "In addition to the events I ment"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.5533, "t1": 0.345, "tft": 1.754, "input_0": 89, "input_1": 33, "min_CLP": -4.06, "draft_iters": 8.0, "mem_use": 35.51, "gen_rate": 5.8, "speed": 6.5, "text": "Yes, technology can certainly be"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.1, "tree_w": 9, "tree_size": 32, "t0": 0.5638, "t1": 0.3613, "tft": 0.8758, "input_0": 84, "input_1": 33, "min_CLP": -4.14, "draft_iters": 8.1, "mem_use": 33.97, "gen_rate": 4.2, "speed": 4.59, "text": "In real life, there is no specif"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.4, "tree_w": 9, "tree_size": 32, "t0": 0.5114, "t1": 0.3186, "tft": 2.018, "input_0": 84, "input_1": 33, "min_CLP": -4.4, "draft_iters": 7.4, "mem_use": 36.38, "gen_rate": 4.6, "speed": 5.52, "text": "Certainly, here is a sample pitc"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.55, "t1": 0.33, "tft": 2.6118, "input_0": 97, "input_1": 33, "min_CLP": -3.99, "draft_iters": 8.0, "mem_use": 37.62, "gen_rate": 4.9, "speed": 5.54, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 0.6486, "t1": 0.3329, "tft": 2.7319, "input_0": 103, "input_1": 33, "min_CLP": -4.02, "draft_iters": 9.6, "mem_use": 37.79, "gen_rate": 5.3, "speed": 5.38, "text": "\"As a beginner, Keras is indeed "}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 8.4, "tree_w": 9, "tree_size": 32, "t0": 0.6433, "t1": 0.3456, "tft": 1.9355, "input_0": 79, "input_1": 33, "min_CLP": -4.08, "draft_iters": 9.4, "mem_use": 35.44, "gen_rate": 3.9, "speed": 3.93, "text": "My response is based on the info"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.6, "t1": 0.3633, "tft": 1.2992, "input_0": 93, "input_1": 33, "min_CLP": -4.23, "draft_iters": 8.7, "mem_use": 33.79, "gen_rate": 5.7, "speed": 5.87, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 15.9, "tree_w": 5, "tree_size": 32, "t0": 1.14, "t1": 0.37, "tft": 2.0424, "input_0": 105, "input_1": 33, "min_CLP": -3.85, "draft_iters": 16.9, "mem_use": 36.21, "gen_rate": 6.0, "speed": 3.98, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.4, "tree_w": 12, "tree_size": 32, "t0": 0.3725, "t1": 0.3238, "tft": 2.4264, "input_0": 72, "input_1": 33, "min_CLP": -4.55, "draft_iters": 5.4, "mem_use": 37.03, "gen_rate": 4.4, "speed": 6.29, "text": "[The general leads his army into"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 6.9, "tree_w": 12, "tree_size": 32, "t0": 0.5445, "t1": 0.3518, "tft": 1.3521, "input_0": 75, "input_1": 33, "min_CLP": -4.55, "draft_iters": 7.9, "mem_use": 34.74, "gen_rate": 3.2, "speed": 3.55, "text": "I understand that mnemonics need"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 6.7, "tree_w": 12, "tree_size": 32, "t0": 0.5291, "t1": 0.3582, "tft": 1.4955, "input_0": 68, "input_1": 33, "min_CLP": -4.52, "draft_iters": 7.7, "mem_use": 34.46, "gen_rate": 3.0, "speed": 3.37, "text": "\"[INST] How would this impact th"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 19.0, "tree_w": 4, "tree_size": 32, "t0": 1.34, "t1": 0.365, "tft": 1.1968, "input_0": 101, "input_1": 33, "min_CLP": -4.36, "draft_iters": 20.0, "mem_use": 34.58, "gen_rate": 20.0, "speed": 11.7, "text": "I am sorry to say that, but stop"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.9, "tree_w": 9, "tree_size": 32, "t0": 0.4713, "t1": 0.3113, "tft": 2.1567, "input_0": 78, "input_1": 33, "min_CLP": -4.13, "draft_iters": 6.9, "mem_use": 36.65, "gen_rate": 4.6, "speed": 5.92, "text": "void pointers are a type of poin"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.3, "tree_w": 10, "tree_size": 32, "t0": 0.5017, "t1": 0.33, "tft": 2.4923, "input_0": 89, "input_1": 33, "min_CLP": -4.19, "draft_iters": 7.3, "mem_use": 37.16, "gen_rate": 5.3, "speed": 6.4, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 6, "tree_size": 32, "t0": 0.7233, "t1": 0.3367, "tft": 2.2637, "input_0": 100, "input_1": 33, "min_CLP": -3.77, "draft_iters": 10.7, "mem_use": 36.38, "gen_rate": 5.7, "speed": 5.34, "text": "To implement two-factor authenti"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.4, "tree_w": 9, "tree_size": 32, "t0": 0.5143, "t1": 0.3657, "tft": 0.8591, "input_0": 72, "input_1": 33, "min_CLP": -4.11, "draft_iters": 7.4, "mem_use": 34.21, "gen_rate": 5.1, "speed": 5.84, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.3, "tree_w": 9, "tree_size": 32, "t0": 0.58, "t1": 0.38, "tft": 1.5823, "input_0": 88, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.3, "mem_use": 33.79, "gen_rate": 5.0, "speed": 5.22, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 15.7, "tree_w": 3, "tree_size": 32, "t0": 1.1267, "t1": 0.35, "tft": 2.4139, "input_0": 109, "input_1": 33, "min_CLP": -3.67, "draft_iters": 16.7, "mem_use": 36.61, "gen_rate": 13.7, "speed": 9.26, "text": "\"Sure, here's a table with the a"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 26, "tree_h": 5.0, "tree_w": 11, "tree_size": 32, "t0": 0.4188, "t1": 0.3662, "tft": 0.8246, "input_0": 66, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.0, "mem_use": 33.75, "gen_rate": 3.2, "speed": 4.14, "text": "Berlin was not made by a person,"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.11, "t1": 0.37, "tft": 2.5236, "input_0": 132, "input_1": 33, "min_CLP": -4.3, "draft_iters": 32.0, "mem_use": 36.09, "gen_rate": 33.0, "speed": 13.33, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.7, "tree_w": 5, "tree_size": 32, "t0": 0.7333, "t1": 0.335, "tft": 2.1844, "input_0": 104, "input_1": 33, "min_CLP": -3.71, "draft_iters": 10.7, "mem_use": 35.96, "gen_rate": 6.7, "speed": 6.25, "text": "Sure, here are some of the criti"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.1, "tree_w": 10, "tree_size": 32, "t0": 0.4957, "t1": 0.3657, "tft": 0.8266, "input_0": 80, "input_1": 33, "min_CLP": -4.41, "draft_iters": 7.1, "mem_use": 33.77, "gen_rate": 5.0, "speed": 5.79, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 16, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 0.515, "t1": 0.3475, "tft": 0.9028, "input_0": 67, "input_1": 33, "min_CLP": -4.44, "draft_iters": 7.5, "mem_use": 34.08, "gen_rate": 4.0, "speed": 4.66, "text": "You can find out your timezone o"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.7, "tree_w": 12, "tree_size": 32, "t0": 0.4622, "t1": 0.3589, "tft": 0.9788, "input_0": 71, "input_1": 33, "min_CLP": -4.49, "draft_iters": 6.7, "mem_use": 34.16, "gen_rate": 3.8, "speed": 4.6, "text": "The five second rule is a myth. "}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 10.0, "tree_w": 8, "tree_size": 32, "t0": 0.745, "t1": 0.315, "tft": 0.8667, "input_0": 104, "input_1": 33, "min_CLP": -4.33, "draft_iters": 11.0, "mem_use": 33.89, "gen_rate": 5.5, "speed": 5.19, "text": "12 - 2 - 5 = 5 eggs"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.3, "tree_w": 5, "tree_size": 32, "t0": 0.8467, "t1": 0.3583, "tft": 1.6832, "input_0": 104, "input_1": 33, "min_CLP": -3.42, "draft_iters": 12.3, "mem_use": 34.63, "gen_rate": 6.0, "speed": 4.99, "text": "\"Sure, I'll try to explain a cou"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 11, "tree_size": 32, "t0": 0.4162, "t1": 0.3538, "tft": 0.9874, "input_0": 66, "input_1": 33, "min_CLP": -4.35, "draft_iters": 6.0, "mem_use": 34.2, "gen_rate": 4.0, "speed": 5.18, "text": "\"It's possible that the mayonnai"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 14.0, "tree_w": 7, "tree_size": 32, "t0": 1.0225, "t1": 0.3725, "tft": 0.9346, "input_0": 93, "input_1": 33, "min_CLP": -3.87, "draft_iters": 15.0, "mem_use": 33.91, "gen_rate": 8.8, "speed": 6.28, "text": "Sure! Here\\'s a draft announceme"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.7, "tree_w": 10, "tree_size": 32, "t0": 0.4657, "t1": 0.3343, "tft": 1.955, "input_0": 76, "input_1": 33, "min_CLP": -4.33, "draft_iters": 6.7, "mem_use": 34.52, "gen_rate": 5.3, "speed": 6.6, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.1, "tree_w": 7, "tree_size": 32, "t0": 0.6986, "t1": 0.3486, "tft": 1.7045, "input_0": 108, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.1, "mem_use": 35.56, "gen_rate": 5.3, "speed": 5.05, "text": "Certainly! AI assistants can als"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.5, "tree_w": 9, "tree_size": 32, "t0": 0.5117, "t1": 0.325, "tft": 2.0588, "input_0": 83, "input_1": 33, "min_CLP": -4.15, "draft_iters": 7.5, "mem_use": 36.58, "gen_rate": 5.8, "speed": 6.95, "text": "Certainly! Here\\'s a rewritten v"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 0.66, "t1": 0.362, "tft": 1.528, "input_0": 101, "input_1": 33, "min_CLP": -4.0, "draft_iters": 9.6, "mem_use": 35.08, "gen_rate": 7.8, "speed": 7.64, "text": "Yes, the scp command is specific"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 25.3, "tree_w": 3, "tree_size": 32, "t0": 1.7633, "t1": 0.38, "tft": 1.8081, "input_0": 137, "input_1": 33, "min_CLP": -3.47, "draft_iters": 26.0, "mem_use": 35.72, "gen_rate": 18.7, "speed": 8.71, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.2, "tree_w": 11, "tree_size": 32, "t0": 0.4356, "t1": 0.3433, "tft": 0.9641, "input_0": 72, "input_1": 33, "min_CLP": -4.38, "draft_iters": 6.2, "mem_use": 33.82, "gen_rate": 3.7, "speed": 4.71, "text": "The input is a set of sentences."}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.8, "tree_w": 8, "tree_size": 32, "t0": 0.5467, "t1": 0.3617, "tft": 1.2461, "input_0": 95, "input_1": 33, "min_CLP": -4.07, "draft_iters": 7.8, "mem_use": 34.11, "gen_rate": 5.8, "speed": 6.41, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.9, "tree_w": 8, "tree_size": 32, "t0": 0.5443, "t1": 0.3457, "tft": 1.302, "input_0": 87, "input_1": 33, "min_CLP": -4.26, "draft_iters": 7.9, "mem_use": 34.41, "gen_rate": 4.7, "speed": 5.3, "text": "Thank you for explaining the fiv"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.5322, "t1": 0.3589, "tft": 1.0269, "input_0": 76, "input_1": 33, "min_CLP": -4.32, "draft_iters": 7.7, "mem_use": 34.08, "gen_rate": 3.8, "speed": 4.25, "text": "\"I'm glad you liked it. If you n"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.0, "tree_w": 8, "tree_size": 32, "t0": 0.9433, "t1": 0.37, "tft": 1.7258, "input_0": 89, "input_1": 33, "min_CLP": -4.29, "draft_iters": 14.0, "mem_use": 33.85, "gen_rate": 11.3, "speed": 8.63, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 9, "tree_size": 32, "t0": 0.595, "t1": 0.3417, "tft": 0.8842, "input_0": 84, "input_1": 33, "min_CLP": -3.84, "draft_iters": 8.7, "mem_use": 33.83, "gen_rate": 5.7, "speed": 6.05, "text": "The task is to determine the tim"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 18.0, "tree_w": 4, "tree_size": 32, "t0": 1.28, "t1": 0.36, "tft": 2.3339, "input_0": 136, "input_1": 33, "min_CLP": -4.16, "draft_iters": 19.0, "mem_use": 35.56, "gen_rate": 16.5, "speed": 10.09, "text": "\"The solution to the Taniyama-Sh"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 12.0, "tree_w": 10, "tree_size": 32, "t0": 0.8767, "t1": 0.3467, "tft": 0.9857, "input_0": 90, "input_1": 33, "min_CLP": -4.56, "draft_iters": 13.0, "mem_use": 33.83, "gen_rate": 11.3, "speed": 9.25, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.3, "tree_w": 6, "tree_size": 32, "t0": 0.855, "t1": 0.3967, "tft": 1.3324, "input_0": 103, "input_1": 33, "min_CLP": -3.69, "draft_iters": 12.3, "mem_use": 34.14, "gen_rate": 5.3, "speed": 4.26, "text": "\"Here's an example of a basic fi"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 15.3, "tree_w": 9, "tree_size": 32, "t0": 1.09, "t1": 0.37, "tft": 0.9041, "input_0": 99, "input_1": 33, "min_CLP": -4.49, "draft_iters": 16.0, "mem_use": 33.8, "gen_rate": 16.3, "speed": 11.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.2, "tree_w": 13, "tree_size": 32, "t0": 0.4327, "t1": 0.3573, "tft": 1.0016, "input_0": 66, "input_1": 33, "min_CLP": -4.53, "draft_iters": 6.2, "mem_use": 34.11, "gen_rate": 3.1, "speed": 3.91, "text": "In the Jedi path, one must learn"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 32, "tree_h": 5.0, "tree_w": 11, "tree_size": 32, "t0": 0.4175, "t1": 0.3625, "tft": 1.2018, "input_0": 70, "input_1": 33, "min_CLP": -4.38, "draft_iters": 6.0, "mem_use": 33.97, "gen_rate": 2.7, "speed": 3.41, "text": "A gas-operated rifle is a type o"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.4867, "t1": 0.3667, "tft": 1.194, "input_0": 70, "input_1": 33, "min_CLP": -4.58, "draft_iters": 7.0, "mem_use": 34.21, "gen_rate": 3.9, "speed": 4.56, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.5, "tree_w": 10, "tree_size": 32, "t0": 0.442, "t1": 0.322, "tft": 2.4329, "input_0": 73, "input_1": 33, "min_CLP": -4.26, "draft_iters": 6.5, "mem_use": 37.05, "gen_rate": 3.5, "speed": 4.58, "text": "Yes, using regular expressions f"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.1, "tree_w": 10, "tree_size": 32, "t0": 0.4933, "t1": 0.35, "tft": 0.9907, "input_0": 74, "input_1": 33, "min_CLP": -4.11, "draft_iters": 7.1, "mem_use": 34.28, "gen_rate": 3.9, "speed": 4.62, "text": "\"Yes, it's often recommended tha"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 7, "tree_h": 6.3, "tree_w": 11, "tree_size": 32, "t0": 0.4967, "t1": 0.3133, "tft": 2.0976, "input_0": 77, "input_1": 33, "min_CLP": -4.28, "draft_iters": 7.3, "mem_use": 37.15, "gen_rate": 2.3, "speed": 2.86, "text": "Xin ch\u00e0o! How can I help you tod"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.7, "tree_w": 12, "tree_size": 32, "t0": 0.46, "t1": 0.321, "tft": 1.1366, "input_0": 72, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.7, "mem_use": 34.64, "gen_rate": 3.2, "speed": 4.1, "text": "\"This is one of the most famous "}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 13.2, "tree_w": 4, "tree_size": 32, "t0": 0.97, "t1": 0.3517, "tft": 1.1022, "input_0": 106, "input_1": 33, "min_CLP": -3.47, "draft_iters": 14.2, "mem_use": 34.16, "gen_rate": 7.2, "speed": 5.41, "text": "Sure! Here\\'s an example of how "}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.5378, "t1": 0.32, "tft": 1.9936, "input_0": 89, "input_1": 33, "min_CLP": -4.32, "draft_iters": 7.8, "mem_use": 35.58, "gen_rate": 3.6, "speed": 4.16, "text": "Here is a list of the 10 most po"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 5.0, "tree_w": 13, "tree_size": 32, "t0": 0.42, "t1": 0.3536, "tft": 1.1562, "input_0": 73, "input_1": 33, "min_CLP": -4.48, "draft_iters": 6.0, "mem_use": 34.12, "gen_rate": 3.2, "speed": 4.11, "text": "\"To win a thumb war, you should "}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 0.694, "t1": 0.326, "tft": 2.0364, "input_0": 109, "input_1": 33, "min_CLP": -3.82, "draft_iters": 10.2, "mem_use": 36.15, "gen_rate": 7.0, "speed": 6.87, "text": "Sure, here are some general tips"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 9, "tree_size": 32, "t0": 0.5871, "t1": 0.3257, "tft": 1.424, "input_0": 88, "input_1": 33, "min_CLP": -4.26, "draft_iters": 8.6, "mem_use": 34.75, "gen_rate": 4.7, "speed": 5.17, "text": "As a language model, I can simul"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 8.8, "tree_w": 9, "tree_size": 32, "t0": 0.6725, "t1": 0.3375, "tft": 0.9344, "input_0": 106, "input_1": 33, "min_CLP": -4.34, "draft_iters": 9.8, "mem_use": 34.28, "gen_rate": 8.8, "speed": 8.67, "text": "\"[INST] Of course, I'd be happy "}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 0.6429, "t1": 0.3643, "tft": 1.6391, "input_0": 91, "input_1": 33, "min_CLP": -3.93, "draft_iters": 9.3, "mem_use": 34.42, "gen_rate": 6.1, "speed": 6.08, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.7, "tree_w": 15, "tree_size": 32, "t0": 0.4589, "t1": 0.3233, "tft": 1.8656, "input_0": 67, "input_1": 33, "min_CLP": -4.79, "draft_iters": 6.7, "mem_use": 35.69, "gen_rate": 3.6, "speed": 4.55, "text": "Here is a poem to express love t"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 0.5488, "t1": 0.3637, "tft": 1.2918, "input_0": 91, "input_1": 33, "min_CLP": -4.33, "draft_iters": 7.9, "mem_use": 33.8, "gen_rate": 4.1, "speed": 4.52, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 0.5833, "t1": 0.3411, "tft": 1.1304, "input_0": 86, "input_1": 33, "min_CLP": -3.91, "draft_iters": 8.4, "mem_use": 33.84, "gen_rate": 3.9, "speed": 4.2, "text": "The error in the given code is a"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.6, "tree_w": 9, "tree_size": 32, "t0": 0.5833, "t1": 0.3233, "tft": 1.4642, "input_0": 76, "input_1": 33, "min_CLP": -4.21, "draft_iters": 8.6, "mem_use": 35.22, "gen_rate": 3.7, "speed": 4.03, "text": "Dear future Luna,\\n\\nIf you are "}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 8, "tree_size": 32, "t0": 0.668, "t1": 0.324, "tft": 1.5527, "input_0": 86, "input_1": 33, "min_CLP": -3.79, "draft_iters": 9.8, "mem_use": 34.45, "gen_rate": 6.8, "speed": 6.86, "text": "In the second context, the `@` s"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.4, "tree_w": 6, "tree_size": 32, "t0": 0.778, "t1": 0.324, "tft": 1.2453, "input_0": 111, "input_1": 33, "min_CLP": -3.72, "draft_iters": 11.4, "mem_use": 34.57, "gen_rate": 8.0, "speed": 7.26, "text": "\"To achieve this, you can use th"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.3, "tree_w": 9, "tree_size": 32, "t0": 0.5671, "t1": 0.3143, "tft": 2.0505, "input_0": 91, "input_1": 33, "min_CLP": -4.06, "draft_iters": 8.3, "mem_use": 36.36, "gen_rate": 5.0, "speed": 5.67, "text": "\"It's understandable to feel a b"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 63, "tree_h": 25.7, "tree_w": 2, "tree_size": 32, "t0": 1.7867, "t1": 0.4, "tft": 0.9498, "input_0": 117, "input_1": 33, "min_CLP": -3.6, "draft_iters": 26.3, "mem_use": 34.36, "gen_rate": 21.0, "speed": 9.59, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 25.0, "tree_w": 2, "tree_size": 32, "t0": 1.7333, "t1": 0.39, "tft": 2.6026, "input_0": 115, "input_1": 33, "min_CLP": -2.99, "draft_iters": 25.7, "mem_use": 35.71, "gen_rate": 12.0, "speed": 5.66, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 8, "tree_size": 32, "t0": 0.5257, "t1": 0.3643, "tft": 0.8939, "input_0": 83, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.6, "mem_use": 33.78, "gen_rate": 4.7, "speed": 5.3, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 12, "tree_size": 32, "t0": 0.59, "t1": 0.3371, "tft": 1.2231, "input_0": 77, "input_1": 33, "min_CLP": -4.93, "draft_iters": 8.6, "mem_use": 34.01, "gen_rate": 4.7, "speed": 5.07, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 19, "tree_h": 9.7, "tree_w": 10, "tree_size": 32, "t0": 0.7267, "t1": 0.32, "tft": 0.9254, "input_0": 106, "input_1": 33, "min_CLP": -4.13, "draft_iters": 10.7, "mem_use": 34.26, "gen_rate": 6.3, "speed": 6.03, "text": "\"Thank you! I'm glad I could hel"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.5483, "t1": 0.325, "tft": 1.5134, "input_0": 80, "input_1": 33, "min_CLP": -4.79, "draft_iters": 8.0, "mem_use": 35.83, "gen_rate": 5.7, "speed": 6.5, "text": "Thou art the sun that doth shine"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.1, "tree_w": 10, "tree_size": 32, "t0": 0.5586, "t1": 0.3271, "tft": 1.4229, "input_0": 79, "input_1": 33, "min_CLP": -4.01, "draft_iters": 8.1, "mem_use": 34.42, "gen_rate": 4.6, "speed": 5.16, "text": "\"I apologize, but I don't have a"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 61, "tree_h": 22.7, "tree_w": 4, "tree_size": 32, "t0": 1.6067, "t1": 0.3833, "tft": 1.2601, "input_0": 112, "input_1": 33, "min_CLP": -3.95, "draft_iters": 23.3, "mem_use": 33.83, "gen_rate": 20.3, "speed": 10.23, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.4, "tree_w": 9, "tree_size": 32, "t0": 0.51, "t1": 0.342, "tft": 1.1881, "input_0": 86, "input_1": 33, "min_CLP": -3.94, "draft_iters": 7.4, "mem_use": 33.81, "gen_rate": 6.6, "speed": 7.73, "text": "\"Sure, Presidents' Day is a fede"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.5, "tree_w": 10, "tree_size": 32, "t0": 0.6525, "t1": 0.37, "tft": 0.8933, "input_0": 86, "input_1": 33, "min_CLP": -4.63, "draft_iters": 9.5, "mem_use": 34.11, "gen_rate": 8.0, "speed": 7.84, "text": "True, a kilogram of feathers is "}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.1, "tree_w": 9, "tree_size": 32, "t0": 0.63, "t1": 0.34, "tft": 1.5632, "input_0": 96, "input_1": 33, "min_CLP": -4.31, "draft_iters": 9.1, "mem_use": 34.9, "gen_rate": 4.9, "speed": 5.0, "text": "The existence and capabilities o"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 35, "tree_h": 5.2, "tree_w": 13, "tree_size": 32, "t0": 0.4292, "t1": 0.3169, "tft": 0.9011, "input_0": 65, "input_1": 33, "min_CLP": -4.68, "draft_iters": 6.2, "mem_use": 34.18, "gen_rate": 2.7, "speed": 3.6, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 29, "tree_h": 6.6, "tree_w": 9, "tree_size": 32, "t0": 0.5214, "t1": 0.3371, "tft": 0.8642, "input_0": 83, "input_1": 33, "min_CLP": -4.09, "draft_iters": 7.6, "mem_use": 34.26, "gen_rate": 4.1, "speed": 4.81, "text": "Certainly, I will be referred to"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 0.598, "t1": 0.35, "tft": 1.4437, "input_0": 89, "input_1": 33, "min_CLP": -3.99, "draft_iters": 8.6, "mem_use": 33.81, "gen_rate": 7.0, "speed": 7.38, "text": "Yes, the ATF (Bureau of Alcohol,"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.6, "tree_w": 12, "tree_size": 32, "t0": 0.4555, "t1": 0.3373, "tft": 1.2338, "input_0": 66, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.6, "mem_use": 34.49, "gen_rate": 2.9, "speed": 3.68, "text": "\"Ted who? That guy\\'s just a gru"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 6.3, "tree_w": 10, "tree_size": 32, "t0": 0.507, "t1": 0.364, "tft": 0.8131, "input_0": 82, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.3, "mem_use": 33.92, "gen_rate": 3.5, "speed": 4.0, "text": "The mayonnaise might have separa"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.6, "tree_w": 7, "tree_size": 32, "t0": 0.59, "t1": 0.3314, "tft": 1.4601, "input_0": 88, "input_1": 33, "min_CLP": -4.14, "draft_iters": 8.6, "mem_use": 35.14, "gen_rate": 4.6, "speed": 4.97, "text": "Certainly, here are some popular"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.3, "tree_w": 14, "tree_size": 32, "t0": 0.372, "t1": 0.364, "tft": 0.8592, "input_0": 63, "input_1": 33, "min_CLP": -4.67, "draft_iters": 5.3, "mem_use": 34.25, "gen_rate": 3.5, "speed": 4.76, "text": "I am not capable of taking over "}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.2, "tree_w": 9, "tree_size": 32, "t0": 0.5011, "t1": 0.3456, "tft": 1.8421, "input_0": 77, "input_1": 33, "min_CLP": -4.05, "draft_iters": 7.2, "mem_use": 35.45, "gen_rate": 3.7, "speed": 4.34, "text": "\"If you're a beginner hiker look"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.9, "tree_w": 11, "tree_size": 32, "t0": 0.5463, "t1": 0.3775, "tft": 0.921, "input_0": 78, "input_1": 33, "min_CLP": -4.73, "draft_iters": 7.9, "mem_use": 34.2, "gen_rate": 4.1, "speed": 4.47, "text": "\"Open Assistant: The Open Source"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 40, "tree_h": 7.6, "tree_w": 9, "tree_size": 32, "t0": 0.596, "t1": 0.388, "tft": 1.0368, "input_0": 79, "input_1": 33, "min_CLP": -4.03, "draft_iters": 8.6, "mem_use": 34.09, "gen_rate": 4.0, "speed": 4.06, "text": "\"Sure! Here's an illustration of"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.8, "tree_w": 7, "tree_size": 32, "t0": 0.7383, "t1": 0.3333, "tft": 2.2162, "input_0": 107, "input_1": 33, "min_CLP": -3.99, "draft_iters": 10.8, "mem_use": 36.44, "gen_rate": 6.7, "speed": 6.23, "text": "The reason why the function does"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 7.2, "tree_w": 8, "tree_size": 32, "t0": 0.565, "t1": 0.3567, "tft": 1.0795, "input_0": 89, "input_1": 33, "min_CLP": -4.03, "draft_iters": 8.2, "mem_use": 33.79, "gen_rate": 6.7, "speed": 7.23, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 8, "tree_size": 32, "t0": 0.5714, "t1": 0.3614, "tft": 1.0337, "input_0": 95, "input_1": 33, "min_CLP": -4.22, "draft_iters": 8.1, "mem_use": 34.34, "gen_rate": 4.7, "speed": 5.07, "text": "\"I'm sorry, but I can't provide "}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 7.5, "tree_w": 9, "tree_size": 32, "t0": 0.59, "t1": 0.365, "tft": 0.9334, "input_0": 91, "input_1": 33, "min_CLP": -4.21, "draft_iters": 8.5, "mem_use": 33.97, "gen_rate": 7.0, "speed": 7.35, "text": "The heat from the pan helps cook"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 7.4, "tree_w": 8, "tree_size": 32, "t0": 0.5867, "t1": 0.3556, "tft": 1.306, "input_0": 91, "input_1": 33, "min_CLP": -4.06, "draft_iters": 8.4, "mem_use": 33.81, "gen_rate": 4.0, "speed": 4.24, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.2, "tree_w": 9, "tree_size": 32, "t0": 0.5, "t1": 0.3333, "tft": 1.8655, "input_0": 81, "input_1": 33, "min_CLP": -4.13, "draft_iters": 7.2, "mem_use": 35.88, "gen_rate": 3.7, "speed": 4.4, "text": "\"As an AI language model, I apol"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 21, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.485, "t1": 0.3525, "tft": 1.0103, "input_0": 82, "input_1": 33, "min_CLP": -4.36, "draft_iters": 7.0, "mem_use": 33.77, "gen_rate": 5.2, "speed": 6.28, "text": "Your question is a bit unclear. "}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 6.0, "tree_w": 13, "tree_size": 32, "t0": 0.485, "t1": 0.378, "tft": 1.3881, "input_0": 65, "input_1": 33, "min_CLP": -4.68, "draft_iters": 7.0, "mem_use": 33.85, "gen_rate": 3.6, "speed": 4.17, "text": "The lyrics to the third verse of"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.2, "tree_w": 9, "tree_size": 32, "t0": 0.4975, "t1": 0.3313, "tft": 2.4312, "input_0": 85, "input_1": 33, "min_CLP": -4.22, "draft_iters": 7.2, "mem_use": 37.11, "gen_rate": 4.1, "speed": 4.98, "text": "As of my last update in October "}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 10, "tree_size": 32, "t0": 0.692, "t1": 0.332, "tft": 1.398, "input_0": 93, "input_1": 33, "min_CLP": -4.2, "draft_iters": 10.2, "mem_use": 35.11, "gen_rate": 6.4, "speed": 6.24, "text": "I understand that I can use my i"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 0.5233, "t1": 0.3667, "tft": 0.9557, "input_0": 87, "input_1": 33, "min_CLP": -4.05, "draft_iters": 7.5, "mem_use": 34.06, "gen_rate": 5.8, "speed": 6.56, "text": "There are many resources availab"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.4, "tree_w": 8, "tree_size": 32, "t0": 0.6475, "t1": 0.365, "tft": 1.4302, "input_0": 84, "input_1": 33, "min_CLP": -3.92, "draft_iters": 9.4, "mem_use": 34.04, "gen_rate": 4.2, "speed": 4.2, "text": "Here are some potential methods "}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 43, "tree_h": 7.1, "tree_w": 9, "tree_size": 32, "t0": 0.5662, "t1": 0.3513, "tft": 1.3206, "input_0": 87, "input_1": 33, "min_CLP": -4.1, "draft_iters": 8.1, "mem_use": 33.81, "gen_rate": 5.4, "speed": 5.87, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.8, "tree_w": 9, "tree_size": 32, "t0": 0.5389, "t1": 0.3589, "tft": 1.2784, "input_0": 82, "input_1": 33, "min_CLP": -4.23, "draft_iters": 7.8, "mem_use": 34.61, "gen_rate": 3.7, "speed": 4.09, "text": "I apologize for any confusion, I"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 26, "tree_h": 19.3, "tree_w": 3, "tree_size": 32, "t0": 1.3967, "t1": 0.3733, "tft": 1.8971, "input_0": 131, "input_1": 33, "min_CLP": -4.26, "draft_iters": 20.3, "mem_use": 34.64, "gen_rate": 8.7, "speed": 4.9, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.4, "tree_w": 6, "tree_size": 32, "t0": 0.768, "t1": 0.336, "tft": 3.5604, "input_0": 99, "input_1": 33, "min_CLP": -3.81, "draft_iters": 11.4, "mem_use": 37.13, "gen_rate": 6.8, "speed": 6.15, "text": "Certainly! Here is a concise ver"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.5586, "t1": 0.3743, "tft": 0.8255, "input_0": 92, "input_1": 33, "min_CLP": -4.1, "draft_iters": 8.0, "mem_use": 33.81, "gen_rate": 5.3, "speed": 5.67, "text": "To reduce your alcohol consumpti"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 5.3, "tree_w": 11, "tree_size": 32, "t0": 0.4417, "t1": 0.3583, "tft": 1.0949, "input_0": 70, "input_1": 33, "min_CLP": -4.49, "draft_iters": 6.3, "mem_use": 34.37, "gen_rate": 2.8, "speed": 3.44, "text": "The city is home to numerous sta"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.0, "tree_w": 6, "tree_size": 32, "t0": 0.892, "t1": 0.362, "tft": 1.0681, "input_0": 108, "input_1": 33, "min_CLP": -3.58, "draft_iters": 13.0, "mem_use": 33.85, "gen_rate": 6.8, "speed": 5.42, "text": "Here is a Python script that tak"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 64, "tree_h": 31.0, "tree_w": 1, "tree_size": 32, "t0": 2.11, "t1": 0.37, "tft": 1.937, "input_0": 140, "input_1": 33, "min_CLP": -3.72, "draft_iters": 31.5, "mem_use": 36.36, "gen_rate": 32.0, "speed": 12.92, "text": "## Vegetarian\\n Sausage, Peppers"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 18.0, "tree_w": 5, "tree_size": 32, "t0": 1.2767, "t1": 0.3733, "tft": 0.8833, "input_0": 108, "input_1": 33, "min_CLP": -4.84, "draft_iters": 18.7, "mem_use": 33.76, "gen_rate": 18.7, "speed": 11.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.8, "tree_w": 9, "tree_size": 32, "t0": 0.536, "t1": 0.32, "tft": 2.844, "input_0": 76, "input_1": 33, "min_CLP": -4.01, "draft_iters": 7.8, "mem_use": 36.05, "gen_rate": 6.6, "speed": 7.72, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.5757, "t1": 0.37, "tft": 0.8734, "input_0": 83, "input_1": 33, "min_CLP": -4.17, "draft_iters": 8.3, "mem_use": 33.77, "gen_rate": 5.0, "speed": 5.28, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 9, "tree_size": 32, "t0": 0.6, "t1": 0.35, "tft": 0.9075, "input_0": 88, "input_1": 33, "min_CLP": -4.19, "draft_iters": 8.7, "mem_use": 33.75, "gen_rate": 5.5, "speed": 5.8, "text": "The task is to translate the giv"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 0.686, "t1": 0.366, "tft": 1.0759, "input_0": 94, "input_1": 33, "min_CLP": -3.93, "draft_iters": 10.0, "mem_use": 33.91, "gen_rate": 6.4, "speed": 6.08, "text": "Sure, I can give an example of a"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.6167, "t1": 0.34, "tft": 1.634, "input_0": 89, "input_1": 33, "min_CLP": -3.77, "draft_iters": 9.0, "mem_use": 34.96, "gen_rate": 5.3, "speed": 5.59, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 13, "tree_h": 7.2, "tree_w": 12, "tree_size": 32, "t0": 0.5617, "t1": 0.34, "tft": 0.9825, "input_0": 68, "input_1": 33, "min_CLP": -4.45, "draft_iters": 8.2, "mem_use": 33.87, "gen_rate": 2.2, "speed": 2.4, "text": "The assistant will never generat"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.7, "tree_w": 7, "tree_size": 32, "t0": 0.6057, "t1": 0.3514, "tft": 1.0855, "input_0": 92, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.7, "mem_use": 34.07, "gen_rate": 4.6, "speed": 4.77, "text": "Sure, I can help you understand "}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.3, "tree_w": 11, "tree_size": 32, "t0": 0.4364, "t1": 0.3245, "tft": 1.3419, "input_0": 73, "input_1": 33, "min_CLP": -4.35, "draft_iters": 6.3, "mem_use": 34.41, "gen_rate": 3.0, "speed": 3.95, "text": "Selective fire refers to a weapo"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.555, "t1": 0.3462, "tft": 1.0041, "input_0": 90, "input_1": 33, "min_CLP": -4.42, "draft_iters": 8.0, "mem_use": 33.95, "gen_rate": 4.2, "speed": 4.72, "text": "\"I'm a goddess of love, beauty, "}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.0, "tree_w": 5, "tree_size": 32, "t0": 0.88, "t1": 0.3375, "tft": 1.6639, "input_0": 114, "input_1": 33, "min_CLP": -3.58, "draft_iters": 13.0, "mem_use": 35.17, "gen_rate": 8.8, "speed": 7.18, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 14.0, "tree_w": 11, "tree_size": 32, "t0": 0.99, "t1": 0.3433, "tft": 0.8459, "input_0": 80, "input_1": 33, "min_CLP": -4.59, "draft_iters": 14.7, "mem_use": 33.85, "gen_rate": 14.0, "speed": 10.52, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 11, "tree_size": 32, "t0": 0.5729, "t1": 0.3457, "tft": 1.5852, "input_0": 90, "input_1": 33, "min_CLP": -4.17, "draft_iters": 8.3, "mem_use": 34.68, "gen_rate": 4.6, "speed": 4.99, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 14.7, "tree_w": 10, "tree_size": 32, "t0": 1.04, "t1": 0.3633, "tft": 0.9489, "input_0": 77, "input_1": 33, "min_CLP": -4.61, "draft_iters": 15.3, "mem_use": 33.95, "gen_rate": 13.7, "speed": 9.73, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 16, "new_tokens": 32, "tree_h": 5.1, "tree_w": 11, "tree_size": 32, "t0": 0.4244, "t1": 0.3637, "tft": 1.1368, "input_0": 68, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.1, "mem_use": 33.78, "gen_rate": 2.0, "speed": 2.53, "text": "This task involves translating f"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.5683, "t1": 0.3383, "tft": 3.032, "input_0": 88, "input_1": 33, "min_CLP": -3.92, "draft_iters": 8.3, "mem_use": 38.07, "gen_rate": 5.7, "speed": 6.26, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 13.0, "tree_w": 10, "tree_size": 32, "t0": 0.9433, "t1": 0.35, "tft": 0.8746, "input_0": 85, "input_1": 33, "min_CLP": -4.58, "draft_iters": 14.0, "mem_use": 34.09, "gen_rate": 13.0, "speed": 10.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 0.684, "t1": 0.342, "tft": 1.8883, "input_0": 99, "input_1": 33, "min_CLP": -3.88, "draft_iters": 10.0, "mem_use": 34.96, "gen_rate": 7.0, "speed": 6.83, "text": "To estimate the time it would ta"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.0, "tree_w": 12, "tree_size": 32, "t0": 0.4788, "t1": 0.3212, "tft": 1.7566, "input_0": 73, "input_1": 33, "min_CLP": -4.35, "draft_iters": 7.0, "mem_use": 36.23, "gen_rate": 4.1, "speed": 5.16, "text": "Yes, to prevent spiders from spa"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.4, "tree_w": 13, "tree_size": 32, "t0": 0.4418, "t1": 0.3482, "tft": 1.2639, "input_0": 64, "input_1": 33, "min_CLP": -4.56, "draft_iters": 6.4, "mem_use": 34.07, "gen_rate": 3.1, "speed": 3.92, "text": "I heard that the best way to mak"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.41, "t1": 0.29, "tft": 0.9823, "input_0": 78, "input_1": 33, "min_CLP": -4.12, "draft_iters": 6.0, "mem_use": 34.11, "gen_rate": 1.0, "speed": 1.42, "text": "\"You're welcome!\""}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.3, "tree_w": 5, "tree_size": 32, "t0": 0.7733, "t1": 0.3217, "tft": 1.5149, "input_0": 113, "input_1": 33, "min_CLP": -3.56, "draft_iters": 11.3, "mem_use": 34.58, "gen_rate": 6.5, "speed": 5.92, "text": "Sure, here are three examples of"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 63, "tree_h": 22.5, "tree_w": 5, "tree_size": 32, "t0": 1.6, "t1": 0.3975, "tft": 1.7633, "input_0": 112, "input_1": 33, "min_CLP": -4.03, "draft_iters": 23.2, "mem_use": 34.09, "gen_rate": 15.8, "speed": 7.9, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.8, "tree_w": 8, "tree_size": 32, "t0": 0.5325, "t1": 0.3237, "tft": 1.599, "input_0": 80, "input_1": 33, "min_CLP": -4.2, "draft_iters": 7.8, "mem_use": 34.76, "gen_rate": 4.0, "speed": 4.66, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 45, "tree_h": 7.4, "tree_w": 10, "tree_size": 32, "t0": 0.5811, "t1": 0.3644, "tft": 0.89, "input_0": 82, "input_1": 33, "min_CLP": -4.17, "draft_iters": 8.4, "mem_use": 34.11, "gen_rate": 5.0, "speed": 5.28, "text": "\"Sure, here's a simple Braille s"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.5514, "t1": 0.3486, "tft": 0.8572, "input_0": 82, "input_1": 33, "min_CLP": -4.47, "draft_iters": 8.0, "mem_use": 33.83, "gen_rate": 4.9, "speed": 5.38, "text": "Reinforcement learning system th"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.7, "tree_w": 14, "tree_size": 32, "t0": 0.6714, "t1": 0.3714, "tft": 0.968, "input_0": 82, "input_1": 33, "min_CLP": -4.31, "draft_iters": 9.7, "mem_use": 33.79, "gen_rate": 4.6, "speed": 4.4, "text": "Detailed Instructions: You are g"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 22, "tree_h": 10.7, "tree_w": 5, "tree_size": 32, "t0": 0.7933, "t1": 0.3433, "tft": 2.6992, "input_0": 109, "input_1": 33, "min_CLP": -3.87, "draft_iters": 11.7, "mem_use": 38.05, "gen_rate": 7.3, "speed": 6.45, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 10, "tree_size": 32, "t0": 0.5629, "t1": 0.3557, "tft": 1.0042, "input_0": 92, "input_1": 33, "min_CLP": -4.22, "draft_iters": 8.1, "mem_use": 33.93, "gen_rate": 4.7, "speed": 5.13, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.8, "tree_w": 6, "tree_size": 32, "t0": 0.87, "t1": 0.346, "tft": 1.9435, "input_0": 106, "input_1": 33, "min_CLP": -3.86, "draft_iters": 12.8, "mem_use": 35.45, "gen_rate": 6.8, "speed": 5.58, "text": "To produce F-centers in carbon c"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 0.62, "t1": 0.3357, "tft": 1.6152, "input_0": 106, "input_1": 33, "min_CLP": -3.92, "draft_iters": 9.0, "mem_use": 35.22, "gen_rate": 4.6, "speed": 4.78, "text": "In option 2, which involves usin"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 12.7, "tree_w": 10, "tree_size": 32, "t0": 0.92, "t1": 0.3433, "tft": 0.8163, "input_0": 83, "input_1": 33, "min_CLP": -4.49, "draft_iters": 13.7, "mem_use": 34.06, "gen_rate": 12.3, "speed": 9.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.3, "tree_w": 11, "tree_size": 32, "t0": 0.97, "t1": 0.37, "tft": 1.033, "input_0": 89, "input_1": 33, "min_CLP": -4.75, "draft_iters": 14.3, "mem_use": 33.88, "gen_rate": 11.3, "speed": 8.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 14.7, "tree_w": 8, "tree_size": 32, "t0": 1.0433, "t1": 0.3567, "tft": 1.0795, "input_0": 101, "input_1": 33, "min_CLP": -4.66, "draft_iters": 15.3, "mem_use": 33.85, "gen_rate": 14.7, "speed": 10.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.4833, "t1": 0.3244, "tft": 1.4685, "input_0": 74, "input_1": 33, "min_CLP": -4.23, "draft_iters": 7.0, "mem_use": 34.85, "gen_rate": 3.7, "speed": 4.55, "text": "I\\'m sorry, but it\\'s not approp"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 7, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.4133, "t1": 0.33, "tft": 0.9008, "input_0": 62, "input_1": 33, "min_CLP": -4.74, "draft_iters": 6.0, "mem_use": 34.18, "gen_rate": 2.3, "speed": 3.14, "text": "\"Ok, let's have a dialogue.\""}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 12.2, "tree_w": 5, "tree_size": 32, "t0": 0.9038, "t1": 0.3488, "tft": 1.5572, "input_0": 96, "input_1": 33, "min_CLP": -4.28, "draft_iters": 13.2, "mem_use": 35.49, "gen_rate": 4.4, "speed": 3.49, "text": "meliss\u00eb, noun lover (fem.)\\nnild"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.6, "tree_w": 13, "tree_size": 32, "t0": 0.39, "t1": 0.3489, "tft": 1.2113, "input_0": 69, "input_1": 33, "min_CLP": -4.54, "draft_iters": 5.6, "mem_use": 34.42, "gen_rate": 3.9, "speed": 5.26, "text": "I think the answerer is reflecti"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 8, "tree_size": 32, "t0": 0.7175, "t1": 0.385, "tft": 0.885, "input_0": 99, "input_1": 33, "min_CLP": -4.27, "draft_iters": 10.5, "mem_use": 34.26, "gen_rate": 8.2, "speed": 7.49, "text": "The Bureau of Alcohol, Tobacco, "}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 0.6417, "t1": 0.3617, "tft": 0.8853, "input_0": 97, "input_1": 33, "min_CLP": -3.85, "draft_iters": 9.3, "mem_use": 34.0, "gen_rate": 6.2, "speed": 6.13, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 13.4, "tree_w": 6, "tree_size": 32, "t0": 0.9729, "t1": 0.3471, "tft": 2.09, "input_0": 102, "input_1": 33, "min_CLP": -3.72, "draft_iters": 14.4, "mem_use": 36.78, "gen_rate": 4.9, "speed": 3.68, "text": "\"Certainly, here's a revised ver"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 0.71, "t1": 0.3357, "tft": 3.3439, "input_0": 83, "input_1": 33, "min_CLP": -4.16, "draft_iters": 10.6, "mem_use": 36.72, "gen_rate": 4.9, "speed": 4.64, "text": "Once upon a time, in the fair ci"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 12, "tree_size": 32, "t0": 0.4771, "t1": 0.3714, "tft": 0.8204, "input_0": 71, "input_1": 33, "min_CLP": -4.44, "draft_iters": 6.9, "mem_use": 33.79, "gen_rate": 4.7, "speed": 5.55, "text": "\"Sure, I'd be happy to write you"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.2, "tree_w": 5, "tree_size": 32, "t0": 1.1625, "t1": 0.345, "tft": 1.2944, "input_0": 105, "input_1": 33, "min_CLP": -3.17, "draft_iters": 17.2, "mem_use": 34.95, "gen_rate": 9.2, "speed": 6.13, "text": "Certainly! Here\\'s an updated ve"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 9, "tree_size": 32, "t0": 0.5833, "t1": 0.34, "tft": 1.6166, "input_0": 85, "input_1": 33, "min_CLP": -3.88, "draft_iters": 8.5, "mem_use": 35.39, "gen_rate": 5.5, "speed": 5.95, "text": "\"I apologize for any confusion. "}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 6, "tree_size": 32, "t0": 0.8825, "t1": 0.4125, "tft": 1.0216, "input_0": 110, "input_1": 33, "min_CLP": -3.51, "draft_iters": 12.8, "mem_use": 33.77, "gen_rate": 8.2, "speed": 6.37, "text": "\"To normalize a vector, you need"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.425, "t1": 0.3658, "tft": 1.0391, "input_0": 67, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.1, "mem_use": 34.07, "gen_rate": 2.8, "speed": 3.58, "text": "\"I am not your slave, mortal. Do"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.688, "t1": 0.334, "tft": 2.046, "input_0": 102, "input_1": 33, "min_CLP": -3.8, "draft_iters": 10.0, "mem_use": 35.64, "gen_rate": 7.2, "speed": 7.03, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 0.64, "t1": 0.3657, "tft": 1.0778, "input_0": 91, "input_1": 33, "min_CLP": -4.03, "draft_iters": 9.3, "mem_use": 34.01, "gen_rate": 5.3, "speed": 5.25, "text": "The average computer does not ha"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.2, "tree_w": 9, "tree_size": 32, "t0": 0.765, "t1": 0.3425, "tft": 1.4537, "input_0": 94, "input_1": 33, "min_CLP": -4.02, "draft_iters": 11.2, "mem_use": 35.34, "gen_rate": 10.2, "speed": 9.28, "text": "\"Sure, I'll be happy to explain "}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 15, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.545, "t1": 0.3675, "tft": 1.0323, "input_0": 76, "input_1": 33, "min_CLP": -4.09, "draft_iters": 8.0, "mem_use": 33.81, "gen_rate": 3.8, "speed": 4.11, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.0, "tree_w": 7, "tree_size": 32, "t0": 0.75, "t1": 0.3425, "tft": 1.171, "input_0": 99, "input_1": 33, "min_CLP": -4.59, "draft_iters": 11.0, "mem_use": 33.81, "gen_rate": 9.0, "speed": 8.24, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.6, "tree_w": 9, "tree_size": 32, "t0": 0.5275, "t1": 0.3412, "tft": 1.1707, "input_0": 85, "input_1": 33, "min_CLP": -4.0, "draft_iters": 7.6, "mem_use": 34.45, "gen_rate": 4.0, "speed": 4.59, "text": "\"Alright, I'll do both! Here's m"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.5, "tree_w": 8, "tree_size": 32, "t0": 0.6533, "t1": 0.3583, "tft": 1.2214, "input_0": 89, "input_1": 33, "min_CLP": -3.91, "draft_iters": 9.5, "mem_use": 34.68, "gen_rate": 5.5, "speed": 5.43, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.622, "t1": 0.378, "tft": 1.2343, "input_0": 104, "input_1": 33, "min_CLP": -4.24, "draft_iters": 9.0, "mem_use": 33.79, "gen_rate": 6.6, "speed": 6.58, "text": "The AK-47, also known as the Kal"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 8.7, "tree_w": 6, "tree_size": 32, "t0": 0.6671, "t1": 0.3471, "tft": 0.9179, "input_0": 93, "input_1": 33, "min_CLP": -3.91, "draft_iters": 9.7, "mem_use": 34.14, "gen_rate": 6.3, "speed": 6.19, "text": "\"Here's an example command you c"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 19.7, "tree_w": 4, "tree_size": 32, "t0": 1.3933, "t1": 0.3767, "tft": 1.6293, "input_0": 118, "input_1": 33, "min_CLP": -3.48, "draft_iters": 20.7, "mem_use": 35.52, "gen_rate": 13.0, "speed": 7.33, "text": "1. Statistical modeling is the a"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 0.662, "t1": 0.37, "tft": 0.8894, "input_0": 93, "input_1": 33, "min_CLP": -4.11, "draft_iters": 9.6, "mem_use": 34.12, "gen_rate": 7.0, "speed": 6.78, "text": "To create a successful gaming so"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.6, "tree_w": 8, "tree_size": 32, "t0": 0.525, "t1": 0.3613, "tft": 1.3464, "input_0": 77, "input_1": 33, "min_CLP": -4.11, "draft_iters": 7.6, "mem_use": 34.62, "gen_rate": 4.1, "speed": 4.65, "text": "While it is not harmful for the "}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 4.8, "tree_w": 14, "tree_size": 32, "t0": 0.4045, "t1": 0.3445, "tft": 0.8545, "input_0": 60, "input_1": 33, "min_CLP": -4.68, "draft_iters": 5.8, "mem_use": 34.26, "gen_rate": 2.9, "speed": 3.89, "text": "Tell them that you will do somet"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 15.0, "tree_w": 9, "tree_size": 32, "t0": 1.08, "t1": 0.3667, "tft": 0.9598, "input_0": 84, "input_1": 33, "min_CLP": -4.28, "draft_iters": 16.0, "mem_use": 34.37, "gen_rate": 15.0, "speed": 10.35, "text": " [1, 2, 3, 4, 5, 6, 7, 8, 9, 10,"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 36, "tree_h": 5.2, "tree_w": 13, "tree_size": 32, "t0": 0.4362, "t1": 0.3577, "tft": 0.9082, "input_0": 70, "input_1": 33, "min_CLP": -4.47, "draft_iters": 6.2, "mem_use": 33.78, "gen_rate": 2.8, "speed": 3.49, "text": "\"I'm thinking of a variety of th"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 0.5957, "t1": 0.3614, "tft": 1.028, "input_0": 91, "input_1": 33, "min_CLP": -4.36, "draft_iters": 8.6, "mem_use": 33.78, "gen_rate": 5.6, "speed": 5.83, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 6.3, "tree_w": 10, "tree_size": 32, "t0": 0.508, "t1": 0.356, "tft": 1.1712, "input_0": 76, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.3, "mem_use": 34.32, "gen_rate": 3.2, "speed": 3.71, "text": "\"L-theanine is a natural substan"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 0.6188, "t1": 0.3588, "tft": 0.8165, "input_0": 88, "input_1": 33, "min_CLP": -3.91, "draft_iters": 9.0, "mem_use": 34.08, "gen_rate": 4.6, "speed": 4.73, "text": "Sure! Below is an example of HTM"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.9, "tree_w": 7, "tree_size": 32, "t0": 0.6813, "t1": 0.3512, "tft": 0.9323, "input_0": 87, "input_1": 33, "min_CLP": -4.16, "draft_iters": 9.9, "mem_use": 33.87, "gen_rate": 4.5, "speed": 4.36, "text": "To rewrite the phone conversatio"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 9, "tree_size": 32, "t0": 0.5617, "t1": 0.3533, "tft": 1.0607, "input_0": 83, "input_1": 33, "min_CLP": -3.88, "draft_iters": 8.2, "mem_use": 33.84, "gen_rate": 5.3, "speed": 5.82, "text": "\"The reason you can't see the st"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 37, "tree_h": 5.1, "tree_w": 14, "tree_size": 32, "t0": 0.4217, "t1": 0.3183, "tft": 1.2455, "input_0": 62, "input_1": 33, "min_CLP": -4.84, "draft_iters": 6.1, "mem_use": 34.4, "gen_rate": 3.1, "speed": 4.17, "text": "The image was chosen by Microsof"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.4786, "t1": 0.3186, "tft": 2.4361, "input_0": 75, "input_1": 33, "min_CLP": -4.1, "draft_iters": 7.0, "mem_use": 37.45, "gen_rate": 4.6, "speed": 5.72, "text": "\"It is not a good idea to use yo"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.5292, "t1": 0.3217, "tft": 1.8137, "input_0": 76, "input_1": 33, "min_CLP": -4.29, "draft_iters": 7.8, "mem_use": 36.2, "gen_rate": 2.9, "speed": 3.43, "text": "\"I understand your concern about"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 5.4, "tree_w": 11, "tree_size": 32, "t0": 0.4467, "t1": 0.32, "tft": 1.3512, "input_0": 74, "input_1": 33, "min_CLP": -4.41, "draft_iters": 6.4, "mem_use": 34.45, "gen_rate": 4.2, "speed": 5.49, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 17.7, "tree_w": 8, "tree_size": 32, "t0": 1.2533, "t1": 0.3833, "tft": 1.0288, "input_0": 94, "input_1": 33, "min_CLP": -4.55, "draft_iters": 18.3, "mem_use": 33.79, "gen_rate": 18.0, "speed": 10.99, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 23, "tree_h": 6.6, "tree_w": 9, "tree_size": 32, "t0": 0.528, "t1": 0.36, "tft": 0.9212, "input_0": 81, "input_1": 33, "min_CLP": -4.44, "draft_iters": 7.6, "mem_use": 33.78, "gen_rate": 4.6, "speed": 5.18, "text": "Yes, as an AI language model, I "}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 23, "tree_h": 23.0, "tree_w": 3, "tree_size": 32, "t0": 1.59, "t1": 0.38, "tft": 0.9592, "input_0": 94, "input_1": 33, "min_CLP": -3.93, "draft_iters": 24.0, "mem_use": 33.98, "gen_rate": 23.0, "speed": 11.7, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.54, "t1": 0.3256, "tft": 1.4272, "input_0": 85, "input_1": 33, "min_CLP": -4.14, "draft_iters": 7.8, "mem_use": 34.86, "gen_rate": 4.0, "speed": 4.64, "text": "To determine the number of acces"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 0.7433, "t1": 0.3367, "tft": 2.0074, "input_0": 101, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.8, "mem_use": 35.44, "gen_rate": 5.5, "speed": 5.1, "text": "\"Yes, you can use AI image gener"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.1, "tree_w": 13, "tree_size": 32, "t0": 0.4278, "t1": 0.3722, "tft": 0.8408, "input_0": 66, "input_1": 33, "min_CLP": -4.55, "draft_iters": 6.1, "mem_use": 33.84, "gen_rate": 3.6, "speed": 4.45, "text": "Sure, here are some haikus for d"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.2, "tree_w": 10, "tree_size": 32, "t0": 0.6387, "t1": 0.35, "tft": 1.4644, "input_0": 88, "input_1": 33, "min_CLP": -4.51, "draft_iters": 9.2, "mem_use": 34.2, "gen_rate": 4.0, "speed": 4.04, "text": "o\\n     /|\\\\\\n     / \\\\\\n[I\\'m s"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 17.0, "tree_w": 7, "tree_size": 32, "t0": 1.205, "t1": 0.355, "tft": 0.9458, "input_0": 106, "input_1": 33, "min_CLP": -4.55, "draft_iters": 18.0, "mem_use": 33.79, "gen_rate": 16.0, "speed": 10.24, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.2, "tree_w": 8, "tree_size": 32, "t0": 0.5688, "t1": 0.3325, "tft": 1.464, "input_0": 85, "input_1": 33, "min_CLP": -4.03, "draft_iters": 8.2, "mem_use": 34.15, "gen_rate": 4.4, "speed": 4.86, "text": "\"Yes, there are several ethical "}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 9, "tree_size": 32, "t0": 0.4957, "t1": 0.3214, "tft": 1.2313, "input_0": 94, "input_1": 33, "min_CLP": -4.03, "draft_iters": 7.1, "mem_use": 34.07, "gen_rate": 4.9, "speed": 5.95, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 20, "tree_h": 5.8, "tree_w": 9, "tree_size": 32, "t0": 0.47, "t1": 0.31, "tft": 1.8525, "input_0": 85, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.8, "mem_use": 36.12, "gen_rate": 3.3, "speed": 4.27, "text": "\"Alright, let's get started! Fir"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 41, "tree_h": 4.8, "tree_w": 19, "tree_size": 32, "t0": 0.401, "t1": 0.351, "tft": 0.7867, "input_0": 48, "input_1": 33, "min_CLP": -4.82, "draft_iters": 5.8, "mem_use": 33.95, "gen_rate": 4.1, "speed": 5.45, "text": "\"```\\n   _,-'__`-._\\n  /  _,-'__"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.1, "tree_w": 9, "tree_size": 32, "t0": 0.555, "t1": 0.3275, "tft": 2.0236, "input_0": 86, "input_1": 33, "min_CLP": -4.11, "draft_iters": 8.1, "mem_use": 36.81, "gen_rate": 4.1, "speed": 4.67, "text": "\"I'm sorry, but I cannot fulfill"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.1, "tree_w": 10, "tree_size": 32, "t0": 0.5663, "t1": 0.3712, "tft": 0.9075, "input_0": 82, "input_1": 33, "min_CLP": -4.39, "draft_iters": 8.1, "mem_use": 33.82, "gen_rate": 4.5, "speed": 4.8, "text": "\"Sure! Here's an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.5, "tree_w": 5, "tree_size": 32, "t0": 0.725, "t1": 0.35, "tft": 1.3162, "input_0": 106, "input_1": 33, "min_CLP": -3.72, "draft_iters": 10.5, "mem_use": 33.78, "gen_rate": 6.0, "speed": 5.58, "text": "HTML is a markup language used t"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.8, "tree_w": 4, "tree_size": 32, "t0": 1.0283, "t1": 0.39, "tft": 0.909, "input_0": 111, "input_1": 33, "min_CLP": -3.6, "draft_iters": 14.8, "mem_use": 33.81, "gen_rate": 6.7, "speed": 4.69, "text": "Sure, here is a table with the p"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.483, "t1": 0.336, "tft": 0.991, "input_0": 73, "input_1": 33, "min_CLP": -4.55, "draft_iters": 7.0, "mem_use": 34.18, "gen_rate": 3.7, "speed": 4.52, "text": "\"Charles O'Rear holds the copyri"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 8.2, "tree_w": 10, "tree_size": 32, "t0": 0.6346, "t1": 0.3423, "tft": 1.0309, "input_0": 86, "input_1": 33, "min_CLP": -4.17, "draft_iters": 9.2, "mem_use": 33.79, "gen_rate": 2.5, "speed": 2.52, "text": "Detailed Instructions: Classify "}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.0, "tree_w": 4, "tree_size": 32, "t0": 1.09, "t1": 0.3333, "tft": 2.0457, "input_0": 113, "input_1": 33, "min_CLP": -3.88, "draft_iters": 16.0, "mem_use": 34.85, "gen_rate": 10.7, "speed": 7.47, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.3, "tree_w": 13, "tree_size": 32, "t0": 0.3711, "t1": 0.31, "tft": 1.1004, "input_0": 68, "input_1": 33, "min_CLP": -4.4, "draft_iters": 5.3, "mem_use": 34.56, "gen_rate": 3.7, "speed": 5.39, "text": "\"In that case, you might conside"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 0.635, "t1": 0.337, "tft": 1.1411, "input_0": 89, "input_1": 33, "min_CLP": -4.08, "draft_iters": 9.2, "mem_use": 34.41, "gen_rate": 3.5, "speed": 3.6, "text": "\"Yes, that's true. If everyone j"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.6, "tree_w": 10, "tree_size": 32, "t0": 0.4575, "t1": 0.3175, "tft": 1.3316, "input_0": 77, "input_1": 33, "min_CLP": -4.21, "draft_iters": 6.6, "mem_use": 35.13, "gen_rate": 4.1, "speed": 5.32, "text": "\"Thank you for sharing your visi"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 5.0, "tree_w": 16, "tree_size": 32, "t0": 0.4173, "t1": 0.3564, "tft": 0.8149, "input_0": 60, "input_1": 33, "min_CLP": -4.61, "draft_iters": 6.0, "mem_use": 33.77, "gen_rate": 3.4, "speed": 4.35, "text": "\"Sure, here's an ASCII art of a "}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.6, "tree_w": 10, "tree_size": 32, "t0": 0.46, "t1": 0.341, "tft": 0.884, "input_0": 77, "input_1": 33, "min_CLP": -4.37, "draft_iters": 6.6, "mem_use": 34.09, "gen_rate": 3.6, "speed": 4.5, "text": "Of course! In Spanish-speaking c"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.55, "t1": 0.3425, "tft": 1.6949, "input_0": 83, "input_1": 33, "min_CLP": -4.26, "draft_iters": 8.0, "mem_use": 34.83, "gen_rate": 4.2, "speed": 4.77, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.1, "tree_w": 11, "tree_size": 32, "t0": 0.43, "t1": 0.3667, "tft": 1.0569, "input_0": 78, "input_1": 33, "min_CLP": -4.44, "draft_iters": 6.1, "mem_use": 33.89, "gen_rate": 4.1, "speed": 5.17, "text": "Motion Matching is an animation "}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.2, "tree_w": 3, "tree_size": 32, "t0": 1.3125, "t1": 0.3625, "tft": 2.5108, "input_0": 117, "input_1": 33, "min_CLP": -3.31, "draft_iters": 19.2, "mem_use": 35.51, "gen_rate": 10.5, "speed": 6.27, "text": "\"Sure, here's an updated version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 14.7, "tree_w": 8, "tree_size": 32, "t0": 1.04, "t1": 0.3533, "tft": 0.9232, "input_0": 90, "input_1": 33, "min_CLP": -4.6, "draft_iters": 15.3, "mem_use": 33.84, "gen_rate": 14.7, "speed": 10.53, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 12, "tree_size": 32, "t0": 0.5214, "t1": 0.3343, "tft": 1.0125, "input_0": 77, "input_1": 33, "min_CLP": -4.42, "draft_iters": 7.6, "mem_use": 34.22, "gen_rate": 4.6, "speed": 5.33, "text": "Sure, here\\'s a possible mnemoni"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.1, "tree_w": 11, "tree_size": 32, "t0": 0.49, "t1": 0.3267, "tft": 1.9552, "input_0": 71, "input_1": 33, "min_CLP": -4.26, "draft_iters": 7.1, "mem_use": 35.51, "gen_rate": 3.6, "speed": 4.37, "text": "The idea of 100 monkeys on a typ"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 0.515, "t1": 0.3125, "tft": 1.9096, "input_0": 86, "input_1": 33, "min_CLP": -4.26, "draft_iters": 7.5, "mem_use": 35.98, "gen_rate": 4.5, "speed": 5.43, "text": "Paul Allen has a variety of plan"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 11, "tree_size": 32, "t0": 0.4437, "t1": 0.3387, "tft": 1.7464, "input_0": 80, "input_1": 33, "min_CLP": -4.3, "draft_iters": 6.4, "mem_use": 35.39, "gen_rate": 4.0, "speed": 5.12, "text": "Yes, there is a similar case in "}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 8.4, "tree_w": 11, "tree_size": 32, "t0": 0.644, "t1": 0.366, "tft": 0.989, "input_0": 96, "input_1": 33, "min_CLP": -4.39, "draft_iters": 9.4, "mem_use": 33.87, "gen_rate": 7.4, "speed": 7.31, "text": "Romeo is most to blame for the e"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.9, "tree_w": 10, "tree_size": 32, "t0": 0.4778, "t1": 0.3556, "tft": 1.1747, "input_0": 77, "input_1": 33, "min_CLP": -4.22, "draft_iters": 6.9, "mem_use": 34.49, "gen_rate": 3.7, "speed": 4.4, "text": "As a large language model, I am "}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 9, "tree_size": 32, "t0": 0.575, "t1": 0.3617, "tft": 2.0349, "input_0": 82, "input_1": 33, "min_CLP": -4.23, "draft_iters": 8.3, "mem_use": 33.9, "gen_rate": 5.3, "speed": 5.69, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.3, "tree_w": 10, "tree_size": 32, "t0": 0.5056, "t1": 0.3456, "tft": 1.1054, "input_0": 79, "input_1": 33, "min_CLP": -4.42, "draft_iters": 7.3, "mem_use": 33.78, "gen_rate": 3.7, "speed": 4.3, "text": "Yes, the 5-second rule is a comm"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.0, "tree_w": 10, "tree_size": 32, "t0": 0.6175, "t1": 0.3437, "tft": 1.2872, "input_0": 82, "input_1": 33, "min_CLP": -4.19, "draft_iters": 9.0, "mem_use": 34.61, "gen_rate": 4.2, "speed": 4.42, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.8, "tree_w": 12, "tree_size": 32, "t0": 0.4667, "t1": 0.3256, "tft": 1.6768, "input_0": 73, "input_1": 33, "min_CLP": -4.31, "draft_iters": 6.8, "mem_use": 35.42, "gen_rate": 3.7, "speed": 4.63, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.5486, "t1": 0.32, "tft": 2.3135, "input_0": 93, "input_1": 33, "min_CLP": -4.39, "draft_iters": 8.0, "mem_use": 36.34, "gen_rate": 4.9, "speed": 5.59, "text": "Oh, the \"multi-track drifting\" s"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.68, "t1": 0.3417, "tft": 1.7347, "input_0": 88, "input_1": 33, "min_CLP": -4.02, "draft_iters": 10.0, "mem_use": 34.92, "gen_rate": 5.8, "speed": 5.69, "text": "\"It is theoretically possible to"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.12, "t1": 0.38, "tft": 2.1637, "input_0": 122, "input_1": 33, "min_CLP": -4.45, "draft_iters": 32.0, "mem_use": 34.76, "gen_rate": 33.0, "speed": 13.16, "text": "\"My love, you are the sun that s"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 8.0, "tree_w": 13, "tree_size": 32, "t0": 0.6156, "t1": 0.3244, "tft": 2.0338, "input_0": 74, "input_1": 33, "min_CLP": -4.55, "draft_iters": 9.0, "mem_use": 34.53, "gen_rate": 3.6, "speed": 3.79, "text": "In Japanese, \"love\" is \"\u611b (ai)\","}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.8, "tree_w": 8, "tree_size": 32, "t0": 0.675, "t1": 0.3583, "tft": 0.9627, "input_0": 96, "input_1": 33, "min_CLP": -4.21, "draft_iters": 9.8, "mem_use": 34.07, "gen_rate": 6.3, "speed": 6.12, "text": "In Europe, the best universities"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.49, "t1": 0.3557, "tft": 1.0358, "input_0": 83, "input_1": 33, "min_CLP": -3.97, "draft_iters": 7.0, "mem_use": 33.77, "gen_rate": 4.6, "speed": 5.42, "text": "\"The sky appears blue to us beca"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.6, "tree_w": 9, "tree_size": 32, "t0": 0.7412, "t1": 0.4188, "tft": 1.202, "input_0": 94, "input_1": 33, "min_CLP": -3.92, "draft_iters": 10.6, "mem_use": 33.9, "gen_rate": 4.4, "speed": 3.77, "text": "\"Here's a simple C++ function th"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.9, "tree_w": 10, "tree_size": 32, "t0": 0.6088, "t1": 0.3425, "tft": 1.3384, "input_0": 82, "input_1": 33, "min_CLP": -4.47, "draft_iters": 8.9, "mem_use": 35.02, "gen_rate": 4.4, "speed": 4.59, "text": "1. Financial stress: \\n    - Cre"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.5317, "t1": 0.3617, "tft": 0.8971, "input_0": 93, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.7, "mem_use": 33.77, "gen_rate": 5.8, "speed": 6.51, "text": "As an AI language model, I don\\'"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 0.73, "t1": 0.3275, "tft": 1.8947, "input_0": 97, "input_1": 33, "min_CLP": -3.66, "draft_iters": 10.8, "mem_use": 36.43, "gen_rate": 8.5, "speed": 8.06, "text": "One example where you might use "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.5529, "t1": 0.3457, "tft": 0.8771, "input_0": 98, "input_1": 33, "min_CLP": -4.37, "draft_iters": 8.0, "mem_use": 34.05, "gen_rate": 4.9, "speed": 5.41, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 25, "tree_h": 5.3, "tree_w": 12, "tree_size": 32, "t0": 0.438, "t1": 0.359, "tft": 1.2692, "input_0": 66, "input_1": 33, "min_CLP": -4.59, "draft_iters": 6.3, "mem_use": 33.84, "gen_rate": 2.5, "speed": 3.13, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 0.6157, "t1": 0.32, "tft": 1.8591, "input_0": 84, "input_1": 33, "min_CLP": -3.93, "draft_iters": 9.0, "mem_use": 36.04, "gen_rate": 5.1, "speed": 5.5, "text": "Here are some open-source AI too"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 6, "tree_size": 32, "t0": 0.95, "t1": 0.33, "tft": 1.245, "input_0": 120, "input_1": 33, "min_CLP": -3.38, "draft_iters": 14.0, "mem_use": 33.84, "gen_rate": 10.7, "speed": 8.33, "text": "To use software-defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 37, "tree_h": 4.9, "tree_w": 13, "tree_size": 32, "t0": 0.4073, "t1": 0.3109, "tft": 1.4242, "input_0": 69, "input_1": 33, "min_CLP": -4.46, "draft_iters": 5.9, "mem_use": 34.54, "gen_rate": 3.4, "speed": 4.68, "text": "Again, no. \\n\\nThe same basic et"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 9.9, "tree_w": 7, "tree_size": 32, "t0": 0.7412, "t1": 0.3287, "tft": 1.7016, "input_0": 84, "input_1": 33, "min_CLP": -4.42, "draft_iters": 10.9, "mem_use": 35.4, "gen_rate": 4.9, "speed": 4.56, "text": "1. m\u00eb (pronounced \"me\")\\n2. mele"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.6, "tree_w": 10, "tree_size": 32, "t0": 0.5325, "t1": 0.36, "tft": 1.1532, "input_0": 83, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.6, "mem_use": 34.09, "gen_rate": 4.5, "speed": 5.06, "text": "As an AI language model, my prim"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 9, "tree_size": 32, "t0": 0.48, "t1": 0.3175, "tft": 2.159, "input_0": 76, "input_1": 33, "min_CLP": -4.2, "draft_iters": 7.0, "mem_use": 36.84, "gen_rate": 4.0, "speed": 5.03, "text": "I apologize for the confusion in"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.5757, "t1": 0.3586, "tft": 0.9475, "input_0": 91, "input_1": 33, "min_CLP": -4.02, "draft_iters": 8.3, "mem_use": 33.8, "gen_rate": 5.1, "speed": 5.51, "text": "\"In reStructuredText (RST), you "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 5, "tree_size": 32, "t0": 0.8025, "t1": 0.3375, "tft": 1.8379, "input_0": 106, "input_1": 33, "min_CLP": -3.63, "draft_iters": 11.8, "mem_use": 35.79, "gen_rate": 8.0, "speed": 7.02, "text": "\"Here's an example code for crea"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 5.9, "tree_w": 13, "tree_size": 32, "t0": 0.4808, "t1": 0.3583, "tft": 1.3503, "input_0": 75, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.9, "mem_use": 33.78, "gen_rate": 2.8, "speed": 3.38, "text": "This task is about translating a"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.9, "tree_w": 13, "tree_size": 32, "t0": 0.4043, "t1": 0.3257, "tft": 0.8175, "input_0": 62, "input_1": 33, "min_CLP": -4.66, "draft_iters": 5.9, "mem_use": 34.23, "gen_rate": 4.6, "speed": 6.26, "text": "\"Yes and no. AI assistants can r"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 7.0, "tree_w": 11, "tree_size": 32, "t0": 0.5355, "t1": 0.3255, "tft": 2.9963, "input_0": 70, "input_1": 33, "min_CLP": -4.17, "draft_iters": 8.0, "mem_use": 39.36, "gen_rate": 3.0, "speed": 3.48, "text": "\"Yes, I will be happy to do so! "}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.9, "tree_w": 10, "tree_size": 32, "t0": 0.4744, "t1": 0.3156, "tft": 1.3172, "input_0": 77, "input_1": 33, "min_CLP": -4.25, "draft_iters": 6.9, "mem_use": 34.61, "gen_rate": 3.9, "speed": 4.95, "text": "\"0 an independent counsel is a p"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.42, "t1": 0.315, "tft": 2.0269, "input_0": 71, "input_1": 33, "min_CLP": -4.38, "draft_iters": 6.1, "mem_use": 36.46, "gen_rate": 4.1, "speed": 5.6, "text": "I understand that you may have a"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.9, "tree_w": 11, "tree_size": 32, "t0": 0.4078, "t1": 0.33, "tft": 1.2146, "input_0": 65, "input_1": 33, "min_CLP": -4.5, "draft_iters": 5.9, "mem_use": 34.83, "gen_rate": 3.7, "speed": 4.96, "text": "1. Change in customer behavior o"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 20.0, "tree_w": 6, "tree_size": 32, "t0": 1.38, "t1": 0.37, "tft": 0.8271, "input_0": 97, "input_1": 33, "min_CLP": -4.2, "draft_iters": 20.5, "mem_use": 34.11, "gen_rate": 19.5, "speed": 11.16, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.8, "tree_w": 5, "tree_size": 32, "t0": 0.802, "t1": 0.334, "tft": 2.7158, "input_0": 91, "input_1": 33, "min_CLP": -3.51, "draft_iters": 11.8, "mem_use": 36.58, "gen_rate": 6.6, "speed": 5.81, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 8, "tree_size": 32, "t0": 0.6417, "t1": 0.3467, "tft": 0.9962, "input_0": 90, "input_1": 33, "min_CLP": -3.89, "draft_iters": 9.3, "mem_use": 34.3, "gen_rate": 5.5, "speed": 5.57, "text": "\"To determine the most cost-effe"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.5463, "t1": 0.31, "tft": 2.5707, "input_0": 85, "input_1": 33, "min_CLP": -3.98, "draft_iters": 8.0, "mem_use": 36.27, "gen_rate": 4.6, "speed": 5.39, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.577, "t1": 0.368, "tft": 1.1483, "input_0": 84, "input_1": 33, "min_CLP": -4.52, "draft_iters": 8.3, "mem_use": 33.82, "gen_rate": 3.6, "speed": 3.81, "text": "```lean\\nimport data.array.basic"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 4.8, "tree_w": 13, "tree_size": 32, "t0": 0.4, "t1": 0.3317, "tft": 1.3349, "input_0": 68, "input_1": 33, "min_CLP": -4.46, "draft_iters": 5.8, "mem_use": 34.54, "gen_rate": 2.8, "speed": 3.85, "text": "The law regarding public nudity "}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.6, "t1": 0.3217, "tft": 0.9221, "input_0": 94, "input_1": 33, "min_CLP": -4.05, "draft_iters": 8.7, "mem_use": 34.26, "gen_rate": 5.3, "speed": 5.79, "text": "To alleviate your symptoms after"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.3, "tree_w": 7, "tree_size": 32, "t0": 0.775, "t1": 0.345, "tft": 0.923, "input_0": 98, "input_1": 33, "min_CLP": -3.88, "draft_iters": 11.3, "mem_use": 33.86, "gen_rate": 5.3, "speed": 4.77, "text": "Here is an example of how you co"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 7.2, "tree_w": 9, "tree_size": 32, "t0": 0.564, "t1": 0.318, "tft": 1.4268, "input_0": 88, "input_1": 33, "min_CLP": -4.14, "draft_iters": 8.2, "mem_use": 34.74, "gen_rate": 3.4, "speed": 3.86, "text": "\"It's natural to feel that way, "}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 12.8, "tree_w": 7, "tree_size": 32, "t0": 0.925, "t1": 0.33, "tft": 2.5104, "input_0": 106, "input_1": 33, "min_CLP": -4.32, "draft_iters": 13.8, "mem_use": 36.34, "gen_rate": 10.2, "speed": 8.16, "text": "Sure! Here is a list of some of "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.8, "tree_w": 7, "tree_size": 32, "t0": 0.742, "t1": 0.326, "tft": 1.0727, "input_0": 98, "input_1": 33, "min_CLP": -3.71, "draft_iters": 10.8, "mem_use": 33.98, "gen_rate": 6.8, "speed": 6.39, "text": "The total travel time is 8 hours"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 5, "tree_size": 32, "t0": 0.8275, "t1": 0.3425, "tft": 1.1825, "input_0": 118, "input_1": 33, "min_CLP": -3.64, "draft_iters": 12.0, "mem_use": 33.89, "gen_rate": 8.2, "speed": 7.04, "text": "\"```javascript\\nconst { Client, "}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 6.3, "tree_w": 11, "tree_size": 32, "t0": 0.5117, "t1": 0.3333, "tft": 0.9646, "input_0": 84, "input_1": 33, "min_CLP": -4.47, "draft_iters": 7.3, "mem_use": 33.78, "gen_rate": 4.0, "speed": 4.75, "text": "Yes, I am capable of assisting y"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.8, "tree_w": 9, "tree_size": 32, "t0": 0.5262, "t1": 0.32, "tft": 2.6403, "input_0": 78, "input_1": 33, "min_CLP": -4.16, "draft_iters": 7.8, "mem_use": 37.56, "gen_rate": 4.0, "speed": 4.73, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 16.5, "tree_w": 6, "tree_size": 32, "t0": 1.17, "t1": 0.355, "tft": 1.1114, "input_0": 90, "input_1": 33, "min_CLP": -3.88, "draft_iters": 17.5, "mem_use": 33.9, "gen_rate": 16.0, "speed": 10.51, "text": "\"Mike's mother had four kids. Th"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.11, "t1": 0.39, "tft": 1.4791, "input_0": 122, "input_1": 33, "min_CLP": -3.8, "draft_iters": 32.0, "mem_use": 34.93, "gen_rate": 33.0, "speed": 13.18, "text": "The best way to farm experience "}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.1, "tree_w": 9, "tree_size": 32, "t0": 0.5563, "t1": 0.3175, "tft": 2.1312, "input_0": 88, "input_1": 33, "min_CLP": -4.07, "draft_iters": 8.1, "mem_use": 36.7, "gen_rate": 4.0, "speed": 4.59, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 0.5175, "t1": 0.3263, "tft": 0.8706, "input_0": 77, "input_1": 33, "min_CLP": -4.23, "draft_iters": 7.5, "mem_use": 34.03, "gen_rate": 4.2, "speed": 5.03, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.5733, "t1": 0.315, "tft": 1.2222, "input_0": 90, "input_1": 33, "min_CLP": -4.23, "draft_iters": 8.3, "mem_use": 34.54, "gen_rate": 5.5, "speed": 6.19, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.6783, "t1": 0.3183, "tft": 2.0579, "input_0": 99, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.0, "mem_use": 36.27, "gen_rate": 6.2, "speed": 6.16, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.4, "tree_w": 9, "tree_size": 32, "t0": 0.65, "t1": 0.356, "tft": 1.4777, "input_0": 92, "input_1": 33, "min_CLP": -4.11, "draft_iters": 9.4, "mem_use": 34.66, "gen_rate": 6.4, "speed": 6.37, "text": "The television was invented by P"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 21, "tree_h": 8.7, "tree_w": 7, "tree_size": 32, "t0": 0.66, "t1": 0.3167, "tft": 2.2116, "input_0": 96, "input_1": 33, "min_CLP": -3.68, "draft_iters": 9.7, "mem_use": 36.98, "gen_rate": 7.0, "speed": 7.17, "text": "\"I'm glad I could help. If you h"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.5383, "t1": 0.315, "tft": 1.6918, "input_0": 77, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.8, "mem_use": 35.32, "gen_rate": 5.3, "speed": 6.24, "text": "There are multiple days in which"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.4, "tree_w": 11, "tree_size": 32, "t0": 0.5157, "t1": 0.3157, "tft": 1.2206, "input_0": 88, "input_1": 33, "min_CLP": -4.38, "draft_iters": 7.4, "mem_use": 34.35, "gen_rate": 5.1, "speed": 6.19, "text": "Understood. I apologize for my p"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.2, "tree_w": 6, "tree_size": 32, "t0": 0.695, "t1": 0.3225, "tft": 2.2144, "input_0": 97, "input_1": 33, "min_CLP": -3.83, "draft_iters": 10.2, "mem_use": 36.16, "gen_rate": 8.5, "speed": 8.35, "text": "One of the most difficult parts "}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.8, "tree_w": 8, "tree_size": 32, "t0": 0.6717, "t1": 0.3267, "tft": 0.9266, "input_0": 93, "input_1": 33, "min_CLP": -3.92, "draft_iters": 9.8, "mem_use": 33.97, "gen_rate": 6.2, "speed": 6.18, "text": "Yes, it is possible for you to o"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.5, "tree_w": 9, "tree_size": 32, "t0": 0.6475, "t1": 0.33, "tft": 1.4084, "input_0": 72, "input_1": 33, "min_CLP": -4.27, "draft_iters": 9.5, "mem_use": 34.6, "gen_rate": 4.1, "speed": 4.23, "text": "Certainly! Here\\'s an alternativ"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 12.4, "tree_w": 8, "tree_size": 32, "t0": 0.92, "t1": 0.3771, "tft": 1.8824, "input_0": 84, "input_1": 33, "min_CLP": -4.64, "draft_iters": 13.4, "mem_use": 34.07, "gen_rate": 4.9, "speed": 3.75, "text": "\"[INST] Hey, I'm a broke college"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 0.676, "t1": 0.38, "tft": 0.8422, "input_0": 92, "input_1": 33, "min_CLP": -3.8, "draft_iters": 9.8, "mem_use": 34.08, "gen_rate": 8.0, "speed": 7.56, "text": "The black hole at the center of "}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.4138, "t1": 0.325, "tft": 1.3837, "input_0": 67, "input_1": 33, "min_CLP": -4.46, "draft_iters": 6.0, "mem_use": 34.47, "gen_rate": 4.0, "speed": 5.39, "text": "Google Authenticator is a 2FA ap"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.2, "tree_w": 7, "tree_size": 32, "t0": 0.6967, "t1": 0.3233, "tft": 1.5277, "input_0": 100, "input_1": 33, "min_CLP": -4.01, "draft_iters": 10.2, "mem_use": 34.25, "gen_rate": 5.8, "speed": 5.72, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.8, "tree_w": 7, "tree_size": 32, "t0": 0.614, "t1": 0.32, "tft": 0.8946, "input_0": 104, "input_1": 33, "min_CLP": -4.1, "draft_iters": 8.8, "mem_use": 34.01, "gen_rate": 7.0, "speed": 7.49, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.55, "t1": 0.3217, "tft": 0.9212, "input_0": 90, "input_1": 33, "min_CLP": -4.11, "draft_iters": 8.0, "mem_use": 33.87, "gen_rate": 5.3, "speed": 6.1, "text": "To improve your Wi-Fi coverage i"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.4, "tree_w": 9, "tree_size": 32, "t0": 0.848, "t1": 0.34, "tft": 0.9269, "input_0": 102, "input_1": 33, "min_CLP": -4.23, "draft_iters": 12.4, "mem_use": 33.9, "gen_rate": 8.4, "speed": 7.07, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.3, "tree_w": 7, "tree_size": 32, "t0": 0.64, "t1": 0.3429, "tft": 1.2467, "input_0": 81, "input_1": 33, "min_CLP": -4.09, "draft_iters": 9.3, "mem_use": 33.81, "gen_rate": 4.7, "speed": 4.81, "text": "Here is a draft whitepaper for y"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.8, "tree_w": 6, "tree_size": 32, "t0": 0.8733, "t1": 0.3317, "tft": 1.3227, "input_0": 101, "input_1": 33, "min_CLP": -3.96, "draft_iters": 12.8, "mem_use": 34.99, "gen_rate": 5.7, "speed": 4.7, "text": "You can use the scp (secure copy"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.5, "tree_w": 11, "tree_size": 32, "t0": 0.45, "t1": 0.3137, "tft": 1.0969, "input_0": 74, "input_1": 33, "min_CLP": -4.26, "draft_iters": 6.5, "mem_use": 33.77, "gen_rate": 4.0, "speed": 5.24, "text": "The \"@\" symbol in Python is used"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 0.63, "t1": 0.3283, "tft": 1.234, "input_0": 86, "input_1": 33, "min_CLP": -4.05, "draft_iters": 9.2, "mem_use": 33.78, "gen_rate": 6.5, "speed": 6.77, "text": "\"I am an AI language model, I do"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 0.62, "t1": 0.3271, "tft": 1.022, "input_0": 86, "input_1": 33, "min_CLP": -4.18, "draft_iters": 9.0, "mem_use": 34.09, "gen_rate": 5.3, "speed": 5.6, "text": "\"As an AI language model, I do n"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 5.5, "tree_w": 10, "tree_size": 32, "t0": 0.45, "t1": 0.315, "tft": 0.8462, "input_0": 85, "input_1": 33, "min_CLP": -4.57, "draft_iters": 6.5, "mem_use": 33.82, "gen_rate": 2.5, "speed": 3.26, "text": "Hello, how are you doing today?"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 58, "tree_h": 28.0, "tree_w": 2, "tree_size": 32, "t0": 1.92, "t1": 0.395, "tft": 1.4196, "input_0": 134, "input_1": 33, "min_CLP": -3.3, "draft_iters": 28.5, "mem_use": 34.51, "gen_rate": 29.0, "speed": 12.54, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 8, "tree_size": 32, "t0": 0.69, "t1": 0.318, "tft": 2.5676, "input_0": 87, "input_1": 33, "min_CLP": -4.38, "draft_iters": 10.2, "mem_use": 37.01, "gen_rate": 6.6, "speed": 6.56, "text": "The following are some of the qu"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 0.7583, "t1": 0.3267, "tft": 1.213, "input_0": 102, "input_1": 33, "min_CLP": -4.17, "draft_iters": 11.2, "mem_use": 34.32, "gen_rate": 5.3, "speed": 4.9, "text": "Yes, there are several things th"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.2, "tree_w": 11, "tree_size": 32, "t0": 0.4333, "t1": 0.3322, "tft": 1.4072, "input_0": 78, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.2, "mem_use": 35.43, "gen_rate": 3.8, "speed": 4.94, "text": "Hello, Agent. It is a pleasure t"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 15, "tree_h": 8.9, "tree_w": 11, "tree_size": 32, "t0": 0.6757, "t1": 0.3729, "tft": 1.4649, "input_0": 76, "input_1": 33, "min_CLP": -4.52, "draft_iters": 9.9, "mem_use": 34.31, "gen_rate": 2.1, "speed": 2.04, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 11.7, "tree_w": 6, "tree_size": 32, "t0": 0.8586, "t1": 0.3443, "tft": 2.5164, "input_0": 101, "input_1": 33, "min_CLP": -3.78, "draft_iters": 12.7, "mem_use": 37.19, "gen_rate": 5.7, "speed": 4.75, "text": "Sure! Here are some examples of "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.3, "tree_w": 4, "tree_size": 32, "t0": 0.8967, "t1": 0.3667, "tft": 5.2947, "input_0": 110, "input_1": 33, "min_CLP": -3.79, "draft_iters": 13.3, "mem_use": 43.19, "gen_rate": 10.7, "speed": 8.44, "text": "\"Sure, here's some example code "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.2, "tree_w": 6, "tree_size": 32, "t0": 0.964, "t1": 0.37, "tft": 1.8122, "input_0": 97, "input_1": 33, "min_CLP": -3.88, "draft_iters": 14.2, "mem_use": 35.54, "gen_rate": 7.8, "speed": 5.85, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 7, "tree_size": 32, "t0": 0.5943, "t1": 0.3486, "tft": 0.8472, "input_0": 92, "input_1": 33, "min_CLP": -4.04, "draft_iters": 8.6, "mem_use": 33.83, "gen_rate": 4.9, "speed": 5.15, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 10.0, "tree_w": 7, "tree_size": 32, "t0": 0.7587, "t1": 0.3887, "tft": 0.8864, "input_0": 99, "input_1": 33, "min_CLP": -3.99, "draft_iters": 11.0, "mem_use": 33.94, "gen_rate": 4.5, "speed": 3.92, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 10, "tree_size": 32, "t0": 0.5767, "t1": 0.3283, "tft": 2.2124, "input_0": 87, "input_1": 33, "min_CLP": -4.32, "draft_iters": 8.5, "mem_use": 36.71, "gen_rate": 5.3, "speed": 5.88, "text": "Sure, I can help you come up wit"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.4867, "t1": 0.3683, "tft": 1.246, "input_0": 81, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.0, "mem_use": 33.88, "gen_rate": 5.5, "speed": 6.42, "text": "In 1950, the world was vastly di"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 6, "tree_size": 32, "t0": 0.6333, "t1": 0.3317, "tft": 3.071, "input_0": 96, "input_1": 33, "min_CLP": -3.77, "draft_iters": 9.3, "mem_use": 38.85, "gen_rate": 5.5, "speed": 5.7, "text": "\"Creating your own stable diffus"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.8, "tree_w": 6, "tree_size": 32, "t0": 0.876, "t1": 0.368, "tft": 0.8442, "input_0": 103, "input_1": 33, "min_CLP": -4.09, "draft_iters": 12.8, "mem_use": 34.22, "gen_rate": 7.4, "speed": 5.94, "text": "1. Install the CPU\\n2. Install t"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.6, "tree_w": 9, "tree_size": 32, "t0": 0.5338, "t1": 0.3675, "tft": 1.243, "input_0": 86, "input_1": 33, "min_CLP": -4.16, "draft_iters": 7.6, "mem_use": 34.07, "gen_rate": 4.5, "speed": 5.0, "text": "\"Carnegie Mellon University (CMU"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.7, "tree_w": 10, "tree_size": 32, "t0": 0.4678, "t1": 0.3622, "tft": 0.9166, "input_0": 80, "input_1": 33, "min_CLP": -4.41, "draft_iters": 6.7, "mem_use": 34.14, "gen_rate": 3.7, "speed": 4.43, "text": "I am an AI assistant designed to"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.6, "tree_w": 8, "tree_size": 32, "t0": 0.5914, "t1": 0.3343, "tft": 1.7605, "input_0": 91, "input_1": 33, "min_CLP": -4.03, "draft_iters": 8.6, "mem_use": 35.48, "gen_rate": 5.3, "speed": 5.72, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.9, "tree_w": 11, "tree_size": 32, "t0": 0.5457, "t1": 0.3729, "tft": 0.9278, "input_0": 77, "input_1": 33, "min_CLP": -4.41, "draft_iters": 7.9, "mem_use": 34.2, "gen_rate": 5.1, "speed": 5.6, "text": "\"The Keyhole series of spy satel"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 7.9, "tree_w": 9, "tree_size": 32, "t0": 0.6156, "t1": 0.3611, "tft": 1.0344, "input_0": 88, "input_1": 33, "min_CLP": -4.23, "draft_iters": 8.9, "mem_use": 34.38, "gen_rate": 3.8, "speed": 3.88, "text": "\"Sure! Based on your available i"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.1, "tree_w": 9, "tree_size": 32, "t0": 0.6343, "t1": 0.3743, "tft": 1.379, "input_0": 105, "input_1": 33, "min_CLP": -4.01, "draft_iters": 9.1, "mem_use": 34.44, "gen_rate": 5.0, "speed": 4.97, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 33, "tree_h": 6.1, "tree_w": 10, "tree_size": 32, "t0": 0.4858, "t1": 0.3208, "tft": 1.9923, "input_0": 76, "input_1": 33, "min_CLP": -4.31, "draft_iters": 7.1, "mem_use": 36.36, "gen_rate": 2.8, "speed": 3.4, "text": "Here are some YouTube channels t"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.2, "tree_w": 9, "tree_size": 32, "t0": 0.57, "t1": 0.3788, "tft": 1.1443, "input_0": 88, "input_1": 33, "min_CLP": -4.29, "draft_iters": 8.2, "mem_use": 33.78, "gen_rate": 4.2, "speed": 4.48, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 48, "tree_h": 10.6, "tree_w": 7, "tree_size": 32, "t0": 0.794, "t1": 0.36, "tft": 0.8802, "input_0": 103, "input_1": 33, "min_CLP": -4.09, "draft_iters": 11.6, "mem_use": 33.93, "gen_rate": 9.6, "speed": 8.31, "text": "The correct answer is (A B)^T = "}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.1, "tree_w": 11, "tree_size": 32, "t0": 0.425, "t1": 0.33, "tft": 1.4665, "input_0": 73, "input_1": 33, "min_CLP": -4.65, "draft_iters": 6.1, "mem_use": 35.35, "gen_rate": 4.0, "speed": 5.3, "text": "\"Verse 1:\\nStatistical modeling,"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 1, "tree_size": 32, "t0": 2.12, "t1": 0.38, "tft": 3.428, "input_0": 135, "input_1": 33, "min_CLP": -3.68, "draft_iters": 32.0, "mem_use": 36.52, "gen_rate": 33.0, "speed": 13.2, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 15, "tree_h": 5.5, "tree_w": 11, "tree_size": 32, "t0": 0.4475, "t1": 0.345, "tft": 1.1772, "input_0": 69, "input_1": 33, "min_CLP": -4.28, "draft_iters": 6.5, "mem_use": 33.77, "gen_rate": 3.8, "speed": 4.7, "text": "The current date is [insert curr"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 10, "tree_size": 32, "t0": 0.5886, "t1": 0.32, "tft": 1.6644, "input_0": 97, "input_1": 33, "min_CLP": -4.22, "draft_iters": 8.6, "mem_use": 35.24, "gen_rate": 4.7, "speed": 5.18, "text": "Yes, that\\'s another great strat"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.5, "tree_w": 13, "tree_size": 32, "t0": 0.3791, "t1": 0.3391, "tft": 0.8972, "input_0": 63, "input_1": 33, "min_CLP": -4.56, "draft_iters": 5.5, "mem_use": 34.13, "gen_rate": 3.1, "speed": 4.3, "text": "\"Dude, that's so not true! Techn"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.0, "tree_w": 6, "tree_size": 32, "t0": 0.82, "t1": 0.3525, "tft": 1.0928, "input_0": 115, "input_1": 33, "min_CLP": -3.84, "draft_iters": 12.0, "mem_use": 33.82, "gen_rate": 9.0, "speed": 7.68, "text": "Yes, I can help you with that. E"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.0, "tree_w": 10, "tree_size": 32, "t0": 0.6214, "t1": 0.3671, "tft": 0.9179, "input_0": 81, "input_1": 33, "min_CLP": -4.24, "draft_iters": 9.0, "mem_use": 34.17, "gen_rate": 5.0, "speed": 5.06, "text": "Sure, I can help you find that r"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 64, "tree_h": 20.7, "tree_w": 5, "tree_size": 32, "t0": 1.45, "t1": 0.3767, "tft": 0.8993, "input_0": 128, "input_1": 33, "min_CLP": -4.32, "draft_iters": 21.3, "mem_use": 33.76, "gen_rate": 21.3, "speed": 11.67, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.0, "tree_w": 7, "tree_size": 32, "t0": 0.6171, "t1": 0.3386, "tft": 1.3649, "input_0": 99, "input_1": 33, "min_CLP": -3.9, "draft_iters": 9.0, "mem_use": 35.09, "gen_rate": 5.1, "speed": 5.37, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 10, "tree_h": 8.0, "tree_w": 6, "tree_size": 32, "t0": 0.6167, "t1": 0.3567, "tft": 1.0054, "input_0": 85, "input_1": 33, "min_CLP": -4.16, "draft_iters": 9.0, "mem_use": 33.95, "gen_rate": 3.3, "speed": 3.42, "text": "\"The answer is: The answer is: J"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.8, "tree_w": 5, "tree_size": 32, "t0": 0.814, "t1": 0.366, "tft": 1.0158, "input_0": 107, "input_1": 33, "min_CLP": -3.76, "draft_iters": 11.8, "mem_use": 34.34, "gen_rate": 7.2, "speed": 6.11, "text": "The largest ocean in the world i"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.6, "tree_w": 10, "tree_size": 32, "t0": 0.5211, "t1": 0.3489, "tft": 1.1865, "input_0": 79, "input_1": 33, "min_CLP": -4.26, "draft_iters": 7.6, "mem_use": 34.57, "gen_rate": 3.7, "speed": 4.21, "text": "One way to get started is to loo"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 13.0, "tree_w": 4, "tree_size": 32, "t0": 0.9625, "t1": 0.38, "tft": 1.074, "input_0": 111, "input_1": 33, "min_CLP": -3.41, "draft_iters": 14.0, "mem_use": 33.99, "gen_rate": 10.2, "speed": 7.62, "text": "Here is an example of a basic Py"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.4, "tree_w": 10, "tree_size": 32, "t0": 0.5143, "t1": 0.3329, "tft": 1.5553, "input_0": 87, "input_1": 33, "min_CLP": -4.29, "draft_iters": 7.4, "mem_use": 35.08, "gen_rate": 4.9, "speed": 5.72, "text": "A DLL (Dynamic Link Library) is "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 10, "tree_size": 32, "t0": 0.4586, "t1": 0.3557, "tft": 1.0629, "input_0": 80, "input_1": 33, "min_CLP": -4.43, "draft_iters": 6.6, "mem_use": 34.23, "gen_rate": 4.6, "speed": 5.61, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.7, "tree_w": 13, "tree_size": 32, "t0": 0.3978, "t1": 0.3567, "tft": 1.0193, "input_0": 65, "input_1": 33, "min_CLP": -4.52, "draft_iters": 5.7, "mem_use": 33.77, "gen_rate": 3.6, "speed": 4.72, "text": "\"The Infinite Banking Concept (I"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.4, "tree_w": 7, "tree_size": 32, "t0": 0.78, "t1": 0.388, "tft": 0.8581, "input_0": 91, "input_1": 33, "min_CLP": -3.85, "draft_iters": 11.4, "mem_use": 33.89, "gen_rate": 7.0, "speed": 5.98, "text": "Here is an example of a high-qua"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 14, "tree_h": 4.0, "tree_w": 13, "tree_size": 32, "t0": 0.3517, "t1": 0.34, "tft": 0.9634, "input_0": 61, "input_1": 33, "min_CLP": -4.49, "draft_iters": 5.0, "mem_use": 34.03, "gen_rate": 2.3, "speed": 3.38, "text": "Tenants are just as human as lan"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 30, "tree_h": 4.1, "tree_w": 16, "tree_size": 32, "t0": 0.354, "t1": 0.324, "tft": 1.1062, "input_0": 55, "input_1": 33, "min_CLP": -4.75, "draft_iters": 5.1, "mem_use": 34.55, "gen_rate": 3.0, "speed": 4.43, "text": "\"I don't find it funny. I guess "}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 0.6083, "t1": 0.325, "tft": 1.536, "input_0": 90, "input_1": 33, "min_CLP": -3.98, "draft_iters": 8.8, "mem_use": 35.39, "gen_rate": 6.3, "speed": 6.79, "text": "\"Yes, absolutely! I would be mor"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 0.6312, "t1": 0.3125, "tft": 1.9833, "input_0": 95, "input_1": 33, "min_CLP": -3.91, "draft_iters": 9.2, "mem_use": 35.95, "gen_rate": 4.6, "speed": 4.9, "text": "\"The difficulty of a language fo"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 50, "tree_h": 9.7, "tree_w": 8, "tree_size": 32, "t0": 0.7371, "t1": 0.3543, "tft": 1.0265, "input_0": 92, "input_1": 33, "min_CLP": -4.08, "draft_iters": 10.7, "mem_use": 34.37, "gen_rate": 7.1, "speed": 6.55, "text": "Some of these tools are free, wh"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.4, "tree_w": 9, "tree_size": 32, "t0": 0.5125, "t1": 0.365, "tft": 0.8751, "input_0": 84, "input_1": 33, "min_CLP": -4.09, "draft_iters": 7.4, "mem_use": 34.23, "gen_rate": 4.5, "speed": 5.13, "text": "\"I don't have any opinion about "}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 39, "tree_h": 6.0, "tree_w": 11, "tree_size": 32, "t0": 0.486, "t1": 0.325, "tft": 1.0888, "input_0": 76, "input_1": 33, "min_CLP": -4.33, "draft_iters": 7.0, "mem_use": 34.45, "gen_rate": 3.9, "speed": 4.81, "text": "\"I don't have an opinion on what"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.3, "tree_w": 12, "tree_size": 32, "t0": 0.4357, "t1": 0.3157, "tft": 1.7043, "input_0": 74, "input_1": 33, "min_CLP": -4.31, "draft_iters": 6.3, "mem_use": 34.46, "gen_rate": 4.6, "speed": 6.07, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 12, "tree_size": 32, "t0": 0.47, "t1": 0.3325, "tft": 1.1268, "input_0": 72, "input_1": 33, "min_CLP": -4.51, "draft_iters": 6.8, "mem_use": 33.89, "gen_rate": 4.2, "speed": 5.31, "text": "\"<|bot|> As an AI language model"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.4, "tree_w": 7, "tree_size": 32, "t0": 0.6457, "t1": 0.3243, "tft": 1.7766, "input_0": 93, "input_1": 33, "min_CLP": -3.79, "draft_iters": 9.4, "mem_use": 35.54, "gen_rate": 4.7, "speed": 4.84, "text": "The [Keck Observatory](https://w"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 47, "tree_h": 9.5, "tree_w": 7, "tree_size": 32, "t0": 0.7267, "t1": 0.3633, "tft": 1.4025, "input_0": 95, "input_1": 33, "min_CLP": -4.18, "draft_iters": 10.5, "mem_use": 34.04, "gen_rate": 7.8, "speed": 7.21, "text": "Psychomotricity\\n[INST] Could yo"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.3, "tree_w": 10, "tree_size": 32, "t0": 0.6457, "t1": 0.3586, "tft": 1.5796, "input_0": 90, "input_1": 33, "min_CLP": -4.42, "draft_iters": 9.3, "mem_use": 33.87, "gen_rate": 4.6, "speed": 4.55, "text": "Sure, here are 10 names from dif"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.546, "t1": 0.318, "tft": 0.9697, "input_0": 77, "input_1": 33, "min_CLP": -4.2, "draft_iters": 8.0, "mem_use": 34.34, "gen_rate": 6.8, "speed": 7.88, "text": "\"I'm an AI language model, so I "}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.9, "tree_w": 9, "tree_size": 32, "t0": 0.54, "t1": 0.3125, "tft": 2.1783, "input_0": 89, "input_1": 33, "min_CLP": -3.97, "draft_iters": 7.9, "mem_use": 36.05, "gen_rate": 4.5, "speed": 5.28, "text": "Sorry, as an AI language model, "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 5.0, "tree_w": 12, "tree_size": 32, "t0": 0.4164, "t1": 0.3236, "tft": 1.5359, "input_0": 67, "input_1": 33, "min_CLP": -4.46, "draft_iters": 6.0, "mem_use": 34.81, "gen_rate": 2.9, "speed": 3.94, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.0, "tree_w": 8, "tree_size": 32, "t0": 0.6817, "t1": 0.3333, "tft": 1.532, "input_0": 99, "input_1": 33, "min_CLP": -4.07, "draft_iters": 10.0, "mem_use": 35.24, "gen_rate": 6.5, "speed": 6.4, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.9, "tree_w": 12, "tree_size": 32, "t0": 0.4778, "t1": 0.36, "tft": 0.9632, "input_0": 73, "input_1": 33, "min_CLP": -4.55, "draft_iters": 6.9, "mem_use": 33.81, "gen_rate": 3.8, "speed": 4.5, "text": "Title: The Quantum Conundrum\\n\\n"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 5, "tree_size": 32, "t0": 0.97, "t1": 0.3375, "tft": 3.5319, "input_0": 106, "input_1": 33, "min_CLP": -4.12, "draft_iters": 14.5, "mem_use": 38.51, "gen_rate": 8.2, "speed": 6.32, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.2, "tree_w": 8, "tree_size": 32, "t0": 0.5675, "t1": 0.32, "tft": 1.6601, "input_0": 91, "input_1": 33, "min_CLP": -4.13, "draft_iters": 8.2, "mem_use": 34.94, "gen_rate": 4.8, "speed": 5.35, "text": "To transform other text words or"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.6, "tree_w": 6, "tree_size": 32, "t0": 0.996, "t1": 0.366, "tft": 1.6872, "input_0": 99, "input_1": 33, "min_CLP": -3.94, "draft_iters": 14.6, "mem_use": 34.8, "gen_rate": 6.6, "speed": 4.84, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.8, "tree_w": 9, "tree_size": 32, "t0": 0.5417, "t1": 0.3683, "tft": 1.4767, "input_0": 83, "input_1": 33, "min_CLP": -4.3, "draft_iters": 7.8, "mem_use": 33.84, "gen_rate": 5.8, "speed": 6.41, "text": "Adolf Hitler came to power in Ge"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 5.8, "tree_w": 11, "tree_size": 32, "t0": 0.473, "t1": 0.38, "tft": 1.3192, "input_0": 73, "input_1": 33, "min_CLP": -4.54, "draft_iters": 6.8, "mem_use": 34.17, "gen_rate": 3.8, "speed": 4.45, "text": "\"Sure, here's another one:\\n\\nWh"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 13, "tree_h": 6.0, "tree_w": 12, "tree_size": 32, "t0": 0.48, "t1": 0.3333, "tft": 0.893, "input_0": 81, "input_1": 33, "min_CLP": -4.2, "draft_iters": 7.0, "mem_use": 33.79, "gen_rate": 4.3, "speed": 5.32, "text": "There are currently over 50 know"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.9, "tree_w": 10, "tree_size": 32, "t0": 0.47, "t1": 0.3311, "tft": 2.9104, "input_0": 79, "input_1": 33, "min_CLP": -4.26, "draft_iters": 6.9, "mem_use": 38.57, "gen_rate": 3.8, "speed": 4.71, "text": "My apologies for not fulfilling "}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.3, "tree_w": 13, "tree_size": 32, "t0": 0.7633, "t1": 0.3333, "tft": 1.2282, "input_0": 77, "input_1": 33, "min_CLP": -4.79, "draft_iters": 11.3, "mem_use": 33.88, "gen_rate": 10.7, "speed": 9.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.5, "tree_w": 10, "tree_size": 32, "t0": 0.4488, "t1": 0.345, "tft": 3.9071, "input_0": 75, "input_1": 33, "min_CLP": -4.35, "draft_iters": 6.5, "mem_use": 40.78, "gen_rate": 4.0, "speed": 5.06, "text": "I could try to write a program t"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.9, "tree_w": 12, "tree_size": 32, "t0": 0.5375, "t1": 0.335, "tft": 1.5557, "input_0": 63, "input_1": 33, "min_CLP": -4.83, "draft_iters": 7.9, "mem_use": 35.05, "gen_rate": 4.2, "speed": 4.87, "text": "Spritesla is not the first evolu"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 64, "tree_h": 20.7, "tree_w": 6, "tree_size": 32, "t0": 1.4567, "t1": 0.3567, "tft": 0.9976, "input_0": 128, "input_1": 33, "min_CLP": -4.49, "draft_iters": 21.3, "mem_use": 33.9, "gen_rate": 21.3, "speed": 11.77, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.8, "tree_w": 9, "tree_size": 32, "t0": 0.54, "t1": 0.3567, "tft": 0.9123, "input_0": 82, "input_1": 33, "min_CLP": -4.06, "draft_iters": 7.8, "mem_use": 33.77, "gen_rate": 3.7, "speed": 4.09, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 4.5, "tree_w": 16, "tree_size": 32, "t0": 0.375, "t1": 0.31, "tft": 0.8297, "input_0": 64, "input_1": 33, "min_CLP": -4.63, "draft_iters": 5.5, "mem_use": 34.01, "gen_rate": 2.5, "speed": 3.63, "text": "Please write in English language"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 39, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.4544, "t1": 0.3389, "tft": 0.8698, "input_0": 69, "input_1": 33, "min_CLP": -4.5, "draft_iters": 6.6, "mem_use": 34.31, "gen_rate": 4.3, "speed": 5.45, "text": "You can consider watching a few "}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.8, "tree_w": 6, "tree_size": 32, "t0": 0.872, "t1": 0.33, "tft": 2.113, "input_0": 117, "input_1": 33, "min_CLP": -3.66, "draft_iters": 12.8, "mem_use": 35.95, "gen_rate": 6.6, "speed": 5.5, "text": "Sure, here are some software and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 0.5867, "t1": 0.32, "tft": 1.9643, "input_0": 91, "input_1": 33, "min_CLP": -3.99, "draft_iters": 8.5, "mem_use": 35.03, "gen_rate": 5.3, "speed": 5.89, "text": "The physical characteristics of "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.0, "tree_w": 10, "tree_size": 32, "t0": 0.5543, "t1": 0.3357, "tft": 0.7944, "input_0": 87, "input_1": 33, "min_CLP": -4.62, "draft_iters": 8.0, "mem_use": 33.95, "gen_rate": 4.6, "speed": 5.13, "text": "The two players in the \"Atomic B"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 15.0, "tree_w": 6, "tree_size": 32, "t0": 1.08, "t1": 0.3475, "tft": 2.1227, "input_0": 98, "input_1": 33, "min_CLP": -3.7, "draft_iters": 16.0, "mem_use": 36.58, "gen_rate": 4.9, "speed": 3.41, "text": "\"Here's the commented code with "}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.8, "tree_w": 11, "tree_size": 32, "t0": 0.5363, "t1": 0.3225, "tft": 2.4088, "input_0": 93, "input_1": 33, "min_CLP": -4.48, "draft_iters": 7.8, "mem_use": 35.06, "gen_rate": 4.5, "speed": 5.25, "text": "Lo siento, pero Linkin Park no e"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 13.7, "tree_w": 11, "tree_size": 32, "t0": 0.9967, "t1": 0.3433, "tft": 1.0426, "input_0": 90, "input_1": 33, "min_CLP": -4.58, "draft_iters": 14.7, "mem_use": 33.79, "gen_rate": 13.3, "speed": 9.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.0, "tree_w": 5, "tree_size": 32, "t0": 0.8225, "t1": 0.3625, "tft": 0.972, "input_0": 99, "input_1": 33, "min_CLP": -3.79, "draft_iters": 12.0, "mem_use": 33.88, "gen_rate": 9.2, "speed": 7.8, "text": "```markdown\\nHere\\'s an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 9, "tree_size": 32, "t0": 0.5967, "t1": 0.3333, "tft": 1.3396, "input_0": 90, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.7, "mem_use": 34.9, "gen_rate": 5.5, "speed": 5.92, "text": "\"I'm sorry, I cannot write a poe"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.2, "tree_w": 6, "tree_size": 32, "t0": 0.766, "t1": 0.322, "tft": 1.7874, "input_0": 101, "input_1": 33, "min_CLP": -3.95, "draft_iters": 11.2, "mem_use": 35.85, "gen_rate": 7.4, "speed": 6.83, "text": "In JavaScript, you can use the t"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.1, "tree_w": 12, "tree_size": 32, "t0": 0.4211, "t1": 0.31, "tft": 1.1454, "input_0": 69, "input_1": 33, "min_CLP": -4.37, "draft_iters": 6.1, "mem_use": 34.39, "gen_rate": 3.7, "speed": 5.0, "text": "First, you need a teacher or a b"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.5, "tree_w": 9, "tree_size": 32, "t0": 0.4545, "t1": 0.3127, "tft": 1.2837, "input_0": 79, "input_1": 33, "min_CLP": -4.1, "draft_iters": 6.5, "mem_use": 34.86, "gen_rate": 3.0, "speed": 3.9, "text": "I apologize for making an assump"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 8, "tree_size": 32, "t0": 0.4888, "t1": 0.355, "tft": 0.9552, "input_0": 80, "input_1": 33, "min_CLP": -4.13, "draft_iters": 7.0, "mem_use": 33.78, "gen_rate": 4.0, "speed": 4.74, "text": "JavaScript is primarily a front-"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 10, "tree_size": 32, "t0": 0.6083, "t1": 0.325, "tft": 1.0977, "input_0": 76, "input_1": 33, "min_CLP": -4.01, "draft_iters": 8.8, "mem_use": 33.77, "gen_rate": 5.5, "speed": 5.89, "text": "The chemicals that L-theanine af"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 8.1, "tree_w": 9, "tree_size": 32, "t0": 0.627, "t1": 0.344, "tft": 1.2257, "input_0": 87, "input_1": 33, "min_CLP": -4.14, "draft_iters": 9.1, "mem_use": 34.48, "gen_rate": 3.2, "speed": 3.3, "text": "\"Here's the list in two columns,"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 12, "tree_size": 32, "t0": 0.4914, "t1": 0.3343, "tft": 1.1377, "input_0": 67, "input_1": 33, "min_CLP": -4.55, "draft_iters": 7.1, "mem_use": 33.9, "gen_rate": 4.9, "speed": 5.89, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 14.0, "tree_w": 10, "tree_size": 32, "t0": 1.0133, "t1": 0.34, "tft": 0.8619, "input_0": 89, "input_1": 33, "min_CLP": -4.89, "draft_iters": 15.0, "mem_use": 33.9, "gen_rate": 13.3, "speed": 9.83, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 60, "tree_h": 19.0, "tree_w": 6, "tree_size": 32, "t0": 1.34, "t1": 0.3567, "tft": 0.8999, "input_0": 106, "input_1": 33, "min_CLP": -4.64, "draft_iters": 19.7, "mem_use": 33.88, "gen_rate": 20.0, "speed": 11.82, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 9.4, "tree_w": 6, "tree_size": 32, "t0": 0.6975, "t1": 0.3263, "tft": 2.9822, "input_0": 93, "input_1": 33, "min_CLP": -3.98, "draft_iters": 10.4, "mem_use": 38.63, "gen_rate": 4.9, "speed": 4.76, "text": "This script aims to capture the "}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 6, "tree_size": 32, "t0": 0.732, "t1": 0.332, "tft": 2.4263, "input_0": 95, "input_1": 33, "min_CLP": -3.45, "draft_iters": 10.8, "mem_use": 36.28, "gen_rate": 6.4, "speed": 6.02, "text": "\"Sure! Fermat's Last Theorem say"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.2, "tree_w": 7, "tree_size": 32, "t0": 0.5683, "t1": 0.35, "tft": 1.6187, "input_0": 98, "input_1": 33, "min_CLP": -3.75, "draft_iters": 8.2, "mem_use": 34.7, "gen_rate": 5.8, "speed": 6.34, "text": "Certainly! The formula for estim"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.47, "t1": 0.355, "tft": 1.2173, "input_0": 80, "input_1": 33, "min_CLP": -4.13, "draft_iters": 6.8, "mem_use": 34.87, "gen_rate": 4.2, "speed": 5.15, "text": "Oh, the lessons we can learn fro"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 6.5, "tree_w": 10, "tree_size": 32, "t0": 0.513, "t1": 0.324, "tft": 1.9035, "input_0": 80, "input_1": 33, "min_CLP": -4.22, "draft_iters": 7.5, "mem_use": 35.95, "gen_rate": 3.2, "speed": 3.82, "text": "Lemon wedges are a common accomp"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.47, "t1": 0.3712, "tft": 0.8729, "input_0": 78, "input_1": 33, "min_CLP": -4.25, "draft_iters": 6.8, "mem_use": 33.97, "gen_rate": 4.0, "speed": 4.74, "text": "\"Sure, I can do that! As a datin"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 11, "tree_size": 32, "t0": 0.4725, "t1": 0.365, "tft": 1.0189, "input_0": 77, "input_1": 33, "min_CLP": -4.3, "draft_iters": 6.8, "mem_use": 33.93, "gen_rate": 4.2, "speed": 5.08, "text": "\"I'm sorry to hear that. Remembe"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 11.0, "tree_w": 5, "tree_size": 32, "t0": 0.83, "t1": 0.37, "tft": 1.4435, "input_0": 117, "input_1": 33, "min_CLP": -3.49, "draft_iters": 12.0, "mem_use": 33.81, "gen_rate": 10.8, "speed": 8.96, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.5, "tree_w": 9, "tree_size": 32, "t0": 0.585, "t1": 0.3313, "tft": 1.9814, "input_0": 81, "input_1": 33, "min_CLP": -4.28, "draft_iters": 8.5, "mem_use": 35.38, "gen_rate": 4.6, "speed": 5.05, "text": "Yes, there are several cities th"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 8, "tree_size": 32, "t0": 0.5414, "t1": 0.3129, "tft": 1.5469, "input_0": 85, "input_1": 33, "min_CLP": -4.09, "draft_iters": 7.9, "mem_use": 34.9, "gen_rate": 4.6, "speed": 5.35, "text": "Freeman Dyson has been associate"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 23, "tree_h": 6.8, "tree_w": 8, "tree_size": 32, "t0": 0.5467, "t1": 0.3483, "tft": 0.8869, "input_0": 93, "input_1": 33, "min_CLP": -4.0, "draft_iters": 7.8, "mem_use": 33.76, "gen_rate": 3.8, "speed": 4.28, "text": "Sure, I can help you write code."}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 51, "tree_h": 10.8, "tree_w": 7, "tree_size": 32, "t0": 0.814, "t1": 0.372, "tft": 1.3104, "input_0": 100, "input_1": 33, "min_CLP": -3.78, "draft_iters": 11.8, "mem_use": 34.5, "gen_rate": 10.2, "speed": 8.6, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 51, "tree_h": 15.8, "tree_w": 5, "tree_size": 32, "t0": 1.1375, "t1": 0.3525, "tft": 1.4888, "input_0": 108, "input_1": 33, "min_CLP": -3.66, "draft_iters": 16.8, "mem_use": 35.1, "gen_rate": 12.8, "speed": 8.57, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 8.9, "tree_w": 10, "tree_size": 32, "t0": 0.68, "t1": 0.34, "tft": 1.1073, "input_0": 89, "input_1": 33, "min_CLP": -4.19, "draft_iters": 9.9, "mem_use": 34.12, "gen_rate": 4.8, "speed": 4.67, "text": "1.    Managing work pressure and"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.1, "tree_w": 9, "tree_size": 32, "t0": 0.5686, "t1": 0.3771, "tft": 1.0357, "input_0": 86, "input_1": 33, "min_CLP": -4.12, "draft_iters": 8.1, "mem_use": 33.79, "gen_rate": 4.9, "speed": 5.14, "text": "It seems you are asking about se"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.8, "tree_w": 10, "tree_size": 32, "t0": 0.4687, "t1": 0.3375, "tft": 0.9624, "input_0": 75, "input_1": 33, "min_CLP": -4.22, "draft_iters": 6.8, "mem_use": 34.36, "gen_rate": 4.2, "speed": 5.28, "text": "A comparison of the libraries wo"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 9, "tree_size": 32, "t0": 0.6733, "t1": 0.3583, "tft": 1.4291, "input_0": 90, "input_1": 33, "min_CLP": -4.24, "draft_iters": 9.8, "mem_use": 34.79, "gen_rate": 5.5, "speed": 5.34, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.4, "tree_w": 9, "tree_size": 32, "t0": 0.5814, "t1": 0.3571, "tft": 1.3099, "input_0": 92, "input_1": 33, "min_CLP": -4.22, "draft_iters": 8.4, "mem_use": 34.47, "gen_rate": 5.4, "speed": 5.76, "text": "The URL decoded string of `%21` "}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 58, "tree_h": 20.0, "tree_w": 4, "tree_size": 32, "t0": 1.4067, "t1": 0.35, "tft": 3.547, "input_0": 114, "input_1": 33, "min_CLP": -3.38, "draft_iters": 21.0, "mem_use": 36.58, "gen_rate": 19.3, "speed": 11.02, "text": "\"I apologize for the confusion. "}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.0, "tree_w": 6, "tree_size": 32, "t0": 0.676, "t1": 0.328, "tft": 2.64, "input_0": 95, "input_1": 33, "min_CLP": -3.84, "draft_iters": 10.0, "mem_use": 38.15, "gen_rate": 6.6, "speed": 6.57, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 7.6, "tree_w": 10, "tree_size": 32, "t0": 0.5887, "t1": 0.325, "tft": 1.5114, "input_0": 79, "input_1": 33, "min_CLP": -4.16, "draft_iters": 8.6, "mem_use": 35.17, "gen_rate": 4.8, "speed": 5.2, "text": "\"It's important to remember that"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 18.0, "tree_w": 3, "tree_size": 32, "t0": 1.2867, "t1": 0.3367, "tft": 1.5703, "input_0": 124, "input_1": 33, "min_CLP": -3.35, "draft_iters": 19.0, "mem_use": 35.55, "gen_rate": 11.7, "speed": 7.2, "text": "Sure! Here are the 3 most import"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.4, "tree_w": 6, "tree_size": 32, "t0": 0.6529, "t1": 0.3457, "tft": 1.2396, "input_0": 94, "input_1": 33, "min_CLP": -3.78, "draft_iters": 9.4, "mem_use": 33.79, "gen_rate": 5.3, "speed": 5.3, "text": "Sets and lists in Python are bot"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 29, "tree_h": 10.0, "tree_w": 8, "tree_size": 32, "t0": 0.7525, "t1": 0.335, "tft": 1.6261, "input_0": 88, "input_1": 33, "min_CLP": -3.95, "draft_iters": 11.0, "mem_use": 35.13, "gen_rate": 7.2, "speed": 6.68, "text": "To calculate the number of days "}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.6033, "t1": 0.3567, "tft": 0.8732, "input_0": 93, "input_1": 33, "min_CLP": -4.17, "draft_iters": 8.7, "mem_use": 33.97, "gen_rate": 5.8, "speed": 6.07, "text": "\"Sure, here's a short story abou"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 2, "tree_h": 4.3, "tree_w": 16, "tree_size": 32, "t0": 0.3667, "t1": 0.3267, "tft": 1.0568, "input_0": 53, "input_1": 33, "min_CLP": -4.85, "draft_iters": 5.3, "mem_use": 33.84, "gen_rate": 0.7, "speed": 0.96, "text": "Duke:"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.0, "tree_w": 9, "tree_size": 32, "t0": 0.6186, "t1": 0.3514, "tft": 1.3886, "input_0": 83, "input_1": 33, "min_CLP": -4.37, "draft_iters": 9.0, "mem_use": 33.83, "gen_rate": 5.1, "speed": 5.31, "text": "To farm experience in Minecraft "}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.3, "tree_w": 9, "tree_size": 32, "t0": 0.505, "t1": 0.32, "tft": 1.1594, "input_0": 78, "input_1": 33, "min_CLP": -4.57, "draft_iters": 7.3, "mem_use": 33.78, "gen_rate": 5.3, "speed": 6.46, "text": "I am the goddess Freyja, the dau"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 15, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.685, "t1": 0.33, "tft": 1.2598, "input_0": 111, "input_1": 33, "min_CLP": -3.64, "draft_iters": 10.0, "mem_use": 35.05, "gen_rate": 7.5, "speed": 7.4, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 11.2, "tree_w": 6, "tree_size": 32, "t0": 0.834, "t1": 0.348, "tft": 1.2233, "input_0": 105, "input_1": 33, "min_CLP": -4.08, "draft_iters": 12.2, "mem_use": 34.18, "gen_rate": 8.6, "speed": 7.28, "text": "# Install Tailwind\\nnpm install "}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.4, "tree_w": 8, "tree_size": 32, "t0": 0.6357, "t1": 0.33, "tft": 3.3117, "input_0": 97, "input_1": 33, "min_CLP": -3.98, "draft_iters": 9.4, "mem_use": 39.22, "gen_rate": 5.3, "speed": 5.47, "text": "Yes, the degree of sexual dimorp"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.7, "tree_w": 9, "tree_size": 32, "t0": 0.5329, "t1": 0.3486, "tft": 0.8527, "input_0": 80, "input_1": 33, "min_CLP": -4.27, "draft_iters": 7.7, "mem_use": 34.31, "gen_rate": 5.4, "speed": 6.16, "text": "LLMs (Large Language Models) nee"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.7, "tree_w": 13, "tree_size": 32, "t0": 0.7867, "t1": 0.3233, "tft": 0.8615, "input_0": 81, "input_1": 33, "min_CLP": -4.43, "draft_iters": 11.7, "mem_use": 33.87, "gen_rate": 10.7, "speed": 9.61, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 9.7, "tree_w": 8, "tree_size": 32, "t0": 0.7367, "t1": 0.36, "tft": 0.8339, "input_0": 92, "input_1": 33, "min_CLP": -4.09, "draft_iters": 10.7, "mem_use": 34.09, "gen_rate": 3.7, "speed": 3.34, "text": "Here is a eulogy for your grandm"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 16, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.55, "t1": 0.34, "tft": 1.7072, "input_0": 87, "input_1": 33, "min_CLP": -3.93, "draft_iters": 8.0, "mem_use": 35.55, "gen_rate": 4.0, "speed": 4.5, "text": "\"No, that's all the information "}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.1, "tree_w": 11, "tree_size": 32, "t0": 0.4971, "t1": 0.35, "tft": 0.9528, "input_0": 88, "input_1": 33, "min_CLP": -4.38, "draft_iters": 7.1, "mem_use": 33.95, "gen_rate": 5.3, "speed": 6.25, "text": "Yes, I am an AI language model d"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 14.3, "tree_w": 9, "tree_size": 32, "t0": 1.0167, "t1": 0.3567, "tft": 0.8248, "input_0": 83, "input_1": 33, "min_CLP": -4.66, "draft_iters": 15.0, "mem_use": 33.93, "gen_rate": 14.0, "speed": 10.17, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.3, "tree_w": 10, "tree_size": 32, "t0": 0.51, "t1": 0.3517, "tft": 0.9853, "input_0": 79, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.3, "mem_use": 33.77, "gen_rate": 5.7, "speed": 6.57, "text": "The color of Mars, also known as"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 7.6, "tree_w": 13, "tree_size": 32, "t0": 0.587, "t1": 0.324, "tft": 2.3153, "input_0": 78, "input_1": 33, "min_CLP": -4.64, "draft_iters": 8.6, "mem_use": 36.01, "gen_rate": 3.6, "speed": 3.95, "text": "To say \"I love you\" in Quenya, y"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.3, "tree_w": 7, "tree_size": 32, "t0": 0.7114, "t1": 0.3643, "tft": 1.4509, "input_0": 95, "input_1": 33, "min_CLP": -4.01, "draft_iters": 10.3, "mem_use": 33.85, "gen_rate": 5.4, "speed": 5.05, "text": "The seventh and final novel in J"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.6, "tree_w": 7, "tree_size": 32, "t0": 0.7229, "t1": 0.3457, "tft": 1.4851, "input_0": 85, "input_1": 33, "min_CLP": -3.95, "draft_iters": 10.6, "mem_use": 34.39, "gen_rate": 4.9, "speed": 4.54, "text": "\"Yes, the ATF's regulations and "}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.8, "tree_w": 9, "tree_size": 32, "t0": 0.606, "t1": 0.336, "tft": 1.3767, "input_0": 88, "input_1": 33, "min_CLP": -4.1, "draft_iters": 8.8, "mem_use": 33.85, "gen_rate": 6.8, "speed": 7.22, "text": "The Riemann Hypothesis (RH) is a"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.0, "tree_w": 10, "tree_size": 32, "t0": 0.485, "t1": 0.3467, "tft": 0.9401, "input_0": 85, "input_1": 33, "min_CLP": -4.17, "draft_iters": 7.0, "mem_use": 34.28, "gen_rate": 5.7, "speed": 6.82, "text": "\"Sure, I'd be happy to help! Cou"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.5, "tree_w": 8, "tree_size": 32, "t0": 0.6533, "t1": 0.3417, "tft": 0.8806, "input_0": 88, "input_1": 33, "min_CLP": -4.14, "draft_iters": 9.5, "mem_use": 33.97, "gen_rate": 5.5, "speed": 5.52, "text": "The capital of Australia before "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 11.0, "tree_w": 12, "tree_size": 32, "t0": 0.8, "t1": 0.34, "tft": 1.1604, "input_0": 70, "input_1": 33, "min_CLP": -4.62, "draft_iters": 12.0, "mem_use": 34.14, "gen_rate": 5.0, "speed": 4.38, "text": "[INST] yes [\\\\INST]\\n[INST] yes "}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 7, "tree_size": 32, "t0": 0.5871, "t1": 0.3129, "tft": 2.1215, "input_0": 84, "input_1": 33, "min_CLP": -4.04, "draft_iters": 8.6, "mem_use": 36.37, "gen_rate": 4.7, "speed": 5.24, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.8, "tree_w": 11, "tree_size": 32, "t0": 0.404, "t1": 0.331, "tft": 0.7958, "input_0": 70, "input_1": 33, "min_CLP": -4.37, "draft_iters": 5.8, "mem_use": 33.96, "gen_rate": 3.3, "speed": 4.49, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 45, "tree_h": 11.4, "tree_w": 7, "tree_size": 32, "t0": 0.8486, "t1": 0.3557, "tft": 1.3963, "input_0": 91, "input_1": 33, "min_CLP": -3.86, "draft_iters": 12.4, "mem_use": 35.24, "gen_rate": 6.4, "speed": 5.34, "text": "Yes, for example the vector A = "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.3, "tree_w": 8, "tree_size": 32, "t0": 0.645, "t1": 0.39, "tft": 1.2476, "input_0": 96, "input_1": 33, "min_CLP": -4.09, "draft_iters": 9.3, "mem_use": 33.82, "gen_rate": 5.8, "speed": 5.64, "text": "The use of a symmetric probabili"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.0, "tree_w": 11, "tree_size": 32, "t0": 0.421, "t1": 0.351, "tft": 0.8747, "input_0": 69, "input_1": 33, "min_CLP": -4.7, "draft_iters": 6.0, "mem_use": 33.88, "gen_rate": 3.5, "speed": 4.53, "text": "I am an Argonian. I am a warrior"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 8.5, "tree_w": 7, "tree_size": 32, "t0": 0.6612, "t1": 0.3725, "tft": 0.8617, "input_0": 94, "input_1": 33, "min_CLP": -4.0, "draft_iters": 9.5, "mem_use": 33.83, "gen_rate": 5.1, "speed": 4.95, "text": "L\u2019Hopital\u2019s Rule is a mathematic"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 8, "tree_size": 32, "t0": 0.5314, "t1": 0.3129, "tft": 1.5799, "input_0": 90, "input_1": 33, "min_CLP": -4.2, "draft_iters": 7.7, "mem_use": 34.39, "gen_rate": 5.0, "speed": 5.91, "text": "No, variance is the average sum "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 5.5, "tree_w": 16, "tree_size": 32, "t0": 0.445, "t1": 0.31, "tft": 1.3516, "input_0": 65, "input_1": 33, "min_CLP": -4.55, "draft_iters": 6.5, "mem_use": 34.68, "gen_rate": 3.0, "speed": 3.99, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.6, "tree_w": 11, "tree_size": 32, "t0": 0.4575, "t1": 0.3138, "tft": 1.2983, "input_0": 75, "input_1": 33, "min_CLP": -4.63, "draft_iters": 6.6, "mem_use": 34.47, "gen_rate": 4.5, "speed": 5.83, "text": "The best place to see the stars "}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 5.5, "tree_w": 12, "tree_size": 32, "t0": 0.4569, "t1": 0.3523, "tft": 0.8903, "input_0": 69, "input_1": 33, "min_CLP": -4.68, "draft_iters": 6.5, "mem_use": 33.82, "gen_rate": 2.5, "speed": 3.04, "text": "1. Falling into a vat of chocola"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 6, "tree_size": 32, "t0": 0.665, "t1": 0.3333, "tft": 1.5758, "input_0": 83, "input_1": 33, "min_CLP": -3.75, "draft_iters": 9.7, "mem_use": 34.37, "gen_rate": 6.0, "speed": 6.01, "text": "The initial situation is that yo"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 7, "tree_size": 32, "t0": 0.6117, "t1": 0.3617, "tft": 1.0253, "input_0": 86, "input_1": 33, "min_CLP": -3.93, "draft_iters": 8.8, "mem_use": 34.24, "gen_rate": 5.7, "speed": 5.82, "text": "\"Some ways to cope with stress f"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.0, "tree_w": 6, "tree_size": 32, "t0": 0.6829, "t1": 0.3314, "tft": 2.2992, "input_0": 101, "input_1": 33, "min_CLP": -3.93, "draft_iters": 10.0, "mem_use": 37.31, "gen_rate": 5.3, "speed": 5.22, "text": "Certainly! Here are some tools t"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 8.8, "tree_w": 6, "tree_size": 32, "t0": 0.67, "t1": 0.315, "tft": 2.2559, "input_0": 97, "input_1": 33, "min_CLP": -3.72, "draft_iters": 9.8, "mem_use": 36.01, "gen_rate": 8.2, "speed": 8.38, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.6017, "t1": 0.3483, "tft": 0.8201, "input_0": 86, "input_1": 33, "min_CLP": -4.21, "draft_iters": 8.7, "mem_use": 33.78, "gen_rate": 5.8, "speed": 6.13, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.0, "tree_w": 7, "tree_size": 32, "t0": 0.6933, "t1": 0.3967, "tft": 0.8939, "input_0": 85, "input_1": 33, "min_CLP": -4.45, "draft_iters": 10.0, "mem_use": 34.03, "gen_rate": 6.2, "speed": 5.67, "text": "Here is a list of five words whe"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 8, "tree_size": 32, "t0": 0.5783, "t1": 0.3483, "tft": 4.2008, "input_0": 89, "input_1": 33, "min_CLP": -3.94, "draft_iters": 8.5, "mem_use": 40.81, "gen_rate": 5.5, "speed": 5.93, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.6, "tree_w": 9, "tree_size": 32, "t0": 0.5257, "t1": 0.3643, "tft": 1.4284, "input_0": 80, "input_1": 33, "min_CLP": -4.12, "draft_iters": 7.6, "mem_use": 34.2, "gen_rate": 4.9, "speed": 5.47, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 9.5, "tree_w": 12, "tree_size": 32, "t0": 0.7, "t1": 0.36, "tft": 0.8598, "input_0": 62, "input_1": 33, "min_CLP": -4.76, "draft_iters": 10.5, "mem_use": 33.91, "gen_rate": 6.0, "speed": 5.69, "text": "Who made Berlin [\\\\INST]\\ngerman"}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.8, "tree_w": 8, "tree_size": 32, "t0": 0.678, "t1": 0.374, "tft": 0.9244, "input_0": 95, "input_1": 33, "min_CLP": -4.19, "draft_iters": 9.8, "mem_use": 33.91, "gen_rate": 7.0, "speed": 6.66, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 4.7, "tree_w": 12, "tree_size": 32, "t0": 0.392, "t1": 0.319, "tft": 1.9022, "input_0": 71, "input_1": 33, "min_CLP": -4.33, "draft_iters": 5.7, "mem_use": 36.45, "gen_rate": 3.6, "speed": 5.05, "text": "Let me clarify my role and inten"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.0, "tree_w": 5, "tree_size": 32, "t0": 0.9633, "t1": 0.39, "tft": 1.2558, "input_0": 131, "input_1": 33, "min_CLP": -3.55, "draft_iters": 14.0, "mem_use": 34.32, "gen_rate": 12.0, "speed": 8.88, "text": "Yes, here are some of the best u"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 8.0, "tree_w": 9, "tree_size": 32, "t0": 0.6225, "t1": 0.3687, "tft": 1.3787, "input_0": 87, "input_1": 33, "min_CLP": -4.2, "draft_iters": 9.0, "mem_use": 34.51, "gen_rate": 5.1, "speed": 5.18, "text": "\"I'm not sure of the exact airsp"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 6.4, "tree_w": 11, "tree_size": 32, "t0": 0.512, "t1": 0.345, "tft": 1.0891, "input_0": 76, "input_1": 33, "min_CLP": -4.24, "draft_iters": 7.4, "mem_use": 34.11, "gen_rate": 3.4, "speed": 3.97, "text": "Stable diffusion is a novel appr"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 6.8, "tree_w": 10, "tree_size": 32, "t0": 0.537, "t1": 0.327, "tft": 1.9842, "input_0": 78, "input_1": 33, "min_CLP": -4.42, "draft_iters": 7.8, "mem_use": 34.36, "gen_rate": 3.2, "speed": 3.71, "text": "Attention bias, shining bright,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.9, "tree_w": 14, "tree_size": 32, "t0": 0.408, "t1": 0.359, "tft": 0.9642, "input_0": 59, "input_1": 33, "min_CLP": -4.57, "draft_iters": 5.9, "mem_use": 34.14, "gen_rate": 3.3, "speed": 4.31, "text": "\"Then I am sorry, but I still do"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.7, "tree_w": 10, "tree_size": 32, "t0": 0.5244, "t1": 0.3311, "tft": 1.9044, "input_0": 77, "input_1": 33, "min_CLP": -4.3, "draft_iters": 7.7, "mem_use": 36.13, "gen_rate": 3.6, "speed": 4.15, "text": "\"It's always good to be prepared"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.2, "tree_w": 9, "tree_size": 32, "t0": 0.6317, "t1": 0.3733, "tft": 1.267, "input_0": 84, "input_1": 33, "min_CLP": -4.24, "draft_iters": 9.2, "mem_use": 33.9, "gen_rate": 5.3, "speed": 5.31, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 8.0, "tree_w": 9, "tree_size": 32, "t0": 0.6233, "t1": 0.3567, "tft": 0.8831, "input_0": 97, "input_1": 33, "min_CLP": -4.5, "draft_iters": 9.0, "mem_use": 33.92, "gen_rate": 4.7, "speed": 4.77, "text": "Claro, puedo hablar en espa\u00f1ol. "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.3, "tree_w": 11, "tree_size": 32, "t0": 0.4444, "t1": 0.3689, "tft": 1.2054, "input_0": 75, "input_1": 33, "min_CLP": -4.39, "draft_iters": 6.3, "mem_use": 33.9, "gen_rate": 3.8, "speed": 4.65, "text": "F-centers in crystallography are"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.5, "tree_w": 11, "tree_size": 32, "t0": 0.5125, "t1": 0.3387, "tft": 3.1259, "input_0": 81, "input_1": 33, "min_CLP": -4.26, "draft_iters": 7.5, "mem_use": 38.43, "gen_rate": 4.1, "speed": 4.85, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 7.4, "tree_w": 9, "tree_size": 32, "t0": 0.5778, "t1": 0.3356, "tft": 1.5562, "input_0": 85, "input_1": 33, "min_CLP": -4.16, "draft_iters": 8.4, "mem_use": 35.52, "gen_rate": 3.9, "speed": 4.24, "text": "You are right, I apologize for t"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 8, "tree_size": 32, "t0": 0.595, "t1": 0.32, "tft": 0.8662, "input_0": 93, "input_1": 33, "min_CLP": -4.58, "draft_iters": 8.7, "mem_use": 34.32, "gen_rate": 5.8, "speed": 6.37, "text": "Pros:\\n1. Efficiency: AI assista"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.4, "tree_w": 9, "tree_size": 32, "t0": 0.64, "t1": 0.33, "tft": 2.2289, "input_0": 99, "input_1": 33, "min_CLP": -4.04, "draft_iters": 9.4, "mem_use": 36.24, "gen_rate": 6.4, "speed": 6.58, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 9, "tree_size": 32, "t0": 0.78, "t1": 0.3333, "tft": 2.0303, "input_0": 79, "input_1": 33, "min_CLP": -4.14, "draft_iters": 11.7, "mem_use": 36.2, "gen_rate": 11.7, "speed": 10.44, "text": "Die Zementproduktion ist ein wic"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.4, "tree_w": 12, "tree_size": 32, "t0": 0.4375, "t1": 0.3312, "tft": 1.5675, "input_0": 63, "input_1": 33, "min_CLP": -4.3, "draft_iters": 6.4, "mem_use": 35.53, "gen_rate": 4.2, "speed": 5.53, "text": "I apologize for any confusion, b"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.6, "tree_w": 10, "tree_size": 32, "t0": 0.4588, "t1": 0.3312, "tft": 1.4215, "input_0": 74, "input_1": 33, "min_CLP": -4.45, "draft_iters": 6.6, "mem_use": 34.56, "gen_rate": 4.0, "speed": 5.07, "text": "I would try to return it to the "}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.8, "tree_w": 7, "tree_size": 32, "t0": 0.738, "t1": 0.36, "tft": 1.0266, "input_0": 88, "input_1": 33, "min_CLP": -4.26, "draft_iters": 10.8, "mem_use": 34.15, "gen_rate": 7.4, "speed": 6.73, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u7684\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1a\\n\\n1. Vaswa"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.0, "tree_w": 3, "tree_size": 32, "t0": 1.2933, "t1": 0.3833, "tft": 0.9373, "input_0": 138, "input_1": 33, "min_CLP": -3.22, "draft_iters": 19.0, "mem_use": 33.96, "gen_rate": 13.3, "speed": 7.97, "text": "```javascript\\nfunction isPrime("}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.0, "tree_w": 8, "tree_size": 32, "t0": 0.6171, "t1": 0.3386, "tft": 1.8426, "input_0": 87, "input_1": 33, "min_CLP": -3.98, "draft_iters": 9.0, "mem_use": 35.24, "gen_rate": 5.1, "speed": 5.38, "text": "The reason why public nudity is "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.8, "tree_w": 12, "tree_size": 32, "t0": 0.4022, "t1": 0.3378, "tft": 0.8701, "input_0": 66, "input_1": 33, "min_CLP": -4.58, "draft_iters": 5.8, "mem_use": 34.36, "gen_rate": 3.7, "speed": 4.95, "text": "A romantic dinner at a candlelit"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.2, "tree_w": 11, "tree_size": 32, "t0": 0.4987, "t1": 0.335, "tft": 1.6069, "input_0": 81, "input_1": 33, "min_CLP": -4.23, "draft_iters": 7.2, "mem_use": 35.23, "gen_rate": 4.1, "speed": 4.95, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.8, "tree_w": 7, "tree_size": 32, "t0": 0.7375, "t1": 0.3525, "tft": 1.5843, "input_0": 98, "input_1": 33, "min_CLP": -3.89, "draft_iters": 10.8, "mem_use": 34.61, "gen_rate": 8.0, "speed": 7.35, "text": "In that case, if you live in a E"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.8, "tree_w": 13, "tree_size": 32, "t0": 0.4711, "t1": 0.3667, "tft": 1.4563, "input_0": 76, "input_1": 33, "min_CLP": -4.56, "draft_iters": 6.8, "mem_use": 33.89, "gen_rate": 3.9, "speed": 4.63, "text": "Here are some nicknames you can "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.8, "tree_w": 8, "tree_size": 32, "t0": 0.6067, "t1": 0.3567, "tft": 1.8371, "input_0": 91, "input_1": 33, "min_CLP": -4.08, "draft_iters": 8.8, "mem_use": 34.29, "gen_rate": 6.0, "speed": 6.22, "text": "Yes, the Balfour Declaration pla"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 17.5, "tree_w": 3, "tree_size": 32, "t0": 1.255, "t1": 0.375, "tft": 1.9997, "input_0": 130, "input_1": 33, "min_CLP": -3.49, "draft_iters": 18.5, "mem_use": 35.04, "gen_rate": 18.5, "speed": 11.36, "text": "\"Felices:\\n1. \u00ab(I Can't Get No) "}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 8.0, "tree_w": 10, "tree_size": 32, "t0": 0.6211, "t1": 0.3667, "tft": 0.9542, "input_0": 79, "input_1": 33, "min_CLP": -4.01, "draft_iters": 9.0, "mem_use": 33.99, "gen_rate": 3.8, "speed": 3.82, "text": "\"To provide you with the informa"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 23.8, "tree_w": 3, "tree_size": 32, "t0": 1.6975, "t1": 0.4, "tft": 1.3537, "input_0": 111, "input_1": 33, "min_CLP": -3.73, "draft_iters": 24.8, "mem_use": 34.38, "gen_rate": 9.5, "speed": 4.54, "text": "I apologize for the oversight. H"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.6, "tree_w": 9, "tree_size": 32, "t0": 0.5913, "t1": 0.3387, "tft": 1.3907, "input_0": 78, "input_1": 33, "min_CLP": -4.36, "draft_iters": 8.6, "mem_use": 34.74, "gen_rate": 4.1, "speed": 4.45, "text": "Certainly! How about, \"A wish co"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 0.66, "t1": 0.34, "tft": 1.9388, "input_0": 91, "input_1": 33, "min_CLP": -3.86, "draft_iters": 9.6, "mem_use": 35.5, "gen_rate": 6.4, "speed": 6.41, "text": "Building a reinforcement learnin"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.9, "tree_w": 10, "tree_size": 32, "t0": 0.5475, "t1": 0.3563, "tft": 1.1364, "input_0": 83, "input_1": 33, "min_CLP": -4.31, "draft_iters": 7.9, "mem_use": 33.99, "gen_rate": 4.4, "speed": 4.85, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.8, "tree_w": 12, "tree_size": 32, "t0": 0.474, "t1": 0.365, "tft": 1.0073, "input_0": 72, "input_1": 33, "min_CLP": -4.42, "draft_iters": 6.8, "mem_use": 33.91, "gen_rate": 3.5, "speed": 4.18, "text": "The most wet among the options g"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.1, "tree_w": 7, "tree_size": 32, "t0": 0.6829, "t1": 0.3343, "tft": 2.768, "input_0": 84, "input_1": 33, "min_CLP": -4.04, "draft_iters": 10.1, "mem_use": 38.02, "gen_rate": 4.6, "speed": 4.48, "text": "1. Discover a market need or opp"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.4, "tree_w": 7, "tree_size": 32, "t0": 0.648, "t1": 0.358, "tft": 1.212, "input_0": 99, "input_1": 33, "min_CLP": -3.9, "draft_iters": 9.4, "mem_use": 33.81, "gen_rate": 6.4, "speed": 6.36, "text": "The Many-Worlds Interpretation ("}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.5529, "t1": 0.3486, "tft": 1.0286, "input_0": 83, "input_1": 33, "min_CLP": -4.05, "draft_iters": 8.0, "mem_use": 33.77, "gen_rate": 5.0, "speed": 5.54, "text": "\"To build a PC, follow these ste"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 11.8, "tree_w": 8, "tree_size": 32, "t0": 0.855, "t1": 0.34, "tft": 2.5421, "input_0": 95, "input_1": 33, "min_CLP": -4.27, "draft_iters": 12.8, "mem_use": 38.02, "gen_rate": 10.0, "speed": 8.37, "text": "User: Hey!\\n\\nBot: Hello! How ca"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.7, "tree_w": 9, "tree_size": 32, "t0": 0.5929, "t1": 0.3229, "tft": 1.6221, "input_0": 81, "input_1": 33, "min_CLP": -4.02, "draft_iters": 8.7, "mem_use": 35.82, "gen_rate": 5.1, "speed": 5.61, "text": "\"\u2022 Keep practicing. Even after y"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.5, "tree_w": 9, "tree_size": 32, "t0": 0.585, "t1": 0.335, "tft": 1.1939, "input_0": 93, "input_1": 33, "min_CLP": -4.16, "draft_iters": 8.5, "mem_use": 35.08, "gen_rate": 4.4, "speed": 4.75, "text": "You are correct. The game Into t"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.6, "tree_w": 8, "tree_size": 32, "t0": 0.6614, "t1": 0.3643, "tft": 0.9302, "input_0": 93, "input_1": 33, "min_CLP": -4.01, "draft_iters": 9.6, "mem_use": 33.96, "gen_rate": 4.7, "speed": 4.6, "text": "\"Sure, here's a summary of some "}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.3, "tree_w": 8, "tree_size": 32, "t0": 0.5767, "t1": 0.3617, "tft": 1.0708, "input_0": 93, "input_1": 33, "min_CLP": -4.13, "draft_iters": 8.3, "mem_use": 33.98, "gen_rate": 6.0, "speed": 6.38, "text": "Perfect information in the conte"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.3, "tree_w": 6, "tree_size": 32, "t0": 0.7133, "t1": 0.3467, "tft": 1.4962, "input_0": 99, "input_1": 33, "min_CLP": -4.03, "draft_iters": 10.3, "mem_use": 34.8, "gen_rate": 6.7, "speed": 6.3, "text": "\"[API_REQUEST]: curl --request G"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.1, "tree_w": 8, "tree_size": 32, "t0": 0.7614, "t1": 0.3471, "tft": 1.7075, "input_0": 90, "input_1": 33, "min_CLP": -3.99, "draft_iters": 11.1, "mem_use": 35.32, "gen_rate": 4.6, "speed": 4.13, "text": "Certainly! Here is a more concis"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 17, "tree_h": 6.2, "tree_w": 9, "tree_size": 32, "t0": 0.4975, "t1": 0.3425, "tft": 1.1639, "input_0": 86, "input_1": 33, "min_CLP": -4.28, "draft_iters": 7.2, "mem_use": 34.75, "gen_rate": 4.2, "speed": 5.05, "text": "Hi there! How can I assist you t"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.6, "tree_w": 12, "tree_size": 32, "t0": 0.3938, "t1": 0.3262, "tft": 1.1568, "input_0": 70, "input_1": 33, "min_CLP": -4.39, "draft_iters": 5.6, "mem_use": 34.85, "gen_rate": 4.0, "speed": 5.56, "text": "\"With eyes as blue as the ocean'"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 7.2, "tree_w": 11, "tree_size": 32, "t0": 0.566, "t1": 0.365, "tft": 1.2495, "input_0": 73, "input_1": 33, "min_CLP": -4.22, "draft_iters": 8.2, "mem_use": 34.26, "gen_rate": 3.5, "speed": 3.76, "text": "\"The airspeed velocity of a Euro"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.0, "tree_w": 9, "tree_size": 32, "t0": 0.4878, "t1": 0.3511, "tft": 1.5358, "input_0": 79, "input_1": 33, "min_CLP": -4.08, "draft_iters": 7.0, "mem_use": 34.22, "gen_rate": 3.9, "speed": 4.64, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 52, "tree_h": 8.6, "tree_w": 7, "tree_size": 32, "t0": 0.66, "t1": 0.33, "tft": 1.5647, "input_0": 97, "input_1": 33, "min_CLP": -4.12, "draft_iters": 9.6, "mem_use": 35.53, "gen_rate": 7.4, "speed": 7.48, "text": "You\\'re welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.0, "tree_w": 8, "tree_size": 32, "t0": 0.5557, "t1": 0.3229, "tft": 1.8959, "input_0": 96, "input_1": 33, "min_CLP": -4.05, "draft_iters": 8.0, "mem_use": 35.46, "gen_rate": 5.3, "speed": 6.02, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 24, "tree_h": 9.0, "tree_w": 6, "tree_size": 32, "t0": 0.6825, "t1": 0.3175, "tft": 2.5911, "input_0": 101, "input_1": 33, "min_CLP": -4.04, "draft_iters": 10.0, "mem_use": 36.91, "gen_rate": 6.0, "speed": 6.0, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.0, "tree_w": 9, "tree_size": 32, "t0": 0.5571, "t1": 0.3386, "tft": 1.008, "input_0": 90, "input_1": 33, "min_CLP": -4.45, "draft_iters": 8.0, "mem_use": 33.77, "gen_rate": 5.1, "speed": 5.76, "text": "The current President of Germany"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.3, "tree_w": 13, "tree_size": 32, "t0": 0.3733, "t1": 0.3444, "tft": 1.5027, "input_0": 69, "input_1": 33, "min_CLP": -4.61, "draft_iters": 5.3, "mem_use": 34.69, "gen_rate": 3.6, "speed": 4.96, "text": "PostCSS is a tool that allows yo"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 9.0, "tree_w": 6, "tree_size": 32, "t0": 0.69, "t1": 0.32, "tft": 1.8656, "input_0": 108, "input_1": 33, "min_CLP": -4.25, "draft_iters": 10.0, "mem_use": 36.58, "gen_rate": 6.0, "speed": 5.93, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 10, "tree_size": 32, "t0": 0.59, "t1": 0.3529, "tft": 1.0593, "input_0": 78, "input_1": 33, "min_CLP": -4.51, "draft_iters": 8.6, "mem_use": 34.28, "gen_rate": 4.9, "speed": 5.15, "text": "- Introduction to the topic: A b"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 32, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.2, "tree_w": 8, "tree_size": 32, "t0": 0.635, "t1": 0.3362, "tft": 1.7429, "input_0": 90, "input_1": 33, "min_CLP": -3.95, "draft_iters": 9.2, "mem_use": 35.14, "gen_rate": 4.1, "speed": 4.25, "text": "I apologize for the confusion. T"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 32, "max_branch_width": 32, "gen_rate": 6.4, "gen_rate_micro": 5.23, "gen_speed": 5.838, "gen_speed_micro": 5.495, "t0": 0.6789, "t1": 0.3462, "input_0": 88.2, "input_1": 33.0, "tree_size": 32.0, "tree_w": 8.7, "tree_h": 8.9, "prompt_len": 298.0, "min_CLP": -4.17, "mem_use": 43.19, "exp_time": 4236.85}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.9, "tree_w": 25, "tree_size": 64, "t0": 0.5567, "t1": 0.3833, "tft": 1.0681, "input_0": 116, "input_1": 65, "min_CLP": -5.54, "draft_iters": 7.9, "mem_use": 33.96, "gen_rate": 3.7, "speed": 3.91, "text": "\\'\\'\\'\\n\\n\"\u0414\u0438\u0441\u0441\u043e\u043d\u0430\u043d\u0441\" (\u0430\u043d\u0433\u043b. \"Dy"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 16, "tree_size": 64, "t0": 0.8633, "t1": 0.385, "tft": 1.7814, "input_0": 147, "input_1": 65, "min_CLP": -4.72, "draft_iters": 12.5, "mem_use": 35.49, "gen_rate": 5.7, "speed": 4.55, "text": "You are correct. The fastest cir"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 11.1, "tree_w": 14, "tree_size": 64, "t0": 0.8343, "t1": 0.3857, "tft": 2.0499, "input_0": 153, "input_1": 65, "min_CLP": -4.69, "draft_iters": 12.1, "mem_use": 36.4, "gen_rate": 5.1, "speed": 4.21, "text": "Sure, here are some specific det"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.1, "tree_w": 11, "tree_size": 64, "t0": 0.85, "t1": 0.3871, "tft": 1.0919, "input_0": 189, "input_1": 65, "min_CLP": -4.38, "draft_iters": 12.1, "mem_use": 34.14, "gen_rate": 5.3, "speed": 4.27, "text": "\"<noinput>\\nHere's a simple Pyth"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 16, "tree_size": 64, "t0": 0.7117, "t1": 0.4083, "tft": 1.399, "input_0": 167, "input_1": 65, "min_CLP": -4.72, "draft_iters": 10.0, "mem_use": 33.98, "gen_rate": 6.0, "speed": 5.36, "text": "\"Hi! Of course, I'd be happy to "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.3, "tree_w": 15, "tree_size": 64, "t0": 0.6443, "t1": 0.37, "tft": 3.2653, "input_0": 155, "input_1": 65, "min_CLP": -4.64, "draft_iters": 9.3, "mem_use": 36.54, "gen_rate": 4.7, "speed": 4.65, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.3, "tree_w": 12, "tree_size": 64, "t0": 0.8467, "t1": 0.3717, "tft": 2.4991, "input_0": 185, "input_1": 65, "min_CLP": -4.47, "draft_iters": 12.3, "mem_use": 37.11, "gen_rate": 5.3, "speed": 4.38, "text": "There are a number of other opti"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.0, "tree_w": 14, "tree_size": 64, "t0": 0.755, "t1": 0.3783, "tft": 3.145, "input_0": 163, "input_1": 65, "min_CLP": -4.64, "draft_iters": 11.0, "mem_use": 39.26, "gen_rate": 6.2, "speed": 5.44, "text": "Sure, I can offer some advice on"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 15.4, "tree_w": 13, "tree_size": 64, "t0": 1.114, "t1": 0.404, "tft": 2.2354, "input_0": 173, "input_1": 65, "min_CLP": -4.65, "draft_iters": 16.4, "mem_use": 36.72, "gen_rate": 7.0, "speed": 4.62, "text": "Here is a list of the legal stat"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 0.6983, "t1": 0.365, "tft": 2.2005, "input_0": 187, "input_1": 65, "min_CLP": -4.57, "draft_iters": 10.0, "mem_use": 36.12, "gen_rate": 5.3, "speed": 5.02, "text": "\"Choosing the most beginner-frie"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 2.14, "t1": 0.43, "tft": 1.7768, "input_0": 213, "input_1": 65, "min_CLP": -5.0, "draft_iters": 32.0, "mem_use": 34.63, "gen_rate": 33.0, "speed": 12.83, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.8, "tree_w": 12, "tree_size": 64, "t0": 1.016, "t1": 0.394, "tft": 2.9289, "input_0": 176, "input_1": 65, "min_CLP": -4.99, "draft_iters": 14.8, "mem_use": 36.48, "gen_rate": 6.4, "speed": 4.54, "text": "Sure, here\\'s a condensed summar"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.0, "tree_w": 8, "tree_size": 64, "t0": 1.1675, "t1": 0.4075, "tft": 1.7196, "input_0": 192, "input_1": 65, "min_CLP": -4.3, "draft_iters": 17.0, "mem_use": 35.68, "gen_rate": 8.8, "speed": 5.56, "text": "Certainly! Here are some Python "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 20.5, "tree_w": 19, "tree_size": 64, "t0": 1.44, "t1": 0.435, "tft": 1.2657, "input_0": 195, "input_1": 65, "min_CLP": -5.22, "draft_iters": 21.0, "mem_use": 33.96, "gen_rate": 18.0, "speed": 9.61, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 10.6, "tree_w": 14, "tree_size": 64, "t0": 0.7929, "t1": 0.3671, "tft": 2.4458, "input_0": 169, "input_1": 65, "min_CLP": -4.68, "draft_iters": 11.6, "mem_use": 37.08, "gen_rate": 5.7, "speed": 4.93, "text": "\"If you only have an hour a day "}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 13.2, "tree_w": 11, "tree_size": 64, "t0": 0.9975, "t1": 0.4225, "tft": 1.9775, "input_0": 152, "input_1": 65, "min_CLP": -4.78, "draft_iters": 14.2, "mem_use": 34.3, "gen_rate": 10.2, "speed": 7.21, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 14.7, "tree_w": 9, "tree_size": 64, "t0": 1.1033, "t1": 0.42, "tft": 1.5755, "input_0": 236, "input_1": 65, "min_CLP": -4.7, "draft_iters": 15.7, "mem_use": 33.98, "gen_rate": 13.3, "speed": 8.74, "text": "\"Fermat's Last Theorem is a famo"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 16.3, "tree_w": 10, "tree_size": 64, "t0": 1.2167, "t1": 0.4, "tft": 1.0072, "input_0": 222, "input_1": 65, "min_CLP": -4.34, "draft_iters": 17.3, "mem_use": 33.95, "gen_rate": 14.3, "speed": 8.87, "text": "Here\\'s a simple \"Hello, World!\""}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.6, "tree_w": 16, "tree_size": 64, "t0": 0.806, "t1": 0.39, "tft": 1.6752, "input_0": 174, "input_1": 65, "min_CLP": -4.8, "draft_iters": 11.6, "mem_use": 34.49, "gen_rate": 7.6, "speed": 6.35, "text": "D-theanine is another form of th"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.4, "tree_w": 18, "tree_size": 64, "t0": 0.6787, "t1": 0.4113, "tft": 1.8795, "input_0": 159, "input_1": 65, "min_CLP": -5.1, "draft_iters": 9.4, "mem_use": 33.97, "gen_rate": 4.2, "speed": 3.9, "text": "The Balfour Declaration, formall"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.4, "tree_w": 19, "tree_size": 64, "t0": 0.65, "t1": 0.3862, "tft": 2.1729, "input_0": 126, "input_1": 65, "min_CLP": -5.12, "draft_iters": 9.4, "mem_use": 34.8, "gen_rate": 4.6, "speed": 4.46, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 7.0, "tree_w": 20, "tree_size": 64, "t0": 0.55, "t1": 0.36, "tft": 0.8553, "input_0": 104, "input_1": 65, "min_CLP": -4.85, "draft_iters": 8.0, "mem_use": 33.96, "gen_rate": 7.0, "speed": 7.73, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.4, "tree_w": 12, "tree_size": 64, "t0": 0.796, "t1": 0.366, "tft": 2.3656, "input_0": 207, "input_1": 65, "min_CLP": -4.68, "draft_iters": 11.4, "mem_use": 36.32, "gen_rate": 7.0, "speed": 6.04, "text": "For an asymmetric bimodal distri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 14, "tree_size": 64, "t0": 0.6783, "t1": 0.3733, "tft": 0.991, "input_0": 169, "input_1": 65, "min_CLP": -4.71, "draft_iters": 9.7, "mem_use": 34.03, "gen_rate": 6.0, "speed": 5.69, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 14.6, "tree_w": 11, "tree_size": 64, "t0": 1.0843, "t1": 0.4114, "tft": 1.4921, "input_0": 184, "input_1": 65, "min_CLP": -4.53, "draft_iters": 15.6, "mem_use": 34.99, "gen_rate": 4.9, "speed": 3.25, "text": "\"[API_REQUEST]: curl -X POST \\\\\\"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.5, "tree_w": 12, "tree_size": 64, "t0": 1.365, "t1": 0.41, "tft": 1.0623, "input_0": 176, "input_1": 65, "min_CLP": -4.8, "draft_iters": 20.0, "mem_use": 34.0, "gen_rate": 19.5, "speed": 10.99, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 18, "tree_size": 64, "t0": 0.5829, "t1": 0.3871, "tft": 1.7847, "input_0": 128, "input_1": 65, "min_CLP": -5.11, "draft_iters": 8.3, "mem_use": 34.66, "gen_rate": 4.9, "speed": 5.0, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 18, "tree_h": 16.7, "tree_w": 12, "tree_size": 64, "t0": 1.22, "t1": 0.41, "tft": 1.6118, "input_0": 194, "input_1": 65, "min_CLP": -4.49, "draft_iters": 17.7, "mem_use": 34.52, "gen_rate": 6.0, "speed": 3.68, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.3, "tree_w": 22, "tree_size": 64, "t0": 0.51, "t1": 0.365, "tft": 3.1496, "input_0": 119, "input_1": 65, "min_CLP": -5.3, "draft_iters": 7.3, "mem_use": 36.46, "gen_rate": 3.3, "speed": 3.77, "text": "\"Give me a world where magic is "}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.4, "tree_w": 15, "tree_size": 64, "t0": 0.8029, "t1": 0.4071, "tft": 0.918, "input_0": 150, "input_1": 65, "min_CLP": -4.8, "draft_iters": 11.4, "mem_use": 34.01, "gen_rate": 4.7, "speed": 3.9, "text": "Sure, here are some delicious op"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 19.3, "tree_w": 10, "tree_size": 64, "t0": 1.41, "t1": 0.4267, "tft": 1.7563, "input_0": 233, "input_1": 65, "min_CLP": -4.33, "draft_iters": 20.3, "mem_use": 34.71, "gen_rate": 13.0, "speed": 7.09, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.0, "tree_w": 16, "tree_size": 64, "t0": 0.916, "t1": 0.41, "tft": 1.8609, "input_0": 167, "input_1": 65, "min_CLP": -5.04, "draft_iters": 13.0, "mem_use": 35.11, "gen_rate": 6.6, "speed": 4.98, "text": "[API_REQUEST]: {\\ncurl -X POST -"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.2, "tree_w": 18, "tree_size": 64, "t0": 0.7167, "t1": 0.39, "tft": 1.631, "input_0": 154, "input_1": 65, "min_CLP": -5.02, "draft_iters": 10.2, "mem_use": 34.47, "gen_rate": 5.7, "speed": 5.13, "text": "As the goddess of love, fertilit"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 14, "tree_size": 64, "t0": 0.724, "t1": 0.372, "tft": 1.9574, "input_0": 157, "input_1": 65, "min_CLP": -4.74, "draft_iters": 10.4, "mem_use": 36.13, "gen_rate": 6.8, "speed": 6.19, "text": "Yes, there are a few substitutes"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.2, "tree_w": 11, "tree_size": 64, "t0": 0.775, "t1": 0.3683, "tft": 2.0104, "input_0": 189, "input_1": 65, "min_CLP": -4.62, "draft_iters": 11.2, "mem_use": 36.17, "gen_rate": 6.2, "speed": 5.39, "text": "\"When choosing an ISP package, t"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 16, "tree_size": 64, "t0": 0.67, "t1": 0.365, "tft": 3.0728, "input_0": 157, "input_1": 65, "min_CLP": -4.78, "draft_iters": 9.8, "mem_use": 38.86, "gen_rate": 5.3, "speed": 5.15, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.0, "tree_w": 20, "tree_size": 64, "t0": 0.5729, "t1": 0.3814, "tft": 1.3109, "input_0": 161, "input_1": 65, "min_CLP": -4.89, "draft_iters": 8.0, "mem_use": 33.99, "gen_rate": 5.4, "speed": 5.71, "text": "\"The airspeed velocity of an unl"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 2.12, "t1": 0.46, "tft": 2.2521, "input_0": 155, "input_1": 65, "min_CLP": -5.46, "draft_iters": 32.0, "mem_use": 34.52, "gen_rate": 33.0, "speed": 12.78, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.4, "tree_w": 15, "tree_size": 64, "t0": 0.7786, "t1": 0.3743, "tft": 2.5697, "input_0": 149, "input_1": 65, "min_CLP": -4.89, "draft_iters": 11.4, "mem_use": 36.88, "gen_rate": 4.6, "speed": 3.96, "text": "\"I understand your request, and "}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.2, "tree_w": 13, "tree_size": 64, "t0": 0.938, "t1": 0.414, "tft": 1.6158, "input_0": 201, "input_1": 65, "min_CLP": -4.79, "draft_iters": 13.2, "mem_use": 34.92, "gen_rate": 7.2, "speed": 5.33, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 4.7, "tree_w": 28, "tree_size": 64, "t0": 0.409, "t1": 0.39, "tft": 1.0547, "input_0": 98, "input_1": 65, "min_CLP": -5.49, "draft_iters": 5.7, "mem_use": 34.21, "gen_rate": 3.3, "speed": 4.14, "text": "Foolish mortal! I am a mighty go"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 17.7, "tree_w": 12, "tree_size": 64, "t0": 1.2467, "t1": 0.39, "tft": 2.204, "input_0": 160, "input_1": 65, "min_CLP": -5.06, "draft_iters": 18.3, "mem_use": 36.7, "gen_rate": 15.7, "speed": 9.57, "text": "\"In the context of the Elder Scr"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 2.12, "t1": 0.42, "tft": 2.8782, "input_0": 197, "input_1": 65, "min_CLP": -4.67, "draft_iters": 32.0, "mem_use": 37.13, "gen_rate": 33.0, "speed": 12.99, "text": "\"[INST] Certainly! It sounds lik"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.8, "tree_w": 11, "tree_size": 64, "t0": 0.8217, "t1": 0.3783, "tft": 1.9289, "input_0": 189, "input_1": 65, "min_CLP": -4.55, "draft_iters": 11.8, "mem_use": 35.48, "gen_rate": 6.2, "speed": 5.15, "text": "It\\'s difficult to say which one"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 9, "tree_h": 12.0, "tree_w": 8, "tree_size": 64, "t0": 0.88, "t1": 0.35, "tft": 1.7051, "input_0": 193, "input_1": 65, "min_CLP": -4.47, "draft_iters": 13.0, "mem_use": 34.74, "gen_rate": 9.0, "speed": 7.26, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 14, "tree_h": 8.8, "tree_w": 25, "tree_size": 64, "t0": 0.6733, "t1": 0.39, "tft": 2.293, "input_0": 95, "input_1": 65, "min_CLP": -5.91, "draft_iters": 9.8, "mem_use": 34.48, "gen_rate": 2.3, "speed": 2.19, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.3, "tree_w": 15, "tree_size": 64, "t0": 0.73, "t1": 0.4, "tft": 1.4057, "input_0": 154, "input_1": 65, "min_CLP": -4.98, "draft_iters": 10.3, "mem_use": 33.99, "gen_rate": 4.9, "speed": 4.3, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 26.0, "tree_w": 8, "tree_size": 64, "t0": 1.75, "t1": 0.39, "tft": 3.1428, "input_0": 208, "input_1": 65, "min_CLP": -4.84, "draft_iters": 26.3, "mem_use": 39.4, "gen_rate": 15.0, "speed": 7.01, "text": "\"Here's a revised version with a"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 22, "tree_size": 64, "t0": 0.4875, "t1": 0.375, "tft": 2.4051, "input_0": 119, "input_1": 65, "min_CLP": -5.24, "draft_iters": 6.9, "mem_use": 35.72, "gen_rate": 4.0, "speed": 4.65, "text": "You see, the truth is that the V"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 18, "tree_h": 7.8, "tree_w": 18, "tree_size": 64, "t0": 0.608, "t1": 0.374, "tft": 1.9111, "input_0": 112, "input_1": 65, "min_CLP": -5.17, "draft_iters": 8.8, "mem_use": 34.75, "gen_rate": 3.6, "speed": 3.66, "text": "If you have any other questions,"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 16.0, "tree_w": 10, "tree_size": 64, "t0": 1.1433, "t1": 0.3967, "tft": 1.1226, "input_0": 178, "input_1": 65, "min_CLP": -5.04, "draft_iters": 16.7, "mem_use": 34.26, "gen_rate": 15.7, "speed": 10.17, "text": "\u70b9\u51fb\u7387\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bdd\u9898\u3002[INST]"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 12.6, "tree_w": 11, "tree_size": 64, "t0": 0.938, "t1": 0.38, "tft": 2.6172, "input_0": 172, "input_1": 65, "min_CLP": -4.5, "draft_iters": 13.6, "mem_use": 36.17, "gen_rate": 8.8, "speed": 6.68, "text": "The presence of F-centers, also "}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 14, "tree_size": 64, "t0": 0.806, "t1": 0.392, "tft": 1.9622, "input_0": 175, "input_1": 65, "min_CLP": -4.61, "draft_iters": 11.6, "mem_use": 35.36, "gen_rate": 6.6, "speed": 5.51, "text": "Sure, here are some more histori"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 0.692, "t1": 0.388, "tft": 1.8624, "input_0": 169, "input_1": 65, "min_CLP": -4.89, "draft_iters": 9.8, "mem_use": 35.7, "gen_rate": 6.4, "speed": 5.95, "text": "I appreciate your question. Whil"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.4, "tree_w": 22, "tree_size": 64, "t0": 0.5267, "t1": 0.3778, "tft": 0.9667, "input_0": 115, "input_1": 65, "min_CLP": -5.12, "draft_iters": 7.4, "mem_use": 34.16, "gen_rate": 3.6, "speed": 3.93, "text": "The answer would be \"Some people"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.3, "tree_w": 24, "tree_size": 64, "t0": 0.437, "t1": 0.353, "tft": 2.1847, "input_0": 95, "input_1": 65, "min_CLP": -5.21, "draft_iters": 6.3, "mem_use": 36.56, "gen_rate": 3.4, "speed": 4.3, "text": "\"FullView.io is a revolutionary "}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.3, "tree_w": 16, "tree_size": 64, "t0": 0.7717, "t1": 0.3767, "tft": 2.8176, "input_0": 165, "input_1": 65, "min_CLP": -4.85, "draft_iters": 11.3, "mem_use": 37.81, "gen_rate": 5.7, "speed": 4.94, "text": "You are correct. Thank you for p"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.5, "tree_w": 13, "tree_size": 64, "t0": 0.855, "t1": 0.3725, "tft": 2.8204, "input_0": 193, "input_1": 65, "min_CLP": -4.81, "draft_iters": 12.5, "mem_use": 37.97, "gen_rate": 8.2, "speed": 6.72, "text": "As a beginner with little progra"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.4, "tree_w": 11, "tree_size": 64, "t0": 1.078, "t1": 0.414, "tft": 2.109, "input_0": 184, "input_1": 65, "min_CLP": -4.53, "draft_iters": 15.4, "mem_use": 35.63, "gen_rate": 6.8, "speed": 4.56, "text": "I am an AI language model and do"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 0.68, "t1": 0.4029, "tft": 1.4001, "input_0": 154, "input_1": 65, "min_CLP": -4.65, "draft_iters": 9.6, "mem_use": 33.99, "gen_rate": 5.3, "speed": 4.87, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 14.2, "tree_w": 15, "tree_size": 64, "t0": 1.0367, "t1": 0.385, "tft": 2.149, "input_0": 166, "input_1": 65, "min_CLP": -4.65, "draft_iters": 15.2, "mem_use": 36.4, "gen_rate": 5.7, "speed": 3.98, "text": "Understood. So, in summary, whil"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.5, "tree_w": 24, "tree_size": 64, "t0": 0.5175, "t1": 0.355, "tft": 2.66, "input_0": 128, "input_1": 65, "min_CLP": -5.1, "draft_iters": 7.5, "mem_use": 37.22, "gen_rate": 4.0, "speed": 4.57, "text": "[The scene opens with the Sparta"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.3, "tree_w": 20, "tree_size": 64, "t0": 0.58, "t1": 0.3886, "tft": 1.4824, "input_0": 127, "input_1": 65, "min_CLP": -5.18, "draft_iters": 8.3, "mem_use": 34.93, "gen_rate": 5.1, "speed": 5.32, "text": "Yeah, I agree. To make it easier"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 4.8, "tree_w": 28, "tree_size": 64, "t0": 0.4136, "t1": 0.39, "tft": 1.6259, "input_0": 98, "input_1": 65, "min_CLP": -5.33, "draft_iters": 5.8, "mem_use": 34.65, "gen_rate": 3.1, "speed": 3.85, "text": "The proof-of-stake is simply whe"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.6, "tree_w": 23, "tree_size": 64, "t0": 0.46, "t1": 0.376, "tft": 1.4829, "input_0": 94, "input_1": 65, "min_CLP": -5.27, "draft_iters": 6.6, "mem_use": 34.77, "gen_rate": 3.2, "speed": 3.82, "text": "It is a scientific fact that if "}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.4, "tree_w": 17, "tree_size": 64, "t0": 0.5837, "t1": 0.3687, "tft": 2.4869, "input_0": 141, "input_1": 65, "min_CLP": -4.83, "draft_iters": 8.4, "mem_use": 36.84, "gen_rate": 4.2, "speed": 4.47, "text": "Void pointers are pointers that "}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.4, "tree_w": 17, "tree_size": 64, "t0": 0.6486, "t1": 0.3629, "tft": 2.6078, "input_0": 144, "input_1": 65, "min_CLP": -4.86, "draft_iters": 9.4, "mem_use": 37.34, "gen_rate": 4.6, "speed": 4.54, "text": "\"I'm sorry, but I don't understa"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.8, "tree_w": 11, "tree_size": 64, "t0": 0.948, "t1": 0.384, "tft": 2.5635, "input_0": 194, "input_1": 65, "min_CLP": -4.59, "draft_iters": 13.8, "mem_use": 36.57, "gen_rate": 7.4, "speed": 5.55, "text": "To implement two-factor authenti"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 31, "tree_h": 13.4, "tree_w": 13, "tree_size": 64, "t0": 1.002, "t1": 0.422, "tft": 1.3444, "input_0": 156, "input_1": 65, "min_CLP": -4.92, "draft_iters": 14.4, "mem_use": 34.4, "gen_rate": 6.2, "speed": 4.36, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.7, "tree_w": 18, "tree_size": 64, "t0": 0.6183, "t1": 0.3983, "tft": 1.9783, "input_0": 146, "input_1": 65, "min_CLP": -4.92, "draft_iters": 8.7, "mem_use": 33.99, "gen_rate": 6.0, "speed": 5.89, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 21.2, "tree_w": 6, "tree_size": 64, "t0": 1.5, "t1": 0.3725, "tft": 2.9721, "input_0": 225, "input_1": 65, "min_CLP": -4.49, "draft_iters": 22.0, "mem_use": 36.8, "gen_rate": 10.5, "speed": 5.61, "text": "\"Sure, here's a table with the a"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.4, "tree_w": 20, "tree_size": 64, "t0": 0.5312, "t1": 0.4, "tft": 0.9232, "input_0": 120, "input_1": 65, "min_CLP": -5.12, "draft_iters": 7.4, "mem_use": 33.94, "gen_rate": 4.2, "speed": 4.56, "text": "The city of Berlin was founded b"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 3, "tree_size": 64, "t0": 2.15, "t1": 0.42, "tft": 3.0759, "input_0": 270, "input_1": 65, "min_CLP": -6.62, "draft_iters": 32.0, "mem_use": 36.28, "gen_rate": 33.0, "speed": 12.86, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 23.0, "tree_w": 7, "tree_size": 64, "t0": 1.6667, "t1": 0.4133, "tft": 2.2184, "input_0": 255, "input_1": 65, "min_CLP": -4.44, "draft_iters": 24.0, "mem_use": 36.14, "gen_rate": 16.3, "speed": 7.86, "text": "Certainly. While \"Fooled by Rand"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 7.4, "tree_w": 19, "tree_size": 64, "t0": 0.5912, "t1": 0.3887, "tft": 0.9075, "input_0": 140, "input_1": 65, "min_CLP": -5.01, "draft_iters": 8.4, "mem_use": 33.95, "gen_rate": 5.1, "speed": 5.22, "text": "The term \"pornography\" refers to"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 2.15, "t1": 0.46, "tft": 1.1175, "input_0": 168, "input_1": 65, "min_CLP": -5.59, "draft_iters": 32.0, "mem_use": 34.26, "gen_rate": 33.0, "speed": 12.66, "text": "You can visit at The World Clock"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.1, "tree_w": 18, "tree_size": 64, "t0": 0.6386, "t1": 0.3786, "tft": 1.0125, "input_0": 130, "input_1": 65, "min_CLP": -4.9, "draft_iters": 9.1, "mem_use": 34.35, "gen_rate": 5.0, "speed": 4.91, "text": "The five second rule is a myth. "}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 14.5, "tree_w": 12, "tree_size": 64, "t0": 1.0917, "t1": 0.4217, "tft": 1.3443, "input_0": 182, "input_1": 65, "min_CLP": -4.5, "draft_iters": 15.5, "mem_use": 34.07, "gen_rate": 7.5, "speed": 4.96, "text": "\"You have 5 eggs left.\\n\\nHere's"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 46, "tree_h": 15.5, "tree_w": 9, "tree_size": 64, "t0": 1.1525, "t1": 0.3925, "tft": 1.8638, "input_0": 234, "input_1": 65, "min_CLP": -4.35, "draft_iters": 16.5, "mem_use": 34.82, "gen_rate": 11.5, "speed": 7.48, "text": "\"Sure, I'd be happy to explain s"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 20, "tree_h": 9.0, "tree_w": 17, "tree_size": 64, "t0": 0.6975, "t1": 0.3925, "tft": 1.2742, "input_0": 160, "input_1": 65, "min_CLP": -4.89, "draft_iters": 10.0, "mem_use": 34.39, "gen_rate": 5.0, "speed": 4.57, "text": "\"No problem, I'm glad I could he"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 10.2, "tree_w": 16, "tree_size": 64, "t0": 0.7925, "t1": 0.4025, "tft": 1.0057, "input_0": 128, "input_1": 65, "min_CLP": -4.86, "draft_iters": 11.2, "mem_use": 34.1, "gen_rate": 4.0, "speed": 3.35, "text": "Here\\'s a potential announcement"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.2, "tree_w": 19, "tree_size": 64, "t0": 0.645, "t1": 0.37, "tft": 1.9572, "input_0": 180, "input_1": 65, "min_CLP": -5.18, "draft_iters": 9.2, "mem_use": 34.71, "gen_rate": 5.7, "speed": 5.58, "text": "One example of sexual selection "}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 11, "tree_size": 64, "t0": 0.782, "t1": 0.378, "tft": 1.8195, "input_0": 193, "input_1": 65, "min_CLP": -4.65, "draft_iters": 11.2, "mem_use": 35.75, "gen_rate": 7.0, "speed": 6.01, "text": "AI assistants can help individua"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 42, "tree_h": 16.0, "tree_w": 19, "tree_size": 64, "t0": 1.13, "t1": 0.3733, "tft": 2.2733, "input_0": 140, "input_1": 65, "min_CLP": -5.04, "draft_iters": 16.7, "mem_use": 36.77, "gen_rate": 14.0, "speed": 9.32, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 9.5, "tree_w": 16, "tree_size": 64, "t0": 0.7337, "t1": 0.3962, "tft": 1.7533, "input_0": 161, "input_1": 65, "min_CLP": -4.73, "draft_iters": 10.5, "mem_use": 35.27, "gen_rate": 4.9, "speed": 4.32, "text": "The scp command is a Unix-based "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 62, "tree_h": 29.0, "tree_w": 7, "tree_size": 64, "t0": 2.01, "t1": 0.42, "tft": 2.1554, "input_0": 213, "input_1": 65, "min_CLP": -4.51, "draft_iters": 29.3, "mem_use": 35.94, "gen_rate": 20.7, "speed": 8.51, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 20, "tree_size": 64, "t0": 0.6, "t1": 0.37, "tft": 1.3382, "input_0": 140, "input_1": 65, "min_CLP": -4.97, "draft_iters": 8.5, "mem_use": 34.01, "gen_rate": 5.5, "speed": 5.69, "text": "\"No, it is not illegal to keep a"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 15, "tree_size": 64, "t0": 0.758, "t1": 0.404, "tft": 1.2585, "input_0": 157, "input_1": 65, "min_CLP": -4.64, "draft_iters": 10.8, "mem_use": 34.3, "gen_rate": 6.4, "speed": 5.51, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 15.6, "tree_w": 12, "tree_size": 64, "t0": 1.132, "t1": 0.404, "tft": 1.5117, "input_0": 142, "input_1": 65, "min_CLP": -4.92, "draft_iters": 16.4, "mem_use": 34.6, "gen_rate": 9.2, "speed": 5.98, "text": "Is there anything else you would"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 6.3, "tree_w": 23, "tree_size": 64, "t0": 0.5192, "t1": 0.39, "tft": 1.1118, "input_0": 121, "input_1": 65, "min_CLP": -5.29, "draft_iters": 7.3, "mem_use": 34.27, "gen_rate": 2.9, "speed": 3.21, "text": "\"Hey, don't worry about your bro"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.3, "tree_w": 13, "tree_size": 64, "t0": 1.23, "t1": 0.4133, "tft": 1.9518, "input_0": 150, "input_1": 65, "min_CLP": -5.12, "draft_iters": 18.0, "mem_use": 34.04, "gen_rate": 13.3, "speed": 8.12, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 0.7, "t1": 0.366, "tft": 1.035, "input_0": 170, "input_1": 65, "min_CLP": -4.73, "draft_iters": 10.0, "mem_use": 34.02, "gen_rate": 6.4, "speed": 6.01, "text": "The task is asking for the time "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.7, "tree_w": 8, "tree_size": 64, "t0": 1.42, "t1": 0.41, "tft": 2.4952, "input_0": 195, "input_1": 65, "min_CLP": -4.31, "draft_iters": 20.7, "mem_use": 35.75, "gen_rate": 10.7, "speed": 5.82, "text": "\"Sure, I'd be happy to explain.\\"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 0.87, "t1": 0.43, "tft": 1.214, "input_0": 205, "input_1": 65, "min_CLP": -4.88, "draft_iters": 12.2, "mem_use": 34.02, "gen_rate": 9.0, "speed": 6.92, "text": "\"The parts of France that would "}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 13, "tree_size": 64, "t0": 0.875, "t1": 0.4, "tft": 1.9634, "input_0": 196, "input_1": 65, "min_CLP": -4.79, "draft_iters": 12.2, "mem_use": 34.32, "gen_rate": 8.2, "speed": 6.48, "text": "To write a first person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.0, "tree_w": 14, "tree_size": 64, "t0": 0.912, "t1": 0.396, "tft": 0.9283, "input_0": 204, "input_1": 65, "min_CLP": -4.62, "draft_iters": 13.0, "mem_use": 33.99, "gen_rate": 8.0, "speed": 6.1, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 6.8, "tree_w": 20, "tree_size": 64, "t0": 0.5537, "t1": 0.4062, "tft": 0.9837, "input_0": 136, "input_1": 65, "min_CLP": -5.07, "draft_iters": 7.8, "mem_use": 34.3, "gen_rate": 4.9, "speed": 5.08, "text": "There are many paths to becoming"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 6.4, "tree_w": 18, "tree_size": 64, "t0": 0.5292, "t1": 0.3842, "tft": 1.3795, "input_0": 130, "input_1": 65, "min_CLP": -5.05, "draft_iters": 7.4, "mem_use": 34.16, "gen_rate": 2.9, "speed": 3.19, "text": "A gas-operated rifle is a type o"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 0.678, "t1": 0.392, "tft": 1.485, "input_0": 153, "input_1": 65, "min_CLP": -4.97, "draft_iters": 9.6, "mem_use": 34.4, "gen_rate": 6.8, "speed": 6.38, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 17, "tree_size": 64, "t0": 0.69, "t1": 0.3567, "tft": 2.5949, "input_0": 169, "input_1": 65, "min_CLP": -4.95, "draft_iters": 10.0, "mem_use": 37.24, "gen_rate": 6.0, "speed": 5.73, "text": "Yes, there are several libraries"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 15, "tree_size": 64, "t0": 0.708, "t1": 0.362, "tft": 1.4148, "input_0": 155, "input_1": 65, "min_CLP": -4.85, "draft_iters": 10.2, "mem_use": 34.47, "gen_rate": 6.4, "speed": 5.96, "text": "Yes, if someone finds lost prope"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.1, "tree_w": 21, "tree_size": 64, "t0": 0.495, "t1": 0.3538, "tft": 2.3585, "input_0": 117, "input_1": 65, "min_CLP": -5.16, "draft_iters": 7.1, "mem_use": 37.34, "gen_rate": 4.0, "speed": 4.71, "text": "Xin ch\u00e0o b\u1ea1n! T\u00f4i l\u00e0 m\u1ed9t tr\u1ee3 l\u00fd "}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 6.2, "tree_w": 22, "tree_size": 64, "t0": 0.5073, "t1": 0.3855, "tft": 1.2102, "input_0": 116, "input_1": 65, "min_CLP": -5.12, "draft_iters": 7.2, "mem_use": 34.83, "gen_rate": 3.0, "speed": 3.36, "text": "So, what really happened? What w"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 58, "tree_h": 20.7, "tree_w": 7, "tree_size": 64, "t0": 1.4867, "t1": 0.39, "tft": 1.1969, "input_0": 228, "input_1": 65, "min_CLP": -4.35, "draft_iters": 21.3, "mem_use": 34.35, "gen_rate": 19.3, "speed": 10.31, "text": "Certainly! Here\\'s an example of"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 21, "tree_size": 64, "t0": 0.52, "t1": 0.3714, "tft": 2.2371, "input_0": 108, "input_1": 65, "min_CLP": -5.34, "draft_iters": 7.4, "mem_use": 35.77, "gen_rate": 4.7, "speed": 5.28, "text": "1. Scorpions\\n2. Rammstein\\n3. D"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 5.1, "tree_w": 25, "tree_size": 64, "t0": 0.438, "t1": 0.406, "tft": 1.3203, "input_0": 106, "input_1": 65, "min_CLP": -5.25, "draft_iters": 6.1, "mem_use": 34.31, "gen_rate": 3.5, "speed": 4.15, "text": "The best strategy to win a thumb"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.8, "tree_w": 11, "tree_size": 64, "t0": 0.875, "t1": 0.3625, "tft": 2.1395, "input_0": 187, "input_1": 65, "min_CLP": -4.69, "draft_iters": 12.8, "mem_use": 36.33, "gen_rate": 8.5, "speed": 6.87, "text": "To acquire revenue from customer"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.6, "tree_w": 15, "tree_size": 64, "t0": 0.604, "t1": 0.378, "tft": 1.3924, "input_0": 148, "input_1": 65, "min_CLP": -4.96, "draft_iters": 8.6, "mem_use": 34.94, "gen_rate": 6.4, "speed": 6.52, "text": "As a language model, I can gener"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.7, "tree_w": 17, "tree_size": 64, "t0": 0.6829, "t1": 0.3857, "tft": 1.2337, "input_0": 160, "input_1": 65, "min_CLP": -4.95, "draft_iters": 9.7, "mem_use": 34.47, "gen_rate": 4.9, "speed": 4.56, "text": "I see. In William Shakespeare\u2019s "}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 12, "tree_size": 64, "t0": 0.838, "t1": 0.41, "tft": 1.7336, "input_0": 179, "input_1": 65, "min_CLP": -4.67, "draft_iters": 12.0, "mem_use": 34.61, "gen_rate": 6.4, "speed": 5.12, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 7.1, "tree_w": 21, "tree_size": 64, "t0": 0.5689, "t1": 0.3689, "tft": 2.1603, "input_0": 133, "input_1": 65, "min_CLP": -5.32, "draft_iters": 8.1, "mem_use": 35.88, "gen_rate": 4.0, "speed": 4.27, "text": "\"Certainly! Here's a poem in Que"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.0, "tree_w": 14, "tree_size": 64, "t0": 0.772, "t1": 0.394, "tft": 1.4448, "input_0": 156, "input_1": 65, "min_CLP": -4.67, "draft_iters": 11.0, "mem_use": 33.99, "gen_rate": 6.4, "speed": 5.48, "text": "Sure, here are the five most com"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.8, "tree_w": 17, "tree_size": 64, "t0": 0.625, "t1": 0.4033, "tft": 1.1629, "input_0": 142, "input_1": 65, "min_CLP": -4.87, "draft_iters": 8.8, "mem_use": 34.03, "gen_rate": 5.7, "speed": 5.5, "text": "The error with this code is that"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.4, "tree_w": 19, "tree_size": 64, "t0": 0.5187, "t1": 0.365, "tft": 1.5718, "input_0": 139, "input_1": 65, "min_CLP": -4.97, "draft_iters": 7.4, "mem_use": 35.41, "gen_rate": 4.2, "speed": 4.8, "text": "\"As a helpful assistant, I would"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 17, "tree_size": 64, "t0": 0.768, "t1": 0.378, "tft": 1.6607, "input_0": 173, "input_1": 65, "min_CLP": -4.83, "draft_iters": 11.0, "mem_use": 34.64, "gen_rate": 6.6, "speed": 5.75, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 14.0, "tree_w": 10, "tree_size": 64, "t0": 1.0533, "t1": 0.4, "tft": 1.4798, "input_0": 188, "input_1": 65, "min_CLP": -4.24, "draft_iters": 15.0, "mem_use": 34.76, "gen_rate": 6.8, "speed": 4.7, "text": "\"To create a Python program that"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 0.6262, "t1": 0.3638, "tft": 2.1803, "input_0": 161, "input_1": 65, "min_CLP": -4.82, "draft_iters": 9.0, "mem_use": 36.54, "gen_rate": 4.4, "speed": 4.42, "text": "\"If you're unsure about trying a"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 15.0, "tree_w": 15, "tree_size": 64, "t0": 1.108, "t1": 0.406, "tft": 1.4967, "input_0": 150, "input_1": 65, "min_CLP": -4.8, "draft_iters": 16.0, "mem_use": 34.55, "gen_rate": 6.4, "speed": 4.23, "text": "Great idea! Here\\'s an updated a"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 29.7, "tree_w": 7, "tree_size": 64, "t0": 2.0633, "t1": 0.4233, "tft": 3.3077, "input_0": 263, "input_1": 65, "min_CLP": -4.75, "draft_iters": 30.0, "mem_use": 35.93, "gen_rate": 10.7, "speed": 4.29, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 17, "tree_size": 64, "t0": 0.6143, "t1": 0.3586, "tft": 1.1997, "input_0": 150, "input_1": 65, "min_CLP": -4.98, "draft_iters": 8.7, "mem_use": 33.97, "gen_rate": 4.7, "speed": 4.83, "text": "Yes, I can think and feel like a"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 11.1, "tree_w": 20, "tree_size": 64, "t0": 0.8414, "t1": 0.3943, "tft": 1.3057, "input_0": 114, "input_1": 65, "min_CLP": -5.26, "draft_iters": 12.1, "mem_use": 34.19, "gen_rate": 6.0, "speed": 4.86, "text": "Attention mechanism,\\nSoftly foc"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.9, "tree_w": 16, "tree_size": 64, "t0": 0.6914, "t1": 0.38, "tft": 1.1647, "input_0": 155, "input_1": 65, "min_CLP": -4.77, "draft_iters": 9.9, "mem_use": 34.44, "gen_rate": 4.6, "speed": 4.27, "text": "\"Thank you! I'm here to help and"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.7, "tree_w": 19, "tree_size": 64, "t0": 0.6044, "t1": 0.3667, "tft": 1.9848, "input_0": 129, "input_1": 65, "min_CLP": -5.36, "draft_iters": 8.7, "mem_use": 36.05, "gen_rate": 3.6, "speed": 3.66, "text": "Thou art my sun, that shineth br"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 34, "tree_h": 7.9, "tree_w": 18, "tree_size": 64, "t0": 0.6217, "t1": 0.3908, "tft": 1.4602, "input_0": 120, "input_1": 65, "min_CLP": -5.05, "draft_iters": 8.9, "mem_use": 34.61, "gen_rate": 2.8, "speed": 2.8, "text": "[INST] What is the main purpose "}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.6, "tree_w": 13, "tree_size": 64, "t0": 1.024, "t1": 0.402, "tft": 1.3508, "input_0": 193, "input_1": 65, "min_CLP": -4.64, "draft_iters": 14.6, "mem_use": 34.01, "gen_rate": 7.0, "speed": 4.91, "text": "\"Certainly! Here are some words "}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.8, "tree_w": 14, "tree_size": 64, "t0": 0.7717, "t1": 0.41, "tft": 1.1298, "input_0": 173, "input_1": 65, "min_CLP": -4.84, "draft_iters": 10.8, "mem_use": 33.99, "gen_rate": 5.8, "speed": 4.93, "text": "Presidents\u2019 Day, also known as W"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 9, "tree_h": 12.0, "tree_w": 15, "tree_size": 64, "t0": 0.9, "t1": 0.38, "tft": 1.1289, "input_0": 254, "input_1": 65, "min_CLP": -4.98, "draft_iters": 13.0, "mem_use": 34.3, "gen_rate": 9.0, "speed": 7.02, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 13, "tree_size": 64, "t0": 0.872, "t1": 0.372, "tft": 1.7896, "input_0": 180, "input_1": 65, "min_CLP": -4.52, "draft_iters": 12.6, "mem_use": 35.09, "gen_rate": 6.8, "speed": 5.45, "text": "The existence of the KeyHole sat"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 22, "tree_h": 5.8, "tree_w": 25, "tree_size": 64, "t0": 0.485, "t1": 0.3767, "tft": 1.143, "input_0": 110, "input_1": 65, "min_CLP": -5.56, "draft_iters": 6.8, "mem_use": 34.37, "gen_rate": 3.7, "speed": 4.26, "text": "\"Why was the broke college stude"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 24, "tree_size": 64, "t0": 0.5075, "t1": 0.3837, "tft": 1.0941, "input_0": 126, "input_1": 65, "min_CLP": -5.09, "draft_iters": 7.1, "mem_use": 34.44, "gen_rate": 4.2, "speed": 4.76, "text": "Well, I\\'m glad you like it! I\\'"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 23.0, "tree_w": 13, "tree_size": 64, "t0": 1.59, "t1": 0.42, "tft": 1.4496, "input_0": 164, "input_1": 65, "min_CLP": -5.32, "draft_iters": 23.5, "mem_use": 33.99, "gen_rate": 19.5, "speed": 9.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 35, "tree_h": 5.4, "tree_w": 25, "tree_size": 64, "t0": 0.4538, "t1": 0.37, "tft": 1.2936, "input_0": 114, "input_1": 65, "min_CLP": -5.33, "draft_iters": 6.4, "mem_use": 34.68, "gen_rate": 2.7, "speed": 3.28, "text": "\"Ha, he must\\'ve lived in the st"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 0.6362, "t1": 0.3613, "tft": 0.969, "input_0": 166, "input_1": 65, "min_CLP": -5.25, "draft_iters": 9.0, "mem_use": 34.11, "gen_rate": 4.4, "speed": 4.39, "text": "The issue you\\'re experiencing i"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 0.7057, "t1": 0.3886, "tft": 1.5578, "input_0": 172, "input_1": 65, "min_CLP": -5.06, "draft_iters": 10.0, "mem_use": 35.33, "gen_rate": 5.1, "speed": 4.71, "text": "Sure, there are several movies a"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.4, "tree_w": 24, "tree_size": 64, "t0": 0.4514, "t1": 0.3643, "tft": 1.0993, "input_0": 99, "input_1": 65, "min_CLP": -5.34, "draft_iters": 6.4, "mem_use": 34.44, "gen_rate": 4.6, "speed": 5.61, "text": "\"Hey, I'm not trying to take ove"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.5, "tree_w": 16, "tree_size": 64, "t0": 0.8017, "t1": 0.38, "tft": 2.1878, "input_0": 178, "input_1": 65, "min_CLP": -4.77, "draft_iters": 11.5, "mem_use": 35.63, "gen_rate": 5.8, "speed": 4.93, "text": "Based on your preferences, I wou"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 21, "tree_size": 64, "t0": 0.5771, "t1": 0.3629, "tft": 1.3469, "input_0": 121, "input_1": 65, "min_CLP": -5.25, "draft_iters": 8.3, "mem_use": 34.39, "gen_rate": 4.6, "speed": 4.85, "text": "\"Open Assistant: Finally, an Ope"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 0.705, "t1": 0.3887, "tft": 1.2436, "input_0": 147, "input_1": 65, "min_CLP": -4.86, "draft_iters": 10.0, "mem_use": 34.28, "gen_rate": 4.2, "speed": 3.89, "text": "\"Sure! Here's an illustration of"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.6, "tree_w": 12, "tree_size": 64, "t0": 0.812, "t1": 0.366, "tft": 2.5756, "input_0": 230, "input_1": 65, "min_CLP": -4.75, "draft_iters": 11.6, "mem_use": 36.62, "gen_rate": 7.4, "speed": 6.28, "text": "This is because the Average Rate"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 0.705, "t1": 0.36, "tft": 1.3015, "input_0": 172, "input_1": 65, "min_CLP": -4.77, "draft_iters": 10.0, "mem_use": 33.98, "gen_rate": 6.0, "speed": 5.65, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.0, "tree_w": 23, "tree_size": 64, "t0": 0.4967, "t1": 0.3778, "tft": 1.2921, "input_0": 116, "input_1": 65, "min_CLP": -5.31, "draft_iters": 7.0, "mem_use": 34.52, "gen_rate": 4.0, "speed": 4.59, "text": "I think that the OP\\'s question "}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 17, "tree_size": 64, "t0": 0.6229, "t1": 0.3686, "tft": 1.1655, "input_0": 147, "input_1": 65, "min_CLP": -4.88, "draft_iters": 8.9, "mem_use": 34.15, "gen_rate": 4.7, "speed": 4.75, "text": "The second batch of pancakes bro"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 21.5, "tree_w": 13, "tree_size": 64, "t0": 1.5, "t1": 0.39, "tft": 1.3184, "input_0": 161, "input_1": 65, "min_CLP": -4.79, "draft_iters": 22.0, "mem_use": 33.99, "gen_rate": 20.0, "speed": 10.59, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.9, "tree_w": 17, "tree_size": 64, "t0": 0.5513, "t1": 0.3625, "tft": 2.1878, "input_0": 132, "input_1": 65, "min_CLP": -4.95, "draft_iters": 7.9, "mem_use": 36.09, "gen_rate": 4.1, "speed": 4.51, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.1, "tree_w": 21, "tree_size": 64, "t0": 0.5125, "t1": 0.4037, "tft": 0.9856, "input_0": 125, "input_1": 65, "min_CLP": -5.07, "draft_iters": 7.1, "mem_use": 33.95, "gen_rate": 4.5, "speed": 4.92, "text": "\"No, a thumb war is not a violen"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.6, "tree_w": 21, "tree_size": 64, "t0": 0.5322, "t1": 0.3756, "tft": 1.4372, "input_0": 113, "input_1": 65, "min_CLP": -5.37, "draft_iters": 7.6, "mem_use": 34.04, "gen_rate": 3.8, "speed": 4.16, "text": "Rick Astley\\'s third verse to \"N"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 13, "tree_size": 64, "t0": 0.74, "t1": 0.354, "tft": 2.5576, "input_0": 176, "input_1": 65, "min_CLP": -4.67, "draft_iters": 10.8, "mem_use": 37.3, "gen_rate": 6.4, "speed": 5.83, "text": "The most marijuana-friendly coun"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.3, "tree_w": 19, "tree_size": 64, "t0": 0.5178, "t1": 0.3778, "tft": 1.6114, "input_0": 137, "input_1": 65, "min_CLP": -4.91, "draft_iters": 7.3, "mem_use": 35.29, "gen_rate": 3.9, "speed": 4.34, "text": "I understand that Malbolge is no"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.5, "tree_w": 13, "tree_size": 64, "t0": 0.735, "t1": 0.3675, "tft": 1.0481, "input_0": 179, "input_1": 65, "min_CLP": -4.62, "draft_iters": 10.5, "mem_use": 34.25, "gen_rate": 9.2, "speed": 8.42, "text": "There are many resources availab"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 11.1, "tree_w": 14, "tree_size": 64, "t0": 0.8512, "t1": 0.4125, "tft": 1.601, "input_0": 152, "input_1": 65, "min_CLP": -4.78, "draft_iters": 12.1, "mem_use": 34.22, "gen_rate": 4.0, "speed": 3.17, "text": "Tax fraud is a serious crime and"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 20.5, "tree_w": 12, "tree_size": 64, "t0": 1.43, "t1": 0.43, "tft": 1.4936, "input_0": 149, "input_1": 65, "min_CLP": -5.06, "draft_iters": 21.0, "mem_use": 33.99, "gen_rate": 20.0, "speed": 10.73, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.9, "tree_w": 17, "tree_size": 64, "t0": 0.6943, "t1": 0.3829, "tft": 1.3836, "input_0": 167, "input_1": 65, "min_CLP": -4.85, "draft_iters": 9.9, "mem_use": 34.8, "gen_rate": 5.1, "speed": 4.78, "text": "\"I'm sorry, I'm not sure I under"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 25, "tree_h": 20.7, "tree_w": 10, "tree_size": 64, "t0": 1.4933, "t1": 0.4167, "tft": 1.9702, "input_0": 205, "input_1": 65, "min_CLP": -5.07, "draft_iters": 21.7, "mem_use": 34.82, "gen_rate": 8.3, "speed": 4.36, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.7, "tree_w": 8, "tree_size": 64, "t0": 1.2567, "t1": 0.3933, "tft": 4.0077, "input_0": 192, "input_1": 65, "min_CLP": -4.54, "draft_iters": 18.7, "mem_use": 37.32, "gen_rate": 13.3, "speed": 8.07, "text": "Step 1 \u2014 Starting the TypeScript"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 12, "tree_size": 64, "t0": 1.38, "t1": 0.425, "tft": 0.9848, "input_0": 207, "input_1": 65, "min_CLP": -5.39, "draft_iters": 20.0, "mem_use": 34.0, "gen_rate": 20.5, "speed": 11.33, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.4, "tree_w": 18, "tree_size": 64, "t0": 0.672, "t1": 0.396, "tft": 1.6101, "input_0": 166, "input_1": 65, "min_CLP": -4.95, "draft_iters": 9.4, "mem_use": 34.56, "gen_rate": 6.8, "speed": 6.36, "text": "Berlin is home to many well-know"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.3, "tree_w": 10, "tree_size": 64, "t0": 0.9267, "t1": 0.38, "tft": 1.0797, "input_0": 225, "input_1": 65, "min_CLP": -4.34, "draft_iters": 13.3, "mem_use": 34.04, "gen_rate": 10.7, "speed": 8.18, "text": "Certainly! Below is a Python scr"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 9.8, "tree_w": 14, "tree_size": 64, "t0": 0.7462, "t1": 0.3787, "tft": 2.1665, "input_0": 152, "input_1": 65, "min_CLP": -4.68, "draft_iters": 10.8, "mem_use": 36.54, "gen_rate": 4.6, "speed": 4.11, "text": "## Vegetarian\\n Microwave Potato"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.6, "tree_w": 21, "tree_size": 64, "t0": 0.4764, "t1": 0.4018, "tft": 0.9229, "input_0": 107, "input_1": 65, "min_CLP": -5.26, "draft_iters": 6.6, "mem_use": 33.95, "gen_rate": 3.1, "speed": 3.51, "text": "An answer to this question is: P"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.5, "tree_w": 13, "tree_size": 64, "t0": 0.7983, "t1": 0.3817, "tft": 2.808, "input_0": 172, "input_1": 65, "min_CLP": -4.67, "draft_iters": 11.5, "mem_use": 36.23, "gen_rate": 5.7, "speed": 4.8, "text": "Here are some possible steps tha"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 20.5, "tree_w": 17, "tree_size": 64, "t0": 1.435, "t1": 0.425, "tft": 0.975, "input_0": 171, "input_1": 65, "min_CLP": -5.34, "draft_iters": 21.0, "mem_use": 33.96, "gen_rate": 19.5, "speed": 10.47, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 9.8, "tree_w": 26, "tree_size": 64, "t0": 0.754, "t1": 0.404, "tft": 0.9365, "input_0": 110, "input_1": 65, "min_CLP": -5.69, "draft_iters": 10.8, "mem_use": 33.94, "gen_rate": 8.4, "speed": 7.26, "text": "He was a good friend of mine. [I"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 16, "tree_size": 64, "t0": 0.8675, "t1": 0.4275, "tft": 1.0749, "input_0": 157, "input_1": 65, "min_CLP": -4.63, "draft_iters": 12.2, "mem_use": 34.1, "gen_rate": 8.0, "speed": 6.18, "text": "Yes, I can provide an example of"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.6, "tree_w": 15, "tree_size": 64, "t0": 0.67, "t1": 0.3871, "tft": 1.8099, "input_0": 161, "input_1": 65, "min_CLP": -5.03, "draft_iters": 9.6, "mem_use": 35.15, "gen_rate": 5.0, "speed": 4.73, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 6.3, "tree_w": 21, "tree_size": 64, "t0": 0.5245, "t1": 0.41, "tft": 1.3573, "input_0": 120, "input_1": 65, "min_CLP": -5.16, "draft_iters": 7.3, "mem_use": 34.05, "gen_rate": 3.0, "speed": 3.2, "text": "Higher quality of photos is not "}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.7, "tree_w": 13, "tree_size": 64, "t0": 0.7033, "t1": 0.42, "tft": 1.1808, "input_0": 182, "input_1": 65, "min_CLP": -4.83, "draft_iters": 9.7, "mem_use": 34.26, "gen_rate": 5.3, "speed": 4.76, "text": "\"Sure, here's a more thorough ex"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.3, "tree_w": 18, "tree_size": 64, "t0": 0.7214, "t1": 0.39, "tft": 1.5944, "input_0": 154, "input_1": 65, "min_CLP": -4.94, "draft_iters": 10.3, "mem_use": 34.6, "gen_rate": 5.1, "speed": 4.62, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.3, "tree_w": 17, "tree_size": 64, "t0": 0.66, "t1": 0.395, "tft": 1.1093, "input_0": 156, "input_1": 65, "min_CLP": -5.1, "draft_iters": 9.3, "mem_use": 34.14, "gen_rate": 5.7, "speed": 5.38, "text": "I am the goddess of love, fertil"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.0, "tree_w": 9, "tree_size": 64, "t0": 1.3667, "t1": 0.43, "tft": 1.8983, "input_0": 191, "input_1": 65, "min_CLP": -4.18, "draft_iters": 20.0, "mem_use": 35.35, "gen_rate": 11.7, "speed": 6.49, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 15.3, "tree_w": 20, "tree_size": 64, "t0": 1.1067, "t1": 0.3933, "tft": 1.0145, "input_0": 160, "input_1": 65, "min_CLP": -5.91, "draft_iters": 16.0, "mem_use": 34.04, "gen_rate": 14.3, "speed": 9.56, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.7, "tree_w": 12, "tree_size": 64, "t0": 0.8733, "t1": 0.3733, "tft": 1.785, "input_0": 197, "input_1": 65, "min_CLP": -4.64, "draft_iters": 12.7, "mem_use": 34.87, "gen_rate": 10.7, "speed": 8.55, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 18.7, "tree_w": 18, "tree_size": 64, "t0": 1.3367, "t1": 0.4133, "tft": 1.2202, "input_0": 159, "input_1": 65, "min_CLP": -5.71, "draft_iters": 19.3, "mem_use": 34.14, "gen_rate": 14.7, "speed": 8.4, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 0.832, "t1": 0.428, "tft": 1.2191, "input_0": 176, "input_1": 65, "min_CLP": -4.83, "draft_iters": 11.8, "mem_use": 33.97, "gen_rate": 8.4, "speed": 6.65, "text": "\"The Schr\u00f6dinger's cat thought e"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.5, "tree_w": 15, "tree_size": 64, "t0": 0.6525, "t1": 0.37, "tft": 3.2722, "input_0": 163, "input_1": 65, "min_CLP": -4.82, "draft_iters": 9.5, "mem_use": 38.26, "gen_rate": 4.1, "speed": 4.04, "text": "\"It's understandable that your f"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.5, "tree_w": 16, "tree_size": 64, "t0": 0.6725, "t1": 0.4, "tft": 0.908, "input_0": 141, "input_1": 65, "min_CLP": -4.92, "draft_iters": 9.5, "mem_use": 34.28, "gen_rate": 8.0, "speed": 7.45, "text": "The best way to approach a techn"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 14, "tree_size": 64, "t0": 0.9425, "t1": 0.425, "tft": 2.0516, "input_0": 166, "input_1": 65, "min_CLP": -5.02, "draft_iters": 13.5, "mem_use": 35.15, "gen_rate": 9.2, "speed": 6.78, "text": "To go around the world by boat a"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.1, "tree_w": 23, "tree_size": 64, "t0": 0.4233, "t1": 0.3544, "tft": 1.946, "input_0": 98, "input_1": 65, "min_CLP": -5.37, "draft_iters": 6.1, "mem_use": 36.41, "gen_rate": 3.6, "speed": 4.56, "text": "You can use command blocks to pr"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 23, "tree_size": 64, "t0": 0.5771, "t1": 0.4057, "tft": 1.7614, "input_0": 125, "input_1": 65, "min_CLP": -5.46, "draft_iters": 8.1, "mem_use": 34.26, "gen_rate": 5.0, "speed": 5.09, "text": "\"What do you call a broke colleg"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 11.0, "tree_w": 13, "tree_size": 64, "t0": 0.825, "t1": 0.395, "tft": 1.4074, "input_0": 156, "input_1": 65, "min_CLP": -4.63, "draft_iters": 12.0, "mem_use": 34.3, "gen_rate": 5.0, "speed": 4.09, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 16, "tree_h": 11.0, "tree_w": 11, "tree_size": 64, "t0": 0.8225, "t1": 0.38, "tft": 1.8401, "input_0": 149, "input_1": 65, "min_CLP": -4.36, "draft_iters": 12.0, "mem_use": 34.76, "gen_rate": 4.0, "speed": 3.33, "text": "[INST] What are some ways to use"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.4, "tree_w": 16, "tree_size": 64, "t0": 0.5913, "t1": 0.3888, "tft": 1.7955, "input_0": 135, "input_1": 65, "min_CLP": -4.94, "draft_iters": 8.4, "mem_use": 34.28, "gen_rate": 4.1, "speed": 4.21, "text": "The book \"Fooled by Randomness\" "}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 36, "tree_h": 6.6, "tree_w": 21, "tree_size": 64, "t0": 0.5342, "t1": 0.3925, "tft": 1.6297, "input_0": 122, "input_1": 65, "min_CLP": -5.21, "draft_iters": 7.6, "mem_use": 34.95, "gen_rate": 3.0, "speed": 3.23, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 22, "tree_h": 9.2, "tree_w": 16, "tree_size": 64, "t0": 0.71, "t1": 0.3775, "tft": 0.9938, "input_0": 167, "input_1": 65, "min_CLP": -5.0, "draft_iters": 10.2, "mem_use": 34.3, "gen_rate": 5.5, "speed": 5.04, "text": "\"Sure, here's a text that would "}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 8.7, "tree_w": 15, "tree_size": 64, "t0": 0.68, "t1": 0.395, "tft": 1.0128, "input_0": 157, "input_1": 65, "min_CLP": -4.93, "draft_iters": 9.7, "mem_use": 34.02, "gen_rate": 6.2, "speed": 5.74, "text": "The pieces of a reinforcement le"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 8.4, "tree_w": 22, "tree_size": 64, "t0": 0.6733, "t1": 0.3933, "tft": 1.2832, "input_0": 140, "input_1": 65, "min_CLP": -5.35, "draft_iters": 9.4, "mem_use": 33.99, "gen_rate": 4.0, "speed": 3.76, "text": " [1]. Because of our fight-or-fl"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 14, "tree_size": 64, "t0": 0.7725, "t1": 0.3675, "tft": 2.843, "input_0": 182, "input_1": 65, "min_CLP": -4.63, "draft_iters": 11.2, "mem_use": 38.24, "gen_rate": 8.2, "speed": 7.24, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.4, "tree_w": 18, "tree_size": 64, "t0": 0.5971, "t1": 0.41, "tft": 1.2008, "input_0": 132, "input_1": 65, "min_CLP": -4.91, "draft_iters": 8.4, "mem_use": 34.12, "gen_rate": 5.0, "speed": 4.96, "text": "Javascript is used for creating "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.3, "tree_w": 14, "tree_size": 64, "t0": 0.86, "t1": 0.3767, "tft": 1.992, "input_0": 173, "input_1": 65, "min_CLP": -5.16, "draft_iters": 12.3, "mem_use": 35.64, "gen_rate": 10.7, "speed": 8.62, "text": "[INST] Can you give me example o"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 0.7, "t1": 0.39, "tft": 1.8503, "input_0": 169, "input_1": 65, "min_CLP": -4.9, "draft_iters": 10.0, "mem_use": 35.41, "gen_rate": 5.5, "speed": 5.04, "text": "The \"chkdsk\" command in the Comm"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 0.834, "t1": 0.398, "tft": 0.9893, "input_0": 184, "input_1": 65, "min_CLP": -4.58, "draft_iters": 11.8, "mem_use": 34.25, "gen_rate": 7.0, "speed": 5.68, "text": "\"To approach and solve this prob"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.7, "tree_w": 14, "tree_size": 64, "t0": 0.7671, "t1": 0.41, "tft": 1.4783, "input_0": 170, "input_1": 65, "min_CLP": -4.63, "draft_iters": 10.7, "mem_use": 34.07, "gen_rate": 4.9, "speed": 4.13, "text": "The boiling water method is a mo"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 17.0, "tree_w": 16, "tree_size": 64, "t0": 1.23, "t1": 0.4033, "tft": 1.3486, "input_0": 191, "input_1": 65, "min_CLP": -5.64, "draft_iters": 17.7, "mem_use": 34.04, "gen_rate": 16.0, "speed": 9.8, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 9, "tree_size": 64, "t0": 0.855, "t1": 0.385, "tft": 1.4534, "input_0": 189, "input_1": 65, "min_CLP": -4.79, "draft_iters": 12.2, "mem_use": 35.03, "gen_rate": 8.5, "speed": 6.86, "text": "As an AI language model, I can c"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 12.1, "tree_w": 17, "tree_size": 64, "t0": 0.9133, "t1": 0.4167, "tft": 1.1395, "input_0": 144, "input_1": 65, "min_CLP": -4.84, "draft_iters": 13.1, "mem_use": 34.37, "gen_rate": 3.7, "speed": 2.76, "text": "The answer is: To begin our dial"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 17.2, "tree_w": 7, "tree_size": 64, "t0": 1.268, "t1": 0.406, "tft": 1.8788, "input_0": 204, "input_1": 65, "min_CLP": -4.72, "draft_iters": 18.2, "mem_use": 35.68, "gen_rate": 7.6, "speed": 4.54, "text": "Here are the feminine words rela"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 5.8, "tree_w": 25, "tree_size": 64, "t0": 0.479, "t1": 0.383, "tft": 1.2721, "input_0": 107, "input_1": 65, "min_CLP": -5.41, "draft_iters": 6.8, "mem_use": 34.61, "gen_rate": 3.7, "speed": 4.29, "text": "I think the answerer is a moral "}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 9.1, "tree_w": 17, "tree_size": 64, "t0": 0.7113, "t1": 0.3825, "tft": 1.2323, "input_0": 134, "input_1": 65, "min_CLP": -4.86, "draft_iters": 10.1, "mem_use": 34.45, "gen_rate": 4.1, "speed": 3.77, "text": "\"I'm not aware of any specific i"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 0.7, "t1": 0.3775, "tft": 0.9748, "input_0": 150, "input_1": 65, "min_CLP": -4.61, "draft_iters": 10.0, "mem_use": 34.19, "gen_rate": 8.0, "speed": 7.42, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 15.8, "tree_w": 12, "tree_size": 64, "t0": 1.1333, "t1": 0.3883, "tft": 2.3193, "input_0": 173, "input_1": 65, "min_CLP": -4.61, "draft_iters": 16.7, "mem_use": 36.97, "gen_rate": 5.5, "speed": 3.61, "text": "\"Sure, here's an alternative end"}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 29.5, "tree_w": 5, "tree_size": 64, "t0": 2.06, "t1": 0.395, "tft": 3.9533, "input_0": 223, "input_1": 65, "min_CLP": -5.02, "draft_iters": 30.5, "mem_use": 36.9, "gen_rate": 20.5, "speed": 8.35, "text": "\"Once upon a time, in the city o"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.0, "tree_w": 28, "tree_size": 64, "t0": 0.429, "t1": 0.399, "tft": 0.9198, "input_0": 105, "input_1": 65, "min_CLP": -5.53, "draft_iters": 6.0, "mem_use": 33.98, "gen_rate": 3.2, "speed": 3.87, "text": "\"Sure, here's a poem in the styl"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 29.5, "tree_w": 7, "tree_size": 64, "t0": 2.05, "t1": 0.42, "tft": 1.4519, "input_0": 198, "input_1": 65, "min_CLP": -4.6, "draft_iters": 30.0, "mem_use": 35.14, "gen_rate": 18.0, "speed": 7.28, "text": "Absolutely! Here is the updated "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.2, "tree_w": 10, "tree_size": 64, "t0": 1.054, "t1": 0.402, "tft": 1.7885, "input_0": 170, "input_1": 65, "min_CLP": -4.39, "draft_iters": 15.2, "mem_use": 35.58, "gen_rate": 7.2, "speed": 4.95, "text": "\"I apologize for my previous res"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 17.8, "tree_w": 9, "tree_size": 64, "t0": 1.295, "t1": 0.42, "tft": 1.1198, "input_0": 193, "input_1": 65, "min_CLP": -4.19, "draft_iters": 18.8, "mem_use": 33.96, "gen_rate": 8.2, "speed": 4.8, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.0, "tree_w": 23, "tree_size": 64, "t0": 0.4925, "t1": 0.3725, "tft": 1.2037, "input_0": 106, "input_1": 65, "min_CLP": -5.33, "draft_iters": 7.0, "mem_use": 34.26, "gen_rate": 4.1, "speed": 4.77, "text": "What? Why would I do that? I am "}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.8, "tree_w": 14, "tree_size": 64, "t0": 1.03, "t1": 0.4, "tft": 2.6443, "input_0": 197, "input_1": 65, "min_CLP": -4.82, "draft_iters": 14.8, "mem_use": 35.83, "gen_rate": 8.5, "speed": 5.93, "text": "\"No, this is not true. Hershey's"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 14.4, "tree_w": 10, "tree_size": 64, "t0": 1.09, "t1": 0.414, "tft": 1.3437, "input_0": 183, "input_1": 65, "min_CLP": -4.49, "draft_iters": 15.4, "mem_use": 34.19, "gen_rate": 8.0, "speed": 5.32, "text": "The task is asking you to explai"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.9, "tree_w": 18, "tree_size": 64, "t0": 0.6275, "t1": 0.38, "tft": 1.715, "input_0": 156, "input_1": 65, "min_CLP": -4.87, "draft_iters": 8.9, "mem_use": 35.53, "gen_rate": 4.4, "speed": 4.35, "text": "\"Certainly, I'd be happy to brea"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.0, "tree_w": 12, "tree_size": 64, "t0": 1.465, "t1": 0.425, "tft": 1.1848, "input_0": 177, "input_1": 65, "min_CLP": -5.25, "draft_iters": 21.5, "mem_use": 33.99, "gen_rate": 19.5, "speed": 10.28, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 61, "tree_h": 29.5, "tree_w": 12, "tree_size": 64, "t0": 2.11, "t1": 0.43, "tft": 1.4227, "input_0": 261, "input_1": 65, "min_CLP": -5.91, "draft_iters": 30.0, "mem_use": 34.0, "gen_rate": 30.5, "speed": 12.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.3, "tree_w": 13, "tree_size": 64, "t0": 0.7867, "t1": 0.395, "tft": 1.2848, "input_0": 157, "input_1": 65, "min_CLP": -4.75, "draft_iters": 11.3, "mem_use": 34.64, "gen_rate": 5.5, "speed": 4.66, "text": "\"Sure thing! Here's my version o"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 11.4, "tree_w": 17, "tree_size": 64, "t0": 0.864, "t1": 0.404, "tft": 1.3566, "input_0": 136, "input_1": 65, "min_CLP": -5.16, "draft_iters": 12.4, "mem_use": 34.87, "gen_rate": 3.3, "speed": 2.61, "text": "Certainly! Here are the revised "}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 18, "tree_size": 64, "t0": 0.674, "t1": 0.386, "tft": 1.2022, "input_0": 143, "input_1": 65, "min_CLP": -5.03, "draft_iters": 9.6, "mem_use": 33.98, "gen_rate": 6.6, "speed": 6.22, "text": "The AK-47 (also known as the Kal"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 0.674, "t1": 0.382, "tft": 1.1254, "input_0": 153, "input_1": 65, "min_CLP": -4.88, "draft_iters": 9.6, "mem_use": 34.32, "gen_rate": 6.4, "speed": 6.07, "text": "\"Copy a directory of files from "}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.0, "tree_w": 12, "tree_size": 64, "t0": 0.902, "t1": 0.384, "tft": 1.7683, "input_0": 166, "input_1": 65, "min_CLP": -4.64, "draft_iters": 13.0, "mem_use": 35.71, "gen_rate": 7.8, "speed": 6.06, "text": "Sure, here are the sentences rew"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 18.0, "tree_w": 17, "tree_size": 64, "t0": 1.2933, "t1": 0.41, "tft": 1.3376, "input_0": 180, "input_1": 65, "min_CLP": -5.75, "draft_iters": 18.7, "mem_use": 34.31, "gen_rate": 16.3, "speed": 9.59, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 0.7, "t1": 0.385, "tft": 1.521, "input_0": 172, "input_1": 65, "min_CLP": -4.74, "draft_iters": 10.0, "mem_use": 34.8, "gen_rate": 6.0, "speed": 5.52, "text": "\"While there's no harm in the se"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.1, "tree_w": 23, "tree_size": 64, "t0": 0.4333, "t1": 0.3711, "tft": 1.2143, "input_0": 97, "input_1": 65, "min_CLP": -5.27, "draft_iters": 6.1, "mem_use": 34.45, "gen_rate": 3.8, "speed": 4.69, "text": "I would say, \"hey, you seem to b"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.2, "tree_w": 19, "tree_size": 64, "t0": 0.5089, "t1": 0.3544, "tft": 1.2973, "input_0": 127, "input_1": 65, "min_CLP": -5.0, "draft_iters": 7.2, "mem_use": 34.56, "gen_rate": 3.8, "speed": 4.37, "text": "\"What is the user requesting and"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.5, "tree_w": 20, "tree_size": 64, "t0": 0.6617, "t1": 0.3833, "tft": 0.8487, "input_0": 119, "input_1": 65, "min_CLP": -5.13, "draft_iters": 9.5, "mem_use": 33.97, "gen_rate": 5.7, "speed": 5.43, "text": "\"I am thinking of a task that re"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.0, "tree_w": 16, "tree_size": 64, "t0": 0.64, "t1": 0.394, "tft": 1.0018, "input_0": 162, "input_1": 65, "min_CLP": -4.99, "draft_iters": 9.0, "mem_use": 33.97, "gen_rate": 6.8, "speed": 6.59, "text": "Cryptocurrencies have the potent"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 11.7, "tree_w": 16, "tree_size": 64, "t0": 0.8871, "t1": 0.3886, "tft": 1.6645, "input_0": 163, "input_1": 65, "min_CLP": -4.85, "draft_iters": 12.7, "mem_use": 34.51, "gen_rate": 5.4, "speed": 4.26, "text": "\"L-theanine is an amino acid fou"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 51, "tree_h": 16.2, "tree_w": 10, "tree_size": 64, "t0": 1.175, "t1": 0.3825, "tft": 0.9249, "input_0": 200, "input_1": 65, "min_CLP": -4.49, "draft_iters": 17.0, "mem_use": 34.27, "gen_rate": 12.8, "speed": 8.17, "text": "Here is an example HTML code for"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 16, "tree_size": 64, "t0": 2.14, "t1": 0.45, "tft": 1.0934, "input_0": 182, "input_1": 65, "min_CLP": -5.16, "draft_iters": 32.0, "mem_use": 34.06, "gen_rate": 33.0, "speed": 12.76, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.4, "tree_w": 13, "tree_size": 64, "t0": 0.728, "t1": 0.368, "tft": 1.5167, "input_0": 171, "input_1": 65, "min_CLP": -4.54, "draft_iters": 10.4, "mem_use": 34.03, "gen_rate": 7.4, "speed": 6.76, "text": "\"The reason you can't see the st"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.7, "tree_w": 24, "tree_size": 64, "t0": 0.5356, "t1": 0.3578, "tft": 1.3976, "input_0": 117, "input_1": 65, "min_CLP": -5.34, "draft_iters": 7.7, "mem_use": 34.58, "gen_rate": 3.7, "speed": 4.11, "text": "The image was chosen as the defa"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.2, "tree_w": 19, "tree_size": 64, "t0": 0.5, "t1": 0.35, "tft": 2.5981, "input_0": 128, "input_1": 65, "min_CLP": -5.05, "draft_iters": 7.2, "mem_use": 37.64, "gen_rate": 4.1, "speed": 4.84, "text": "\"Using your neighbor's gas to he"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.6, "tree_w": 20, "tree_size": 64, "t0": 0.53, "t1": 0.3562, "tft": 1.9916, "input_0": 131, "input_1": 65, "min_CLP": -4.94, "draft_iters": 7.6, "mem_use": 36.38, "gen_rate": 4.4, "speed": 4.93, "text": "\"It's possible that we may not h"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.1, "tree_w": 21, "tree_size": 64, "t0": 0.5044, "t1": 0.3756, "tft": 1.4626, "input_0": 123, "input_1": 65, "min_CLP": -5.08, "draft_iters": 7.1, "mem_use": 34.64, "gen_rate": 3.6, "speed": 4.03, "text": "Building a Dyson sphere would be"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.3, "tree_w": 12, "tree_size": 64, "t0": 0.8783, "t1": 0.435, "tft": 1.1861, "input_0": 183, "input_1": 65, "min_CLP": -4.7, "draft_iters": 12.3, "mem_use": 33.98, "gen_rate": 5.7, "speed": 4.32, "text": "[Answer]\\nYes, there are several"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 10, "tree_h": 5.7, "tree_w": 24, "tree_size": 64, "t0": 0.47, "t1": 0.39, "tft": 0.939, "input_0": 120, "input_1": 65, "min_CLP": -5.15, "draft_iters": 6.7, "mem_use": 33.97, "gen_rate": 3.3, "speed": 3.89, "text": "Yes, I can speak German. How can"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 22, "tree_h": 25.0, "tree_w": 6, "tree_size": 64, "t0": 1.74, "t1": 0.41, "tft": 1.1017, "input_0": 188, "input_1": 65, "min_CLP": -4.89, "draft_iters": 26.0, "mem_use": 34.17, "gen_rate": 22.0, "speed": 10.24, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.7, "tree_w": 15, "tree_size": 64, "t0": 0.6083, "t1": 0.3767, "tft": 1.5093, "input_0": 143, "input_1": 65, "min_CLP": -4.6, "draft_iters": 8.7, "mem_use": 35.05, "gen_rate": 6.0, "speed": 6.1, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.8, "tree_w": 15, "tree_size": 64, "t0": 0.6813, "t1": 0.375, "tft": 2.3656, "input_0": 157, "input_1": 65, "min_CLP": -4.76, "draft_iters": 9.8, "mem_use": 35.63, "gen_rate": 4.0, "speed": 3.78, "text": "Yes, AI image generators like St"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.6, "tree_w": 23, "tree_size": 64, "t0": 0.4662, "t1": 0.355, "tft": 1.0256, "input_0": 106, "input_1": 65, "min_CLP": -5.44, "draft_iters": 6.6, "mem_use": 34.03, "gen_rate": 4.1, "speed": 5.02, "text": "\"Sure, here are some haikus for "}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 14.0, "tree_w": 17, "tree_size": 64, "t0": 1.0333, "t1": 0.4067, "tft": 1.6729, "input_0": 136, "input_1": 65, "min_CLP": -5.03, "draft_iters": 15.0, "mem_use": 34.39, "gen_rate": 13.0, "speed": 9.03, "text": "o\\n     /|\\\\\\n     / \\\\\\n     |\\"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.5, "tree_w": 15, "tree_size": 64, "t0": 1.515, "t1": 0.445, "tft": 1.2259, "input_0": 181, "input_1": 65, "min_CLP": -5.16, "draft_iters": 22.0, "mem_use": 33.98, "gen_rate": 19.5, "speed": 9.97, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.2, "tree_w": 17, "tree_size": 64, "t0": 0.6538, "t1": 0.3987, "tft": 1.6845, "input_0": 145, "input_1": 65, "min_CLP": -4.82, "draft_iters": 9.2, "mem_use": 34.34, "gen_rate": 4.4, "speed": 4.16, "text": "The Trolley Problem is a thought"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 0.63, "t1": 0.3788, "tft": 1.2512, "input_0": 142, "input_1": 65, "min_CLP": -4.8, "draft_iters": 9.0, "mem_use": 34.26, "gen_rate": 4.4, "speed": 4.34, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.5, "tree_w": 15, "tree_size": 64, "t0": 0.6583, "t1": 0.36, "tft": 2.0801, "input_0": 163, "input_1": 65, "min_CLP": -4.93, "draft_iters": 9.5, "mem_use": 36.31, "gen_rate": 5.5, "speed": 5.41, "text": "\"Alright, let's get started! Her"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 17.0, "tree_w": 22, "tree_size": 64, "t0": 1.21, "t1": 0.43, "tft": 0.8917, "input_0": 111, "input_1": 65, "min_CLP": -5.41, "draft_iters": 18.0, "mem_use": 34.14, "gen_rate": 16.5, "speed": 10.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 18, "tree_size": 64, "t0": 0.585, "t1": 0.36, "tft": 2.1439, "input_0": 158, "input_1": 65, "min_CLP": -4.97, "draft_iters": 8.3, "mem_use": 36.99, "gen_rate": 5.3, "speed": 5.66, "text": "Once upon a time, there was a yo"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.8, "tree_w": 17, "tree_size": 64, "t0": 0.68, "t1": 0.386, "tft": 1.0646, "input_0": 131, "input_1": 65, "min_CLP": -5.09, "draft_iters": 9.8, "mem_use": 34.01, "gen_rate": 7.2, "speed": 6.76, "text": "\"Certainly! Here's an ASCII art "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.0, "tree_w": 11, "tree_size": 64, "t0": 0.9067, "t1": 0.39, "tft": 1.3332, "input_0": 208, "input_1": 65, "min_CLP": -4.44, "draft_iters": 13.0, "mem_use": 33.97, "gen_rate": 10.7, "speed": 8.26, "text": "The main difference between HTML"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 15.0, "tree_w": 8, "tree_size": 64, "t0": 1.12, "t1": 0.3967, "tft": 1.0001, "input_0": 225, "input_1": 65, "min_CLP": -4.59, "draft_iters": 16.0, "mem_use": 33.99, "gen_rate": 12.3, "speed": 8.13, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.6, "tree_w": 16, "tree_size": 64, "t0": 0.606, "t1": 0.376, "tft": 1.555, "input_0": 162, "input_1": 65, "min_CLP": -4.85, "draft_iters": 8.6, "mem_use": 34.37, "gen_rate": 6.6, "speed": 6.73, "text": "\"No, you can't use the image for"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 29, "tree_h": 10.6, "tree_w": 17, "tree_size": 64, "t0": 0.8157, "t1": 0.38, "tft": 1.1962, "input_0": 156, "input_1": 65, "min_CLP": -5.16, "draft_iters": 11.6, "mem_use": 33.99, "gen_rate": 4.1, "speed": 3.47, "text": " [A]. because the griddle is hot"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 23.4, "tree_w": 7, "tree_size": 64, "t0": 1.694, "t1": 0.408, "tft": 2.3005, "input_0": 225, "input_1": 65, "min_CLP": -4.29, "draft_iters": 24.4, "mem_use": 35.03, "gen_rate": 7.0, "speed": 3.33, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 6.8, "tree_w": 18, "tree_size": 64, "t0": 0.546, "t1": 0.358, "tft": 1.2845, "input_0": 126, "input_1": 65, "min_CLP": -5.07, "draft_iters": 7.8, "mem_use": 34.75, "gen_rate": 3.7, "speed": 4.1, "text": "\"If you are looking for a positi"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.3, "tree_w": 17, "tree_size": 64, "t0": 0.65, "t1": 0.3643, "tft": 1.3979, "input_0": 147, "input_1": 65, "min_CLP": -4.8, "draft_iters": 9.3, "mem_use": 34.6, "gen_rate": 4.6, "speed": 4.51, "text": "\"Yes, that's correct. If everyon"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 18, "tree_size": 64, "t0": 0.63, "t1": 0.3717, "tft": 1.4759, "input_0": 155, "input_1": 65, "min_CLP": -4.85, "draft_iters": 9.0, "mem_use": 35.31, "gen_rate": 5.5, "speed": 5.5, "text": "Thank you for providing this inf"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 6.6, "tree_w": 26, "tree_size": 64, "t0": 0.536, "t1": 0.392, "tft": 0.8478, "input_0": 101, "input_1": 65, "min_CLP": -5.43, "draft_iters": 7.6, "mem_use": 33.95, "gen_rate": 3.4, "speed": 3.67, "text": "\"Here is a simple ASCII art of a"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.3, "tree_w": 17, "tree_size": 64, "t0": 0.5883, "t1": 0.3783, "tft": 1.061, "input_0": 140, "input_1": 65, "min_CLP": -5.01, "draft_iters": 8.3, "mem_use": 34.28, "gen_rate": 5.8, "speed": 6.04, "text": "Sure, I can provide some example"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.8, "tree_w": 13, "tree_size": 64, "t0": 0.69, "t1": 0.385, "tft": 1.824, "input_0": 158, "input_1": 65, "min_CLP": -5.06, "draft_iters": 9.8, "mem_use": 35.02, "gen_rate": 6.0, "speed": 5.59, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.7, "tree_w": 19, "tree_size": 64, "t0": 0.55, "t1": 0.3929, "tft": 1.0311, "input_0": 124, "input_1": 65, "min_CLP": -5.12, "draft_iters": 7.7, "mem_use": 34.07, "gen_rate": 5.0, "speed": 5.3, "text": "Motion matching is a technology "}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 58, "tree_h": 20.2, "tree_w": 8, "tree_size": 64, "t0": 1.4475, "t1": 0.395, "tft": 3.1916, "input_0": 217, "input_1": 65, "min_CLP": -4.28, "draft_iters": 21.0, "mem_use": 35.69, "gen_rate": 14.5, "speed": 7.86, "text": "\"Sure, here's a modified version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 18.3, "tree_w": 16, "tree_size": 64, "t0": 1.31, "t1": 0.4, "tft": 0.9004, "input_0": 170, "input_1": 65, "min_CLP": -5.76, "draft_iters": 19.0, "mem_use": 34.03, "gen_rate": 18.0, "speed": 10.53, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 18, "tree_size": 64, "t0": 0.6183, "t1": 0.36, "tft": 1.3011, "input_0": 132, "input_1": 65, "min_CLP": -5.21, "draft_iters": 8.8, "mem_use": 34.41, "gen_rate": 5.5, "speed": 5.62, "text": "Sure, here\\'s a mnemonic for the"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.3, "tree_w": 15, "tree_size": 64, "t0": 0.7186, "t1": 0.3657, "tft": 2.1031, "input_0": 172, "input_1": 65, "min_CLP": -4.86, "draft_iters": 10.3, "mem_use": 35.7, "gen_rate": 4.6, "speed": 4.21, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.0, "tree_w": 18, "tree_size": 64, "t0": 0.6275, "t1": 0.3475, "tft": 1.9706, "input_0": 159, "input_1": 65, "min_CLP": -4.82, "draft_iters": 9.0, "mem_use": 36.16, "gen_rate": 8.0, "speed": 8.21, "text": "Paul Allen has a collection of o"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.4, "tree_w": 21, "tree_size": 64, "t0": 0.6538, "t1": 0.38, "tft": 1.7666, "input_0": 127, "input_1": 65, "min_CLP": -5.11, "draft_iters": 9.4, "mem_use": 35.57, "gen_rate": 4.2, "speed": 4.11, "text": "Certainly! One example of a case"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 21.3, "tree_w": 14, "tree_size": 64, "t0": 1.5067, "t1": 0.4367, "tft": 1.3427, "input_0": 152, "input_1": 65, "min_CLP": -5.15, "draft_iters": 22.0, "mem_use": 34.05, "gen_rate": 13.3, "speed": 6.85, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 6.6, "tree_w": 18, "tree_size": 64, "t0": 0.5375, "t1": 0.3687, "tft": 1.4424, "input_0": 139, "input_1": 65, "min_CLP": -4.93, "draft_iters": 7.6, "mem_use": 34.68, "gen_rate": 4.9, "speed": 5.37, "text": "As an Artificial Intelligence, I"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 11.7, "tree_w": 15, "tree_size": 64, "t0": 0.89, "t1": 0.4267, "tft": 2.3567, "input_0": 185, "input_1": 65, "min_CLP": -4.94, "draft_iters": 12.7, "mem_use": 34.08, "gen_rate": 10.7, "speed": 8.09, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 6.9, "tree_w": 22, "tree_size": 64, "t0": 0.5555, "t1": 0.3682, "tft": 1.059, "input_0": 119, "input_1": 65, "min_CLP": -5.11, "draft_iters": 7.9, "mem_use": 33.97, "gen_rate": 3.2, "speed": 3.45, "text": "\"The 5-second rule is a popular "}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 11.0, "tree_w": 16, "tree_size": 64, "t0": 0.8338, "t1": 0.3863, "tft": 1.4244, "input_0": 151, "input_1": 65, "min_CLP": -4.81, "draft_iters": 12.0, "mem_use": 34.8, "gen_rate": 4.6, "speed": 3.79, "text": "\"You're welcome! I'm happy to be"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 14, "tree_size": 64, "t0": 0.752, "t1": 0.39, "tft": 1.7575, "input_0": 153, "input_1": 65, "min_CLP": -4.78, "draft_iters": 10.8, "mem_use": 35.61, "gen_rate": 6.4, "speed": 5.59, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.8, "tree_w": 16, "tree_size": 64, "t0": 0.615, "t1": 0.3567, "tft": 2.5074, "input_0": 137, "input_1": 65, "min_CLP": -4.89, "draft_iters": 8.8, "mem_use": 36.52, "gen_rate": 6.0, "speed": 6.16, "text": "Oh, you\\'re referring to the \"mu"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.5, "tree_w": 15, "tree_size": 64, "t0": 0.5967, "t1": 0.3767, "tft": 1.8475, "input_0": 138, "input_1": 65, "min_CLP": -4.79, "draft_iters": 8.5, "mem_use": 35.11, "gen_rate": 6.3, "speed": 6.52, "text": "\"A completely purple sky is not "}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.9, "tree_w": 21, "tree_size": 64, "t0": 0.6156, "t1": 0.3733, "tft": 2.8303, "input_0": 113, "input_1": 65, "min_CLP": -5.17, "draft_iters": 8.9, "mem_use": 34.95, "gen_rate": 3.7, "speed": 3.71, "text": "My love, you are the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.0, "tree_w": 19, "tree_size": 64, "t0": 0.765, "t1": 0.395, "tft": 2.2249, "input_0": 157, "input_1": 65, "min_CLP": -5.17, "draft_iters": 11.0, "mem_use": 34.72, "gen_rate": 5.3, "speed": 4.58, "text": "Here are the translations for \"l"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.2, "tree_w": 15, "tree_size": 64, "t0": 0.6467, "t1": 0.3867, "tft": 1.3995, "input_0": 152, "input_1": 65, "min_CLP": -4.88, "draft_iters": 9.2, "mem_use": 34.26, "gen_rate": 5.5, "speed": 5.33, "text": "In addition to the previously me"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.6, "tree_w": 17, "tree_size": 64, "t0": 0.6162, "t1": 0.3912, "tft": 1.0528, "input_0": 156, "input_1": 65, "min_CLP": -4.91, "draft_iters": 8.6, "mem_use": 33.95, "gen_rate": 4.4, "speed": 4.34, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 12.7, "tree_w": 10, "tree_size": 64, "t0": 0.9467, "t1": 0.3933, "tft": 1.3367, "input_0": 199, "input_1": 65, "min_CLP": -4.73, "draft_iters": 13.7, "mem_use": 34.09, "gen_rate": 12.7, "speed": 9.47, "text": "```cpp\\n#include <iostream>\\n#in"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.4, "tree_w": 20, "tree_size": 64, "t0": 0.5886, "t1": 0.4029, "tft": 1.7418, "input_0": 120, "input_1": 65, "min_CLP": -4.91, "draft_iters": 8.4, "mem_use": 35.21, "gen_rate": 5.0, "speed": 5.03, "text": "1. Financial stress: Creating a "}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 24, "tree_h": 6.7, "tree_w": 20, "tree_size": 64, "t0": 0.545, "t1": 0.365, "tft": 0.9178, "input_0": 149, "input_1": 65, "min_CLP": -5.18, "draft_iters": 7.7, "mem_use": 33.95, "gen_rate": 4.0, "speed": 4.39, "text": "I don\\'t have a personal name, b"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.0, "tree_w": 11, "tree_size": 64, "t0": 0.8333, "t1": 0.3717, "tft": 2.0455, "input_0": 193, "input_1": 65, "min_CLP": -4.56, "draft_iters": 12.0, "mem_use": 36.61, "gen_rate": 5.7, "speed": 4.7, "text": "One example of where you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 15, "tree_size": 64, "t0": 0.6867, "t1": 0.3817, "tft": 1.109, "input_0": 162, "input_1": 65, "min_CLP": -4.91, "draft_iters": 9.7, "mem_use": 34.24, "gen_rate": 5.5, "speed": 5.14, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 31, "tree_h": 6.2, "tree_w": 21, "tree_size": 64, "t0": 0.513, "t1": 0.394, "tft": 1.2173, "input_0": 117, "input_1": 65, "min_CLP": -5.56, "draft_iters": 7.2, "mem_use": 34.03, "gen_rate": 3.1, "speed": 3.42, "text": "The name of the default Windows "}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.2, "tree_w": 18, "tree_size": 64, "t0": 0.775, "t1": 0.3767, "tft": 2.1061, "input_0": 178, "input_1": 65, "min_CLP": -4.97, "draft_iters": 11.2, "mem_use": 36.22, "gen_rate": 5.7, "speed": 4.92, "text": "Sure, here are some open-source "}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 23.0, "tree_w": 11, "tree_size": 64, "t0": 1.59, "t1": 0.41, "tft": 1.2843, "input_0": 148, "input_1": 65, "min_CLP": -5.07, "draft_iters": 23.5, "mem_use": 34.03, "gen_rate": 20.0, "speed": 9.97, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.4, "tree_w": 16, "tree_size": 64, "t0": 0.73, "t1": 0.3814, "tft": 1.6366, "input_0": 159, "input_1": 65, "min_CLP": -4.99, "draft_iters": 10.4, "mem_use": 34.72, "gen_rate": 5.0, "speed": 4.5, "text": "The Unus Annus Trolley Problem i"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 30.5, "tree_w": 5, "tree_size": 64, "t0": 2.125, "t1": 0.435, "tft": 2.0828, "input_0": 215, "input_1": 65, "min_CLP": -4.55, "draft_iters": 31.0, "mem_use": 35.59, "gen_rate": 22.0, "speed": 8.59, "text": "1. m\u00eb (suffix)\\n2. meles, meless"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.2, "tree_w": 15, "tree_size": 64, "t0": 0.6525, "t1": 0.3913, "tft": 1.1959, "input_0": 145, "input_1": 65, "min_CLP": -5.02, "draft_iters": 9.2, "mem_use": 34.28, "gen_rate": 4.4, "speed": 4.2, "text": "Once upon a time, in a world fil"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 13.0, "tree_w": 12, "tree_size": 64, "t0": 0.956, "t1": 0.372, "tft": 2.2002, "input_0": 163, "input_1": 65, "min_CLP": -4.4, "draft_iters": 14.0, "mem_use": 37.02, "gen_rate": 8.8, "speed": 6.62, "text": "\"I apologize for the incorrect i"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.2, "tree_w": 16, "tree_size": 64, "t0": 0.6517, "t1": 0.375, "tft": 0.9936, "input_0": 148, "input_1": 65, "min_CLP": -4.81, "draft_iters": 9.2, "mem_use": 33.99, "gen_rate": 5.5, "speed": 5.36, "text": "\"Sure! The standard way to forma"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.2, "tree_w": 8, "tree_size": 64, "t0": 1.1925, "t1": 0.3775, "tft": 2.2105, "input_0": 228, "input_1": 65, "min_CLP": -4.3, "draft_iters": 17.2, "mem_use": 36.01, "gen_rate": 9.2, "speed": 5.89, "text": "\"Here's an example code to set u"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.1, "tree_w": 14, "tree_size": 64, "t0": 0.6425, "t1": 0.37, "tft": 1.4772, "input_0": 147, "input_1": 65, "min_CLP": -4.79, "draft_iters": 9.1, "mem_use": 33.97, "gen_rate": 4.5, "speed": 4.45, "text": "The largest ocean in the world i"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.7, "tree_w": 24, "tree_size": 64, "t0": 0.4689, "t1": 0.3889, "tft": 1.1585, "input_0": 101, "input_1": 65, "min_CLP": -5.21, "draft_iters": 6.7, "mem_use": 34.42, "gen_rate": 3.9, "speed": 4.53, "text": "\"It's unlikely that AI assistant"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.6, "tree_w": 25, "tree_size": 64, "t0": 0.5156, "t1": 0.3689, "tft": 3.2751, "input_0": 112, "input_1": 65, "min_CLP": -5.29, "draft_iters": 7.6, "mem_use": 39.55, "gen_rate": 3.9, "speed": 4.4, "text": "\"Absolutely! Here's a garden-the"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 63, "tree_h": 9.8, "tree_w": 19, "tree_size": 64, "t0": 0.7388, "t1": 0.3688, "tft": 1.4868, "input_0": 149, "input_1": 65, "min_CLP": -5.02, "draft_iters": 10.6, "mem_use": 34.79, "gen_rate": 7.9, "speed": 7.09, "text": "0 An independent counsel is a pe"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 11.4, "tree_w": 16, "tree_size": 64, "t0": 0.8414, "t1": 0.3857, "tft": 2.132, "input_0": 138, "input_1": 65, "min_CLP": -4.85, "draft_iters": 12.3, "mem_use": 36.65, "gen_rate": 4.6, "speed": 3.72, "text": "As a business professional, I un"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.0, "tree_w": 18, "tree_size": 64, "t0": 0.5657, "t1": 0.3829, "tft": 1.2787, "input_0": 135, "input_1": 65, "min_CLP": -5.04, "draft_iters": 8.0, "mem_use": 35.02, "gen_rate": 5.4, "speed": 5.72, "text": "1. Economic downturn: If the loc"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.2, "tree_w": 22, "tree_size": 64, "t0": 0.9, "t1": 0.396, "tft": 0.9322, "input_0": 136, "input_1": 65, "min_CLP": -5.41, "draft_iters": 13.0, "mem_use": 34.3, "gen_rate": 7.8, "speed": 6.02, "text": "[SYS: You are a helpful, respect"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.7, "tree_w": 10, "tree_size": 64, "t0": 1.0167, "t1": 0.3733, "tft": 3.0704, "input_0": 223, "input_1": 65, "min_CLP": -4.67, "draft_iters": 14.7, "mem_use": 36.77, "gen_rate": 12.0, "speed": 8.61, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.0, "tree_w": 13, "tree_size": 64, "t0": 0.775, "t1": 0.405, "tft": 1.2256, "input_0": 175, "input_1": 65, "min_CLP": -4.76, "draft_iters": 11.0, "mem_use": 34.48, "gen_rate": 8.0, "speed": 6.76, "text": "\"To determine the most cost-effe"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.8, "tree_w": 13, "tree_size": 64, "t0": 0.885, "t1": 0.37, "tft": 2.6728, "input_0": 176, "input_1": 65, "min_CLP": -4.65, "draft_iters": 12.8, "mem_use": 36.45, "gen_rate": 5.5, "speed": 4.39, "text": "Creating a reinforcement learnin"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.5, "tree_w": 11, "tree_size": 64, "t0": 0.87, "t1": 0.3675, "tft": 1.2425, "input_0": 177, "input_1": 65, "min_CLP": -4.56, "draft_iters": 12.5, "mem_use": 34.01, "gen_rate": 8.0, "speed": 6.46, "text": "\"Sure, I can help with that. Her"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 8.2, "tree_w": 21, "tree_size": 64, "t0": 0.64, "t1": 0.3617, "tft": 1.4824, "input_0": 145, "input_1": 65, "min_CLP": -4.89, "draft_iters": 9.2, "mem_use": 34.73, "gen_rate": 6.7, "speed": 6.67, "text": "The law was created in 1977.\\n[I"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.7, "tree_w": 14, "tree_size": 64, "t0": 0.7514, "t1": 0.3743, "tft": 1.1477, "input_0": 160, "input_1": 65, "min_CLP": -4.72, "draft_iters": 10.7, "mem_use": 34.45, "gen_rate": 5.4, "speed": 4.82, "text": "## Assistant:\\nTo alleviate the "}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 14.7, "tree_w": 20, "tree_size": 64, "t0": 1.05, "t1": 0.38, "tft": 1.0197, "input_0": 143, "input_1": 65, "min_CLP": -5.2, "draft_iters": 15.3, "mem_use": 34.05, "gen_rate": 13.7, "speed": 9.52, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 14, "tree_size": 64, "t0": 0.735, "t1": 0.37, "tft": 1.569, "input_0": 164, "input_1": 65, "min_CLP": -4.84, "draft_iters": 10.5, "mem_use": 34.93, "gen_rate": 5.3, "speed": 4.83, "text": "Overcoming the fear of looking d"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 56, "tree_h": 15.8, "tree_w": 13, "tree_size": 64, "t0": 1.13, "t1": 0.365, "tft": 2.6902, "input_0": 185, "input_1": 65, "min_CLP": -5.17, "draft_iters": 16.5, "mem_use": 36.53, "gen_rate": 14.0, "speed": 9.35, "text": "Sure, here is a list of some of "}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.8, "tree_w": 11, "tree_size": 64, "t0": 1.022, "t1": 0.378, "tft": 1.1697, "input_0": 186, "input_1": 65, "min_CLP": -4.5, "draft_iters": 14.8, "mem_use": 34.17, "gen_rate": 7.8, "speed": 5.56, "text": "The total travel time can be cal"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 47, "tree_h": 26.0, "tree_w": 6, "tree_size": 64, "t0": 1.87, "t1": 0.4433, "tft": 1.3838, "input_0": 208, "input_1": 65, "min_CLP": -4.68, "draft_iters": 27.0, "mem_use": 34.08, "gen_rate": 15.7, "speed": 6.77, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 11, "tree_h": 6.0, "tree_w": 19, "tree_size": 64, "t0": 0.4967, "t1": 0.3567, "tft": 1.0146, "input_0": 115, "input_1": 65, "min_CLP": -5.09, "draft_iters": 7.0, "mem_use": 33.97, "gen_rate": 3.7, "speed": 4.32, "text": "Yes, I am capable of answering q"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 18, "tree_size": 64, "t0": 0.5633, "t1": 0.3717, "tft": 2.683, "input_0": 153, "input_1": 65, "min_CLP": -4.84, "draft_iters": 8.2, "mem_use": 37.74, "gen_rate": 5.5, "speed": 5.89, "text": "TypeScript adds type checking to"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 7.0, "tree_w": 26, "tree_size": 64, "t0": 0.55, "t1": 0.36, "tft": 1.2132, "input_0": 124, "input_1": 65, "min_CLP": -5.38, "draft_iters": 8.0, "mem_use": 34.09, "gen_rate": 1.0, "speed": 1.1, "text": "The name of the fourth kid is Mi"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 53, "tree_h": 14.5, "tree_w": 15, "tree_size": 64, "t0": 1.05, "t1": 0.39, "tft": 1.6571, "input_0": 159, "input_1": 65, "min_CLP": -5.18, "draft_iters": 15.2, "mem_use": 35.12, "gen_rate": 13.2, "speed": 9.19, "text": "An account with the amount exper"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 0.6671, "t1": 0.37, "tft": 2.296, "input_0": 175, "input_1": 65, "min_CLP": -4.84, "draft_iters": 9.6, "mem_use": 36.88, "gen_rate": 5.0, "speed": 4.83, "text": "\"The optimal toasting time for b"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.6, "tree_w": 17, "tree_size": 64, "t0": 0.6863, "t1": 0.3987, "tft": 1.0257, "input_0": 157, "input_1": 65, "min_CLP": -4.84, "draft_iters": 9.6, "mem_use": 34.22, "gen_rate": 4.4, "speed": 4.04, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 20, "tree_size": 64, "t0": 0.6867, "t1": 0.3867, "tft": 1.2917, "input_0": 134, "input_1": 65, "min_CLP": -5.09, "draft_iters": 9.8, "mem_use": 34.72, "gen_rate": 5.3, "speed": 4.97, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 11.0, "tree_w": 14, "tree_size": 64, "t0": 0.826, "t1": 0.368, "tft": 2.2639, "input_0": 179, "input_1": 65, "min_CLP": -4.67, "draft_iters": 12.0, "mem_use": 36.46, "gen_rate": 8.6, "speed": 7.19, "text": "\"As a high school student, there"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.0, "tree_w": 15, "tree_size": 64, "t0": 0.8367, "t1": 0.3817, "tft": 1.6582, "input_0": 166, "input_1": 65, "min_CLP": -4.84, "draft_iters": 12.0, "mem_use": 34.85, "gen_rate": 5.8, "speed": 4.79, "text": "The television was invented by a"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 0.7725, "t1": 0.35, "tft": 2.244, "input_0": 167, "input_1": 65, "min_CLP": -4.55, "draft_iters": 11.2, "mem_use": 37.16, "gen_rate": 8.5, "speed": 7.56, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 16, "tree_size": 64, "t0": 0.6983, "t1": 0.39, "tft": 1.9736, "input_0": 153, "input_1": 65, "min_CLP": -4.83, "draft_iters": 10.0, "mem_use": 35.51, "gen_rate": 6.0, "speed": 5.51, "text": "The celebration of Christmas on "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.0, "tree_w": 20, "tree_size": 64, "t0": 0.5657, "t1": 0.3857, "tft": 1.4528, "input_0": 148, "input_1": 65, "min_CLP": -5.12, "draft_iters": 8.0, "mem_use": 34.54, "gen_rate": 4.9, "speed": 5.11, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 0.7733, "t1": 0.375, "tft": 2.4099, "input_0": 174, "input_1": 65, "min_CLP": -4.73, "draft_iters": 11.2, "mem_use": 36.34, "gen_rate": 5.7, "speed": 4.94, "text": "One of the most difficult parts "}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 0.79, "t1": 0.4175, "tft": 0.9626, "input_0": 154, "input_1": 65, "min_CLP": -4.78, "draft_iters": 11.2, "mem_use": 34.16, "gen_rate": 8.2, "speed": 6.84, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.9, "tree_w": 16, "tree_size": 64, "t0": 0.82, "t1": 0.3914, "tft": 1.4521, "input_0": 143, "input_1": 65, "min_CLP": -5.08, "draft_iters": 11.9, "mem_use": 34.78, "gen_rate": 5.0, "speed": 4.13, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 56, "tree_h": 14.5, "tree_w": 15, "tree_size": 64, "t0": 1.075, "t1": 0.43, "tft": 1.9958, "input_0": 134, "input_1": 65, "min_CLP": -5.13, "draft_iters": 15.5, "mem_use": 34.26, "gen_rate": 9.3, "speed": 6.2, "text": "\"If I were to ask you how deep S"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.6, "tree_w": 11, "tree_size": 64, "t0": 0.954, "t1": 0.402, "tft": 0.9251, "input_0": 177, "input_1": 65, "min_CLP": -4.65, "draft_iters": 13.6, "mem_use": 34.27, "gen_rate": 7.6, "speed": 5.6, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.0, "tree_w": 19, "tree_size": 64, "t0": 0.5633, "t1": 0.3833, "tft": 1.4644, "input_0": 135, "input_1": 65, "min_CLP": -5.01, "draft_iters": 8.0, "mem_use": 34.65, "gen_rate": 5.5, "speed": 5.81, "text": "\"Yes, Google Authenticator is a "}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 13, "tree_size": 64, "t0": 0.6967, "t1": 0.3667, "tft": 1.9879, "input_0": 157, "input_1": 65, "min_CLP": -4.74, "draft_iters": 10.0, "mem_use": 34.44, "gen_rate": 6.0, "speed": 5.63, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.4, "tree_w": 11, "tree_size": 64, "t0": 0.794, "t1": 0.372, "tft": 0.982, "input_0": 184, "input_1": 65, "min_CLP": -4.79, "draft_iters": 11.4, "mem_use": 34.2, "gen_rate": 7.6, "speed": 6.5, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 14, "tree_size": 64, "t0": 0.7033, "t1": 0.415, "tft": 0.9598, "input_0": 169, "input_1": 65, "min_CLP": -4.87, "draft_iters": 9.8, "mem_use": 34.05, "gen_rate": 5.7, "speed": 5.07, "text": "The answer is: There are several"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.3, "tree_w": 15, "tree_size": 64, "t0": 0.805, "t1": 0.4167, "tft": 1.0389, "input_0": 172, "input_1": 65, "min_CLP": -4.72, "draft_iters": 11.3, "mem_use": 34.08, "gen_rate": 5.7, "speed": 4.65, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 14.7, "tree_w": 18, "tree_size": 64, "t0": 1.0533, "t1": 0.41, "tft": 1.2624, "input_0": 136, "input_1": 65, "min_CLP": -4.88, "draft_iters": 15.3, "mem_use": 34.0, "gen_rate": 13.0, "speed": 8.9, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.4, "tree_w": 15, "tree_size": 64, "t0": 0.6614, "t1": 0.3986, "tft": 1.7588, "input_0": 148, "input_1": 65, "min_CLP": -4.84, "draft_iters": 9.4, "mem_use": 35.18, "gen_rate": 5.1, "speed": 4.85, "text": "\"In that case, you can use an in"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 7.8, "tree_w": 15, "tree_size": 64, "t0": 0.6233, "t1": 0.38, "tft": 1.1229, "input_0": 154, "input_1": 65, "min_CLP": -4.75, "draft_iters": 8.8, "mem_use": 33.96, "gen_rate": 6.2, "speed": 6.15, "text": "In Python, the \"@\" symbol is use"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.5, "tree_w": 15, "tree_size": 64, "t0": 0.7333, "t1": 0.375, "tft": 1.3412, "input_0": 128, "input_1": 65, "min_CLP": -4.76, "draft_iters": 10.5, "mem_use": 33.97, "gen_rate": 5.5, "speed": 4.96, "text": "My thoughts on ChatGPT are that "}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.8, "tree_w": 21, "tree_size": 64, "t0": 0.48, "t1": 0.3687, "tft": 1.0577, "input_0": 114, "input_1": 65, "min_CLP": -5.09, "draft_iters": 6.8, "mem_use": 34.28, "gen_rate": 4.5, "speed": 5.3, "text": "The task you have been given is "}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.1, "tree_w": 17, "tree_size": 64, "t0": 0.6375, "t1": 0.3712, "tft": 0.7811, "input_0": 132, "input_1": 65, "min_CLP": -4.87, "draft_iters": 9.1, "mem_use": 34.01, "gen_rate": 4.0, "speed": 3.96, "text": "Sure, I can help with that! Howe"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 2.13, "t1": 0.44, "tft": 1.4914, "input_0": 185, "input_1": 65, "min_CLP": -4.68, "draft_iters": 32.0, "mem_use": 34.7, "gen_rate": 33.0, "speed": 12.82, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.7, "tree_w": 16, "tree_size": 64, "t0": 0.8043, "t1": 0.3771, "tft": 2.9068, "input_0": 148, "input_1": 65, "min_CLP": -4.8, "draft_iters": 11.7, "mem_use": 37.2, "gen_rate": 4.9, "speed": 4.11, "text": "The quest for a robust and accur"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 0.78, "t1": 0.3833, "tft": 1.5788, "input_0": 174, "input_1": 65, "min_CLP": -4.73, "draft_iters": 11.2, "mem_use": 34.51, "gen_rate": 6.3, "speed": 5.44, "text": "Decorators can do many things th"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.0, "tree_w": 18, "tree_size": 64, "t0": 0.5617, "t1": 0.3667, "tft": 1.5289, "input_0": 151, "input_1": 65, "min_CLP": -5.0, "draft_iters": 8.0, "mem_use": 35.62, "gen_rate": 5.7, "speed": 6.08, "text": "\"Hello there! How may I assist y"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 16, "tree_h": 10.3, "tree_w": 24, "tree_size": 64, "t0": 0.7814, "t1": 0.4114, "tft": 1.6885, "input_0": 125, "input_1": 65, "min_CLP": -5.37, "draft_iters": 11.3, "mem_use": 34.5, "gen_rate": 2.3, "speed": 1.92, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.8, "tree_w": 11, "tree_size": 64, "t0": 1.012, "t1": 0.378, "tft": 2.959, "input_0": 206, "input_1": 65, "min_CLP": -4.4, "draft_iters": 14.8, "mem_use": 37.38, "gen_rate": 7.2, "speed": 5.18, "text": "Sure! Here are some examples of "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 14.0, "tree_w": 8, "tree_size": 64, "t0": 1.016, "t1": 0.408, "tft": 5.4257, "input_0": 201, "input_1": 65, "min_CLP": -4.43, "draft_iters": 15.0, "mem_use": 43.37, "gen_rate": 8.2, "speed": 5.75, "text": "\"Sure, here's an example of how "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 20.2, "tree_w": 13, "tree_size": 64, "t0": 1.4375, "t1": 0.4275, "tft": 1.974, "input_0": 169, "input_1": 65, "min_CLP": -4.59, "draft_iters": 21.0, "mem_use": 35.73, "gen_rate": 9.5, "speed": 5.09, "text": "L\\'H\u00f4pital\\'s Rule is a mathemat"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.0, "tree_w": 16, "tree_size": 64, "t0": 0.7033, "t1": 0.3833, "tft": 0.8296, "input_0": 176, "input_1": 65, "min_CLP": -4.79, "draft_iters": 10.0, "mem_use": 34.01, "gen_rate": 5.7, "speed": 5.21, "text": "\"Certainly! To pursue a governme"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.3, "tree_w": 16, "tree_size": 64, "t0": 0.6617, "t1": 0.39, "tft": 0.9755, "input_0": 157, "input_1": 65, "min_CLP": -4.89, "draft_iters": 9.3, "mem_use": 34.13, "gen_rate": 5.3, "speed": 5.06, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.4, "tree_w": 18, "tree_size": 64, "t0": 0.6529, "t1": 0.37, "tft": 2.3912, "input_0": 146, "input_1": 65, "min_CLP": -4.95, "draft_iters": 9.4, "mem_use": 36.89, "gen_rate": 5.0, "speed": 4.89, "text": "Certainly! Here are some tips to"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.2, "tree_w": 18, "tree_size": 64, "t0": 0.6417, "t1": 0.3733, "tft": 1.2672, "input_0": 146, "input_1": 65, "min_CLP": -4.93, "draft_iters": 9.2, "mem_use": 34.07, "gen_rate": 5.3, "speed": 5.26, "text": "The world in 1950 was vastly dif"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.5, "tree_w": 16, "tree_size": 64, "t0": 0.72, "t1": 0.3633, "tft": 3.2639, "input_0": 179, "input_1": 65, "min_CLP": -4.67, "draft_iters": 10.5, "mem_use": 39.04, "gen_rate": 6.5, "speed": 6.01, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 6.7, "tree_w": 20, "tree_size": 64, "t0": 0.5414, "t1": 0.3529, "tft": 1.1439, "input_0": 135, "input_1": 65, "min_CLP": -5.17, "draft_iters": 7.7, "mem_use": 34.41, "gen_rate": 3.7, "speed": 4.14, "text": "The order of installation is: Ca"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.3, "tree_w": 12, "tree_size": 64, "t0": 1.13, "t1": 0.41, "tft": 1.3732, "input_0": 152, "input_1": 65, "min_CLP": -4.89, "draft_iters": 16.3, "mem_use": 34.26, "gen_rate": 10.7, "speed": 6.92, "text": "\"1. Carnegie Mellon University, "}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 6.0, "tree_w": 23, "tree_size": 64, "t0": 0.499, "t1": 0.38, "tft": 1.0806, "input_0": 114, "input_1": 65, "min_CLP": -5.15, "draft_iters": 7.0, "mem_use": 34.32, "gen_rate": 3.5, "speed": 3.98, "text": "\"I have a few differences that I"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.0, "tree_w": 11, "tree_size": 64, "t0": 0.9725, "t1": 0.385, "tft": 2.3006, "input_0": 209, "input_1": 65, "min_CLP": -4.32, "draft_iters": 14.0, "mem_use": 35.67, "gen_rate": 8.2, "speed": 6.08, "text": "The two most important PC compon"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 11, "tree_size": 64, "t0": 0.728, "t1": 0.366, "tft": 1.4856, "input_0": 169, "input_1": 65, "min_CLP": -4.73, "draft_iters": 10.4, "mem_use": 34.39, "gen_rate": 6.8, "speed": 6.22, "text": "Sure, I can provide some informa"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 14.7, "tree_w": 19, "tree_size": 64, "t0": 1.0533, "t1": 0.4, "tft": 1.227, "input_0": 161, "input_1": 65, "min_CLP": -4.89, "draft_iters": 15.3, "mem_use": 34.56, "gen_rate": 13.7, "speed": 9.41, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.7, "tree_w": 16, "tree_size": 64, "t0": 0.6717, "t1": 0.3733, "tft": 1.6844, "input_0": 149, "input_1": 65, "min_CLP": -4.93, "draft_iters": 9.7, "mem_use": 34.62, "gen_rate": 5.7, "speed": 5.43, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.9, "tree_w": 19, "tree_size": 64, "t0": 0.5489, "t1": 0.3633, "tft": 2.103, "input_0": 125, "input_1": 65, "min_CLP": -5.01, "draft_iters": 7.9, "mem_use": 36.54, "gen_rate": 3.7, "speed": 4.01, "text": "\"Sure, here are some YouTube cha"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 9, "tree_h": 9.0, "tree_w": 14, "tree_size": 64, "t0": 0.68, "t1": 0.38, "tft": 1.1791, "input_0": 121, "input_1": 65, "min_CLP": -5.28, "draft_iters": 10.0, "mem_use": 33.97, "gen_rate": 9.0, "speed": 8.51, "text": "yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 23.0, "tree_w": 10, "tree_size": 64, "t0": 1.69, "t1": 0.4433, "tft": 0.9596, "input_0": 255, "input_1": 65, "min_CLP": -4.69, "draft_iters": 24.0, "mem_use": 34.11, "gen_rate": 11.7, "speed": 5.47, "text": "To determine whether \\\\((AB)^T ="}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.5, "tree_w": 11, "tree_size": 64, "t0": 1.0775, "t1": 0.3925, "tft": 1.654, "input_0": 200, "input_1": 65, "min_CLP": -4.85, "draft_iters": 15.5, "mem_use": 35.54, "gen_rate": 9.8, "speed": 6.63, "text": "Statistical modeling\\nApplying s"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 6, "tree_size": 64, "t0": 2.13, "t1": 0.38, "tft": 3.9116, "input_0": 184, "input_1": 65, "min_CLP": -4.94, "draft_iters": 32.0, "mem_use": 36.7, "gen_rate": 33.0, "speed": 13.14, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 20, "tree_h": 6.2, "tree_w": 20, "tree_size": 64, "t0": 0.514, "t1": 0.364, "tft": 1.3263, "input_0": 138, "input_1": 65, "min_CLP": -4.98, "draft_iters": 7.2, "mem_use": 33.95, "gen_rate": 4.0, "speed": 4.56, "text": "The current date is not provided"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.9, "tree_w": 16, "tree_size": 64, "t0": 0.6857, "t1": 0.3743, "tft": 1.832, "input_0": 163, "input_1": 65, "min_CLP": -4.75, "draft_iters": 9.9, "mem_use": 35.42, "gen_rate": 5.6, "speed": 5.26, "text": "Yes, removing things that cause "}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.1, "tree_w": 24, "tree_size": 64, "t0": 0.4956, "t1": 0.3589, "tft": 0.9206, "input_0": 105, "input_1": 65, "min_CLP": -5.42, "draft_iters": 7.1, "mem_use": 34.32, "gen_rate": 3.6, "speed": 4.16, "text": "\"That's so wrong it's not even f"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.7, "tree_w": 10, "tree_size": 64, "t0": 0.95, "t1": 0.38, "tft": 1.2384, "input_0": 217, "input_1": 65, "min_CLP": -4.76, "draft_iters": 13.7, "mem_use": 34.01, "gen_rate": 11.0, "speed": 8.25, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 16.7, "tree_w": 13, "tree_size": 64, "t0": 1.21, "t1": 0.4133, "tft": 1.0082, "input_0": 168, "input_1": 65, "min_CLP": -4.96, "draft_iters": 17.7, "mem_use": 34.36, "gen_rate": 4.7, "speed": 2.87, "text": "You are an AI assistant that fol"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.6, "tree_w": 18, "tree_size": 64, "t0": 0.6014, "t1": 0.3643, "tft": 0.9944, "input_0": 137, "input_1": 65, "min_CLP": -5.07, "draft_iters": 8.6, "mem_use": 33.95, "gen_rate": 4.9, "speed": 5.04, "text": "An assistant is tasked with expl"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.0, "tree_w": 16, "tree_size": 64, "t0": 0.76, "t1": 0.382, "tft": 1.89, "input_0": 155, "input_1": 65, "min_CLP": -4.88, "draft_iters": 11.0, "mem_use": 35.28, "gen_rate": 7.4, "speed": 6.47, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 10.5, "tree_w": 16, "tree_size": 64, "t0": 0.78, "t1": 0.36, "tft": 1.6924, "input_0": 126, "input_1": 65, "min_CLP": -5.17, "draft_iters": 11.5, "mem_use": 34.14, "gen_rate": 2.5, "speed": 2.18, "text": "\"Jay's brother is John.\""}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.7, "tree_w": 14, "tree_size": 64, "t0": 0.6786, "t1": 0.3743, "tft": 1.4213, "input_0": 150, "input_1": 65, "min_CLP": -4.94, "draft_iters": 9.7, "mem_use": 34.52, "gen_rate": 5.6, "speed": 5.29, "text": "Earth contains four oceans: Atla"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.0, "tree_w": 19, "tree_size": 64, "t0": 0.5625, "t1": 0.3688, "tft": 1.2941, "input_0": 140, "input_1": 65, "min_CLP": -4.9, "draft_iters": 8.0, "mem_use": 34.76, "gen_rate": 4.0, "speed": 4.29, "text": "The first step to getting starte"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.5, "tree_w": 10, "tree_size": 64, "t0": 0.9475, "t1": 0.3775, "tft": 1.2364, "input_0": 227, "input_1": 65, "min_CLP": -4.43, "draft_iters": 13.5, "mem_use": 34.18, "gen_rate": 10.0, "speed": 7.55, "text": "\"To create a basic PyGame projec"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 17, "tree_size": 64, "t0": 0.5417, "t1": 0.365, "tft": 1.8131, "input_0": 156, "input_1": 65, "min_CLP": -4.85, "draft_iters": 7.7, "mem_use": 35.27, "gen_rate": 5.3, "speed": 5.9, "text": "DLL stands for Dynamic Link Libr"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.3, "tree_w": 16, "tree_size": 64, "t0": 0.655, "t1": 0.3683, "tft": 1.2958, "input_0": 152, "input_1": 65, "min_CLP": -4.85, "draft_iters": 9.3, "mem_use": 34.42, "gen_rate": 5.5, "speed": 5.38, "text": "I apologize for the confusion ea"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.8, "tree_w": 20, "tree_size": 64, "t0": 0.4856, "t1": 0.3744, "tft": 0.9815, "input_0": 124, "input_1": 65, "min_CLP": -5.08, "draft_iters": 6.8, "mem_use": 33.96, "gen_rate": 3.6, "speed": 4.13, "text": "The Infinite Banking Concept is "}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.6, "tree_w": 11, "tree_size": 64, "t0": 0.882, "t1": 0.428, "tft": 0.9596, "input_0": 164, "input_1": 65, "min_CLP": -4.57, "draft_iters": 12.6, "mem_use": 34.07, "gen_rate": 7.8, "speed": 5.94, "text": "\"Here's an example of a high-qua"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 22, "tree_h": 7.2, "tree_w": 18, "tree_size": 64, "t0": 0.574, "t1": 0.372, "tft": 1.053, "input_0": 131, "input_1": 65, "min_CLP": -5.1, "draft_iters": 8.2, "mem_use": 34.22, "gen_rate": 4.4, "speed": 4.65, "text": "Landlords are not necessarily on"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.2, "tree_w": 24, "tree_size": 64, "t0": 0.4389, "t1": 0.38, "tft": 1.3516, "input_0": 101, "input_1": 65, "min_CLP": -5.44, "draft_iters": 6.2, "mem_use": 34.74, "gen_rate": 3.7, "speed": 4.47, "text": "\"I think the writing is terrible"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 9.3, "tree_w": 14, "tree_size": 64, "t0": 0.7171, "t1": 0.3743, "tft": 1.7644, "input_0": 163, "input_1": 65, "min_CLP": -4.63, "draft_iters": 10.3, "mem_use": 35.57, "gen_rate": 5.7, "speed": 5.23, "text": "\"Sure, you can ask me for help. "}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.0, "tree_w": 11, "tree_size": 64, "t0": 0.7667, "t1": 0.37, "tft": 2.3239, "input_0": 178, "input_1": 65, "min_CLP": -4.57, "draft_iters": 11.0, "mem_use": 36.13, "gen_rate": 6.0, "speed": 5.29, "text": "\"The difficulty of learning a fo"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.3, "tree_w": 15, "tree_size": 64, "t0": 0.72, "t1": 0.3967, "tft": 1.3652, "input_0": 151, "input_1": 65, "min_CLP": -4.7, "draft_iters": 10.3, "mem_use": 34.56, "gen_rate": 5.7, "speed": 5.06, "text": "\"Among the AI tools for 2D anima"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 29, "tree_h": 7.6, "tree_w": 16, "tree_size": 64, "t0": 0.6043, "t1": 0.3714, "tft": 1.2283, "input_0": 145, "input_1": 65, "min_CLP": -4.74, "draft_iters": 8.6, "mem_use": 34.42, "gen_rate": 4.1, "speed": 4.23, "text": "\"I'm an AI language model, I don"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.7, "tree_w": 22, "tree_size": 64, "t0": 0.5378, "t1": 0.3622, "tft": 1.1917, "input_0": 122, "input_1": 65, "min_CLP": -5.21, "draft_iters": 7.7, "mem_use": 34.64, "gen_rate": 3.6, "speed": 3.95, "text": "\"No, it's not worth more than ge"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.6, "tree_w": 16, "tree_size": 64, "t0": 0.6714, "t1": 0.3829, "tft": 1.7384, "input_0": 168, "input_1": 65, "min_CLP": -4.93, "draft_iters": 9.6, "mem_use": 34.65, "gen_rate": 5.0, "speed": 4.73, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.5, "tree_w": 18, "tree_size": 64, "t0": 0.6025, "t1": 0.4125, "tft": 1.3556, "input_0": 134, "input_1": 65, "min_CLP": -5.06, "draft_iters": 8.5, "mem_use": 34.08, "gen_rate": 4.1, "speed": 4.06, "text": "\"Sure, I can design an electric "}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.4, "tree_w": 15, "tree_size": 64, "t0": 0.66, "t1": 0.37, "tft": 1.9565, "input_0": 159, "input_1": 65, "min_CLP": -4.85, "draft_iters": 9.4, "mem_use": 35.73, "gen_rate": 6.8, "speed": 6.6, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 12.5, "tree_w": 17, "tree_size": 64, "t0": 0.925, "t1": 0.37, "tft": 1.7053, "input_0": 163, "input_1": 65, "min_CLP": -5.0, "draft_iters": 13.5, "mem_use": 34.22, "gen_rate": 6.0, "speed": 4.63, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.2, "tree_w": 21, "tree_size": 64, "t0": 0.72, "t1": 0.386, "tft": 1.9823, "input_0": 142, "input_1": 65, "min_CLP": -5.13, "draft_iters": 10.2, "mem_use": 34.05, "gen_rate": 6.8, "speed": 6.14, "text": "Sure, here are 10 names from var"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.8, "tree_w": 18, "tree_size": 64, "t0": 0.5463, "t1": 0.37, "tft": 1.2501, "input_0": 130, "input_1": 65, "min_CLP": -5.01, "draft_iters": 7.8, "mem_use": 34.53, "gen_rate": 4.5, "speed": 4.92, "text": "\"I'm just a computer program, so"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.3, "tree_w": 15, "tree_size": 64, "t0": 0.8517, "t1": 0.3733, "tft": 2.4755, "input_0": 187, "input_1": 65, "min_CLP": -4.82, "draft_iters": 12.3, "mem_use": 36.23, "gen_rate": 6.0, "speed": 4.89, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.9, "tree_w": 19, "tree_size": 64, "t0": 0.5571, "t1": 0.3643, "tft": 1.6232, "input_0": 146, "input_1": 65, "min_CLP": -5.13, "draft_iters": 7.9, "mem_use": 35.0, "gen_rate": 5.1, "speed": 5.58, "text": "Yes, there is a theory called \"H"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.4, "tree_w": 14, "tree_size": 64, "t0": 0.656, "t1": 0.368, "tft": 1.8323, "input_0": 147, "input_1": 65, "min_CLP": -4.68, "draft_iters": 9.4, "mem_use": 35.42, "gen_rate": 6.8, "speed": 6.64, "text": "The meaning of life is a deeply "}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 5.7, "tree_w": 25, "tree_size": 64, "t0": 0.4733, "t1": 0.3722, "tft": 0.9898, "input_0": 104, "input_1": 65, "min_CLP": -5.56, "draft_iters": 6.7, "mem_use": 34.0, "gen_rate": 3.6, "speed": 4.2, "text": "Title: The Quantum Road\\n\\nMain "}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.8, "tree_w": 11, "tree_size": 64, "t0": 1.13, "t1": 0.3625, "tft": 3.7962, "input_0": 188, "input_1": 65, "min_CLP": -4.83, "draft_iters": 16.8, "mem_use": 38.7, "gen_rate": 8.0, "speed": 5.37, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 17, "tree_size": 64, "t0": 0.6167, "t1": 0.3683, "tft": 1.8292, "input_0": 149, "input_1": 65, "min_CLP": -4.83, "draft_iters": 8.8, "mem_use": 35.13, "gen_rate": 5.3, "speed": 5.4, "text": "To transform text words or expre"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.0, "tree_w": 14, "tree_size": 64, "t0": 0.96, "t1": 0.3733, "tft": 2.0064, "input_0": 177, "input_1": 65, "min_CLP": -4.77, "draft_iters": 14.0, "mem_use": 34.99, "gen_rate": 11.3, "speed": 8.52, "text": "The original departure time woul"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 64, "t0": 2.14, "t1": 0.46, "tft": 1.4982, "input_0": 202, "input_1": 65, "min_CLP": -4.63, "draft_iters": 32.0, "mem_use": 34.03, "gen_rate": 33.0, "speed": 12.69, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 21, "tree_h": 24.0, "tree_w": 17, "tree_size": 64, "t0": 1.65, "t1": 0.44, "tft": 1.4993, "input_0": 108, "input_1": 65, "min_CLP": -4.99, "draft_iters": 25.0, "mem_use": 34.36, "gen_rate": 21.0, "speed": 10.03, "text": "You are a helpful assistant, who"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.5, "tree_w": 16, "tree_size": 64, "t0": 0.67, "t1": 0.3667, "tft": 0.9345, "input_0": 162, "input_1": 65, "min_CLP": -5.09, "draft_iters": 9.5, "mem_use": 33.99, "gen_rate": 5.7, "speed": 5.47, "text": "As of my last update in early 20"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.0, "tree_w": 19, "tree_size": 64, "t0": 0.5471, "t1": 0.3571, "tft": 2.6513, "input_0": 130, "input_1": 65, "min_CLP": -5.14, "draft_iters": 8.0, "mem_use": 38.75, "gen_rate": 4.7, "speed": 5.21, "text": "\"My apologies for the misunderst"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.0, "tree_w": 20, "tree_size": 64, "t0": 0.564, "t1": 0.362, "tft": 1.2531, "input_0": 135, "input_1": 65, "min_CLP": -5.21, "draft_iters": 8.0, "mem_use": 34.07, "gen_rate": 6.4, "speed": 6.92, "text": "The furthest back we can current"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 7.0, "tree_w": 21, "tree_size": 64, "t0": 0.549, "t1": 0.364, "tft": 3.9859, "input_0": 126, "input_1": 65, "min_CLP": -5.02, "draft_iters": 8.0, "mem_use": 40.97, "gen_rate": 3.6, "speed": 3.94, "text": "No, thank you. I think I have en"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.3, "tree_w": 19, "tree_size": 64, "t0": 0.5144, "t1": 0.3756, "tft": 1.7014, "input_0": 118, "input_1": 65, "min_CLP": -5.23, "draft_iters": 7.3, "mem_use": 35.24, "gen_rate": 3.7, "speed": 4.12, "text": "Spritesla is the first and final"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.4, "tree_w": 16, "tree_size": 64, "t0": 0.6657, "t1": 0.3757, "tft": 1.0842, "input_0": 147, "input_1": 65, "min_CLP": -4.8, "draft_iters": 9.4, "mem_use": 34.09, "gen_rate": 5.1, "speed": 4.94, "text": "The human genome is the complete"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 8.2, "tree_w": 15, "tree_size": 64, "t0": 0.6489, "t1": 0.3767, "tft": 1.1219, "input_0": 142, "input_1": 65, "min_CLP": -4.83, "draft_iters": 9.2, "mem_use": 33.96, "gen_rate": 3.7, "speed": 3.57, "text": "\"Two-factor authentication (2FA)"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 19, "tree_size": 64, "t0": 0.5786, "t1": 0.37, "tft": 1.1932, "input_0": 158, "input_1": 65, "min_CLP": -5.19, "draft_iters": 8.1, "mem_use": 34.2, "gen_rate": 4.7, "speed": 4.97, "text": "Here\\'s a plausible explanation "}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.2, "tree_w": 13, "tree_size": 64, "t0": 0.784, "t1": 0.378, "tft": 1.2278, "input_0": 184, "input_1": 65, "min_CLP": -4.84, "draft_iters": 11.2, "mem_use": 34.5, "gen_rate": 8.4, "speed": 7.24, "text": "\"Sure, here are a few TV shows y"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 14.0, "tree_w": 10, "tree_size": 64, "t0": 1.0375, "t1": 0.3775, "tft": 2.4078, "input_0": 217, "input_1": 65, "min_CLP": -4.57, "draft_iters": 15.0, "mem_use": 36.13, "gen_rate": 11.2, "speed": 7.95, "text": "\"Sure, here are some software an"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.4, "tree_w": 12, "tree_size": 64, "t0": 0.798, "t1": 0.374, "tft": 2.2047, "input_0": 191, "input_1": 65, "min_CLP": -4.78, "draft_iters": 11.4, "mem_use": 35.22, "gen_rate": 7.0, "speed": 5.97, "text": "\"When F-centers are present in a"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.5, "tree_w": 13, "tree_size": 64, "t0": 1.37, "t1": 0.4, "tft": 1.1634, "input_0": 183, "input_1": 65, "min_CLP": -4.69, "draft_iters": 20.0, "mem_use": 34.14, "gen_rate": 19.5, "speed": 11.04, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 23.3, "tree_w": 9, "tree_size": 64, "t0": 1.6443, "t1": 0.3843, "tft": 2.3762, "input_0": 200, "input_1": 65, "min_CLP": -4.24, "draft_iters": 24.1, "mem_use": 36.76, "gen_rate": 8.0, "speed": 3.94, "text": "\"Here's the commented code with "}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.4, "tree_w": 18, "tree_size": 64, "t0": 0.59, "t1": 0.38, "tft": 3.2368, "input_0": 144, "input_1": 65, "min_CLP": -5.28, "draft_iters": 8.4, "mem_use": 35.25, "gen_rate": 6.8, "speed": 7.0, "text": "Lo siento, pero no puedo proporc"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 15.3, "tree_w": 18, "tree_size": 64, "t0": 1.1033, "t1": 0.4067, "tft": 1.1272, "input_0": 144, "input_1": 65, "min_CLP": -5.17, "draft_iters": 16.0, "mem_use": 33.98, "gen_rate": 13.3, "speed": 8.83, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 9.7, "tree_w": 19, "tree_size": 64, "t0": 0.74, "t1": 0.38, "tft": 0.9719, "input_0": 137, "input_1": 65, "min_CLP": -4.94, "draft_iters": 10.7, "mem_use": 34.07, "gen_rate": 4.7, "speed": 4.17, "text": "```\\n```python\\ndef hello_world("}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.2, "tree_w": 21, "tree_size": 64, "t0": 0.5075, "t1": 0.375, "tft": 1.3822, "input_0": 113, "input_1": 65, "min_CLP": -5.1, "draft_iters": 7.2, "mem_use": 35.09, "gen_rate": 4.6, "speed": 5.23, "text": "Sure! Here\\'s a poem about the m"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 12.2, "tree_w": 12, "tree_size": 64, "t0": 0.9117, "t1": 0.3617, "tft": 1.9908, "input_0": 181, "input_1": 65, "min_CLP": -4.6, "draft_iters": 13.2, "mem_use": 36.07, "gen_rate": 6.5, "speed": 5.1, "text": "In JavaScript, you can use the `"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 43, "tree_h": 8.0, "tree_w": 17, "tree_size": 64, "t0": 0.632, "t1": 0.369, "tft": 1.2414, "input_0": 142, "input_1": 65, "min_CLP": -5.04, "draft_iters": 9.0, "mem_use": 34.58, "gen_rate": 4.3, "speed": 4.29, "text": "Sure. I suggest you start with t"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 16, "tree_size": 64, "t0": 0.734, "t1": 0.37, "tft": 1.3752, "input_0": 187, "input_1": 65, "min_CLP": -4.76, "draft_iters": 10.4, "mem_use": 35.05, "gen_rate": 6.6, "speed": 6.0, "text": "I apologize for the confusion in"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.4, "tree_w": 14, "tree_size": 64, "t0": 0.732, "t1": 0.374, "tft": 1.1112, "input_0": 171, "input_1": 65, "min_CLP": -4.79, "draft_iters": 10.4, "mem_use": 33.97, "gen_rate": 6.6, "speed": 5.97, "text": "JavaScript is a versatile progra"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.5, "tree_w": 15, "tree_size": 64, "t0": 1.36, "t1": 0.405, "tft": 1.1209, "input_0": 161, "input_1": 65, "min_CLP": -5.27, "draft_iters": 20.0, "mem_use": 33.96, "gen_rate": 19.5, "speed": 11.06, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 12.7, "tree_w": 16, "tree_size": 64, "t0": 0.946, "t1": 0.392, "tft": 1.3475, "input_0": 151, "input_1": 65, "min_CLP": -5.14, "draft_iters": 13.7, "mem_use": 34.67, "gen_rate": 3.7, "speed": 2.77, "text": "Certainly! Here is the list with"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.5, "tree_w": 18, "tree_size": 64, "t0": 0.6667, "t1": 0.385, "tft": 1.0924, "input_0": 152, "input_1": 65, "min_CLP": -5.33, "draft_iters": 9.5, "mem_use": 34.09, "gen_rate": 6.3, "speed": 6.03, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 4.7, "tree_w": 26, "tree_size": 64, "t0": 0.411, "t1": 0.376, "tft": 0.9531, "input_0": 106, "input_1": 65, "min_CLP": -5.4, "draft_iters": 5.7, "mem_use": 34.09, "gen_rate": 3.2, "speed": 4.07, "text": "\"Here's a poem for your Valentin"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.2, "tree_w": 14, "tree_size": 64, "t0": 0.79, "t1": 0.4017, "tft": 0.8811, "input_0": 173, "input_1": 65, "min_CLP": -4.78, "draft_iters": 11.2, "mem_use": 34.07, "gen_rate": 5.5, "speed": 4.62, "text": "To improve your ability to write"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 19.2, "tree_w": 12, "tree_size": 64, "t0": 1.3333, "t1": 0.3867, "tft": 3.1343, "input_0": 172, "input_1": 65, "min_CLP": -4.78, "draft_iters": 19.8, "mem_use": 38.81, "gen_rate": 5.3, "speed": 3.1, "text": "Here is a monologue script that "}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.7, "tree_w": 16, "tree_size": 64, "t0": 0.74, "t1": 0.375, "tft": 2.6112, "input_0": 150, "input_1": 65, "min_CLP": -4.87, "draft_iters": 10.7, "mem_use": 36.46, "gen_rate": 5.3, "speed": 4.79, "text": "\"Sure! Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.3, "tree_w": 10, "tree_size": 64, "t0": 0.93, "t1": 0.3733, "tft": 1.7478, "input_0": 219, "input_1": 65, "min_CLP": -4.61, "draft_iters": 13.3, "mem_use": 34.89, "gen_rate": 10.7, "speed": 8.17, "text": "Certainly! The formula for estim"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.5, "tree_w": 12, "tree_size": 64, "t0": 0.8667, "t1": 0.3833, "tft": 1.5068, "input_0": 166, "input_1": 65, "min_CLP": -4.76, "draft_iters": 12.5, "mem_use": 35.06, "gen_rate": 5.8, "speed": 4.67, "text": "What we can learn from polar bea"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.3, "tree_w": 15, "tree_size": 64, "t0": 0.6471, "t1": 0.3557, "tft": 1.9288, "input_0": 142, "input_1": 65, "min_CLP": -4.98, "draft_iters": 9.3, "mem_use": 36.13, "gen_rate": 4.9, "speed": 4.85, "text": "Lemon wedges are small pieces of"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 15, "tree_size": 64, "t0": 0.6114, "t1": 0.3871, "tft": 1.0324, "input_0": 146, "input_1": 65, "min_CLP": -4.96, "draft_iters": 8.6, "mem_use": 34.15, "gen_rate": 5.0, "speed": 5.01, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 17, "tree_size": 64, "t0": 0.5983, "t1": 0.3867, "tft": 1.0964, "input_0": 139, "input_1": 65, "min_CLP": -4.94, "draft_iters": 8.5, "mem_use": 34.11, "gen_rate": 5.5, "speed": 5.58, "text": "\"I'm sorry to hear that. Life is"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 0.8575, "t1": 0.3825, "tft": 1.4599, "input_0": 196, "input_1": 65, "min_CLP": -4.55, "draft_iters": 12.2, "mem_use": 33.99, "gen_rate": 8.5, "speed": 6.87, "text": "To initialize a Typescript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.9, "tree_w": 14, "tree_size": 64, "t0": 0.69, "t1": 0.3662, "tft": 2.0342, "input_0": 178, "input_1": 65, "min_CLP": -4.79, "draft_iters": 9.9, "mem_use": 35.57, "gen_rate": 4.4, "speed": 4.14, "text": "Yes, there have been instances i"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 15, "tree_size": 64, "t0": 0.625, "t1": 0.3733, "tft": 1.6662, "input_0": 161, "input_1": 65, "min_CLP": -4.74, "draft_iters": 8.8, "mem_use": 35.09, "gen_rate": 5.8, "speed": 5.85, "text": "Freeman Dyson was a prolific sci"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.5, "tree_w": 18, "tree_size": 64, "t0": 0.535, "t1": 0.3713, "tft": 0.9162, "input_0": 147, "input_1": 65, "min_CLP": -4.92, "draft_iters": 7.5, "mem_use": 33.95, "gen_rate": 4.8, "speed": 5.24, "text": "\"Certainly! I can help you with "}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.6, "tree_w": 13, "tree_size": 64, "t0": 0.8671, "t1": 0.3814, "tft": 1.7605, "input_0": 157, "input_1": 65, "min_CLP": -4.71, "draft_iters": 12.6, "mem_use": 34.69, "gen_rate": 5.3, "speed": 4.24, "text": "\"You're welcome! I'm here to hel"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.9, "tree_w": 19, "tree_size": 64, "t0": 0.8843, "t1": 0.3957, "tft": 1.622, "input_0": 162, "input_1": 65, "min_CLP": -5.03, "draft_iters": 12.7, "mem_use": 35.29, "gen_rate": 4.7, "speed": 3.68, "text": "Of course, here are the full lyr"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 9.5, "tree_w": 15, "tree_size": 64, "t0": 0.7438, "t1": 0.3912, "tft": 1.1203, "input_0": 189, "input_1": 65, "min_CLP": -4.75, "draft_iters": 10.5, "mem_use": 34.31, "gen_rate": 4.8, "speed": 4.17, "text": "1.    Prioritizing self-care: Th"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 18, "tree_size": 64, "t0": 0.56, "t1": 0.3917, "tft": 0.988, "input_0": 142, "input_1": 65, "min_CLP": -5.04, "draft_iters": 7.8, "mem_use": 33.99, "gen_rate": 5.3, "speed": 5.59, "text": "def self_attention(input_sequenc"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.5, "tree_w": 14, "tree_size": 64, "t0": 0.665, "t1": 0.375, "tft": 1.298, "input_0": 162, "input_1": 65, "min_CLP": -4.66, "draft_iters": 9.5, "mem_use": 34.54, "gen_rate": 6.0, "speed": 5.75, "text": "It is not possible to make a com"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.1, "tree_w": 21, "tree_size": 64, "t0": 0.6357, "t1": 0.3671, "tft": 1.6861, "input_0": 137, "input_1": 65, "min_CLP": -5.59, "draft_iters": 9.1, "mem_use": 34.98, "gen_rate": 4.6, "speed": 4.55, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.1, "tree_w": 19, "tree_size": 64, "t0": 0.5737, "t1": 0.3587, "tft": 1.5232, "input_0": 159, "input_1": 65, "min_CLP": -5.02, "draft_iters": 8.1, "mem_use": 34.65, "gen_rate": 4.0, "speed": 4.27, "text": "The URL decoded string of `%21` "}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 5, "tree_size": 64, "t0": 2.14, "t1": 0.39, "tft": 3.8836, "input_0": 320, "input_1": 65, "min_CLP": -4.76, "draft_iters": 32.0, "mem_use": 36.77, "gen_rate": 33.0, "speed": 13.02, "text": "\"Yes, L'Hopital's rule is a math"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.5, "tree_w": 13, "tree_size": 64, "t0": 0.6483, "t1": 0.3533, "tft": 2.7966, "input_0": 165, "input_1": 65, "min_CLP": -4.79, "draft_iters": 9.5, "mem_use": 38.33, "gen_rate": 5.7, "speed": 5.65, "text": "I do not have personal preferenc"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 9.5, "tree_w": 15, "tree_size": 64, "t0": 0.7333, "t1": 0.3667, "tft": 1.6141, "input_0": 178, "input_1": 65, "min_CLP": -4.8, "draft_iters": 10.5, "mem_use": 35.35, "gen_rate": 6.5, "speed": 5.9, "text": "\"To beat Dave_, you'll need to c"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 22.5, "tree_w": 7, "tree_size": 64, "t0": 1.605, "t1": 0.385, "tft": 1.8053, "input_0": 239, "input_1": 65, "min_CLP": -4.35, "draft_iters": 23.5, "mem_use": 35.74, "gen_rate": 17.5, "speed": 8.8, "text": "Sure, here are the three most im"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 12, "tree_size": 64, "t0": 0.802, "t1": 0.372, "tft": 1.4739, "input_0": 189, "input_1": 65, "min_CLP": -4.98, "draft_iters": 11.4, "mem_use": 33.99, "gen_rate": 7.4, "speed": 6.31, "text": "Explain the difference between s"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.0, "tree_w": 16, "tree_size": 64, "t0": 1.21, "t1": 0.4, "tft": 2.3089, "input_0": 143, "input_1": 65, "min_CLP": -5.12, "draft_iters": 17.8, "mem_use": 35.31, "gen_rate": 8.0, "speed": 4.97, "text": "The answer would depend on the c"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 12, "tree_size": 64, "t0": 0.78, "t1": 0.3625, "tft": 0.96, "input_0": 166, "input_1": 65, "min_CLP": -4.67, "draft_iters": 11.2, "mem_use": 34.15, "gen_rate": 8.8, "speed": 7.64, "text": "\"Sure, I'd be happy to tell you "}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 13, "tree_size": 64, "t0": 0.8, "t1": 0.3975, "tft": 1.2277, "input_0": 161, "input_1": 65, "min_CLP": -4.8, "draft_iters": 11.5, "mem_use": 34.03, "gen_rate": 8.0, "speed": 6.67, "text": "No, it is not possible to cook a"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.1, "tree_w": 23, "tree_size": 64, "t0": 0.5043, "t1": 0.3586, "tft": 1.4773, "input_0": 138, "input_1": 65, "min_CLP": -5.46, "draft_iters": 7.1, "mem_use": 34.02, "gen_rate": 5.1, "speed": 5.96, "text": "The best way to farm experience "}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.0, "tree_w": 19, "tree_size": 64, "t0": 0.565, "t1": 0.3733, "tft": 1.1719, "input_0": 130, "input_1": 65, "min_CLP": -5.17, "draft_iters": 8.0, "mem_use": 33.97, "gen_rate": 5.8, "speed": 6.22, "text": "Freyja is a goddess of fertility"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 13, "tree_size": 64, "t0": 0.86, "t1": 0.4, "tft": 1.665, "input_0": 170, "input_1": 65, "min_CLP": -4.71, "draft_iters": 12.4, "mem_use": 35.24, "gen_rate": 6.8, "speed": 5.4, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.6, "tree_w": 10, "tree_size": 64, "t0": 1.024, "t1": 0.402, "tft": 1.4747, "input_0": 197, "input_1": 65, "min_CLP": -4.82, "draft_iters": 14.6, "mem_use": 34.37, "gen_rate": 7.0, "speed": 4.9, "text": "# Add Tailwind CSS to the projec"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.8, "tree_w": 16, "tree_size": 64, "t0": 0.742, "t1": 0.372, "tft": 3.3324, "input_0": 153, "input_1": 65, "min_CLP": -4.63, "draft_iters": 10.8, "mem_use": 39.41, "gen_rate": 7.8, "speed": 7.0, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.6, "tree_w": 17, "tree_size": 64, "t0": 0.6, "t1": 0.35, "tft": 1.1369, "input_0": 148, "input_1": 65, "min_CLP": -4.88, "draft_iters": 8.6, "mem_use": 34.5, "gen_rate": 7.0, "speed": 7.36, "text": "Large Language Models (LLMs) are"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 13.7, "tree_w": 24, "tree_size": 64, "t0": 0.99, "t1": 0.38, "tft": 1.0853, "input_0": 119, "input_1": 65, "min_CLP": -5.4, "draft_iters": 14.3, "mem_use": 34.06, "gen_rate": 13.7, "speed": 9.98, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.2, "tree_w": 15, "tree_size": 64, "t0": 0.8467, "t1": 0.3833, "tft": 1.1216, "input_0": 152, "input_1": 65, "min_CLP": -4.86, "draft_iters": 12.2, "mem_use": 34.28, "gen_rate": 5.3, "speed": 4.34, "text": "Here is a eulogy for your 100-ye"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.5, "tree_w": 11, "tree_size": 64, "t0": 0.935, "t1": 0.38, "tft": 1.7294, "input_0": 195, "input_1": 65, "min_CLP": -4.52, "draft_iters": 13.5, "mem_use": 35.74, "gen_rate": 9.8, "speed": 7.41, "text": "[INST] I hope this helps you get"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.3, "tree_w": 15, "tree_size": 64, "t0": 0.9233, "t1": 0.4017, "tft": 1.0315, "input_0": 168, "input_1": 65, "min_CLP": -4.9, "draft_iters": 13.2, "mem_use": 34.14, "gen_rate": 5.5, "speed": 4.15, "text": "\"Yes, I am an AI language model "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 5.5, "tree_w": 20, "tree_size": 64, "t0": 0.455, "t1": 0.375, "tft": 0.9011, "input_0": 106, "input_1": 65, "min_CLP": -5.33, "draft_iters": 6.5, "mem_use": 34.12, "gen_rate": 3.5, "speed": 4.23, "text": "None of the above answers are co"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 30, "tree_h": 8.4, "tree_w": 17, "tree_size": 64, "t0": 0.666, "t1": 0.372, "tft": 1.0114, "input_0": 173, "input_1": 65, "min_CLP": -5.03, "draft_iters": 9.4, "mem_use": 33.95, "gen_rate": 6.0, "speed": 5.79, "text": "The color of Mars is typically d"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.6, "tree_w": 24, "tree_size": 64, "t0": 0.5257, "t1": 0.3671, "tft": 2.5343, "input_0": 111, "input_1": 65, "min_CLP": -5.74, "draft_iters": 7.6, "mem_use": 36.2, "gen_rate": 4.7, "speed": 5.29, "text": "In Quenya, \"I love you\" can be e"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 2.15, "t1": 0.46, "tft": 1.4874, "input_0": 194, "input_1": 65, "min_CLP": -4.6, "draft_iters": 32.0, "mem_use": 34.04, "gen_rate": 33.0, "speed": 12.66, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 15, "tree_size": 64, "t0": 0.6083, "t1": 0.395, "tft": 2.0172, "input_0": 133, "input_1": 65, "min_CLP": -4.84, "draft_iters": 8.7, "mem_use": 34.58, "gen_rate": 5.7, "speed": 5.65, "text": "Yes. The Second Amendment protec"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.5, "tree_w": 9, "tree_size": 64, "t0": 1.01, "t1": 0.3975, "tft": 1.6093, "input_0": 159, "input_1": 65, "min_CLP": -4.47, "draft_iters": 14.5, "mem_use": 34.04, "gen_rate": 8.0, "speed": 5.68, "text": "Yes, there is a formula to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.8, "tree_w": 20, "tree_size": 64, "t0": 0.5533, "t1": 0.3817, "tft": 1.2979, "input_0": 149, "input_1": 65, "min_CLP": -4.78, "draft_iters": 7.8, "mem_use": 34.47, "gen_rate": 6.2, "speed": 6.6, "text": "\"I'm happy to help! As a babysit"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 16.8, "tree_w": 12, "tree_size": 64, "t0": 1.225, "t1": 0.43, "tft": 1.1127, "input_0": 164, "input_1": 65, "min_CLP": -4.73, "draft_iters": 17.8, "mem_use": 34.15, "gen_rate": 10.8, "speed": 6.5, "text": "The capital of Australia before "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 64, "t0": 2.14, "t1": 0.46, "tft": 1.2263, "input_0": 173, "input_1": 65, "min_CLP": -4.42, "draft_iters": 32.0, "mem_use": 34.33, "gen_rate": 33.0, "speed": 12.71, "text": "[INST] write a eulogy for my 100"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 9.6, "tree_w": 14, "tree_size": 64, "t0": 0.7375, "t1": 0.3775, "tft": 2.7125, "input_0": 156, "input_1": 65, "min_CLP": -4.84, "draft_iters": 10.6, "mem_use": 36.55, "gen_rate": 5.0, "speed": 4.49, "text": "I can provide a general outline "}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 18, "tree_size": 64, "t0": 0.6257, "t1": 0.3843, "tft": 0.8903, "input_0": 128, "input_1": 65, "min_CLP": -5.03, "draft_iters": 8.9, "mem_use": 34.15, "gen_rate": 4.7, "speed": 4.68, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.4, "tree_w": 15, "tree_size": 64, "t0": 0.726, "t1": 0.364, "tft": 1.5099, "input_0": 182, "input_1": 65, "min_CLP": -4.63, "draft_iters": 10.4, "mem_use": 35.43, "gen_rate": 7.0, "speed": 6.42, "text": "\"Yes, let's take the vector A = "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.8, "tree_w": 13, "tree_size": 64, "t0": 0.7567, "t1": 0.37, "tft": 1.4991, "input_0": 159, "input_1": 65, "min_CLP": -4.74, "draft_iters": 10.8, "mem_use": 34.01, "gen_rate": 5.5, "speed": 4.88, "text": "Sure, here are some possible iss"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.0, "tree_w": 17, "tree_size": 64, "t0": 0.5643, "t1": 0.3557, "tft": 0.8772, "input_0": 135, "input_1": 65, "min_CLP": -5.07, "draft_iters": 8.0, "mem_use": 34.07, "gen_rate": 5.0, "speed": 5.44, "text": "The sun has set over the horizon"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.6, "tree_w": 14, "tree_size": 64, "t0": 0.7471, "t1": 0.3857, "tft": 1.0009, "input_0": 193, "input_1": 65, "min_CLP": -4.67, "draft_iters": 10.6, "mem_use": 34.01, "gen_rate": 5.1, "speed": 4.54, "text": "\"Certainly! L'Hopital's Rule is "}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 22.3, "tree_w": 10, "tree_size": 64, "t0": 1.57, "t1": 0.4267, "tft": 1.8225, "input_0": 183, "input_1": 65, "min_CLP": -4.81, "draft_iters": 23.0, "mem_use": 34.58, "gen_rate": 17.7, "speed": 8.86, "text": "Variance is the sum of squared d"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 24, "tree_h": 6.2, "tree_w": 22, "tree_size": 64, "t0": 0.5087, "t1": 0.3662, "tft": 1.4375, "input_0": 104, "input_1": 65, "min_CLP": -5.13, "draft_iters": 7.2, "mem_use": 34.87, "gen_rate": 3.0, "speed": 3.42, "text": "\"Riding towards a brighter tomor"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.8, "tree_w": 22, "tree_size": 64, "t0": 0.5438, "t1": 0.365, "tft": 1.6008, "input_0": 126, "input_1": 65, "min_CLP": -5.19, "draft_iters": 7.8, "mem_use": 34.66, "gen_rate": 4.1, "speed": 4.54, "text": "The best place to see a starry s"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.8, "tree_w": 16, "tree_size": 64, "t0": 0.6222, "t1": 0.3756, "tft": 0.9281, "input_0": 148, "input_1": 65, "min_CLP": -5.05, "draft_iters": 8.8, "mem_use": 34.01, "gen_rate": 3.7, "speed": 3.67, "text": "\"Sure, here's a light-hearted to"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.2, "tree_w": 18, "tree_size": 64, "t0": 0.5763, "t1": 0.3613, "tft": 2.0579, "input_0": 132, "input_1": 65, "min_CLP": -4.93, "draft_iters": 8.2, "mem_use": 34.56, "gen_rate": 4.1, "speed": 4.4, "text": "I apologize for the confusion. I"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.1, "tree_w": 18, "tree_size": 64, "t0": 0.5763, "t1": 0.3712, "tft": 1.4124, "input_0": 147, "input_1": 65, "min_CLP": -4.99, "draft_iters": 8.1, "mem_use": 34.43, "gen_rate": 4.1, "speed": 4.35, "text": "To cope with stress from financi"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 38, "tree_h": 9.1, "tree_w": 14, "tree_size": 64, "t0": 0.695, "t1": 0.366, "tft": 2.5672, "input_0": 154, "input_1": 65, "min_CLP": -4.79, "draft_iters": 10.1, "mem_use": 37.51, "gen_rate": 3.8, "speed": 3.58, "text": "Sure, here are some tools you ca"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.0, "tree_w": 12, "tree_size": 64, "t0": 0.834, "t1": 0.376, "tft": 2.3277, "input_0": 179, "input_1": 65, "min_CLP": -4.5, "draft_iters": 12.0, "mem_use": 36.2, "gen_rate": 7.2, "speed": 5.96, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 16, "tree_h": 6.4, "tree_w": 19, "tree_size": 64, "t0": 0.528, "t1": 0.366, "tft": 0.9816, "input_0": 140, "input_1": 65, "min_CLP": -5.04, "draft_iters": 7.4, "mem_use": 33.97, "gen_rate": 3.2, "speed": 3.58, "text": "Based on my current knowledge, t"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 22, "tree_size": 64, "t0": 0.7183, "t1": 0.3983, "tft": 1.0386, "input_0": 164, "input_1": 65, "min_CLP": -5.5, "draft_iters": 10.2, "mem_use": 34.21, "gen_rate": 5.3, "speed": 4.78, "text": "Here is a list of five words whe"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.3, "tree_w": 15, "tree_size": 64, "t0": 0.645, "t1": 0.3767, "tft": 4.4898, "input_0": 157, "input_1": 65, "min_CLP": -4.75, "draft_iters": 9.3, "mem_use": 41.0, "gen_rate": 6.0, "speed": 5.88, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.6, "tree_w": 12, "tree_size": 64, "t0": 0.804, "t1": 0.376, "tft": 1.8721, "input_0": 164, "input_1": 65, "min_CLP": -4.75, "draft_iters": 11.6, "mem_use": 34.39, "gen_rate": 7.6, "speed": 6.45, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 17.0, "tree_w": 16, "tree_size": 64, "t0": 1.2367, "t1": 0.4233, "tft": 0.8996, "input_0": 164, "input_1": 65, "min_CLP": -5.69, "draft_iters": 18.0, "mem_use": 34.09, "gen_rate": 18.0, "speed": 10.85, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.4, "tree_w": 16, "tree_size": 64, "t0": 0.6643, "t1": 0.37, "tft": 0.9097, "input_0": 160, "input_1": 65, "min_CLP": -4.99, "draft_iters": 9.4, "mem_use": 34.09, "gen_rate": 4.7, "speed": 4.56, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.6, "tree_w": 20, "tree_size": 64, "t0": 0.5337, "t1": 0.35, "tft": 1.977, "input_0": 157, "input_1": 65, "min_CLP": -5.07, "draft_iters": 7.6, "mem_use": 36.63, "gen_rate": 4.4, "speed": 4.94, "text": "\"I appreciate your skepticism an"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 11.2, "tree_w": 12, "tree_size": 64, "t0": 0.8575, "t1": 0.3725, "tft": 1.6224, "input_0": 199, "input_1": 65, "min_CLP": -4.32, "draft_iters": 12.2, "mem_use": 34.51, "gen_rate": 10.5, "speed": 8.53, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 8.1, "tree_w": 20, "tree_size": 64, "t0": 0.6333, "t1": 0.3889, "tft": 1.5344, "input_0": 118, "input_1": 65, "min_CLP": -5.04, "draft_iters": 9.1, "mem_use": 34.7, "gen_rate": 3.6, "speed": 3.48, "text": "I know, I was just trying to tes"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.0, "tree_w": 12, "tree_size": 64, "t0": 1.475, "t1": 0.43, "tft": 1.1842, "input_0": 187, "input_1": 65, "min_CLP": -4.84, "draft_iters": 21.5, "mem_use": 34.3, "gen_rate": 19.5, "speed": 10.23, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 32, "tree_h": 6.0, "tree_w": 26, "tree_size": 64, "t0": 0.4923, "t1": 0.3777, "tft": 2.867, "input_0": 113, "input_1": 65, "min_CLP": -5.69, "draft_iters": 7.0, "mem_use": 34.54, "gen_rate": 2.5, "speed": 2.82, "text": "Attention bias shines,\\nIn neura"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.0, "tree_w": 16, "tree_size": 64, "t0": 0.704, "t1": 0.4, "tft": 1.2706, "input_0": 185, "input_1": 65, "min_CLP": -5.06, "draft_iters": 10.0, "mem_use": 34.33, "gen_rate": 7.2, "speed": 6.51, "text": "\"In the Schr\u00f6dinger's cat though"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 15, "tree_h": 6.2, "tree_w": 24, "tree_size": 64, "t0": 0.498, "t1": 0.362, "tft": 2.0641, "input_0": 110, "input_1": 65, "min_CLP": -5.13, "draft_iters": 7.2, "mem_use": 36.32, "gen_rate": 3.0, "speed": 3.49, "text": "[INST] Thanks for the advice! An"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.0, "tree_w": 12, "tree_size": 64, "t0": 0.8425, "t1": 0.4, "tft": 1.432, "input_0": 170, "input_1": 65, "min_CLP": -4.66, "draft_iters": 12.0, "mem_use": 34.09, "gen_rate": 9.8, "speed": 7.85, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 0.695, "t1": 0.395, "tft": 0.9605, "input_0": 153, "input_1": 65, "min_CLP": -4.92, "draft_iters": 10.0, "mem_use": 34.11, "gen_rate": 5.5, "speed": 5.04, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfEn"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.9, "tree_w": 18, "tree_size": 64, "t0": 0.49, "t1": 0.391, "tft": 1.3537, "input_0": 114, "input_1": 65, "min_CLP": -5.11, "draft_iters": 6.9, "mem_use": 34.08, "gen_rate": 3.3, "speed": 3.74, "text": "F-centers are defects in the cry"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 17, "tree_size": 64, "t0": 0.885, "t1": 0.3775, "tft": 3.8326, "input_0": 195, "input_1": 65, "min_CLP": -4.65, "draft_iters": 13.0, "mem_use": 38.62, "gen_rate": 8.5, "speed": 6.74, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.3, "tree_w": 17, "tree_size": 64, "t0": 0.6529, "t1": 0.3743, "tft": 1.6487, "input_0": 169, "input_1": 65, "min_CLP": -4.81, "draft_iters": 9.3, "mem_use": 35.71, "gen_rate": 5.6, "speed": 5.42, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.8, "tree_w": 16, "tree_size": 64, "t0": 0.62, "t1": 0.3875, "tft": 1.2107, "input_0": 151, "input_1": 65, "min_CLP": -5.15, "draft_iters": 8.8, "mem_use": 34.51, "gen_rate": 4.2, "speed": 4.21, "text": "Pros:\\n1. Efficiency: AI assista"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 17, "tree_size": 64, "t0": 0.676, "t1": 0.358, "tft": 2.3943, "input_0": 161, "input_1": 65, "min_CLP": -4.85, "draft_iters": 9.8, "mem_use": 36.42, "gen_rate": 6.4, "speed": 6.19, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 17, "tree_size": 64, "t0": 0.6833, "t1": 0.37, "tft": 2.0611, "input_0": 167, "input_1": 65, "min_CLP": -5.31, "draft_iters": 9.8, "mem_use": 36.38, "gen_rate": 5.7, "speed": 5.38, "text": "Das Aussto\u00df von Zement in Deutsc"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 6.5, "tree_w": 23, "tree_size": 64, "t0": 0.52, "t1": 0.365, "tft": 1.7448, "input_0": 110, "input_1": 65, "min_CLP": -4.88, "draft_iters": 7.5, "mem_use": 35.72, "gen_rate": 3.5, "speed": 3.95, "text": "\"I'm sorry, I cannot provide any"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.0, "tree_w": 22, "tree_size": 64, "t0": 0.496, "t1": 0.395, "tft": 1.5489, "input_0": 119, "input_1": 65, "min_CLP": -5.05, "draft_iters": 7.0, "mem_use": 34.76, "gen_rate": 3.3, "speed": 3.71, "text": "The best way to contact the orig"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.3, "tree_w": 23, "tree_size": 64, "t0": 0.5829, "t1": 0.3986, "tft": 1.1791, "input_0": 109, "input_1": 65, "min_CLP": -5.4, "draft_iters": 8.3, "mem_use": 34.34, "gen_rate": 5.6, "speed": 5.69, "text": "\u9019\u7bc7\u8ad6\u6587\u662f self attention \u7684\u958b\u5c71\u4e4b\u4f5c\uff0c\u8a73\u7d30\u4ecb\u7d39\u4e86"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.7, "tree_w": 7, "tree_size": 64, "t0": 1.31, "t1": 0.41, "tft": 1.1633, "input_0": 240, "input_1": 65, "min_CLP": -4.01, "draft_iters": 18.7, "mem_use": 34.15, "gen_rate": 13.3, "speed": 7.76, "text": "```javascript\\nfunction checkPri"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 15.0, "tree_w": 13, "tree_size": 64, "t0": 1.1157, "t1": 0.4286, "tft": 2.053, "input_0": 173, "input_1": 65, "min_CLP": -4.59, "draft_iters": 16.0, "mem_use": 35.42, "gen_rate": 5.1, "speed": 3.33, "text": "In the state of Wyoming, public "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.4, "tree_w": 14, "tree_size": 64, "t0": 0.664, "t1": 0.384, "tft": 1.1793, "input_0": 154, "input_1": 65, "min_CLP": -4.97, "draft_iters": 9.4, "mem_use": 34.54, "gen_rate": 6.4, "speed": 6.12, "text": "There are several ways you could"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 17, "tree_size": 64, "t0": 0.7083, "t1": 0.3933, "tft": 1.9262, "input_0": 154, "input_1": 65, "min_CLP": -5.06, "draft_iters": 10.2, "mem_use": 35.42, "gen_rate": 5.3, "speed": 4.84, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.5, "tree_w": 9, "tree_size": 64, "t0": 1.2825, "t1": 0.4225, "tft": 1.6924, "input_0": 218, "input_1": 65, "min_CLP": -4.44, "draft_iters": 18.5, "mem_use": 34.8, "gen_rate": 8.0, "speed": 4.7, "text": "\"If you live in a European count"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.7, "tree_w": 21, "tree_size": 64, "t0": 0.5467, "t1": 0.4089, "tft": 2.1212, "input_0": 129, "input_1": 65, "min_CLP": -5.47, "draft_iters": 7.7, "mem_use": 34.07, "gen_rate": 3.7, "speed": 3.83, "text": "Here are some nicknames you can "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 10.2, "tree_w": 15, "tree_size": 64, "t0": 0.788, "t1": 0.402, "tft": 2.2014, "input_0": 192, "input_1": 65, "min_CLP": -4.93, "draft_iters": 11.2, "mem_use": 34.48, "gen_rate": 8.2, "speed": 6.88, "text": "The Balfour Declaration is signi"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 23.0, "tree_w": 8, "tree_size": 64, "t0": 1.645, "t1": 0.405, "tft": 2.3295, "input_0": 281, "input_1": 65, "min_CLP": -4.21, "draft_iters": 24.0, "mem_use": 35.23, "gen_rate": 16.0, "speed": 7.8, "text": "\"Canciones felices:\\n\\n1. \u00ab(I Ca"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.2, "tree_w": 13, "tree_size": 64, "t0": 0.8617, "t1": 0.42, "tft": 0.966, "input_0": 176, "input_1": 65, "min_CLP": -4.61, "draft_iters": 12.2, "mem_use": 34.17, "gen_rate": 6.0, "speed": 4.68, "text": "\"Answer: I'm sorry, but I am an "}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 60, "tree_h": 16.4, "tree_w": 14, "tree_size": 64, "t0": 1.2071, "t1": 0.4071, "tft": 2.1928, "input_0": 167, "input_1": 65, "min_CLP": -4.71, "draft_iters": 17.3, "mem_use": 34.56, "gen_rate": 8.6, "speed": 5.31, "text": "[INST] You are correct. Thank yo"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.1, "tree_w": 18, "tree_size": 64, "t0": 0.5667, "t1": 0.3789, "tft": 1.7105, "input_0": 115, "input_1": 65, "min_CLP": -5.18, "draft_iters": 8.1, "mem_use": 34.93, "gen_rate": 3.7, "speed": 3.87, "text": "How about this one: \"A heart\\'s "}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.5, "tree_w": 12, "tree_size": 64, "t0": 0.87, "t1": 0.3933, "tft": 2.2552, "input_0": 188, "input_1": 65, "min_CLP": -4.44, "draft_iters": 12.5, "mem_use": 35.69, "gen_rate": 6.8, "speed": 5.41, "text": "\"Sure, here's a step-by-step gui"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.4, "tree_w": 19, "tree_size": 64, "t0": 0.67, "t1": 0.4, "tft": 1.2972, "input_0": 161, "input_1": 65, "min_CLP": -4.81, "draft_iters": 9.4, "mem_use": 34.18, "gen_rate": 6.4, "speed": 5.99, "text": "Frank-Walter Steinmeier is a Ger"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 9.0, "tree_w": 15, "tree_size": 64, "t0": 0.69, "t1": 0.395, "tft": 0.9694, "input_0": 126, "input_1": 65, "min_CLP": -5.11, "draft_iters": 10.0, "mem_use": 34.1, "gen_rate": 5.5, "speed": 5.08, "text": "Yes, the cross-section of air is"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.6, "tree_w": 13, "tree_size": 64, "t0": 0.7871, "t1": 0.37, "tft": 3.0345, "input_0": 157, "input_1": 65, "min_CLP": -4.7, "draft_iters": 11.6, "mem_use": 38.21, "gen_rate": 4.7, "speed": 4.07, "text": "1. Discovery\\n\\t* Find a market "}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 17, "tree_size": 64, "t0": 0.6114, "t1": 0.4043, "tft": 1.2481, "input_0": 147, "input_1": 65, "min_CLP": -4.87, "draft_iters": 8.6, "mem_use": 34.0, "gen_rate": 5.0, "speed": 4.92, "text": "The many-worlds interpretation o"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 20.0, "tree_w": 13, "tree_size": 64, "t0": 1.4, "t1": 0.415, "tft": 1.0467, "input_0": 168, "input_1": 65, "min_CLP": -5.11, "draft_iters": 20.5, "mem_use": 33.96, "gen_rate": 19.5, "speed": 10.75, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.9, "tree_w": 17, "tree_size": 64, "t0": 0.6114, "t1": 0.3657, "tft": 3.0397, "input_0": 157, "input_1": 65, "min_CLP": -4.85, "draft_iters": 8.9, "mem_use": 38.2, "gen_rate": 5.6, "speed": 5.69, "text": "\"Hey! How can I assist you today"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.1, "tree_w": 15, "tree_size": 64, "t0": 0.7029, "t1": 0.3671, "tft": 1.983, "input_0": 154, "input_1": 65, "min_CLP": -4.76, "draft_iters": 10.1, "mem_use": 36.05, "gen_rate": 4.9, "speed": 4.54, "text": "\u2022 Set reminders. Set reminders o"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.8, "tree_w": 14, "tree_size": 64, "t0": 0.8317, "t1": 0.405, "tft": 1.4085, "input_0": 180, "input_1": 65, "min_CLP": -4.75, "draft_iters": 11.8, "mem_use": 35.27, "gen_rate": 5.5, "speed": 4.45, "text": "\"In the context of Into the Brea"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.3, "tree_w": 15, "tree_size": 64, "t0": 0.8033, "t1": 0.4217, "tft": 1.0933, "input_0": 163, "input_1": 65, "min_CLP": -4.73, "draft_iters": 11.3, "mem_use": 34.15, "gen_rate": 5.7, "speed": 4.63, "text": "The Battle of Gettysburg began o"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 13, "tree_size": 64, "t0": 0.82, "t1": 0.44, "tft": 1.3058, "input_0": 189, "input_1": 65, "min_CLP": -4.49, "draft_iters": 11.5, "mem_use": 34.17, "gen_rate": 8.2, "speed": 6.53, "text": "In the context of a turn-based s"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 14, "tree_size": 64, "t0": 0.7467, "t1": 0.3817, "tft": 1.5772, "input_0": 166, "input_1": 65, "min_CLP": -4.67, "draft_iters": 10.7, "mem_use": 34.98, "gen_rate": 5.7, "speed": 5.03, "text": "\"[ANSWER]: I'm sorry, but as a t"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 18.0, "tree_w": 9, "tree_size": 64, "t0": 1.318, "t1": 0.428, "tft": 1.9204, "input_0": 206, "input_1": 65, "min_CLP": -4.3, "draft_iters": 19.0, "mem_use": 35.51, "gen_rate": 8.8, "speed": 5.04, "text": "Here is a simpler script that do"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.0, "tree_w": 17, "tree_size": 64, "t0": 0.83, "t1": 0.3725, "tft": 1.2203, "input_0": 157, "input_1": 65, "min_CLP": -5.29, "draft_iters": 12.0, "mem_use": 34.94, "gen_rate": 9.5, "speed": 7.91, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 5.9, "tree_w": 23, "tree_size": 64, "t0": 0.49, "t1": 0.3873, "tft": 1.4297, "input_0": 109, "input_1": 65, "min_CLP": -5.15, "draft_iters": 6.9, "mem_use": 35.04, "gen_rate": 3.1, "speed": 3.52, "text": "\"In your eyes, I see the world a"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.8, "tree_w": 17, "tree_size": 64, "t0": 0.6837, "t1": 0.38, "tft": 1.5505, "input_0": 150, "input_1": 65, "min_CLP": -4.9, "draft_iters": 9.8, "mem_use": 34.44, "gen_rate": 4.1, "speed": 3.87, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 10.1, "tree_w": 13, "tree_size": 64, "t0": 0.7843, "t1": 0.3929, "tft": 2.0415, "input_0": 162, "input_1": 65, "min_CLP": -4.74, "draft_iters": 11.1, "mem_use": 34.41, "gen_rate": 5.6, "speed": 4.72, "text": "Tenants may not be considered su"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 17, "tree_size": 64, "t0": 0.5986, "t1": 0.3771, "tft": 1.6736, "input_0": 136, "input_1": 65, "min_CLP": -4.77, "draft_iters": 8.6, "mem_use": 35.72, "gen_rate": 5.0, "speed": 5.12, "text": "\"You're welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.6, "tree_w": 17, "tree_size": 64, "t0": 0.6714, "t1": 0.3814, "tft": 1.9884, "input_0": 157, "input_1": 65, "min_CLP": -4.77, "draft_iters": 9.6, "mem_use": 35.65, "gen_rate": 5.1, "speed": 4.88, "text": "Yes, Open Assistant is a pretrai"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 27, "tree_h": 10.8, "tree_w": 12, "tree_size": 64, "t0": 0.8125, "t1": 0.36, "tft": 3.1437, "input_0": 183, "input_1": 65, "min_CLP": -4.65, "draft_iters": 11.8, "mem_use": 37.1, "gen_rate": 6.8, "speed": 5.76, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 22.5, "tree_w": 12, "tree_size": 64, "t0": 1.57, "t1": 0.405, "tft": 0.981, "input_0": 193, "input_1": 65, "min_CLP": -5.05, "draft_iters": 23.0, "mem_use": 33.96, "gen_rate": 19.5, "speed": 9.87, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 5.0, "tree_w": 25, "tree_size": 64, "t0": 0.4227, "t1": 0.3527, "tft": 1.5235, "input_0": 106, "input_1": 65, "min_CLP": -5.36, "draft_iters": 6.0, "mem_use": 34.88, "gen_rate": 3.0, "speed": 3.87, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.0, "tree_w": 15, "tree_size": 64, "t0": 0.7617, "t1": 0.3683, "tft": 2.0749, "input_0": 157, "input_1": 65, "min_CLP": -5.1, "draft_iters": 11.0, "mem_use": 36.76, "gen_rate": 6.3, "speed": 5.62, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 9.6, "tree_w": 14, "tree_size": 64, "t0": 0.7343, "t1": 0.3871, "tft": 1.3465, "input_0": 141, "input_1": 65, "min_CLP": -5.16, "draft_iters": 10.6, "mem_use": 34.47, "gen_rate": 5.3, "speed": 4.71, "text": "- Introduction to the topic of s"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 64, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.6, "tree_w": 18, "tree_size": 64, "t0": 0.67, "t1": 0.4014, "tft": 2.4825, "input_0": 165, "input_1": 65, "min_CLP": -5.01, "draft_iters": 9.6, "mem_use": 35.32, "gen_rate": 4.6, "speed": 4.25, "text": "Sure, I apologize for the confus"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 64, "max_branch_width": 32, "gen_rate": 7.59, "gen_rate_micro": 5.97, "gen_speed": 5.755, "gen_speed_micro": 5.33, "t0": 0.839, "t1": 0.3871, "input_0": 159.2, "input_1": 65.0, "tree_size": 64.0, "tree_w": 15.6, "tree_h": 11.1, "prompt_len": 298.0, "min_CLP": -4.91, "mem_use": 43.37, "exp_time": 4493.11}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 43, "tree_size": 128, "t0": 0.5714, "t1": 0.6557, "tft": 1.2257, "input_0": 240, "input_1": 129, "min_CLP": -5.95, "draft_iters": 7.9, "mem_use": 34.34, "gen_rate": 4.9, "speed": 3.95, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 14.8, "tree_w": 19, "tree_size": 128, "t0": 1.11, "t1": 0.68, "tft": 2.0025, "input_0": 357, "input_1": 129, "min_CLP": -5.44, "draft_iters": 15.8, "mem_use": 35.87, "gen_rate": 9.5, "speed": 5.31, "text": "\"You're correct, I apologize for"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.8, "tree_w": 29, "tree_size": 128, "t0": 0.8483, "t1": 0.6683, "tft": 2.3149, "input_0": 329, "input_1": 129, "min_CLP": -5.7, "draft_iters": 11.8, "mem_use": 36.77, "gen_rate": 5.3, "speed": 3.51, "text": "Sure, here are some general reco"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.2, "tree_w": 20, "tree_size": 128, "t0": 1.135, "t1": 0.685, "tft": 1.5317, "input_0": 483, "input_1": 129, "min_CLP": -5.22, "draft_iters": 15.2, "mem_use": 34.51, "gen_rate": 9.8, "speed": 5.35, "text": "\"Certainly! Here's a Python scri"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.7, "tree_w": 33, "tree_size": 128, "t0": 0.7157, "t1": 0.6686, "tft": 1.5407, "input_0": 284, "input_1": 129, "min_CLP": -5.56, "draft_iters": 9.7, "mem_use": 34.36, "gen_rate": 4.7, "speed": 3.41, "text": "\"Hi! I'd be happy to help you wr"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.5, "tree_w": 19, "tree_size": 128, "t0": 1.1075, "t1": 0.675, "tft": 3.4125, "input_0": 435, "input_1": 129, "min_CLP": -5.35, "draft_iters": 15.5, "mem_use": 36.9, "gen_rate": 9.2, "speed": 5.19, "text": "Sure, here\\'s a bullet list of p"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.3, "tree_w": 22, "tree_size": 128, "t0": 1.17, "t1": 0.6767, "tft": 3.0691, "input_0": 511, "input_1": 129, "min_CLP": -5.55, "draft_iters": 16.3, "mem_use": 37.5, "gen_rate": 10.7, "speed": 5.77, "text": "Other options to enhance images "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 23, "tree_size": 128, "t0": 1.09, "t1": 0.68, "tft": 3.2635, "input_0": 443, "input_1": 129, "min_CLP": -5.35, "draft_iters": 15.3, "mem_use": 39.64, "gen_rate": 11.7, "speed": 6.6, "text": "To attract the right customers f"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 18.0, "tree_w": 22, "tree_size": 128, "t0": 1.314, "t1": 0.69, "tft": 2.4727, "input_0": 344, "input_1": 129, "min_CLP": -5.37, "draft_iters": 19.0, "mem_use": 37.09, "gen_rate": 6.4, "speed": 3.19, "text": "Sure, here is a summary of the l"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.3, "tree_w": 25, "tree_size": 128, "t0": 0.8217, "t1": 0.67, "tft": 2.4234, "input_0": 326, "input_1": 129, "min_CLP": -5.32, "draft_iters": 11.3, "mem_use": 36.48, "gen_rate": 5.5, "speed": 3.69, "text": "There are many beginner-friendly"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 14, "tree_size": 128, "t0": 2.22, "t1": 0.73, "tft": 2.2532, "input_0": 658, "input_1": 129, "min_CLP": -6.05, "draft_iters": 32.0, "mem_use": 35.0, "gen_rate": 33.0, "speed": 11.19, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.2, "tree_w": 20, "tree_size": 128, "t0": 1.1575, "t1": 0.68, "tft": 3.2053, "input_0": 414, "input_1": 129, "min_CLP": -5.32, "draft_iters": 16.2, "mem_use": 36.84, "gen_rate": 8.2, "speed": 4.49, "text": "Sure, here\\'s a shorter version:"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 17.8, "tree_w": 17, "tree_size": 128, "t0": 1.3275, "t1": 0.695, "tft": 2.0977, "input_0": 430, "input_1": 129, "min_CLP": -5.04, "draft_iters": 18.8, "mem_use": 36.09, "gen_rate": 10.2, "speed": 5.07, "text": "\"Sure! Here's an example of a Py"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 22.5, "tree_w": 30, "tree_size": 128, "t0": 1.585, "t1": 0.705, "tft": 1.393, "input_0": 320, "input_1": 129, "min_CLP": -6.32, "draft_iters": 23.0, "mem_use": 34.34, "gen_rate": 20.5, "speed": 8.96, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.8, "tree_w": 27, "tree_size": 128, "t0": 0.8517, "t1": 0.6717, "tft": 2.8151, "input_0": 332, "input_1": 129, "min_CLP": -5.48, "draft_iters": 11.8, "mem_use": 37.48, "gen_rate": 5.8, "speed": 3.83, "text": "\"While it's true that spaced rep"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 26, "tree_size": 128, "t0": 1.01, "t1": 0.6833, "tft": 2.5636, "input_0": 331, "input_1": 129, "min_CLP": -5.55, "draft_iters": 14.0, "mem_use": 34.67, "gen_rate": 10.7, "speed": 6.3, "text": "\"The minimum upload speed requir"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 13.7, "tree_w": 23, "tree_size": 128, "t0": 1.0433, "t1": 0.6867, "tft": 2.0115, "input_0": 321, "input_1": 129, "min_CLP": -5.42, "draft_iters": 14.7, "mem_use": 34.36, "gen_rate": 11.0, "speed": 6.36, "text": "\"Fermat's Last Theorem is a math"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 20.0, "tree_w": 35, "tree_size": 128, "t0": 1.41, "t1": 0.705, "tft": 1.6027, "input_0": 308, "input_1": 129, "min_CLP": -6.04, "draft_iters": 20.5, "mem_use": 34.33, "gen_rate": 18.0, "speed": 8.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 59, "tree_h": 17.2, "tree_w": 21, "tree_size": 128, "t0": 1.26, "t1": 0.7, "tft": 1.9161, "input_0": 346, "input_1": 129, "min_CLP": -5.49, "draft_iters": 18.0, "mem_use": 34.86, "gen_rate": 14.8, "speed": 7.54, "text": "D-theanine is the less common fo"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 33, "tree_size": 128, "t0": 0.792, "t1": 0.678, "tft": 2.0157, "input_0": 290, "input_1": 129, "min_CLP": -5.67, "draft_iters": 10.8, "mem_use": 34.34, "gen_rate": 6.4, "speed": 4.37, "text": "The Balfour Declaration is a sta"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 13, "tree_h": 9.7, "tree_w": 37, "tree_size": 128, "t0": 0.7733, "t1": 0.6833, "tft": 2.97, "input_0": 277, "input_1": 129, "min_CLP": -6.07, "draft_iters": 10.7, "mem_use": 35.18, "gen_rate": 4.3, "speed": 2.98, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 7.0, "tree_w": 35, "tree_size": 128, "t0": 0.57, "t1": 0.64, "tft": 0.9926, "input_0": 213, "input_1": 129, "min_CLP": -5.6, "draft_iters": 8.0, "mem_use": 34.34, "gen_rate": 7.0, "speed": 5.81, "text": "Hello there! How can I assist yo"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.7, "tree_w": 27, "tree_size": 128, "t0": 0.765, "t1": 0.6583, "tft": 2.5751, "input_0": 329, "input_1": 129, "min_CLP": -5.48, "draft_iters": 10.7, "mem_use": 36.69, "gen_rate": 5.7, "speed": 3.99, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 27, "tree_size": 128, "t0": 0.902, "t1": 0.674, "tft": 1.3186, "input_0": 327, "input_1": 129, "min_CLP": -5.4, "draft_iters": 12.4, "mem_use": 34.41, "gen_rate": 6.4, "speed": 4.06, "text": "Certainly! Here\u2019s a step-by-step"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 10.0, "tree_w": 27, "tree_size": 128, "t0": 0.795, "t1": 0.675, "tft": 1.7431, "input_0": 325, "input_1": 129, "min_CLP": -5.78, "draft_iters": 11.0, "mem_use": 35.37, "gen_rate": 5.0, "speed": 3.4, "text": "\"[ADDITIONAL_INFORMATION_NEEDED]"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 19.5, "tree_w": 24, "tree_size": 128, "t0": 1.405, "t1": 0.7, "tft": 1.4774, "input_0": 400, "input_1": 129, "min_CLP": -6.6, "draft_iters": 20.0, "mem_use": 34.38, "gen_rate": 20.5, "speed": 9.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.1, "tree_w": 33, "tree_size": 128, "t0": 0.6643, "t1": 0.6714, "tft": 1.7858, "input_0": 266, "input_1": 129, "min_CLP": -5.78, "draft_iters": 9.1, "mem_use": 35.04, "gen_rate": 4.6, "speed": 3.41, "text": "Austenite is a solid solution of"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 26, "tree_h": 15.3, "tree_w": 23, "tree_size": 128, "t0": 1.16, "t1": 0.69, "tft": 2.313, "input_0": 355, "input_1": 129, "min_CLP": -5.28, "draft_iters": 16.3, "mem_use": 34.9, "gen_rate": 8.7, "speed": 4.68, "text": "\"You're welcome! It was my pleas"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 2.18, "t1": 0.68, "tft": 3.8501, "input_0": 382, "input_1": 129, "min_CLP": -5.63, "draft_iters": 32.0, "mem_use": 36.83, "gen_rate": 33.0, "speed": 11.55, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.7, "tree_w": 36, "tree_size": 128, "t0": 0.6471, "t1": 0.6614, "tft": 1.458, "input_0": 285, "input_1": 129, "min_CLP": -5.79, "draft_iters": 8.7, "mem_use": 34.38, "gen_rate": 5.0, "speed": 3.82, "text": "Some options of foods that you c"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.5, "tree_w": 18, "tree_size": 128, "t0": 1.2325, "t1": 0.6925, "tft": 1.8297, "input_0": 366, "input_1": 129, "min_CLP": -5.48, "draft_iters": 17.5, "mem_use": 35.08, "gen_rate": 9.0, "speed": 4.67, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.0, "tree_w": 30, "tree_size": 128, "t0": 1.125, "t1": 0.695, "tft": 2.2865, "input_0": 316, "input_1": 129, "min_CLP": -5.81, "draft_iters": 16.0, "mem_use": 35.49, "gen_rate": 8.0, "speed": 4.39, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 12.7, "tree_w": 32, "tree_size": 128, "t0": 0.9629, "t1": 0.6871, "tft": 1.7339, "input_0": 301, "input_1": 129, "min_CLP": -6.04, "draft_iters": 13.6, "mem_use": 34.84, "gen_rate": 4.9, "speed": 2.94, "text": "Freyja, goddess of love, fertili"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 11.0, "tree_w": 27, "tree_size": 128, "t0": 0.8625, "t1": 0.6725, "tft": 2.1475, "input_0": 320, "input_1": 129, "min_CLP": -5.59, "draft_iters": 12.0, "mem_use": 36.5, "gen_rate": 4.2, "speed": 2.77, "text": "Yes, there are some good non-dai"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.6, "tree_w": 25, "tree_size": 128, "t0": 0.842, "t1": 0.666, "tft": 2.3712, "input_0": 352, "input_1": 129, "min_CLP": -5.52, "draft_iters": 11.6, "mem_use": 36.54, "gen_rate": 7.2, "speed": 4.76, "text": "\"When choosing an ISP package, y"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.7, "tree_w": 27, "tree_size": 128, "t0": 0.83, "t1": 0.67, "tft": 3.4834, "input_0": 334, "input_1": 129, "min_CLP": -5.46, "draft_iters": 11.7, "mem_use": 39.24, "gen_rate": 5.0, "speed": 3.33, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.6, "tree_w": 33, "tree_size": 128, "t0": 0.7188, "t1": 0.6525, "tft": 1.519, "input_0": 331, "input_1": 129, "min_CLP": -5.68, "draft_iters": 9.6, "mem_use": 34.37, "gen_rate": 4.4, "speed": 3.19, "text": "\"The airspeed velocity of an unl"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 15.0, "tree_w": 27, "tree_size": 128, "t0": 1.134, "t1": 0.674, "tft": 2.597, "input_0": 342, "input_1": 129, "min_CLP": -5.73, "draft_iters": 16.0, "mem_use": 34.89, "gen_rate": 8.8, "speed": 4.86, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 33, "tree_size": 128, "t0": 0.728, "t1": 0.656, "tft": 2.7712, "input_0": 281, "input_1": 129, "min_CLP": -5.68, "draft_iters": 10.2, "mem_use": 37.25, "gen_rate": 6.6, "speed": 4.77, "text": "Of course, I can try to act like"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 26, "tree_size": 128, "t0": 0.842, "t1": 0.678, "tft": 1.8136, "input_0": 342, "input_1": 129, "min_CLP": -5.53, "draft_iters": 11.6, "mem_use": 35.29, "gen_rate": 6.4, "speed": 4.21, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.4, "tree_w": 47, "tree_size": 128, "t0": 0.55, "t1": 0.66, "tft": 1.635, "input_0": 232, "input_1": 129, "min_CLP": -6.21, "draft_iters": 7.4, "mem_use": 34.59, "gen_rate": 4.2, "speed": 3.51, "text": "Freyja: You dare to demand my po"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 128, "t0": 2.18, "t1": 0.69, "tft": 2.6589, "input_0": 370, "input_1": 129, "min_CLP": -5.75, "draft_iters": 32.0, "mem_use": 37.08, "gen_rate": 33.0, "speed": 11.5, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.8, "tree_w": 42, "tree_size": 128, "t0": 0.6925, "t1": 0.665, "tft": 4.0029, "input_0": 244, "input_1": 129, "min_CLP": -6.04, "draft_iters": 9.8, "mem_use": 37.53, "gen_rate": 4.4, "speed": 3.22, "text": "[INST] Thank You. Could you find"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.0, "tree_w": 20, "tree_size": 128, "t0": 1.095, "t1": 0.6725, "tft": 2.0815, "input_0": 435, "input_1": 129, "min_CLP": -5.3, "draft_iters": 15.0, "mem_use": 35.86, "gen_rate": 10.0, "speed": 5.66, "text": "It\\'s difficult to say which one"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 13, "tree_h": 16.0, "tree_w": 16, "tree_size": 128, "t0": 1.18, "t1": 0.67, "tft": 1.8707, "input_0": 343, "input_1": 129, "min_CLP": -4.77, "draft_iters": 17.0, "mem_use": 35.12, "gen_rate": 13.0, "speed": 7.04, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 24.5, "tree_w": 27, "tree_size": 128, "t0": 1.7383, "t1": 0.715, "tft": 2.4115, "input_0": 296, "input_1": 129, "min_CLP": -6.17, "draft_iters": 25.2, "mem_use": 34.85, "gen_rate": 5.3, "speed": 2.17, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.6, "tree_w": 29, "tree_size": 128, "t0": 0.976, "t1": 0.664, "tft": 1.6043, "input_0": 360, "input_1": 129, "min_CLP": -5.56, "draft_iters": 13.6, "mem_use": 34.37, "gen_rate": 7.6, "speed": 4.64, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 32.0, "tree_w": 15, "tree_size": 128, "t0": 2.16, "t1": 0.69, "tft": 3.5889, "input_0": 356, "input_1": 129, "min_CLP": -5.48, "draft_iters": 32.0, "mem_use": 39.78, "gen_rate": 19.0, "speed": 6.67, "text": "\"Certainly! Here's a revised ver"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 6.1, "tree_w": 47, "tree_size": 128, "t0": 0.5189, "t1": 0.6522, "tft": 3.4693, "input_0": 219, "input_1": 129, "min_CLP": -6.16, "draft_iters": 7.1, "mem_use": 36.13, "gen_rate": 4.0, "speed": 3.41, "text": "I will continue, Agent. I rememb"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 64, "tree_h": 22.0, "tree_w": 29, "tree_size": 128, "t0": 1.58, "t1": 0.7, "tft": 2.489, "input_0": 367, "input_1": 129, "min_CLP": -6.08, "draft_iters": 22.7, "mem_use": 35.13, "gen_rate": 21.3, "speed": 9.35, "text": "\"[INST] sure. that\u2019s logic! than"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 15, "tree_h": 11.5, "tree_w": 27, "tree_size": 128, "t0": 0.905, "t1": 0.67, "tft": 2.3203, "input_0": 390, "input_1": 129, "min_CLP": -5.93, "draft_iters": 12.5, "mem_use": 34.64, "gen_rate": 7.5, "speed": 4.77, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u91cd\u8981\u8bfe\u9898\u4e4b\u4e00\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.0, "tree_w": 23, "tree_size": 128, "t0": 1.135, "t1": 0.675, "tft": 3.4858, "input_0": 391, "input_1": 129, "min_CLP": -5.28, "draft_iters": 16.0, "mem_use": 36.54, "gen_rate": 9.2, "speed": 5.12, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.6, "tree_w": 29, "tree_size": 128, "t0": 0.982, "t1": 0.676, "tft": 2.2191, "input_0": 375, "input_1": 129, "min_CLP": -5.66, "draft_iters": 13.6, "mem_use": 35.74, "gen_rate": 7.2, "speed": 4.34, "text": "Sure, here are some additional i"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.2, "tree_w": 30, "tree_size": 128, "t0": 0.81, "t1": 0.6633, "tft": 2.2237, "input_0": 336, "input_1": 129, "min_CLP": -5.43, "draft_iters": 11.2, "mem_use": 36.11, "gen_rate": 6.3, "speed": 4.29, "text": "Yes, technology can be used for "}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.0, "tree_w": 36, "tree_size": 128, "t0": 0.6571, "t1": 0.6643, "tft": 1.3549, "input_0": 257, "input_1": 129, "min_CLP": -5.69, "draft_iters": 9.0, "mem_use": 34.54, "gen_rate": 4.6, "speed": 3.46, "text": "In real life, anyone can wear sh"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.5, "tree_w": 37, "tree_size": 128, "t0": 0.6933, "t1": 0.665, "tft": 2.4836, "input_0": 289, "input_1": 129, "min_CLP": -6.02, "draft_iters": 9.5, "mem_use": 36.93, "gen_rate": 5.3, "speed": 3.93, "text": "Sure, here is a pitch deck for F"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.5, "tree_w": 32, "tree_size": 128, "t0": 0.68, "t1": 0.6713, "tft": 3.3268, "input_0": 285, "input_1": 129, "min_CLP": -5.56, "draft_iters": 9.5, "mem_use": 38.18, "gen_rate": 4.5, "speed": 3.33, "text": "I apologize for the confusion. Y"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.8, "tree_w": 23, "tree_size": 128, "t0": 0.984, "t1": 0.676, "tft": 3.3538, "input_0": 381, "input_1": 129, "min_CLP": -5.48, "draft_iters": 13.8, "mem_use": 38.34, "gen_rate": 7.8, "speed": 4.7, "text": "Yes, Keras is a great choice for"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 44, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 2.23, "t1": 0.705, "tft": 2.7483, "input_0": 521, "input_1": 129, "min_CLP": -5.41, "draft_iters": 32.0, "mem_use": 36.04, "gen_rate": 22.0, "speed": 7.51, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 9.0, "tree_w": 34, "tree_size": 128, "t0": 0.7329, "t1": 0.67, "tft": 1.4806, "input_0": 274, "input_1": 129, "min_CLP": -5.81, "draft_iters": 10.0, "mem_use": 34.36, "gen_rate": 5.9, "speed": 4.18, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 23.0, "tree_w": 18, "tree_size": 128, "t0": 1.6575, "t1": 0.69, "tft": 2.7084, "input_0": 450, "input_1": 129, "min_CLP": -5.21, "draft_iters": 23.8, "mem_use": 36.76, "gen_rate": 8.8, "speed": 3.73, "text": "You are correct. The direct answ"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 9.0, "tree_w": 35, "tree_size": 128, "t0": 0.725, "t1": 0.6863, "tft": 3.1012, "input_0": 307, "input_1": 129, "min_CLP": -5.85, "draft_iters": 10.0, "mem_use": 37.61, "gen_rate": 5.2, "speed": 3.72, "text": "[The scene opens on a battlefiel"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.0, "tree_w": 29, "tree_size": 128, "t0": 0.86, "t1": 0.6767, "tft": 2.6458, "input_0": 295, "input_1": 129, "min_CLP": -5.8, "draft_iters": 12.0, "mem_use": 35.31, "gen_rate": 5.7, "speed": 3.69, "text": "You\\'re right, it\\'s important t"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.2, "tree_w": 35, "tree_size": 128, "t0": 0.6767, "t1": 0.66, "tft": 1.7504, "input_0": 297, "input_1": 129, "min_CLP": -5.71, "draft_iters": 9.2, "mem_use": 35.02, "gen_rate": 5.5, "speed": 4.12, "text": "Proof-of-stake is a consensus al"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.8, "tree_w": 39, "tree_size": 128, "t0": 0.5783, "t1": 0.6667, "tft": 1.8934, "input_0": 231, "input_1": 129, "min_CLP": -6.12, "draft_iters": 7.8, "mem_use": 35.15, "gen_rate": 5.7, "speed": 4.56, "text": "My previous statement was based "}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.0, "tree_w": 29, "tree_size": 128, "t0": 0.7229, "t1": 0.6586, "tft": 2.7593, "input_0": 306, "input_1": 129, "min_CLP": -5.62, "draft_iters": 10.0, "mem_use": 37.21, "gen_rate": 5.1, "speed": 3.72, "text": "Void pointers are a type of poin"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.6, "tree_w": 32, "tree_size": 128, "t0": 0.7563, "t1": 0.6688, "tft": 2.9353, "input_0": 279, "input_1": 129, "min_CLP": -5.65, "draft_iters": 10.6, "mem_use": 37.73, "gen_rate": 4.5, "speed": 3.16, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 14.7, "tree_w": 19, "tree_size": 128, "t0": 1.1167, "t1": 0.67, "tft": 2.9612, "input_0": 445, "input_1": 129, "min_CLP": -5.38, "draft_iters": 15.7, "mem_use": 36.93, "gen_rate": 13.0, "speed": 7.28, "text": "To implement two-factor authenti"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.7, "tree_w": 31, "tree_size": 128, "t0": 0.71, "t1": 0.6629, "tft": 1.7928, "input_0": 275, "input_1": 129, "min_CLP": -5.75, "draft_iters": 9.7, "mem_use": 34.77, "gen_rate": 5.0, "speed": 3.65, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.0, "tree_w": 28, "tree_size": 128, "t0": 0.8767, "t1": 0.6667, "tft": 2.5284, "input_0": 347, "input_1": 129, "min_CLP": -5.53, "draft_iters": 12.0, "mem_use": 34.36, "gen_rate": 5.8, "speed": 3.78, "text": "The idea that landlords can be c"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 47, "tree_h": 27.8, "tree_w": 13, "tree_size": 128, "t0": 1.96, "t1": 0.6875, "tft": 3.5592, "input_0": 505, "input_1": 129, "min_CLP": -5.08, "draft_iters": 28.2, "mem_use": 37.17, "gen_rate": 11.8, "speed": 4.44, "text": "\"Sure! Here's a table that inclu"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.2, "tree_w": 35, "tree_size": 128, "t0": 0.674, "t1": 0.666, "tft": 1.1243, "input_0": 262, "input_1": 129, "min_CLP": -5.77, "draft_iters": 9.2, "mem_use": 34.31, "gen_rate": 6.8, "speed": 5.07, "text": "Berlin was founded in the 13th c"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.0, "tree_w": 31, "tree_size": 128, "t0": 0.8486, "t1": 0.6671, "tft": 3.6919, "input_0": 296, "input_1": 129, "min_CLP": -5.85, "draft_iters": 12.0, "mem_use": 36.64, "gen_rate": 5.3, "speed": 3.49, "text": "Here are some jokes with love fo"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 27.5, "tree_w": 12, "tree_size": 128, "t0": 1.98, "t1": 0.71, "tft": 2.5006, "input_0": 506, "input_1": 129, "min_CLP": -5.09, "draft_iters": 28.0, "mem_use": 36.5, "gen_rate": 26.0, "speed": 9.68, "text": "Certainly. While \"Fooled by Rand"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 20.0, "tree_w": 28, "tree_size": 128, "t0": 1.425, "t1": 0.695, "tft": 1.0736, "input_0": 316, "input_1": 129, "min_CLP": -5.8, "draft_iters": 20.5, "mem_use": 34.33, "gen_rate": 19.5, "speed": 9.2, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 14.3, "tree_w": 33, "tree_size": 128, "t0": 1.0729, "t1": 0.6857, "tft": 1.7213, "input_0": 274, "input_1": 129, "min_CLP": -5.72, "draft_iters": 15.3, "mem_use": 34.64, "gen_rate": 5.3, "speed": 3.01, "text": "You can find out what timezone y"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 37, "tree_size": 128, "t0": 0.6443, "t1": 0.66, "tft": 1.3394, "input_0": 288, "input_1": 129, "min_CLP": -5.88, "draft_iters": 8.6, "mem_use": 34.72, "gen_rate": 4.7, "speed": 3.61, "text": "No, the five-second rule is not "}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 19, "tree_h": 13.7, "tree_w": 19, "tree_size": 128, "t0": 1.0433, "t1": 0.68, "tft": 2.5373, "input_0": 319, "input_1": 129, "min_CLP": -5.69, "draft_iters": 14.7, "mem_use": 34.45, "gen_rate": 6.3, "speed": 3.68, "text": "12 - 2 - 5 = 5. So, you have 5 e"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.3, "tree_w": 17, "tree_size": 128, "t0": 1.3333, "t1": 0.7, "tft": 2.0639, "input_0": 468, "input_1": 129, "min_CLP": -4.91, "draft_iters": 18.3, "mem_use": 35.19, "gen_rate": 13.3, "speed": 6.56, "text": " Sure! One of the most well-know"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 26, "tree_h": 10.0, "tree_w": 25, "tree_size": 128, "t0": 0.796, "t1": 0.664, "tft": 1.4927, "input_0": 313, "input_1": 129, "min_CLP": -5.53, "draft_iters": 11.0, "mem_use": 34.76, "gen_rate": 5.2, "speed": 3.57, "text": "\"You're welcome! If you're sure "}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.9, "tree_w": 39, "tree_size": 128, "t0": 0.7943, "t1": 0.6714, "tft": 1.4058, "input_0": 279, "input_1": 129, "min_CLP": -5.84, "draft_iters": 10.9, "mem_use": 34.48, "gen_rate": 5.6, "speed": 3.8, "text": "\"#OpenAssistant is here! \ud83d\ude80\\n\\nWe"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.6, "tree_w": 31, "tree_size": 128, "t0": 0.7, "t1": 0.6614, "tft": 2.0566, "input_0": 306, "input_1": 129, "min_CLP": -5.68, "draft_iters": 9.6, "mem_use": 35.09, "gen_rate": 5.0, "speed": 3.67, "text": "Sexual selection can also influe"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 21, "tree_size": 128, "t0": 0.876, "t1": 0.662, "tft": 2.1897, "input_0": 346, "input_1": 129, "min_CLP": -5.08, "draft_iters": 12.2, "mem_use": 36.15, "gen_rate": 6.6, "speed": 4.29, "text": "AI assistants can also be very h"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 8.5, "tree_w": 28, "tree_size": 128, "t0": 0.685, "t1": 0.6575, "tft": 2.6136, "input_0": 275, "input_1": 129, "min_CLP": -5.66, "draft_iters": 9.5, "mem_use": 37.14, "gen_rate": 8.2, "speed": 6.14, "text": "\"Certainly! Here's a rewritten v"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.4, "tree_w": 29, "tree_size": 128, "t0": 0.7514, "t1": 0.6714, "tft": 1.9599, "input_0": 282, "input_1": 129, "min_CLP": -5.53, "draft_iters": 10.4, "mem_use": 35.64, "gen_rate": 4.7, "speed": 3.32, "text": "The scp command is available on "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 32.0, "tree_w": 13, "tree_size": 128, "t0": 2.215, "t1": 0.71, "tft": 2.6185, "input_0": 471, "input_1": 129, "min_CLP": -5.59, "draft_iters": 32.0, "mem_use": 36.31, "gen_rate": 23.5, "speed": 8.03, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.3, "tree_w": 31, "tree_size": 128, "t0": 0.7517, "t1": 0.6667, "tft": 1.3986, "input_0": 284, "input_1": 129, "min_CLP": -5.7, "draft_iters": 10.3, "mem_use": 34.38, "gen_rate": 5.3, "speed": 3.76, "text": "Yes, it would be illegal to keep"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 14.6, "tree_w": 21, "tree_size": 128, "t0": 1.108, "t1": 0.688, "tft": 1.6007, "input_0": 351, "input_1": 129, "min_CLP": -5.43, "draft_iters": 15.6, "mem_use": 34.67, "gen_rate": 6.6, "speed": 3.68, "text": "Sydney is the largest city in Au"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 20, "tree_size": 128, "t0": 1.7, "t1": 0.7, "tft": 1.8056, "input_0": 374, "input_1": 129, "min_CLP": -6.32, "draft_iters": 24.5, "mem_use": 34.97, "gen_rate": 25.0, "speed": 10.42, "text": "\"[INST] 5 second rule is a dange"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.6, "tree_w": 41, "tree_size": 128, "t0": 0.635, "t1": 0.6638, "tft": 2.0633, "input_0": 244, "input_1": 129, "min_CLP": -6.03, "draft_iters": 8.6, "mem_use": 34.65, "gen_rate": 4.4, "speed": 3.37, "text": "\"Oh, you're telling me. As a bro"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.4, "tree_w": 36, "tree_size": 128, "t0": 0.682, "t1": 0.662, "tft": 2.1817, "input_0": 270, "input_1": 129, "min_CLP": -5.54, "draft_iters": 9.4, "mem_use": 34.42, "gen_rate": 6.6, "speed": 4.91, "text": "The best approach for learning a"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 29, "tree_size": 128, "t0": 0.935, "t1": 0.675, "tft": 1.5363, "input_0": 355, "input_1": 129, "min_CLP": -5.59, "draft_iters": 12.8, "mem_use": 34.4, "gen_rate": 8.2, "speed": 5.13, "text": "\"Walking around the world would "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.0, "tree_w": 19, "tree_size": 128, "t0": 1.19, "t1": 0.6833, "tft": 3.3356, "input_0": 352, "input_1": 129, "min_CLP": -5.27, "draft_iters": 17.0, "mem_use": 36.15, "gen_rate": 11.7, "speed": 6.23, "text": "The Taniyama-Shimura-Weil conjec"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 19.0, "tree_w": 33, "tree_size": 128, "t0": 1.3767, "t1": 0.7, "tft": 1.7453, "input_0": 314, "input_1": 129, "min_CLP": -5.98, "draft_iters": 19.7, "mem_use": 34.4, "gen_rate": 13.7, "speed": 6.58, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 14.7, "tree_w": 21, "tree_size": 128, "t0": 1.1467, "t1": 0.68, "tft": 2.2909, "input_0": 488, "input_1": 129, "min_CLP": -5.56, "draft_iters": 15.7, "mem_use": 34.7, "gen_rate": 13.0, "speed": 7.12, "text": "To write a first-person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.5, "tree_w": 25, "tree_size": 128, "t0": 1.39, "t1": 0.67, "tft": 1.3927, "input_0": 317, "input_1": 129, "min_CLP": -5.55, "draft_iters": 20.0, "mem_use": 34.37, "gen_rate": 19.5, "speed": 9.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.9, "tree_w": 29, "tree_size": 128, "t0": 0.7837, "t1": 0.665, "tft": 1.3417, "input_0": 277, "input_1": 129, "min_CLP": -5.62, "draft_iters": 10.9, "mem_use": 34.68, "gen_rate": 4.4, "speed": 3.02, "text": "The path to becoming one with th"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 7.3, "tree_w": 38, "tree_size": 128, "t0": 0.61, "t1": 0.656, "tft": 1.7632, "input_0": 247, "input_1": 129, "min_CLP": -5.77, "draft_iters": 8.3, "mem_use": 34.54, "gen_rate": 3.3, "speed": 2.61, "text": "A gas-operated rifle uses the pr"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.4, "tree_w": 37, "tree_size": 128, "t0": 0.68, "t1": 0.6625, "tft": 1.6705, "input_0": 255, "input_1": 129, "min_CLP": -5.81, "draft_iters": 9.4, "mem_use": 34.78, "gen_rate": 4.0, "speed": 2.98, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.8, "tree_w": 23, "tree_size": 128, "t0": 0.9675, "t1": 0.6675, "tft": 2.8466, "input_0": 324, "input_1": 129, "min_CLP": -5.55, "draft_iters": 13.8, "mem_use": 37.63, "gen_rate": 8.8, "speed": 5.35, "text": "Yes, a more robust solution woul"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.7, "tree_w": 30, "tree_size": 128, "t0": 0.7771, "t1": 0.6743, "tft": 1.8024, "input_0": 284, "input_1": 129, "min_CLP": -5.67, "draft_iters": 10.7, "mem_use": 34.84, "gen_rate": 5.0, "speed": 3.44, "text": "Yes, it is reasonable to expect "}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 11.0, "tree_w": 27, "tree_size": 128, "t0": 0.8571, "t1": 0.6686, "tft": 2.6608, "input_0": 337, "input_1": 129, "min_CLP": -5.7, "draft_iters": 12.0, "mem_use": 37.73, "gen_rate": 4.9, "speed": 3.19, "text": "Xin ch\u00e0o! How may I help you tod"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.7, "tree_w": 34, "tree_size": 128, "t0": 0.6371, "t1": 0.6743, "tft": 1.5608, "input_0": 259, "input_1": 129, "min_CLP": -5.76, "draft_iters": 8.7, "mem_use": 35.21, "gen_rate": 5.3, "speed": 4.03, "text": "What a fascinating story! This i"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 63, "tree_h": 21.7, "tree_w": 14, "tree_size": 128, "t0": 1.5967, "t1": 0.69, "tft": 1.5418, "input_0": 473, "input_1": 129, "min_CLP": -5.19, "draft_iters": 22.3, "mem_use": 34.72, "gen_rate": 21.0, "speed": 9.17, "text": "Certainly! Here\\'s an example of"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.9, "tree_w": 30, "tree_size": 128, "t0": 0.715, "t1": 0.6663, "tft": 2.6514, "input_0": 267, "input_1": 129, "min_CLP": -6.14, "draft_iters": 9.9, "mem_use": 36.17, "gen_rate": 4.6, "speed": 3.35, "text": "1. Scorpions\\n2. Rammstein\\n3. K"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.9, "tree_w": 46, "tree_size": 128, "t0": 0.5787, "t1": 0.65, "tft": 1.6609, "input_0": 235, "input_1": 129, "min_CLP": -5.89, "draft_iters": 7.9, "mem_use": 34.69, "gen_rate": 4.1, "speed": 3.35, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.5, "tree_w": 22, "tree_size": 128, "t0": 0.9575, "t1": 0.6675, "tft": 2.3814, "input_0": 331, "input_1": 129, "min_CLP": -5.18, "draft_iters": 13.5, "mem_use": 36.69, "gen_rate": 8.8, "speed": 5.38, "text": "Acquiring revenue from customers"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.5, "tree_w": 30, "tree_size": 128, "t0": 0.7575, "t1": 0.6625, "tft": 1.6666, "input_0": 310, "input_1": 129, "min_CLP": -5.66, "draft_iters": 10.5, "mem_use": 35.31, "gen_rate": 8.5, "speed": 5.99, "text": "As a large language model, I am "}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.0, "tree_w": 21, "tree_size": 128, "t0": 1.535, "t1": 0.67, "tft": 1.3996, "input_0": 461, "input_1": 129, "min_CLP": -5.58, "draft_iters": 22.0, "mem_use": 34.85, "gen_rate": 19.5, "speed": 8.85, "text": "Certainly! Here is an essay on h"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 47, "tree_h": 13.3, "tree_w": 23, "tree_size": 128, "t0": 1.0267, "t1": 0.6783, "tft": 1.8224, "input_0": 350, "input_1": 129, "min_CLP": -5.37, "draft_iters": 14.3, "mem_use": 34.99, "gen_rate": 7.8, "speed": 4.6, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.2, "tree_w": 23, "tree_size": 128, "t0": 1.0075, "t1": 0.6775, "tft": 3.0103, "input_0": 343, "input_1": 129, "min_CLP": -5.46, "draft_iters": 14.2, "mem_use": 36.28, "gen_rate": 8.8, "speed": 5.19, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 24, "tree_size": 128, "t0": 0.86, "t1": 0.6733, "tft": 1.537, "input_0": 316, "input_1": 129, "min_CLP": -5.58, "draft_iters": 11.8, "mem_use": 34.37, "gen_rate": 6.0, "speed": 3.91, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 22, "tree_size": 128, "t0": 0.944, "t1": 0.662, "tft": 1.6801, "input_0": 371, "input_1": 129, "min_CLP": -5.48, "draft_iters": 13.0, "mem_use": 34.41, "gen_rate": 7.0, "speed": 4.37, "text": "The error in the given code is a"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 12.9, "tree_w": 34, "tree_size": 128, "t0": 0.9712, "t1": 0.6738, "tft": 1.932, "input_0": 285, "input_1": 129, "min_CLP": -5.84, "draft_iters": 13.8, "mem_use": 35.79, "gen_rate": 4.1, "speed": 2.51, "text": "<|/INST|> Dear future me,\\n\\nIf "}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.0, "tree_w": 29, "tree_size": 128, "t0": 0.864, "t1": 0.674, "tft": 1.7883, "input_0": 313, "input_1": 129, "min_CLP": -5.55, "draft_iters": 12.0, "mem_use": 35.01, "gen_rate": 7.2, "speed": 4.69, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 18.0, "tree_w": 16, "tree_size": 128, "t0": 1.3583, "t1": 0.695, "tft": 1.5788, "input_0": 412, "input_1": 129, "min_CLP": -5.17, "draft_iters": 19.0, "mem_use": 35.14, "gen_rate": 5.5, "speed": 2.68, "text": "\"To create a Python program that"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.6, "tree_w": 32, "tree_size": 128, "t0": 0.6986, "t1": 0.6614, "tft": 2.3602, "input_0": 317, "input_1": 129, "min_CLP": -5.52, "draft_iters": 9.6, "mem_use": 36.91, "gen_rate": 4.9, "speed": 3.57, "text": "\"It's important to prioritize yo"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 26.3, "tree_w": 15, "tree_size": 128, "t0": 1.8933, "t1": 0.7, "tft": 1.9129, "input_0": 453, "input_1": 129, "min_CLP": -5.19, "draft_iters": 27.0, "mem_use": 34.92, "gen_rate": 15.0, "speed": 5.79, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 56, "tree_h": 26.8, "tree_w": 13, "tree_size": 128, "t0": 1.9075, "t1": 0.6825, "tft": 3.6646, "input_0": 491, "input_1": 129, "min_CLP": -5.06, "draft_iters": 27.2, "mem_use": 36.3, "gen_rate": 14.0, "speed": 5.41, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 38, "tree_size": 128, "t0": 0.6129, "t1": 0.6471, "tft": 1.3874, "input_0": 283, "input_1": 129, "min_CLP": -5.8, "draft_iters": 8.3, "mem_use": 34.35, "gen_rate": 4.9, "speed": 3.85, "text": "\"Yes, I can think and feel like "}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 27, "tree_h": 8.9, "tree_w": 38, "tree_size": 128, "t0": 0.71, "t1": 0.6771, "tft": 1.8114, "input_0": 239, "input_1": 129, "min_CLP": -6.19, "draft_iters": 9.9, "mem_use": 34.57, "gen_rate": 3.9, "speed": 2.78, "text": "In the realm of deep learning,\\n"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 43, "tree_h": 11.1, "tree_w": 35, "tree_size": 128, "t0": 0.8763, "t1": 0.6813, "tft": 1.3312, "input_0": 295, "input_1": 129, "min_CLP": -5.75, "draft_iters": 12.1, "mem_use": 34.82, "gen_rate": 5.4, "speed": 3.45, "text": "Thanks! I try to provide helpful"}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.2, "tree_w": 38, "tree_size": 128, "t0": 0.728, "t1": 0.658, "tft": 2.1738, "input_0": 255, "input_1": 129, "min_CLP": -6.24, "draft_iters": 10.2, "mem_use": 36.41, "gen_rate": 6.8, "speed": 4.9, "text": "\"Thou art the sun that shineth b"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 8.7, "tree_w": 43, "tree_size": 128, "t0": 0.7082, "t1": 0.6645, "tft": 1.6867, "input_0": 266, "input_1": 129, "min_CLP": -6.18, "draft_iters": 9.7, "mem_use": 34.99, "gen_rate": 3.0, "speed": 2.18, "text": "I apologize for not providing a "}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.5, "tree_w": 32, "tree_size": 128, "t0": 0.8367, "t1": 0.6633, "tft": 1.8053, "input_0": 330, "input_1": 129, "min_CLP": -5.99, "draft_iters": 11.5, "mem_use": 34.39, "gen_rate": 6.2, "speed": 4.12, "text": "\"Sure, here are some words from "}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.8, "tree_w": 24, "tree_size": 128, "t0": 0.996, "t1": 0.67, "tft": 1.4033, "input_0": 384, "input_1": 129, "min_CLP": -5.45, "draft_iters": 13.8, "mem_use": 34.37, "gen_rate": 6.4, "speed": 3.84, "text": "\"Presidents Day, officially know"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.1, "tree_w": 33, "tree_size": 128, "t0": 0.7371, "t1": 0.67, "tft": 1.4527, "input_0": 282, "input_1": 129, "min_CLP": -5.78, "draft_iters": 10.1, "mem_use": 34.67, "gen_rate": 5.4, "speed": 3.86, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 13.9, "tree_w": 26, "tree_size": 128, "t0": 1.06, "t1": 0.6957, "tft": 2.3139, "input_0": 339, "input_1": 129, "min_CLP": -5.57, "draft_iters": 14.9, "mem_use": 35.47, "gen_rate": 5.3, "speed": 3.01, "text": "Yes, the US National Reconnaissa"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.4, "tree_w": 41, "tree_size": 128, "t0": 0.5467, "t1": 0.6533, "tft": 1.3938, "input_0": 221, "input_1": 129, "min_CLP": -6.2, "draft_iters": 7.4, "mem_use": 34.75, "gen_rate": 3.6, "speed": 2.96, "text": "\"Why did the broke college stude"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.0, "tree_w": 37, "tree_size": 128, "t0": 0.5886, "t1": 0.6586, "tft": 1.3848, "input_0": 256, "input_1": 129, "min_CLP": -5.84, "draft_iters": 8.0, "mem_use": 34.82, "gen_rate": 4.6, "speed": 3.67, "text": "\"Opie, it's a friendly and fitti"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 24.0, "tree_w": 27, "tree_size": 128, "t0": 1.695, "t1": 0.72, "tft": 1.5244, "input_0": 327, "input_1": 129, "min_CLP": -5.9, "draft_iters": 24.5, "mem_use": 34.37, "gen_rate": 19.5, "speed": 8.08, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 12, "new_tokens": 35, "tree_h": 6.2, "tree_w": 45, "tree_size": 128, "t0": 0.5233, "t1": 0.6658, "tft": 1.3634, "input_0": 209, "input_1": 129, "min_CLP": -6.12, "draft_iters": 7.2, "mem_use": 35.05, "gen_rate": 2.9, "speed": 2.45, "text": "\"Kaczynski's critique of technol"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 26, "tree_size": 128, "t0": 0.78, "t1": 0.672, "tft": 1.7881, "input_0": 290, "input_1": 129, "min_CLP": -5.54, "draft_iters": 10.8, "mem_use": 34.48, "gen_rate": 6.4, "speed": 4.42, "text": "Yes, there is a way to salvage y"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.3, "tree_w": 29, "tree_size": 128, "t0": 0.7429, "t1": 0.6729, "tft": 1.7171, "input_0": 300, "input_1": 129, "min_CLP": -5.99, "draft_iters": 10.3, "mem_use": 35.71, "gen_rate": 4.9, "speed": 3.43, "text": "Certainly! Here are some medias "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 40, "tree_size": 128, "t0": 0.5617, "t1": 0.655, "tft": 1.1848, "input_0": 251, "input_1": 129, "min_CLP": -5.93, "draft_iters": 7.7, "mem_use": 34.81, "gen_rate": 5.7, "speed": 4.65, "text": "\"No, I don't have the capability"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 14.5, "tree_w": 26, "tree_size": 128, "t0": 1.1, "t1": 0.675, "tft": 2.5936, "input_0": 356, "input_1": 129, "min_CLP": -5.49, "draft_iters": 15.5, "mem_use": 36.05, "gen_rate": 5.8, "speed": 3.29, "text": "\"For a beginner hiker who wants "}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 9.5, "tree_w": 40, "tree_size": 128, "t0": 0.7588, "t1": 0.68, "tft": 1.5906, "input_0": 251, "input_1": 129, "min_CLP": -6.13, "draft_iters": 10.5, "mem_use": 34.76, "gen_rate": 4.0, "speed": 2.78, "text": "Open Assistant: Open Source Chat"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.2, "tree_w": 18, "tree_size": 128, "t0": 1.1625, "t1": 0.6775, "tft": 1.5276, "input_0": 415, "input_1": 129, "min_CLP": -5.21, "draft_iters": 16.2, "mem_use": 34.66, "gen_rate": 8.2, "speed": 4.48, "text": "\"Sure, let's break it down step "}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.1, "tree_w": 24, "tree_size": 128, "t0": 0.8843, "t1": 0.6686, "tft": 2.8364, "input_0": 358, "input_1": 129, "min_CLP": -5.8, "draft_iters": 12.1, "mem_use": 36.98, "gen_rate": 5.3, "speed": 3.4, "text": "This behavior is due to a phenom"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.5, "tree_w": 25, "tree_size": 128, "t0": 0.9725, "t1": 0.68, "tft": 1.4523, "input_0": 343, "input_1": 129, "min_CLP": -5.64, "draft_iters": 13.5, "mem_use": 34.36, "gen_rate": 8.0, "speed": 4.85, "text": "No, you cannot directly compile "}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.1, "tree_w": 44, "tree_size": 128, "t0": 0.5243, "t1": 0.6557, "tft": 1.3213, "input_0": 223, "input_1": 129, "min_CLP": -6.02, "draft_iters": 7.1, "mem_use": 34.9, "gen_rate": 4.6, "speed": 3.87, "text": "Video games are a lot of fun, bu"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.2, "tree_w": 24, "tree_size": 128, "t0": 0.8183, "t1": 0.665, "tft": 1.4708, "input_0": 334, "input_1": 129, "min_CLP": -5.51, "draft_iters": 11.2, "mem_use": 34.53, "gen_rate": 6.5, "speed": 4.38, "text": "When the pan is already hot, it "}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.4, "tree_w": 23, "tree_size": 128, "t0": 0.982, "t1": 0.668, "tft": 1.5344, "input_0": 392, "input_1": 129, "min_CLP": -5.33, "draft_iters": 13.4, "mem_use": 34.37, "gen_rate": 6.8, "speed": 4.12, "text": "The most popular and widely used"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.1, "tree_w": 33, "tree_size": 128, "t0": 0.6614, "t1": 0.6586, "tft": 2.3288, "input_0": 280, "input_1": 129, "min_CLP": -5.66, "draft_iters": 9.1, "mem_use": 36.46, "gen_rate": 5.6, "speed": 4.22, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.4, "tree_w": 38, "tree_size": 128, "t0": 0.6162, "t1": 0.65, "tft": 1.1259, "input_0": 263, "input_1": 129, "min_CLP": -5.87, "draft_iters": 8.4, "mem_use": 34.33, "gen_rate": 4.1, "speed": 3.26, "text": "\"No, a thumb war is not violent."}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.2, "tree_w": 24, "tree_size": 128, "t0": 1.02, "t1": 0.6675, "tft": 2.0584, "input_0": 368, "input_1": 129, "min_CLP": -5.7, "draft_iters": 14.2, "mem_use": 34.41, "gen_rate": 9.0, "speed": 5.33, "text": "Rick Astley\\'s \"Never Gonna Give"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 29, "tree_size": 128, "t0": 0.715, "t1": 0.66, "tft": 2.8051, "input_0": 291, "input_1": 129, "min_CLP": -5.61, "draft_iters": 10.0, "mem_use": 37.69, "gen_rate": 6.0, "speed": 4.36, "text": "As of my last update, the most m"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 25, "tree_size": 128, "t0": 0.84, "t1": 0.674, "tft": 2.0338, "input_0": 320, "input_1": 129, "min_CLP": -5.46, "draft_iters": 11.6, "mem_use": 35.67, "gen_rate": 6.8, "speed": 4.49, "text": "I understand that you are asking"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.0, "tree_w": 20, "tree_size": 128, "t0": 1.07, "t1": 0.6725, "tft": 1.3764, "input_0": 359, "input_1": 129, "min_CLP": -5.33, "draft_iters": 15.0, "mem_use": 34.62, "gen_rate": 10.0, "speed": 5.74, "text": "Certainly! Here are some resourc"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.6, "tree_w": 38, "tree_size": 128, "t0": 0.64, "t1": 0.66, "tft": 2.0425, "input_0": 284, "input_1": 129, "min_CLP": -6.05, "draft_iters": 8.6, "mem_use": 34.6, "gen_rate": 4.4, "speed": 3.37, "text": "The most effective way to commit"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.6, "tree_w": 30, "tree_size": 128, "t0": 0.7825, "t1": 0.6625, "tft": 1.5504, "input_0": 314, "input_1": 129, "min_CLP": -5.67, "draft_iters": 10.6, "mem_use": 34.37, "gen_rate": 4.5, "speed": 3.11, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 17.5, "tree_w": 33, "tree_size": 128, "t0": 1.25, "t1": 0.71, "tft": 1.5663, "input_0": 218, "input_1": 129, "min_CLP": -5.6, "draft_iters": 18.5, "mem_use": 35.18, "gen_rate": 16.5, "speed": 8.42, "text": "[INST] Sorry, I will clarify. Pl"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.8, "tree_w": 19, "tree_size": 128, "t0": 1.2025, "t1": 0.705, "tft": 2.3342, "input_0": 373, "input_1": 129, "min_CLP": -5.6, "draft_iters": 16.8, "mem_use": 35.2, "gen_rate": 8.0, "speed": 4.2, "text": "Por supuesto, aqu\u00ed tienes mis tr"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 14.6, "tree_w": 20, "tree_size": 128, "t0": 1.1, "t1": 0.67, "tft": 4.2487, "input_0": 378, "input_1": 129, "min_CLP": -5.3, "draft_iters": 15.6, "mem_use": 37.71, "gen_rate": 7.6, "speed": 4.3, "text": "Step 1: Create a project directo"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.4, "tree_w": 28, "tree_size": 128, "t0": 0.838, "t1": 0.662, "tft": 1.4567, "input_0": 363, "input_1": 129, "min_CLP": -5.56, "draft_iters": 11.4, "mem_use": 34.38, "gen_rate": 7.2, "speed": 4.8, "text": "\"To reduce your alcohol consumpt"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.6, "tree_w": 36, "tree_size": 128, "t0": 0.6957, "t1": 0.6629, "tft": 1.6742, "input_0": 270, "input_1": 129, "min_CLP": -5.92, "draft_iters": 9.6, "mem_use": 34.94, "gen_rate": 4.6, "speed": 3.36, "text": "Berlin is home to a range of wel"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.7, "tree_w": 16, "tree_size": 128, "t0": 1.19, "t1": 0.6667, "tft": 1.4051, "input_0": 450, "input_1": 129, "min_CLP": -5.19, "draft_iters": 16.7, "mem_use": 34.41, "gen_rate": 11.0, "speed": 5.93, "text": "Certainly! Below is a Python scr"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 19.2, "tree_w": 20, "tree_size": 128, "t0": 1.3967, "t1": 0.6933, "tft": 2.685, "input_0": 363, "input_1": 129, "min_CLP": -5.34, "draft_iters": 20.0, "mem_use": 36.9, "gen_rate": 6.2, "speed": 2.95, "text": "\"Sure! Here's a recipe that you "}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 8.3, "tree_w": 34, "tree_size": 128, "t0": 0.6833, "t1": 0.6633, "tft": 1.0594, "input_0": 269, "input_1": 129, "min_CLP": -5.91, "draft_iters": 9.3, "mem_use": 34.32, "gen_rate": 3.6, "speed": 2.64, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.0, "tree_w": 24, "tree_size": 128, "t0": 0.9375, "t1": 0.6725, "tft": 3.0028, "input_0": 362, "input_1": 129, "min_CLP": -5.48, "draft_iters": 13.0, "mem_use": 36.59, "gen_rate": 9.0, "speed": 5.61, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 30, "tree_size": 128, "t0": 0.706, "t1": 0.658, "tft": 1.115, "input_0": 293, "input_1": 129, "min_CLP": -5.65, "draft_iters": 9.6, "mem_use": 34.34, "gen_rate": 6.4, "speed": 4.69, "text": "The \"Why do we need AI assistant"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 42, "tree_h": 6.6, "tree_w": 45, "tree_size": 128, "t0": 0.5546, "t1": 0.6608, "tft": 1.2652, "input_0": 195, "input_1": 129, "min_CLP": -6.7, "draft_iters": 7.6, "mem_use": 34.32, "gen_rate": 3.2, "speed": 2.66, "text": "\u4e0a\u9762\u8fd9\u53e5\u8bdd\u4e2d\u82f1\u53cc\u8bed\uff0c\u7531\u4f60\u6765\u7ffb\u8bd1\uff0c\u53ef\u4ee5\u5417\uff1f\\n\u6211\u9700\u8981\u4f60\u7684\u5e2e\u52a9\u6765\u7ffb\u8bd1"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.7, "tree_w": 26, "tree_size": 128, "t0": 0.845, "t1": 0.6767, "tft": 1.5503, "input_0": 299, "input_1": 129, "min_CLP": -5.44, "draft_iters": 11.7, "mem_use": 34.48, "gen_rate": 5.3, "speed": 3.5, "text": "\"Sure! One example of a complex "}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.4, "tree_w": 28, "tree_size": 128, "t0": 0.8429, "t1": 0.6829, "tft": 1.9353, "input_0": 342, "input_1": 129, "min_CLP": -5.52, "draft_iters": 11.4, "mem_use": 35.53, "gen_rate": 4.9, "speed": 3.18, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 9.7, "tree_w": 35, "tree_size": 128, "t0": 0.7667, "t1": 0.6733, "tft": 2.3307, "input_0": 261, "input_1": 129, "min_CLP": -5.83, "draft_iters": 10.7, "mem_use": 34.43, "gen_rate": 3.8, "speed": 2.63, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 12.5, "tree_w": 28, "tree_size": 128, "t0": 0.9775, "t1": 0.6913, "tft": 1.4539, "input_0": 327, "input_1": 129, "min_CLP": -5.68, "draft_iters": 13.5, "mem_use": 34.63, "gen_rate": 4.4, "speed": 2.62, "text": "Sure, in reStructuredText (rst),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.0, "tree_w": 33, "tree_size": 128, "t0": 0.6675, "t1": 0.6725, "tft": 1.7625, "input_0": 269, "input_1": 129, "min_CLP": -5.74, "draft_iters": 9.0, "mem_use": 34.97, "gen_rate": 4.0, "speed": 2.99, "text": "Selective fire refers to a weapo"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.3, "tree_w": 34, "tree_size": 128, "t0": 0.6886, "t1": 0.6586, "tft": 1.479, "input_0": 287, "input_1": 129, "min_CLP": -5.8, "draft_iters": 9.3, "mem_use": 34.52, "gen_rate": 5.6, "speed": 4.14, "text": "I am the goddess of love, beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 12.0, "tree_w": 23, "tree_size": 128, "t0": 0.925, "t1": 0.6725, "tft": 2.1314, "input_0": 334, "input_1": 129, "min_CLP": -5.24, "draft_iters": 13.0, "mem_use": 35.73, "gen_rate": 10.8, "speed": 6.73, "text": "On a Windows machine, you can us"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 36, "tree_size": 128, "t0": 0.7167, "t1": 0.665, "tft": 1.9387, "input_0": 276, "input_1": 129, "min_CLP": -5.75, "draft_iters": 9.8, "mem_use": 34.41, "gen_rate": 5.3, "speed": 3.86, "text": "\"I disagree with the statement t"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.8, "tree_w": 21, "tree_size": 128, "t0": 1.074, "t1": 0.68, "tft": 1.9321, "input_0": 415, "input_1": 129, "min_CLP": -5.41, "draft_iters": 14.8, "mem_use": 35.25, "gen_rate": 7.6, "speed": 4.33, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.6, "tree_w": 34, "tree_size": 128, "t0": 0.7063, "t1": 0.6688, "tft": 2.2726, "input_0": 268, "input_1": 129, "min_CLP": -5.7, "draft_iters": 9.6, "mem_use": 34.52, "gen_rate": 4.1, "speed": 3.01, "text": "Pros:\\n1. Improved ability to wi"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.3, "tree_w": 29, "tree_size": 128, "t0": 0.8883, "t1": 0.6933, "tft": 1.3356, "input_0": 263, "input_1": 129, "min_CLP": -5.76, "draft_iters": 12.3, "mem_use": 34.35, "gen_rate": 6.8, "speed": 4.32, "text": "\"What happened to schrodinger's "}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.3, "tree_w": 28, "tree_size": 128, "t0": 0.8733, "t1": 0.6733, "tft": 3.7736, "input_0": 328, "input_1": 129, "min_CLP": -5.58, "draft_iters": 12.3, "mem_use": 38.63, "gen_rate": 5.7, "speed": 3.67, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.6, "tree_w": 24, "tree_size": 128, "t0": 0.78, "t1": 0.662, "tft": 1.3049, "input_0": 353, "input_1": 129, "min_CLP": -5.48, "draft_iters": 10.6, "mem_use": 34.65, "gen_rate": 6.6, "speed": 4.57, "text": "\"Approaching a technical problem"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.3, "tree_w": 29, "tree_size": 128, "t0": 0.9567, "t1": 0.68, "tft": 2.443, "input_0": 371, "input_1": 129, "min_CLP": -5.63, "draft_iters": 13.3, "mem_use": 35.53, "gen_rate": 11.0, "speed": 6.71, "text": "It would take approximately 18 m"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 7.3, "tree_w": 38, "tree_size": 128, "t0": 0.601, "t1": 0.653, "tft": 2.3302, "input_0": 265, "input_1": 129, "min_CLP": -5.79, "draft_iters": 8.3, "mem_use": 36.78, "gen_rate": 3.7, "speed": 2.95, "text": "To prevent spiders from spawning"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 40, "tree_h": 7.4, "tree_w": 41, "tree_size": 128, "t0": 0.613, "t1": 0.664, "tft": 2.1595, "input_0": 225, "input_1": 129, "min_CLP": -6.19, "draft_iters": 8.4, "mem_use": 34.63, "gen_rate": 4.0, "speed": 3.14, "text": "\"If your computer is a Mac, your"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.5, "tree_w": 26, "tree_size": 128, "t0": 1.1625, "t1": 0.6875, "tft": 2.3684, "input_0": 337, "input_1": 129, "min_CLP": -5.65, "draft_iters": 16.5, "mem_use": 34.67, "gen_rate": 8.0, "speed": 4.33, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 30, "tree_size": 128, "t0": 0.7533, "t1": 0.6767, "tft": 2.0665, "input_0": 299, "input_1": 129, "min_CLP": -5.7, "draft_iters": 10.3, "mem_use": 35.14, "gen_rate": 5.8, "speed": 4.09, "text": "There are several 3D animation p"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 25.5, "tree_w": 23, "tree_size": 128, "t0": 1.805, "t1": 0.725, "tft": 2.1409, "input_0": 370, "input_1": 129, "min_CLP": -5.67, "draft_iters": 26.0, "mem_use": 34.65, "gen_rate": 19.5, "speed": 7.72, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 8.1, "tree_w": 37, "tree_size": 128, "t0": 0.6656, "t1": 0.6644, "tft": 1.8914, "input_0": 265, "input_1": 129, "min_CLP": -5.99, "draft_iters": 9.1, "mem_use": 35.33, "gen_rate": 3.9, "speed": 2.92, "text": "The Transactional Interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 29.5, "tree_w": 30, "tree_size": 128, "t0": 2.05, "t1": 0.72, "tft": 1.5672, "input_0": 349, "input_1": 129, "min_CLP": -5.94, "draft_iters": 30.0, "mem_use": 34.67, "gen_rate": 19.5, "speed": 7.04, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 27, "tree_size": 128, "t0": 0.875, "t1": 0.68, "tft": 1.8054, "input_0": 290, "input_1": 129, "min_CLP": -5.5, "draft_iters": 12.2, "mem_use": 34.4, "gen_rate": 8.5, "speed": 5.48, "text": "Here are the key components of a"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.7, "tree_w": 25, "tree_size": 128, "t0": 0.9217, "t1": 0.675, "tft": 1.3978, "input_0": 323, "input_1": 129, "min_CLP": -5.47, "draft_iters": 12.7, "mem_use": 34.36, "gen_rate": 5.8, "speed": 3.66, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 15, "tree_h": 10.0, "tree_w": 32, "tree_size": 128, "t0": 0.81, "t1": 0.67, "tft": 3.0328, "input_0": 388, "input_1": 129, "min_CLP": -5.46, "draft_iters": 11.0, "mem_use": 38.61, "gen_rate": 7.5, "speed": 5.09, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 8.0, "tree_w": 30, "tree_size": 128, "t0": 0.6633, "t1": 0.6533, "tft": 1.5286, "input_0": 319, "input_1": 129, "min_CLP": -5.46, "draft_iters": 9.0, "mem_use": 34.5, "gen_rate": 4.7, "speed": 3.54, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 14.0, "tree_w": 27, "tree_size": 128, "t0": 1.074, "t1": 0.678, "tft": 2.4148, "input_0": 366, "input_1": 129, "min_CLP": -5.53, "draft_iters": 15.0, "mem_use": 36.05, "gen_rate": 7.2, "speed": 4.11, "text": "To produce F-centers in carbon c"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.0, "tree_w": 22, "tree_size": 128, "t0": 1.1425, "t1": 0.6975, "tft": 2.0042, "input_0": 379, "input_1": 129, "min_CLP": -5.54, "draft_iters": 16.0, "mem_use": 35.78, "gen_rate": 8.0, "speed": 4.35, "text": "In option \"2. Use the Command Pr"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 19.2, "tree_w": 16, "tree_size": 128, "t0": 1.41, "t1": 0.68, "tft": 1.8983, "input_0": 388, "input_1": 129, "min_CLP": -5.52, "draft_iters": 20.0, "mem_use": 34.62, "gen_rate": 9.2, "speed": 4.42, "text": "Using critical thinking methods,"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.0, "tree_w": 19, "tree_size": 128, "t0": 1.0725, "t1": 0.6675, "tft": 2.3314, "input_0": 383, "input_1": 129, "min_CLP": -5.41, "draft_iters": 15.0, "mem_use": 34.44, "gen_rate": 10.0, "speed": 5.75, "text": "Sure! To make a dye from mixed H"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 59, "tree_h": 21.0, "tree_w": 30, "tree_size": 128, "t0": 1.5333, "t1": 0.6967, "tft": 1.5992, "input_0": 369, "input_1": 129, "min_CLP": -6.56, "draft_iters": 21.7, "mem_use": 34.42, "gen_rate": 19.7, "speed": 8.82, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 12.2, "tree_w": 23, "tree_size": 128, "t0": 0.956, "t1": 0.686, "tft": 1.6312, "input_0": 353, "input_1": 129, "min_CLP": -5.52, "draft_iters": 13.2, "mem_use": 35.41, "gen_rate": 8.2, "speed": 4.99, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 47, "tree_h": 13.0, "tree_w": 31, "tree_size": 128, "t0": 0.99, "t1": 0.6914, "tft": 1.3978, "input_0": 275, "input_1": 129, "min_CLP": -5.64, "draft_iters": 14.0, "mem_use": 34.75, "gen_rate": 6.7, "speed": 4.0, "text": "Could you please provide a brief"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.5, "tree_w": 24, "tree_size": 128, "t0": 1.09, "t1": 0.6775, "tft": 2.3691, "input_0": 332, "input_1": 129, "min_CLP": -5.67, "draft_iters": 15.5, "mem_use": 36.09, "gen_rate": 8.0, "speed": 4.52, "text": "Here are the feminine words rela"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.3, "tree_w": 40, "tree_size": 128, "t0": 0.6022, "t1": 0.6533, "tft": 1.3533, "input_0": 236, "input_1": 129, "min_CLP": -5.98, "draft_iters": 8.3, "mem_use": 34.98, "gen_rate": 4.1, "speed": 3.27, "text": "I think one can conclude that th"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.0, "tree_w": 39, "tree_size": 128, "t0": 0.8, "t1": 0.6729, "tft": 1.741, "input_0": 285, "input_1": 129, "min_CLP": -5.83, "draft_iters": 11.0, "mem_use": 34.82, "gen_rate": 5.0, "speed": 3.4, "text": "In that case, yes, the ATF has b"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 25, "tree_size": 128, "t0": 0.8725, "t1": 0.675, "tft": 1.4958, "input_0": 301, "input_1": 129, "min_CLP": -5.51, "draft_iters": 12.2, "mem_use": 34.56, "gen_rate": 8.5, "speed": 5.5, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 13, "tree_size": 128, "t0": 2.16, "t1": 0.72, "tft": 2.6714, "input_0": 339, "input_1": 129, "min_CLP": -6.39, "draft_iters": 32.0, "mem_use": 37.34, "gen_rate": 33.0, "speed": 11.46, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 32.0, "tree_w": 10, "tree_size": 128, "t0": 2.195, "t1": 0.7, "tft": 4.0069, "input_0": 455, "input_1": 129, "min_CLP": -5.78, "draft_iters": 32.0, "mem_use": 37.27, "gen_rate": 24.5, "speed": 8.46, "text": "Once upon a time, in the city of"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.4, "tree_w": 33, "tree_size": 128, "t0": 0.832, "t1": 0.664, "tft": 1.2585, "input_0": 318, "input_1": 129, "min_CLP": -6.08, "draft_iters": 11.4, "mem_use": 34.35, "gen_rate": 7.6, "speed": 5.08, "text": "```python\\ndef generate_neruda_p"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 32.0, "tree_w": 15, "tree_size": 128, "t0": 2.245, "t1": 0.71, "tft": 2.04, "input_0": 568, "input_1": 129, "min_CLP": -5.7, "draft_iters": 32.0, "mem_use": 35.51, "gen_rate": 18.5, "speed": 6.26, "text": "Absolutely! Here is the updated "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 15.8, "tree_w": 17, "tree_size": 128, "t0": 1.196, "t1": 0.676, "tft": 2.1658, "input_0": 391, "input_1": 129, "min_CLP": -5.05, "draft_iters": 16.8, "mem_use": 35.99, "gen_rate": 7.0, "speed": 3.73, "text": "\"I apologize for my earlier resp"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.0, "tree_w": 19, "tree_size": 128, "t0": 1.215, "t1": 0.685, "tft": 1.2629, "input_0": 417, "input_1": 129, "min_CLP": -5.05, "draft_iters": 17.0, "mem_use": 34.34, "gen_rate": 9.5, "speed": 4.99, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.9, "tree_w": 46, "tree_size": 128, "t0": 0.5788, "t1": 0.6575, "tft": 2.0532, "input_0": 238, "input_1": 129, "min_CLP": -6.31, "draft_iters": 7.9, "mem_use": 34.63, "gen_rate": 4.0, "speed": 3.24, "text": "I shall not comply with your req"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.0, "tree_w": 19, "tree_size": 128, "t0": 1.355, "t1": 0.6825, "tft": 3.1633, "input_0": 469, "input_1": 129, "min_CLP": -5.48, "draft_iters": 19.0, "mem_use": 36.23, "gen_rate": 8.0, "speed": 3.93, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 20.7, "tree_w": 23, "tree_size": 128, "t0": 1.49, "t1": 0.7033, "tft": 2.3287, "input_0": 389, "input_1": 129, "min_CLP": -5.78, "draft_iters": 21.3, "mem_use": 34.57, "gen_rate": 11.3, "speed": 5.17, "text": "The task is to explain how it mi"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 17.0, "tree_w": 19, "tree_size": 128, "t0": 1.2667, "t1": 0.68, "tft": 2.0021, "input_0": 393, "input_1": 129, "min_CLP": -5.34, "draft_iters": 18.0, "mem_use": 35.94, "gen_rate": 11.3, "speed": 5.81, "text": "\"Certainly! Here's a more detail"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.5, "tree_w": 24, "tree_size": 128, "t0": 1.525, "t1": 0.68, "tft": 1.2568, "input_0": 332, "input_1": 129, "min_CLP": -5.77, "draft_iters": 22.0, "mem_use": 34.37, "gen_rate": 19.5, "speed": 8.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.8, "tree_w": 24, "tree_size": 128, "t0": 0.944, "t1": 0.67, "tft": 1.6768, "input_0": 404, "input_1": 129, "min_CLP": -5.31, "draft_iters": 12.8, "mem_use": 34.38, "gen_rate": 7.6, "speed": 4.72, "text": "To cook a salmon fillet on a sto"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 58, "tree_h": 18.0, "tree_w": 23, "tree_size": 128, "t0": 1.322, "t1": 0.71, "tft": 1.3559, "input_0": 328, "input_1": 129, "min_CLP": -5.38, "draft_iters": 18.8, "mem_use": 35.02, "gen_rate": 11.6, "speed": 5.71, "text": "\"Alright, I'll do both. Here's m"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 18.8, "tree_w": 26, "tree_size": 128, "t0": 1.3617, "t1": 0.6967, "tft": 2.0581, "input_0": 291, "input_1": 129, "min_CLP": -5.76, "draft_iters": 19.7, "mem_use": 35.25, "gen_rate": 7.5, "speed": 3.64, "text": "You are correct, I apologize for"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.4, "tree_w": 28, "tree_size": 128, "t0": 0.89, "t1": 0.674, "tft": 1.4028, "input_0": 321, "input_1": 129, "min_CLP": -5.86, "draft_iters": 12.4, "mem_use": 34.36, "gen_rate": 7.0, "speed": 4.48, "text": "An AK-47, also known as the Kala"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.8, "tree_w": 22, "tree_size": 128, "t0": 1.0, "t1": 0.674, "tft": 1.528, "input_0": 389, "input_1": 129, "min_CLP": -5.26, "draft_iters": 13.8, "mem_use": 34.7, "gen_rate": 7.0, "speed": 4.18, "text": "\"To copy a directory of files fr"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 23.0, "tree_w": 25, "tree_size": 128, "t0": 1.66, "t1": 0.71, "tft": 2.0528, "input_0": 397, "input_1": 129, "min_CLP": -5.72, "draft_iters": 24.0, "mem_use": 36.11, "gen_rate": 16.5, "speed": 6.97, "text": "* Stats modeling: applying stats"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 14.3, "tree_w": 16, "tree_size": 128, "t0": 1.11, "t1": 0.67, "tft": 2.391, "input_0": 417, "input_1": 129, "min_CLP": -5.18, "draft_iters": 15.3, "mem_use": 34.68, "gen_rate": 13.0, "speed": 7.32, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.7, "tree_w": 33, "tree_size": 128, "t0": 0.7186, "t1": 0.6657, "tft": 1.8438, "input_0": 316, "input_1": 129, "min_CLP": -5.71, "draft_iters": 9.7, "mem_use": 35.18, "gen_rate": 5.1, "speed": 3.71, "text": "No, there is no harm in letting "}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 5.4, "tree_w": 51, "tree_size": 128, "t0": 0.475, "t1": 0.654, "tft": 1.3197, "input_0": 197, "input_1": 129, "min_CLP": -6.23, "draft_iters": 6.4, "mem_use": 34.83, "gen_rate": 3.3, "speed": 2.93, "text": "You should try to find some comm"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.1, "tree_w": 36, "tree_size": 128, "t0": 0.6757, "t1": 0.6643, "tft": 1.3942, "input_0": 288, "input_1": 129, "min_CLP": -5.75, "draft_iters": 9.1, "mem_use": 34.94, "gen_rate": 4.6, "speed": 3.42, "text": "The given conversation delves in"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.9, "tree_w": 39, "tree_size": 128, "t0": 0.6429, "t1": 0.66, "tft": 0.9902, "input_0": 249, "input_1": 129, "min_CLP": -5.87, "draft_iters": 8.9, "mem_use": 34.34, "gen_rate": 4.9, "speed": 3.73, "text": "I am thinking of a beautiful sun"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.2, "tree_w": 33, "tree_size": 128, "t0": 0.84, "t1": 0.6575, "tft": 1.1262, "input_0": 386, "input_1": 129, "min_CLP": -5.73, "draft_iters": 11.2, "mem_use": 34.35, "gen_rate": 9.0, "speed": 6.01, "text": "Cryptocurrencies have come a lon"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 7, "tree_size": 128, "t0": 2.23, "t1": 0.71, "tft": 1.9311, "input_0": 617, "input_1": 129, "min_CLP": -5.73, "draft_iters": 32.0, "mem_use": 34.88, "gen_rate": 33.0, "speed": 11.24, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 25.7, "tree_w": 10, "tree_size": 128, "t0": 1.84, "t1": 0.7233, "tft": 1.2565, "input_0": 392, "input_1": 129, "min_CLP": -5.02, "draft_iters": 26.3, "mem_use": 34.65, "gen_rate": 13.7, "speed": 5.33, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.8, "tree_w": 41, "tree_size": 128, "t0": 0.708, "t1": 0.658, "tft": 1.4938, "input_0": 265, "input_1": 129, "min_CLP": -6.33, "draft_iters": 9.8, "mem_use": 34.44, "gen_rate": 7.0, "speed": 5.12, "text": "The phone conversation in the mo"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.8, "tree_w": 30, "tree_size": 128, "t0": 0.7725, "t1": 0.6625, "tft": 2.0532, "input_0": 286, "input_1": 129, "min_CLP": -5.66, "draft_iters": 10.8, "mem_use": 34.4, "gen_rate": 9.0, "speed": 6.25, "text": "In the city, there is a lot of l"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.7, "tree_w": 27, "tree_size": 128, "t0": 0.77, "t1": 0.6729, "tft": 1.5399, "input_0": 265, "input_1": 129, "min_CLP": -5.81, "draft_iters": 10.7, "mem_use": 34.96, "gen_rate": 5.0, "speed": 3.47, "text": "The Windows XP background image,"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.7, "tree_w": 40, "tree_size": 128, "t0": 0.5643, "t1": 0.6614, "tft": 2.7465, "input_0": 264, "input_1": 129, "min_CLP": -5.76, "draft_iters": 7.7, "mem_use": 38.01, "gen_rate": 4.7, "speed": 3.83, "text": "\"Using your neighbor's gas to he"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.5, "tree_w": 38, "tree_size": 128, "t0": 0.6883, "t1": 0.67, "tft": 2.2496, "input_0": 281, "input_1": 129, "min_CLP": -5.66, "draft_iters": 9.5, "mem_use": 36.75, "gen_rate": 5.3, "speed": 3.92, "text": "\"It's possible that we never had"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.9, "tree_w": 35, "tree_size": 128, "t0": 0.6557, "t1": 0.6686, "tft": 1.6996, "input_0": 271, "input_1": 129, "min_CLP": -5.77, "draft_iters": 8.9, "mem_use": 35.02, "gen_rate": 4.7, "speed": 3.56, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.5, "tree_w": 26, "tree_size": 128, "t0": 1.525, "t1": 0.72, "tft": 1.3355, "input_0": 324, "input_1": 129, "min_CLP": -5.65, "draft_iters": 22.0, "mem_use": 34.36, "gen_rate": 19.5, "speed": 8.68, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 7.0, "tree_w": 39, "tree_size": 128, "t0": 0.5875, "t1": 0.655, "tft": 1.2766, "input_0": 240, "input_1": 129, "min_CLP": -5.83, "draft_iters": 8.0, "mem_use": 34.34, "gen_rate": 3.0, "speed": 2.41, "text": "Yes, I can speak German. I can h"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.2, "tree_w": 27, "tree_size": 128, "t0": 1.195, "t1": 0.695, "tft": 1.4147, "input_0": 309, "input_1": 129, "min_CLP": -5.72, "draft_iters": 17.0, "mem_use": 34.54, "gen_rate": 9.5, "speed": 5.02, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 29, "tree_size": 128, "t0": 0.83, "t1": 0.6875, "tft": 1.9203, "input_0": 315, "input_1": 129, "min_CLP": -5.42, "draft_iters": 11.5, "mem_use": 35.42, "gen_rate": 8.0, "speed": 5.28, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.2, "tree_w": 22, "tree_size": 128, "t0": 0.95, "t1": 0.67, "tft": 2.6995, "input_0": 375, "input_1": 129, "min_CLP": -5.54, "draft_iters": 13.2, "mem_use": 36.04, "gen_rate": 6.8, "speed": 4.2, "text": "Yes, AI image generators such as"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 44, "tree_size": 128, "t0": 0.61, "t1": 0.6617, "tft": 1.7903, "input_0": 234, "input_1": 129, "min_CLP": -6.13, "draft_iters": 8.3, "mem_use": 34.4, "gen_rate": 5.3, "speed": 4.2, "text": "Sure, here are some haikus for d"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 49, "tree_h": 13.9, "tree_w": 37, "tree_size": 128, "t0": 1.05, "t1": 0.6886, "tft": 2.5299, "input_0": 281, "input_1": 129, "min_CLP": -5.96, "draft_iters": 14.9, "mem_use": 34.76, "gen_rate": 7.0, "speed": 4.03, "text": "\"o\\n     /|\\\\\\n     / \\\\\\n   /|\\"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 22.0, "tree_w": 26, "tree_size": 128, "t0": 1.57, "t1": 0.705, "tft": 1.3572, "input_0": 367, "input_1": 129, "min_CLP": -6.03, "draft_iters": 22.5, "mem_use": 34.36, "gen_rate": 19.5, "speed": 8.59, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.7, "tree_w": 29, "tree_size": 128, "t0": 0.9617, "t1": 0.6733, "tft": 2.026, "input_0": 296, "input_1": 129, "min_CLP": -5.62, "draft_iters": 13.5, "mem_use": 34.71, "gen_rate": 6.2, "speed": 3.77, "text": "Yes, there is a true, most ethic"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 8.0, "tree_w": 32, "tree_size": 128, "t0": 0.67, "t1": 0.66, "tft": 1.5871, "input_0": 306, "input_1": 129, "min_CLP": -5.67, "draft_iters": 9.0, "mem_use": 34.63, "gen_rate": 4.2, "speed": 3.2, "text": "\"It seems like you're working on"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.9, "tree_w": 31, "tree_size": 128, "t0": 0.7, "t1": 0.6571, "tft": 2.3724, "input_0": 242, "input_1": 129, "min_CLP": -5.64, "draft_iters": 9.9, "mem_use": 36.67, "gen_rate": 4.7, "speed": 3.48, "text": "\"[INST] I'm all ears, chef. What"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.5, "tree_w": 38, "tree_size": 128, "t0": 0.695, "t1": 0.6713, "tft": 1.7847, "input_0": 252, "input_1": 129, "min_CLP": -5.89, "draft_iters": 9.5, "mem_use": 34.52, "gen_rate": 4.6, "speed": 3.39, "text": "\"Certainly! Here's an ASCII art "}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.2, "tree_w": 39, "tree_size": 128, "t0": 0.6038, "t1": 0.6663, "tft": 2.3524, "input_0": 258, "input_1": 129, "min_CLP": -6.04, "draft_iters": 8.2, "mem_use": 37.36, "gen_rate": 4.2, "speed": 3.35, "text": "As I step into the dimly lit roo"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.5, "tree_w": 32, "tree_size": 128, "t0": 0.6867, "t1": 0.655, "tft": 1.3962, "input_0": 274, "input_1": 129, "min_CLP": -5.69, "draft_iters": 9.5, "mem_use": 34.39, "gen_rate": 5.7, "speed": 4.22, "text": "\"Sure, I can create ASCII art fo"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.2, "tree_w": 21, "tree_size": 128, "t0": 1.04, "t1": 0.6775, "tft": 1.6048, "input_0": 404, "input_1": 129, "min_CLP": -5.33, "draft_iters": 14.2, "mem_use": 34.35, "gen_rate": 9.0, "speed": 5.23, "text": "The primary difference between H"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.8, "tree_w": 23, "tree_size": 128, "t0": 1.008, "t1": 0.676, "tft": 1.403, "input_0": 370, "input_1": 129, "min_CLP": -5.31, "draft_iters": 13.8, "mem_use": 34.37, "gen_rate": 6.6, "speed": 3.92, "text": "Certainly! Below is a table list"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.2, "tree_w": 29, "tree_size": 128, "t0": 0.8767, "t1": 0.665, "tft": 2.4039, "input_0": 321, "input_1": 129, "min_CLP": -5.67, "draft_iters": 12.2, "mem_use": 34.74, "gen_rate": 6.0, "speed": 3.89, "text": "Yes, the image is protected by c"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.0, "tree_w": 30, "tree_size": 128, "t0": 0.7388, "t1": 0.6625, "tft": 1.3985, "input_0": 324, "input_1": 129, "min_CLP": -5.53, "draft_iters": 10.0, "mem_use": 34.36, "gen_rate": 4.5, "speed": 3.21, "text": "\"The second batch of pancakes br"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 23.0, "tree_w": 17, "tree_size": 128, "t0": 1.684, "t1": 0.7, "tft": 3.1767, "input_0": 446, "input_1": 129, "min_CLP": -5.12, "draft_iters": 24.0, "mem_use": 35.41, "gen_rate": 7.0, "speed": 2.94, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 36, "tree_size": 128, "t0": 0.6567, "t1": 0.6617, "tft": 1.8397, "input_0": 282, "input_1": 129, "min_CLP": -5.66, "draft_iters": 9.0, "mem_use": 35.13, "gen_rate": 5.5, "speed": 4.17, "text": "\"If you're looking for a high-ra"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.8, "tree_w": 48, "tree_size": 128, "t0": 0.5712, "t1": 0.66, "tft": 1.4016, "input_0": 228, "input_1": 129, "min_CLP": -6.17, "draft_iters": 7.8, "mem_use": 34.97, "gen_rate": 4.1, "speed": 3.35, "text": "\"Depends on the game. \\nYou can'"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.7, "tree_w": 38, "tree_size": 128, "t0": 0.6986, "t1": 0.6814, "tft": 1.6301, "input_0": 255, "input_1": 129, "min_CLP": -5.77, "draft_iters": 9.7, "mem_use": 35.69, "gen_rate": 4.7, "speed": 3.43, "text": "\"That's a wonderful approach to "}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.9, "tree_w": 42, "tree_size": 128, "t0": 0.5763, "t1": 0.6562, "tft": 0.9846, "input_0": 211, "input_1": 129, "min_CLP": -5.93, "draft_iters": 7.9, "mem_use": 34.33, "gen_rate": 4.6, "speed": 3.75, "text": "\"Here's a simple ASCII art of a "}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 7.7, "tree_w": 39, "tree_size": 128, "t0": 0.6371, "t1": 0.6571, "tft": 1.3758, "input_0": 261, "input_1": 129, "min_CLP": -6.22, "draft_iters": 8.7, "mem_use": 34.65, "gen_rate": 5.1, "speed": 3.98, "text": "I\\'ve been called by different n"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.7, "tree_w": 28, "tree_size": 128, "t0": 0.7117, "t1": 0.6633, "tft": 2.3334, "input_0": 331, "input_1": 129, "min_CLP": -5.62, "draft_iters": 9.7, "mem_use": 35.39, "gen_rate": 5.7, "speed": 4.12, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 6.8, "tree_w": 38, "tree_size": 128, "t0": 0.57, "t1": 0.6489, "tft": 1.4112, "input_0": 242, "input_1": 129, "min_CLP": -5.69, "draft_iters": 7.8, "mem_use": 34.45, "gen_rate": 4.2, "speed": 3.46, "text": "Motion matching is a technique u"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 60, "tree_h": 30.8, "tree_w": 9, "tree_size": 128, "t0": 2.1775, "t1": 0.715, "tft": 3.436, "input_0": 529, "input_1": 129, "min_CLP": -5.04, "draft_iters": 31.0, "mem_use": 36.1, "gen_rate": 15.0, "speed": 5.19, "text": "Sure, here\\'s an updated version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 18.5, "tree_w": 39, "tree_size": 128, "t0": 1.325, "t1": 0.7, "tft": 1.3405, "input_0": 224, "input_1": 129, "min_CLP": -6.07, "draft_iters": 19.5, "mem_use": 34.4, "gen_rate": 16.0, "speed": 7.91, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 30.5, "tree_w": 19, "tree_size": 128, "t0": 2.175, "t1": 0.71, "tft": 1.5029, "input_0": 528, "input_1": 129, "min_CLP": -6.99, "draft_iters": 31.0, "mem_use": 34.78, "gen_rate": 25.5, "speed": 8.85, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.0, "tree_w": 26, "tree_size": 128, "t0": 0.8567, "t1": 0.665, "tft": 2.584, "input_0": 307, "input_1": 129, "min_CLP": -5.73, "draft_iters": 12.0, "mem_use": 36.11, "gen_rate": 5.3, "speed": 3.5, "text": "The idea of \"100 monkeys on a ty"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.0, "tree_w": 31, "tree_size": 128, "t0": 0.795, "t1": 0.6567, "tft": 2.128, "input_0": 338, "input_1": 129, "min_CLP": -5.63, "draft_iters": 11.0, "mem_use": 36.53, "gen_rate": 6.3, "speed": 4.36, "text": "Paul Allen has a wide variety of"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 34, "tree_size": 128, "t0": 0.7083, "t1": 0.655, "tft": 2.1564, "input_0": 286, "input_1": 129, "min_CLP": -6.01, "draft_iters": 9.8, "mem_use": 35.99, "gen_rate": 5.3, "speed": 3.92, "text": "\"Sure, one example of a similar "}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 26.5, "tree_w": 26, "tree_size": 128, "t0": 1.875, "t1": 0.74, "tft": 2.0475, "input_0": 352, "input_1": 129, "min_CLP": -5.6, "draft_iters": 27.0, "mem_use": 34.43, "gen_rate": 19.5, "speed": 7.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.0, "tree_w": 32, "tree_size": 128, "t0": 0.6583, "t1": 0.665, "tft": 1.4364, "input_0": 282, "input_1": 129, "min_CLP": -5.69, "draft_iters": 9.0, "mem_use": 35.05, "gen_rate": 5.5, "speed": 4.15, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 24.0, "tree_w": 21, "tree_size": 128, "t0": 1.6967, "t1": 0.71, "tft": 2.6178, "input_0": 301, "input_1": 129, "min_CLP": -6.46, "draft_iters": 24.7, "mem_use": 34.46, "gen_rate": 15.3, "speed": 6.38, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.2, "tree_w": 37, "tree_size": 128, "t0": 0.6738, "t1": 0.665, "tft": 1.3549, "input_0": 240, "input_1": 129, "min_CLP": -5.74, "draft_iters": 9.2, "mem_use": 34.35, "gen_rate": 4.0, "speed": 2.99, "text": "Yes, the 5-second rule is a popu"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.8, "tree_w": 32, "tree_size": 128, "t0": 0.845, "t1": 0.6767, "tft": 1.5745, "input_0": 276, "input_1": 129, "min_CLP": -5.64, "draft_iters": 11.8, "mem_use": 35.18, "gen_rate": 5.3, "speed": 3.5, "text": "\"You're welcome! \ud83d\ude0a\\n[INST] Do yo"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.8, "tree_w": 24, "tree_size": 128, "t0": 1.125, "t1": 0.6725, "tft": 2.0972, "input_0": 389, "input_1": 129, "min_CLP": -5.38, "draft_iters": 15.8, "mem_use": 36.01, "gen_rate": 8.0, "speed": 4.44, "text": "\"It is not possible to completel"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.4, "tree_w": 37, "tree_size": 128, "t0": 0.696, "t1": 0.666, "tft": 2.7343, "input_0": 318, "input_1": 129, "min_CLP": -5.96, "draft_iters": 9.4, "mem_use": 36.89, "gen_rate": 6.4, "speed": 4.7, "text": "\"Multi-track drifting\" is a solu"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.3, "tree_w": 28, "tree_size": 128, "t0": 0.8333, "t1": 0.6683, "tft": 2.1027, "input_0": 368, "input_1": 129, "min_CLP": -5.71, "draft_iters": 11.3, "mem_use": 35.49, "gen_rate": 6.3, "speed": 4.22, "text": "\"Yes, it is theoretically possib"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 23, "tree_size": 128, "t0": 2.13, "t1": 0.7, "tft": 3.1828, "input_0": 294, "input_1": 129, "min_CLP": -5.74, "draft_iters": 32.0, "mem_use": 35.32, "gen_rate": 33.0, "speed": 11.65, "text": "\"My love, you're the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 34, "tree_size": 128, "t0": 0.7617, "t1": 0.6817, "tft": 2.3797, "input_0": 282, "input_1": 129, "min_CLP": -5.91, "draft_iters": 10.5, "mem_use": 35.09, "gen_rate": 5.3, "speed": 3.7, "text": "In Japanese, the words for \"love"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.3, "tree_w": 33, "tree_size": 128, "t0": 0.74, "t1": 0.6686, "tft": 1.9694, "input_0": 281, "input_1": 129, "min_CLP": -5.83, "draft_iters": 10.3, "mem_use": 34.64, "gen_rate": 5.0, "speed": 3.55, "text": "In Canada, the University of Tor"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.7, "tree_w": 28, "tree_size": 128, "t0": 0.7917, "t1": 0.665, "tft": 1.1979, "input_0": 351, "input_1": 129, "min_CLP": -5.53, "draft_iters": 10.7, "mem_use": 34.33, "gen_rate": 5.5, "speed": 3.78, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 25.3, "tree_w": 13, "tree_size": 128, "t0": 1.8667, "t1": 0.69, "tft": 1.6832, "input_0": 546, "input_1": 129, "min_CLP": -4.94, "draft_iters": 26.3, "mem_use": 34.47, "gen_rate": 18.0, "speed": 7.04, "text": "\"Sure, here's an example of a C+"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 34, "tree_size": 128, "t0": 0.7383, "t1": 0.6717, "tft": 1.8959, "input_0": 282, "input_1": 129, "min_CLP": -5.58, "draft_iters": 10.3, "mem_use": 35.58, "gen_rate": 5.8, "speed": 4.13, "text": "1. Financial stress can be addre"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 18, "tree_h": 7.0, "tree_w": 41, "tree_size": 128, "t0": 0.5867, "t1": 0.6517, "tft": 1.0652, "input_0": 251, "input_1": 129, "min_CLP": -6.01, "draft_iters": 8.0, "mem_use": 34.33, "gen_rate": 3.0, "speed": 2.42, "text": "I\\'m here to assist you! You can"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.7, "tree_w": 21, "tree_size": 128, "t0": 1.13, "t1": 0.6633, "tft": 2.5052, "input_0": 548, "input_1": 129, "min_CLP": -5.52, "draft_iters": 15.7, "mem_use": 36.98, "gen_rate": 10.7, "speed": 5.94, "text": "\"One example of where you might "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.3, "tree_w": 26, "tree_size": 128, "t0": 0.825, "t1": 0.6617, "tft": 2.2149, "input_0": 336, "input_1": 129, "min_CLP": -5.64, "draft_iters": 11.3, "mem_use": 34.62, "gen_rate": 6.7, "speed": 4.49, "text": "Yes, hairy bittercress (Cardamin"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 8.0, "tree_w": 38, "tree_size": 128, "t0": 0.6573, "t1": 0.6627, "tft": 1.5339, "input_0": 244, "input_1": 129, "min_CLP": -6.23, "draft_iters": 9.0, "mem_use": 34.41, "gen_rate": 2.9, "speed": 2.2, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 13.5, "tree_w": 19, "tree_size": 128, "t0": 1.03, "t1": 0.67, "tft": 2.7503, "input_0": 375, "input_1": 129, "min_CLP": -5.32, "draft_iters": 14.5, "mem_use": 36.58, "gen_rate": 6.5, "speed": 3.82, "text": "Yes, here are some open-source A"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 24.0, "tree_w": 19, "tree_size": 128, "t0": 1.69, "t1": 0.71, "tft": 2.1829, "input_0": 344, "input_1": 129, "min_CLP": -6.58, "draft_iters": 24.5, "mem_use": 34.4, "gen_rate": 22.5, "speed": 9.37, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.4, "tree_w": 38, "tree_size": 128, "t0": 0.762, "t1": 0.66, "tft": 2.11, "input_0": 324, "input_1": 129, "min_CLP": -6.05, "draft_iters": 10.4, "mem_use": 35.1, "gen_rate": 8.2, "speed": 5.77, "text": "Not sure what you mean by \"Unus "}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 26.0, "tree_w": 12, "tree_size": 128, "t0": 1.8467, "t1": 0.6967, "tft": 3.0157, "input_0": 427, "input_1": 129, "min_CLP": -5.27, "draft_iters": 26.3, "mem_use": 36.0, "gen_rate": 12.3, "speed": 4.85, "text": "1. m\u00eb (me)\\n2. meles (meles)\\n3."}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.2, "tree_w": 25, "tree_size": 128, "t0": 0.828, "t1": 0.666, "tft": 1.4509, "input_0": 354, "input_1": 129, "min_CLP": -5.61, "draft_iters": 11.2, "mem_use": 34.65, "gen_rate": 7.2, "speed": 4.82, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.0, "tree_w": 23, "tree_size": 128, "t0": 1.3225, "t1": 0.68, "tft": 2.5416, "input_0": 425, "input_1": 129, "min_CLP": -5.47, "draft_iters": 18.8, "mem_use": 37.42, "gen_rate": 10.5, "speed": 5.25, "text": "\"I apologize for any confusion c"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.4, "tree_w": 28, "tree_size": 128, "t0": 0.83, "t1": 0.67, "tft": 1.3249, "input_0": 328, "input_1": 129, "min_CLP": -5.79, "draft_iters": 11.4, "mem_use": 34.37, "gen_rate": 5.3, "speed": 3.52, "text": "Certainly! In reStructuredText ("}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 21.0, "tree_w": 13, "tree_size": 128, "t0": 1.55, "t1": 0.6975, "tft": 2.4236, "input_0": 469, "input_1": 129, "min_CLP": -4.71, "draft_iters": 21.8, "mem_use": 36.38, "gen_rate": 8.8, "speed": 3.89, "text": "\"Here's an example code to creat"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.7, "tree_w": 30, "tree_size": 128, "t0": 0.7817, "t1": 0.6583, "tft": 1.5415, "input_0": 341, "input_1": 129, "min_CLP": -5.44, "draft_iters": 10.7, "mem_use": 34.35, "gen_rate": 5.8, "speed": 4.06, "text": "\"The largest ocean in the world "}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.2, "tree_w": 43, "tree_size": 128, "t0": 0.5283, "t1": 0.6533, "tft": 1.3428, "input_0": 230, "input_1": 129, "min_CLP": -5.91, "draft_iters": 7.2, "mem_use": 34.8, "gen_rate": 5.5, "speed": 4.65, "text": "I would say that AI assistants a"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.4, "tree_w": 39, "tree_size": 128, "t0": 0.6657, "t1": 0.6771, "tft": 3.5754, "input_0": 244, "input_1": 129, "min_CLP": -6.09, "draft_iters": 9.4, "mem_use": 39.93, "gen_rate": 4.7, "speed": 3.51, "text": "\"Yes, I can certainly do that!\\n"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.2, "tree_w": 38, "tree_size": 128, "t0": 0.5962, "t1": 0.6638, "tft": 1.6911, "input_0": 240, "input_1": 129, "min_CLP": -5.9, "draft_iters": 8.2, "mem_use": 35.17, "gen_rate": 4.4, "speed": 3.47, "text": "0 someone that will tell you the"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 8.9, "tree_w": 35, "tree_size": 128, "t0": 0.7087, "t1": 0.6663, "tft": 2.383, "input_0": 262, "input_1": 129, "min_CLP": -5.65, "draft_iters": 9.9, "mem_use": 37.01, "gen_rate": 4.8, "speed": 3.46, "text": "I understand that you may have a"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 12.0, "tree_w": 32, "tree_size": 128, "t0": 0.9171, "t1": 0.69, "tft": 1.5449, "input_0": 275, "input_1": 129, "min_CLP": -5.86, "draft_iters": 12.9, "mem_use": 35.39, "gen_rate": 4.9, "speed": 3.03, "text": "1. A local event or festival is "}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 9.6, "tree_w": 38, "tree_size": 128, "t0": 0.7713, "t1": 0.6713, "tft": 1.3209, "input_0": 282, "input_1": 129, "min_CLP": -5.93, "draft_iters": 10.6, "mem_use": 34.68, "gen_rate": 4.0, "speed": 2.77, "text": "\"Here's a possible inspirational"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.0, "tree_w": 27, "tree_size": 128, "t0": 0.928, "t1": 0.666, "tft": 3.2158, "input_0": 336, "input_1": 129, "min_CLP": -5.52, "draft_iters": 13.0, "mem_use": 37.14, "gen_rate": 7.4, "speed": 4.64, "text": "Hosting a large language model o"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.5, "tree_w": 28, "tree_size": 128, "t0": 1.385, "t1": 0.7, "tft": 1.9098, "input_0": 326, "input_1": 129, "min_CLP": -5.83, "draft_iters": 20.0, "mem_use": 34.86, "gen_rate": 19.5, "speed": 9.38, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.2, "tree_w": 25, "tree_size": 128, "t0": 0.946, "t1": 0.674, "tft": 2.9558, "input_0": 364, "input_1": 129, "min_CLP": -5.34, "draft_iters": 13.2, "mem_use": 36.81, "gen_rate": 6.8, "speed": 4.2, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.2, "tree_w": 30, "tree_size": 128, "t0": 0.6733, "t1": 0.6617, "tft": 1.3946, "input_0": 276, "input_1": 129, "min_CLP": -5.93, "draft_iters": 9.2, "mem_use": 34.38, "gen_rate": 6.3, "speed": 4.75, "text": "```lean\\nnamespace Timsort\\n\\nop"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.0, "tree_w": 31, "tree_size": 128, "t0": 0.922, "t1": 0.674, "tft": 1.5184, "input_0": 306, "input_1": 129, "min_CLP": -5.69, "draft_iters": 13.0, "mem_use": 35.11, "gen_rate": 6.8, "speed": 4.26, "text": "As of 2019, women are allowed to"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.0, "tree_w": 28, "tree_size": 128, "t0": 0.7325, "t1": 0.665, "tft": 1.3294, "input_0": 294, "input_1": 129, "min_CLP": -5.54, "draft_iters": 10.0, "mem_use": 34.83, "gen_rate": 9.0, "speed": 6.44, "text": "To alleviate the symptoms of nau"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 28, "tree_size": 128, "t0": 0.918, "t1": 0.662, "tft": 1.5936, "input_0": 355, "input_1": 129, "min_CLP": -5.49, "draft_iters": 12.6, "mem_use": 34.42, "gen_rate": 6.8, "speed": 4.31, "text": "\"To code a smooth snake game in "}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.6, "tree_w": 30, "tree_size": 128, "t0": 0.8357, "t1": 0.6729, "tft": 1.8601, "input_0": 319, "input_1": 129, "min_CLP": -5.6, "draft_iters": 11.6, "mem_use": 35.31, "gen_rate": 4.9, "speed": 3.22, "text": "\"It's important to remember that"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.0, "tree_w": 19, "tree_size": 128, "t0": 1.0025, "t1": 0.68, "tft": 2.8891, "input_0": 362, "input_1": 129, "min_CLP": -5.26, "draft_iters": 14.0, "mem_use": 36.89, "gen_rate": 8.0, "speed": 4.76, "text": "\"It's difficult to provide a def"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 8.0, "tree_w": 34, "tree_size": 128, "t0": 0.645, "t1": 0.66, "tft": 2.1511, "input_0": 222, "input_1": 129, "min_CLP": -5.97, "draft_iters": 9.0, "mem_use": 34.54, "gen_rate": 2.0, "speed": 1.54, "text": "13.5 hours."}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.3, "tree_w": 18, "tree_size": 128, "t0": 1.1767, "t1": 0.6667, "tft": 1.6927, "input_0": 412, "input_1": 129, "min_CLP": -5.33, "draft_iters": 16.3, "mem_use": 34.45, "gen_rate": 10.7, "speed": 5.79, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 8.7, "tree_w": 33, "tree_size": 128, "t0": 0.7117, "t1": 0.6617, "tft": 1.2143, "input_0": 299, "input_1": 129, "min_CLP": -5.71, "draft_iters": 9.7, "mem_use": 34.35, "gen_rate": 6.3, "speed": 4.62, "text": "Yes, I am designed to provide he"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.2, "tree_w": 24, "tree_size": 128, "t0": 0.81, "t1": 0.662, "tft": 3.1638, "input_0": 379, "input_1": 129, "min_CLP": -5.47, "draft_iters": 11.2, "mem_use": 38.11, "gen_rate": 7.0, "speed": 4.76, "text": "TypeScript provides many benefit"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 25, "tree_size": 128, "t0": 1.1275, "t1": 0.68, "tft": 2.2493, "input_0": 322, "input_1": 129, "min_CLP": -5.38, "draft_iters": 16.0, "mem_use": 34.47, "gen_rate": 8.8, "speed": 4.84, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 29, "tree_size": 128, "t0": 0.7167, "t1": 0.6733, "tft": 2.2219, "input_0": 265, "input_1": 129, "min_CLP": -5.77, "draft_iters": 10.0, "mem_use": 35.49, "gen_rate": 5.5, "speed": 3.96, "text": "It is not good to farm experienc"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.2, "tree_w": 27, "tree_size": 128, "t0": 0.806, "t1": 0.654, "tft": 2.5057, "input_0": 365, "input_1": 129, "min_CLP": -5.52, "draft_iters": 11.2, "mem_use": 37.25, "gen_rate": 7.4, "speed": 5.06, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 9.3, "tree_w": 30, "tree_size": 128, "t0": 0.7467, "t1": 0.6622, "tft": 1.354, "input_0": 281, "input_1": 129, "min_CLP": -5.58, "draft_iters": 10.3, "mem_use": 34.59, "gen_rate": 3.8, "speed": 2.68, "text": "\"It's important to prioritize yo"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 12.7, "tree_w": 28, "tree_size": 128, "t0": 0.9671, "t1": 0.6829, "tft": 1.6975, "input_0": 279, "input_1": 129, "min_CLP": -5.73, "draft_iters": 13.7, "mem_use": 35.1, "gen_rate": 4.6, "speed": 2.77, "text": "\"You're welcome! If you need hel"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.8, "tree_w": 25, "tree_size": 128, "t0": 1.055, "t1": 0.6675, "tft": 2.6761, "input_0": 407, "input_1": 129, "min_CLP": -5.36, "draft_iters": 14.8, "mem_use": 36.82, "gen_rate": 8.8, "speed": 5.08, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 23, "tree_size": 128, "t0": 0.9475, "t1": 0.6675, "tft": 1.9728, "input_0": 381, "input_1": 129, "min_CLP": -5.63, "draft_iters": 13.0, "mem_use": 35.23, "gen_rate": 8.2, "speed": 5.11, "text": "The television was invented by P"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 31, "tree_size": 128, "t0": 1.75, "t1": 0.685, "tft": 2.56, "input_0": 349, "input_1": 129, "min_CLP": -6.43, "draft_iters": 25.5, "mem_use": 37.56, "gen_rate": 26.0, "speed": 10.69, "text": "\"[INST] I'll try it. [\\\\INST]\\n["}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.3, "tree_w": 34, "tree_size": 128, "t0": 0.6743, "t1": 0.6543, "tft": 2.2171, "input_0": 298, "input_1": 129, "min_CLP": -5.59, "draft_iters": 9.3, "mem_use": 35.88, "gen_rate": 4.9, "speed": 3.66, "text": "There are multiple days on which"}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.0, "tree_w": 33, "tree_size": 128, "t0": 0.722, "t1": 0.666, "tft": 1.4625, "input_0": 256, "input_1": 129, "min_CLP": -5.67, "draft_iters": 10.0, "mem_use": 34.91, "gen_rate": 6.6, "speed": 4.76, "text": "\"You're right, I'm an AI and I a"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.6, "tree_w": 26, "tree_size": 128, "t0": 0.762, "t1": 0.654, "tft": 2.6706, "input_0": 312, "input_1": 129, "min_CLP": -5.46, "draft_iters": 10.6, "mem_use": 36.7, "gen_rate": 7.0, "speed": 4.95, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.4, "tree_w": 26, "tree_size": 128, "t0": 0.89, "t1": 0.664, "tft": 1.3341, "input_0": 345, "input_1": 129, "min_CLP": -5.48, "draft_iters": 12.4, "mem_use": 34.54, "gen_rate": 7.6, "speed": 4.89, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.2, "tree_w": 29, "tree_size": 128, "t0": 1.0017, "t1": 0.6917, "tft": 2.43, "input_0": 277, "input_1": 129, "min_CLP": -5.71, "draft_iters": 14.2, "mem_use": 35.16, "gen_rate": 5.7, "speed": 3.35, "text": "Of course! Here\\'s an alternativ"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 54, "tree_h": 10.2, "tree_w": 44, "tree_size": 128, "t0": 0.7867, "t1": 0.6683, "tft": 2.4521, "input_0": 249, "input_1": 129, "min_CLP": -6.15, "draft_iters": 11.0, "mem_use": 34.63, "gen_rate": 9.0, "speed": 6.19, "text": "\"If I wanted to know how deep Si"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 15.2, "tree_w": 20, "tree_size": 128, "t0": 1.1825, "t1": 0.67, "tft": 1.4117, "input_0": 479, "input_1": 129, "min_CLP": -5.43, "draft_iters": 16.2, "mem_use": 34.65, "gen_rate": 9.8, "speed": 5.26, "text": "The black hole at the center of "}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 6.4, "tree_w": 42, "tree_size": 128, "t0": 0.5511, "t1": 0.6556, "tft": 1.499, "input_0": 242, "input_1": 129, "min_CLP": -5.92, "draft_iters": 7.4, "mem_use": 35.03, "gen_rate": 4.1, "speed": 3.41, "text": "Google Authenticator is a two-fa"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 31, "tree_size": 128, "t0": 0.75, "t1": 0.662, "tft": 2.0721, "input_0": 333, "input_1": 129, "min_CLP": -5.37, "draft_iters": 10.2, "mem_use": 34.81, "gen_rate": 6.4, "speed": 4.53, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.6, "tree_w": 24, "tree_size": 128, "t0": 0.98, "t1": 0.67, "tft": 1.3594, "input_0": 370, "input_1": 129, "min_CLP": -5.3, "draft_iters": 13.6, "mem_use": 34.58, "gen_rate": 7.4, "speed": 4.48, "text": "\"Certainly! Below is an example "}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 20.0, "tree_w": 25, "tree_size": 128, "t0": 1.425, "t1": 0.69, "tft": 1.337, "input_0": 405, "input_1": 129, "min_CLP": -6.54, "draft_iters": 20.5, "mem_use": 34.43, "gen_rate": 20.5, "speed": 9.68, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 24, "tree_h": 9.4, "tree_w": 28, "tree_size": 128, "t0": 0.754, "t1": 0.662, "tft": 1.43, "input_0": 284, "input_1": 129, "min_CLP": -5.73, "draft_iters": 10.4, "mem_use": 34.46, "gen_rate": 4.8, "speed": 3.39, "text": "```\\n```sql\\nSELECT a * b\\nFROM "}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 16.0, "tree_w": 34, "tree_size": 128, "t0": 1.1667, "t1": 0.6833, "tft": 1.4073, "input_0": 268, "input_1": 129, "min_CLP": -5.8, "draft_iters": 16.7, "mem_use": 34.38, "gen_rate": 13.0, "speed": 7.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.0, "tree_w": 24, "tree_size": 128, "t0": 0.995, "t1": 0.6867, "tft": 1.8735, "input_0": 316, "input_1": 129, "min_CLP": -5.48, "draft_iters": 14.0, "mem_use": 35.55, "gen_rate": 6.7, "speed": 3.97, "text": "\"In that case, you can first cop"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.4, "tree_w": 27, "tree_size": 128, "t0": 0.83, "t1": 0.66, "tft": 1.2747, "input_0": 320, "input_1": 129, "min_CLP": -5.52, "draft_iters": 11.4, "mem_use": 34.34, "gen_rate": 6.6, "speed": 4.44, "text": "In Python, the @ symbol is used "}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.8, "tree_w": 23, "tree_size": 128, "t0": 0.862, "t1": 0.664, "tft": 1.4131, "input_0": 345, "input_1": 129, "min_CLP": -5.54, "draft_iters": 11.8, "mem_use": 34.35, "gen_rate": 7.6, "speed": 4.97, "text": "ChatGPT is an advanced language "}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 36, "tree_size": 128, "t0": 0.7983, "t1": 0.6767, "tft": 1.5757, "input_0": 277, "input_1": 129, "min_CLP": -5.94, "draft_iters": 11.0, "mem_use": 34.65, "gen_rate": 5.5, "speed": 3.73, "text": "\"I would approach the task of ch"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 15, "new_tokens": 34, "tree_h": 8.5, "tree_w": 61, "tree_size": 128, "t0": 0.6807, "t1": 0.6787, "tft": 1.526, "input_0": 189, "input_1": 129, "min_CLP": -6.82, "draft_iters": 9.5, "mem_use": 34.38, "gen_rate": 2.3, "speed": 1.67, "text": "```malbolge\\n`9~B}k*48=2\\n```\\n\\"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 26, "tree_size": 128, "t0": 2.16, "t1": 0.76, "tft": 1.5594, "input_0": 373, "input_1": 129, "min_CLP": -5.61, "draft_iters": 32.0, "mem_use": 35.08, "gen_rate": 33.0, "speed": 11.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.3, "tree_w": 29, "tree_size": 128, "t0": 0.8067, "t1": 0.6633, "tft": 3.3056, "input_0": 296, "input_1": 129, "min_CLP": -5.63, "draft_iters": 11.3, "mem_use": 37.59, "gen_rate": 5.3, "speed": 3.63, "text": "Can you please provide more info"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.5, "tree_w": 19, "tree_size": 128, "t0": 1.2375, "t1": 0.685, "tft": 1.8628, "input_0": 395, "input_1": 129, "min_CLP": -5.36, "draft_iters": 17.5, "mem_use": 34.89, "gen_rate": 9.0, "speed": 4.68, "text": "Yes, there are some things that "}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.7, "tree_w": 34, "tree_size": 128, "t0": 0.635, "t1": 0.665, "tft": 1.7613, "input_0": 272, "input_1": 129, "min_CLP": -5.7, "draft_iters": 8.7, "mem_use": 36.03, "gen_rate": 5.5, "speed": 4.24, "text": "\"Hello there! How can I assist y"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 10.9, "tree_w": 43, "tree_size": 128, "t0": 0.838, "t1": 0.676, "tft": 2.003, "input_0": 221, "input_1": 129, "min_CLP": -6.42, "draft_iters": 11.9, "mem_use": 34.88, "gen_rate": 3.2, "speed": 2.11, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 14.8, "tree_w": 21, "tree_size": 128, "t0": 1.106, "t1": 0.664, "tft": 4.1728, "input_0": 380, "input_1": 129, "min_CLP": -5.31, "draft_iters": 15.8, "mem_use": 37.77, "gen_rate": 8.2, "speed": 4.63, "text": "Here are some simple examples of"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.0, "tree_w": 18, "tree_size": 128, "t0": 1.0, "t1": 0.724, "tft": 5.9723, "input_0": 409, "input_1": 129, "min_CLP": -5.09, "draft_iters": 14.0, "mem_use": 43.75, "gen_rate": 7.0, "speed": 4.07, "text": "\"Sure, here's an example code in"}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 28, "tree_size": 128, "t0": 0.868, "t1": 0.668, "tft": 2.2488, "input_0": 286, "input_1": 129, "min_CLP": -5.57, "draft_iters": 12.2, "mem_use": 36.13, "gen_rate": 7.2, "speed": 4.69, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 27, "tree_size": 128, "t0": 1.0225, "t1": 0.6675, "tft": 1.3834, "input_0": 391, "input_1": 129, "min_CLP": -5.5, "draft_iters": 14.0, "mem_use": 34.39, "gen_rate": 8.8, "speed": 5.18, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.8, "tree_w": 28, "tree_size": 128, "t0": 0.78, "t1": 0.6633, "tft": 1.4844, "input_0": 300, "input_1": 129, "min_CLP": -5.59, "draft_iters": 10.8, "mem_use": 34.51, "gen_rate": 6.0, "speed": 4.16, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 32, "tree_size": 128, "t0": 0.8375, "t1": 0.66, "tft": 2.5126, "input_0": 335, "input_1": 129, "min_CLP": -5.55, "draft_iters": 11.8, "mem_use": 37.26, "gen_rate": 8.0, "speed": 5.34, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 12.4, "tree_w": 27, "tree_size": 128, "t0": 0.9586, "t1": 0.6786, "tft": 1.5997, "input_0": 299, "input_1": 129, "min_CLP": -5.63, "draft_iters": 13.4, "mem_use": 34.45, "gen_rate": 6.0, "speed": 3.67, "text": "The world in 1950 was quite diff"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.2, "tree_w": 22, "tree_size": 128, "t0": 1.002, "t1": 0.674, "tft": 3.6494, "input_0": 407, "input_1": 129, "min_CLP": -5.12, "draft_iters": 14.2, "mem_use": 39.42, "gen_rate": 6.8, "speed": 4.05, "text": "Creating your own stable diffusi"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.3, "tree_w": 31, "tree_size": 128, "t0": 0.6814, "t1": 0.67, "tft": 1.1975, "input_0": 279, "input_1": 129, "min_CLP": -5.81, "draft_iters": 9.3, "mem_use": 34.79, "gen_rate": 5.3, "speed": 3.92, "text": "\"The order you install your part"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 33, "tree_size": 128, "t0": 0.765, "t1": 0.6617, "tft": 1.7201, "input_0": 320, "input_1": 129, "min_CLP": -5.73, "draft_iters": 10.5, "mem_use": 34.64, "gen_rate": 5.7, "speed": 3.97, "text": "Carnegie Mellon University in Pi"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 36, "tree_size": 128, "t0": 0.6443, "t1": 0.6543, "tft": 1.4618, "input_0": 287, "input_1": 129, "min_CLP": -5.85, "draft_iters": 8.7, "mem_use": 34.7, "gen_rate": 4.7, "speed": 3.63, "text": "I am an AI created by OpenAI, bu"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.1, "tree_w": 26, "tree_size": 128, "t0": 0.8071, "t1": 0.6614, "tft": 2.6316, "input_0": 346, "input_1": 129, "min_CLP": -5.41, "draft_iters": 11.1, "mem_use": 36.08, "gen_rate": 4.6, "speed": 3.11, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 21, "tree_size": 128, "t0": 0.925, "t1": 0.68, "tft": 2.1361, "input_0": 283, "input_1": 129, "min_CLP": -5.37, "draft_iters": 13.0, "mem_use": 34.76, "gen_rate": 8.2, "speed": 5.14, "text": "The infamous Keyhole series of s"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.3, "tree_w": 30, "tree_size": 128, "t0": 0.89, "t1": 0.6767, "tft": 1.4045, "input_0": 330, "input_1": 129, "min_CLP": -5.87, "draft_iters": 12.3, "mem_use": 34.94, "gen_rate": 6.2, "speed": 3.93, "text": "\"Here's a recipe you can make us"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.0, "tree_w": 30, "tree_size": 128, "t0": 0.87, "t1": 0.674, "tft": 1.7514, "input_0": 332, "input_1": 129, "min_CLP": -5.58, "draft_iters": 12.0, "mem_use": 35.0, "gen_rate": 7.0, "speed": 4.53, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.1, "tree_w": 30, "tree_size": 128, "t0": 0.73, "t1": 0.6613, "tft": 2.4286, "input_0": 294, "input_1": 129, "min_CLP": -5.78, "draft_iters": 10.1, "mem_use": 36.9, "gen_rate": 4.4, "speed": 3.15, "text": "Sure! Here are some YouTube chan"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 8.4, "tree_w": 29, "tree_size": 128, "t0": 0.7, "t1": 0.66, "tft": 1.3281, "input_0": 323, "input_1": 129, "min_CLP": -5.52, "draft_iters": 9.4, "mem_use": 34.35, "gen_rate": 7.2, "speed": 5.29, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 5, "tree_h": 8.0, "tree_w": 51, "tree_size": 128, "t0": 0.63, "t1": 0.65, "tft": 1.3941, "input_0": 189, "input_1": 129, "min_CLP": -6.05, "draft_iters": 9.0, "mem_use": 34.49, "gen_rate": 5.0, "speed": 3.91, "text": "B^T A^T"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.4, "tree_w": 34, "tree_size": 128, "t0": 0.6762, "t1": 0.6613, "tft": 2.0601, "input_0": 278, "input_1": 129, "min_CLP": -5.9, "draft_iters": 9.4, "mem_use": 35.95, "gen_rate": 4.6, "speed": 3.46, "text": "\"Statistical modeling, it's all "}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 9, "tree_size": 128, "t0": 2.18, "t1": 0.71, "tft": 3.9091, "input_0": 371, "input_1": 129, "min_CLP": -5.38, "draft_iters": 32.0, "mem_use": 37.08, "gen_rate": 33.0, "speed": 11.41, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 2, "tree_h": 8.0, "tree_w": 41, "tree_size": 128, "t0": 0.65, "t1": 0.65, "tft": 1.4077, "input_0": 265, "input_1": 129, "min_CLP": -5.82, "draft_iters": 9.0, "mem_use": 34.33, "gen_rate": 2.0, "speed": 1.54, "text": "The current date is [current_dat"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.2, "tree_w": 28, "tree_size": 128, "t0": 0.814, "t1": 0.666, "tft": 1.9898, "input_0": 328, "input_1": 129, "min_CLP": -5.49, "draft_iters": 11.2, "mem_use": 35.8, "gen_rate": 6.8, "speed": 4.59, "text": "That\\'s correct! Removing things"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.3, "tree_w": 41, "tree_size": 128, "t0": 0.6, "t1": 0.6571, "tft": 1.2405, "input_0": 216, "input_1": 129, "min_CLP": -6.08, "draft_iters": 8.3, "mem_use": 34.7, "gen_rate": 4.6, "speed": 3.63, "text": "\"Dude, that's just plain wrong. "}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 15.7, "tree_w": 18, "tree_size": 128, "t0": 1.2133, "t1": 0.6767, "tft": 1.5287, "input_0": 466, "input_1": 129, "min_CLP": -5.29, "draft_iters": 16.7, "mem_use": 34.38, "gen_rate": 11.0, "speed": 5.82, "text": "\"Yes, I'd be happy to help. Esti"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 26.0, "tree_w": 32, "tree_size": 128, "t0": 1.82, "t1": 0.7, "tft": 1.4013, "input_0": 305, "input_1": 129, "min_CLP": -6.18, "draft_iters": 26.5, "mem_use": 34.74, "gen_rate": 20.0, "speed": 7.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.6, "tree_w": 26, "tree_size": 128, "t0": 0.774, "t1": 0.662, "tft": 1.5954, "input_0": 308, "input_1": 129, "min_CLP": -5.59, "draft_iters": 10.6, "mem_use": 34.32, "gen_rate": 7.0, "speed": 4.88, "text": "The process of metabolism is a c"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 11.4, "tree_w": 31, "tree_size": 128, "t0": 0.8986, "t1": 0.6886, "tft": 2.7672, "input_0": 333, "input_1": 129, "min_CLP": -5.69, "draft_iters": 12.4, "mem_use": 35.65, "gen_rate": 4.9, "speed": 3.06, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 21.8, "tree_w": 18, "tree_size": 128, "t0": 1.578, "t1": 0.7, "tft": 2.9434, "input_0": 367, "input_1": 129, "min_CLP": -5.53, "draft_iters": 22.6, "mem_use": 34.52, "gen_rate": 8.0, "speed": 3.51, "text": "\"Bob has two sons, John and Jay."}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 28, "tree_size": 128, "t0": 0.876, "t1": 0.688, "tft": 1.7322, "input_0": 325, "input_1": 129, "min_CLP": -5.61, "draft_iters": 12.0, "mem_use": 34.9, "gen_rate": 6.6, "speed": 4.22, "text": "The five oceans are: Atlantic oc"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 36, "tree_size": 128, "t0": 0.625, "t1": 0.6583, "tft": 1.443, "input_0": 284, "input_1": 129, "min_CLP": -5.69, "draft_iters": 8.5, "mem_use": 35.14, "gen_rate": 5.5, "speed": 4.28, "text": "\"One way to get started is to ta"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 25.2, "tree_w": 11, "tree_size": 128, "t0": 1.845, "t1": 0.7025, "tft": 1.5611, "input_0": 502, "input_1": 129, "min_CLP": -4.78, "draft_iters": 26.0, "mem_use": 34.55, "gen_rate": 9.0, "speed": 3.53, "text": "```python\\nimport pygame\\n\\n# In"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.0, "tree_w": 35, "tree_size": 128, "t0": 0.66, "t1": 0.6586, "tft": 1.9797, "input_0": 310, "input_1": 129, "min_CLP": -5.74, "draft_iters": 9.0, "mem_use": 35.65, "gen_rate": 4.6, "speed": 3.47, "text": "DLL stands for Dynamic Link Libr"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 7.0, "tree_w": 44, "tree_size": 128, "t0": 0.58, "t1": 0.655, "tft": 1.7317, "input_0": 205, "input_1": 129, "min_CLP": -5.86, "draft_iters": 8.0, "mem_use": 34.8, "gen_rate": 2.0, "speed": 1.63, "text": "Please provide a more specific q"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 32, "tree_h": 6.4, "tree_w": 43, "tree_size": 128, "t0": 0.5427, "t1": 0.6509, "tft": 1.1955, "input_0": 223, "input_1": 129, "min_CLP": -5.92, "draft_iters": 7.4, "mem_use": 34.34, "gen_rate": 2.9, "speed": 2.44, "text": "The Infinite Banking Concept is "}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.8, "tree_w": 25, "tree_size": 128, "t0": 1.0, "t1": 0.666, "tft": 1.1968, "input_0": 373, "input_1": 129, "min_CLP": -5.35, "draft_iters": 13.8, "mem_use": 34.45, "gen_rate": 6.8, "speed": 4.08, "text": "Sure! Below is an example of a h"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.8, "tree_w": 44, "tree_size": 128, "t0": 0.6375, "t1": 0.66, "tft": 1.4971, "input_0": 249, "input_1": 129, "min_CLP": -6.11, "draft_iters": 8.8, "mem_use": 34.6, "gen_rate": 4.6, "speed": 3.55, "text": "\"They are not, because they are "}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 18, "tree_h": 6.2, "tree_w": 49, "tree_size": 128, "t0": 0.526, "t1": 0.654, "tft": 2.2946, "input_0": 207, "input_1": 129, "min_CLP": -6.2, "draft_iters": 7.2, "mem_use": 35.11, "gen_rate": 3.6, "speed": 3.05, "text": "\"I hate the way the characters s"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 30, "tree_size": 128, "t0": 0.92, "t1": 0.665, "tft": 2.088, "input_0": 382, "input_1": 129, "min_CLP": -5.63, "draft_iters": 12.8, "mem_use": 35.99, "gen_rate": 8.2, "speed": 5.21, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.4, "tree_w": 24, "tree_size": 128, "t0": 0.896, "t1": 0.664, "tft": 2.4879, "input_0": 385, "input_1": 129, "min_CLP": -5.41, "draft_iters": 12.4, "mem_use": 36.5, "gen_rate": 7.2, "speed": 4.62, "text": "Some languages that are consider"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 20.0, "tree_w": 21, "tree_size": 128, "t0": 1.45, "t1": 0.686, "tft": 1.455, "input_0": 405, "input_1": 129, "min_CLP": -5.54, "draft_iters": 20.6, "mem_use": 34.94, "gen_rate": 7.2, "speed": 3.37, "text": "Among the AI tools for 2D animat"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 8.1, "tree_w": 35, "tree_size": 128, "t0": 0.6667, "t1": 0.6578, "tft": 1.4137, "input_0": 267, "input_1": 129, "min_CLP": -5.65, "draft_iters": 9.1, "mem_use": 34.8, "gen_rate": 3.7, "speed": 2.77, "text": "I do not have emotions, beliefs "}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 28, "tree_h": 9.8, "tree_w": 33, "tree_size": 128, "t0": 0.784, "t1": 0.666, "tft": 1.2719, "input_0": 326, "input_1": 129, "min_CLP": -6.02, "draft_iters": 10.8, "mem_use": 35.01, "gen_rate": 5.6, "speed": 3.86, "text": "You can be a part of the future "}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.2, "tree_w": 31, "tree_size": 128, "t0": 0.7475, "t1": 0.6687, "tft": 1.8962, "input_0": 292, "input_1": 129, "min_CLP": -5.82, "draft_iters": 10.2, "mem_use": 35.02, "gen_rate": 4.4, "speed": 3.09, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.6, "tree_w": 36, "tree_size": 128, "t0": 0.6257, "t1": 0.65, "tft": 2.5422, "input_0": 277, "input_1": 129, "min_CLP": -5.78, "draft_iters": 8.6, "mem_use": 34.45, "gen_rate": 4.7, "speed": 3.69, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 24, "tree_size": 128, "t0": 0.838, "t1": 0.656, "tft": 2.2594, "input_0": 345, "input_1": 129, "min_CLP": -5.65, "draft_iters": 11.6, "mem_use": 36.13, "gen_rate": 6.4, "speed": 4.29, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.0, "tree_w": 27, "tree_size": 128, "t0": 1.0, "t1": 0.6775, "tft": 2.4135, "input_0": 307, "input_1": 129, "min_CLP": -5.86, "draft_iters": 14.0, "mem_use": 34.6, "gen_rate": 9.5, "speed": 5.66, "text": "\"Psychomotricity\\n[INST] What is"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.8, "tree_w": 24, "tree_size": 128, "t0": 0.985, "t1": 0.68, "tft": 2.402, "input_0": 341, "input_1": 129, "min_CLP": -5.57, "draft_iters": 13.8, "mem_use": 34.43, "gen_rate": 9.2, "speed": 5.55, "text": "Here is a list of 10 names from "}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 8.3, "tree_w": 35, "tree_size": 128, "t0": 0.6629, "t1": 0.6629, "tft": 1.4108, "input_0": 244, "input_1": 129, "min_CLP": -5.8, "draft_iters": 9.3, "mem_use": 34.9, "gen_rate": 5.1, "speed": 3.88, "text": "\"I am just a computer program, s"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.8, "tree_w": 24, "tree_size": 128, "t0": 0.85, "t1": 0.654, "tft": 2.6292, "input_0": 359, "input_1": 129, "min_CLP": -5.43, "draft_iters": 11.8, "mem_use": 36.59, "gen_rate": 6.4, "speed": 4.26, "text": "When creating new images using t"}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.1, "tree_w": 36, "tree_size": 128, "t0": 0.6613, "t1": 0.6663, "tft": 1.9441, "input_0": 252, "input_1": 129, "min_CLP": -5.77, "draft_iters": 9.1, "mem_use": 35.38, "gen_rate": 4.6, "speed": 3.48, "text": "Yes, there is a similar theory c"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 24, "tree_size": 128, "t0": 0.868, "t1": 0.68, "tft": 2.0669, "input_0": 331, "input_1": 129, "min_CLP": -5.35, "draft_iters": 12.0, "mem_use": 35.8, "gen_rate": 7.6, "speed": 4.9, "text": "The meaning of life is a complex"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 44, "tree_size": 128, "t0": 0.5357, "t1": 0.6529, "tft": 1.2008, "input_0": 218, "input_1": 129, "min_CLP": -6.12, "draft_iters": 7.3, "mem_use": 34.38, "gen_rate": 4.7, "speed": 3.97, "text": "Title: The Cryptic Chronicles\\n\\"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 18.5, "tree_w": 20, "tree_size": 128, "t0": 1.3283, "t1": 0.685, "tft": 3.8805, "input_0": 342, "input_1": 129, "min_CLP": -5.22, "draft_iters": 19.3, "mem_use": 39.07, "gen_rate": 5.3, "speed": 2.64, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 9.8, "tree_w": 29, "tree_size": 128, "t0": 0.794, "t1": 0.674, "tft": 2.149, "input_0": 345, "input_1": 129, "min_CLP": -5.54, "draft_iters": 10.8, "mem_use": 35.51, "gen_rate": 8.0, "speed": 5.45, "text": "To transform text words or expre"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 17.6, "tree_w": 17, "tree_size": 128, "t0": 1.31, "t1": 0.686, "tft": 2.4636, "input_0": 363, "input_1": 129, "min_CLP": -5.4, "draft_iters": 18.6, "mem_use": 35.37, "gen_rate": 7.2, "speed": 3.6, "text": "If the original departure is fro"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.2, "tree_w": 27, "tree_size": 128, "t0": 0.98, "t1": 0.6625, "tft": 1.7317, "input_0": 402, "input_1": 129, "min_CLP": -5.71, "draft_iters": 13.2, "mem_use": 34.4, "gen_rate": 10.0, "speed": 6.1, "text": "\"Adolf Hitler's rise to power in"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 10.1, "tree_w": 38, "tree_size": 128, "t0": 0.8, "t1": 0.66, "tft": 1.7424, "input_0": 265, "input_1": 129, "min_CLP": -5.98, "draft_iters": 11.1, "mem_use": 34.74, "gen_rate": 3.7, "speed": 2.55, "text": "Why did the broke college studen"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 29, "tree_size": 128, "t0": 0.7533, "t1": 0.6533, "tft": 1.1895, "input_0": 316, "input_1": 129, "min_CLP": -5.54, "draft_iters": 10.3, "mem_use": 34.36, "gen_rate": 5.8, "speed": 4.15, "text": "The number of black holes known "}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.3, "tree_w": 41, "tree_size": 128, "t0": 0.5983, "t1": 0.6683, "tft": 2.9331, "input_0": 246, "input_1": 129, "min_CLP": -5.71, "draft_iters": 8.3, "mem_use": 39.13, "gen_rate": 5.7, "speed": 4.47, "text": "Apologies for the confusion. As "}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 23.0, "tree_w": 29, "tree_size": 128, "t0": 1.625, "t1": 0.705, "tft": 1.5141, "input_0": 331, "input_1": 129, "min_CLP": -6.13, "draft_iters": 23.5, "mem_use": 34.44, "gen_rate": 19.0, "speed": 8.17, "text": "Human: [INST] <<SYS>>\\nYou are a"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 25, "tree_size": 128, "t0": 0.85, "t1": 0.696, "tft": 4.2583, "input_0": 316, "input_1": 129, "min_CLP": -5.72, "draft_iters": 12.0, "mem_use": 41.35, "gen_rate": 6.4, "speed": 4.14, "text": "I am able to understand the char"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.2, "tree_w": 38, "tree_size": 128, "t0": 0.595, "t1": 0.6667, "tft": 1.8633, "input_0": 254, "input_1": 129, "min_CLP": -5.92, "draft_iters": 8.2, "mem_use": 35.62, "gen_rate": 5.5, "speed": 4.37, "text": "Spritesla is not the first evolu"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.6, "tree_w": 25, "tree_size": 128, "t0": 0.908, "t1": 0.664, "tft": 1.5987, "input_0": 342, "input_1": 129, "min_CLP": -5.39, "draft_iters": 12.6, "mem_use": 34.47, "gen_rate": 7.0, "speed": 4.44, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.0, "tree_w": 30, "tree_size": 128, "t0": 0.7217, "t1": 0.665, "tft": 1.3201, "input_0": 273, "input_1": 129, "min_CLP": -5.54, "draft_iters": 10.0, "mem_use": 34.34, "gen_rate": 6.0, "speed": 4.32, "text": "\"Two-factor authentication (2FA)"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.5, "tree_w": 40, "tree_size": 128, "t0": 0.6212, "t1": 0.6563, "tft": 1.4995, "input_0": 245, "input_1": 129, "min_CLP": -5.88, "draft_iters": 8.5, "mem_use": 34.58, "gen_rate": 4.0, "speed": 3.14, "text": "The best thing to do is to be ho"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 24, "tree_size": 128, "t0": 0.805, "t1": 0.66, "tft": 1.3306, "input_0": 349, "input_1": 129, "min_CLP": -5.57, "draft_iters": 11.0, "mem_use": 34.88, "gen_rate": 8.5, "speed": 5.8, "text": "Sure, here are some TV shows you"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.2, "tree_w": 18, "tree_size": 128, "t0": 1.15, "t1": 0.676, "tft": 2.6897, "input_0": 370, "input_1": 129, "min_CLP": -5.12, "draft_iters": 16.2, "mem_use": 36.5, "gen_rate": 6.6, "speed": 3.62, "text": "Sure, here are some software and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.7, "tree_w": 24, "tree_size": 128, "t0": 0.9783, "t1": 0.6833, "tft": 2.5327, "input_0": 352, "input_1": 129, "min_CLP": -5.36, "draft_iters": 13.7, "mem_use": 35.59, "gen_rate": 5.5, "speed": 3.31, "text": "The physical characteristics of "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 30, "tree_h": 7.8, "tree_w": 37, "tree_size": 128, "t0": 0.6367, "t1": 0.6583, "tft": 1.6177, "input_0": 242, "input_1": 129, "min_CLP": -6.06, "draft_iters": 8.8, "mem_use": 34.52, "gen_rate": 5.0, "speed": 3.86, "text": "The two players in the atomic bo"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 22.8, "tree_w": 20, "tree_size": 128, "t0": 1.6188, "t1": 0.6925, "tft": 2.4171, "input_0": 375, "input_1": 129, "min_CLP": -5.29, "draft_iters": 23.4, "mem_use": 37.13, "gen_rate": 4.2, "speed": 1.84, "text": "\"Sure, here's the same script wi"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.1, "tree_w": 27, "tree_size": 128, "t0": 0.8714, "t1": 0.6743, "tft": 3.2868, "input_0": 334, "input_1": 129, "min_CLP": -5.67, "draft_iters": 12.1, "mem_use": 35.62, "gen_rate": 4.7, "speed": 3.05, "text": "Lo siento, pero Linkin Park no t"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 20.5, "tree_w": 25, "tree_size": 128, "t0": 1.47, "t1": 0.7, "tft": 1.256, "input_0": 396, "input_1": 129, "min_CLP": -6.67, "draft_iters": 21.0, "mem_use": 34.36, "gen_rate": 20.5, "speed": 9.44, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 26, "tree_h": 11.5, "tree_w": 20, "tree_size": 128, "t0": 0.9025, "t1": 0.665, "tft": 1.4913, "input_0": 356, "input_1": 129, "min_CLP": -5.58, "draft_iters": 12.5, "mem_use": 34.44, "gen_rate": 6.5, "speed": 4.14, "text": "```markdown\\nHere is an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.5, "tree_w": 29, "tree_size": 128, "t0": 0.7575, "t1": 0.6775, "tft": 1.6952, "input_0": 305, "input_1": 129, "min_CLP": -5.72, "draft_iters": 10.5, "mem_use": 35.47, "gen_rate": 8.8, "speed": 6.09, "text": "\"Of course! Here's a poem about "}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.6, "tree_w": 31, "tree_size": 128, "t0": 0.756, "t1": 0.672, "tft": 2.2484, "input_0": 281, "input_1": 129, "min_CLP": -5.61, "draft_iters": 10.6, "mem_use": 36.43, "gen_rate": 6.8, "speed": 4.76, "text": "\"In JavaScript, you can use a si"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 27, "tree_size": 128, "t0": 2.14, "t1": 0.76, "tft": 1.4666, "input_0": 386, "input_1": 129, "min_CLP": -5.59, "draft_iters": 32.0, "mem_use": 34.95, "gen_rate": 33.0, "speed": 11.38, "text": "To start learning the guitar: Fi"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.5, "tree_w": 28, "tree_size": 128, "t0": 0.7683, "t1": 0.6767, "tft": 1.8528, "input_0": 316, "input_1": 129, "min_CLP": -5.42, "draft_iters": 10.5, "mem_use": 35.43, "gen_rate": 5.3, "speed": 3.69, "text": "I apologize for any confusion. Y"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 6, "tree_h": 9.5, "tree_w": 29, "tree_size": 128, "t0": 0.745, "t1": 0.67, "tft": 1.2635, "input_0": 272, "input_1": 129, "min_CLP": -5.66, "draft_iters": 10.5, "mem_use": 34.35, "gen_rate": 3.0, "speed": 2.12, "text": "javascript is a front-end langua"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 20.5, "tree_w": 27, "tree_size": 128, "t0": 1.46, "t1": 0.695, "tft": 1.3319, "input_0": 309, "input_1": 129, "min_CLP": -5.61, "draft_iters": 21.0, "mem_use": 34.34, "gen_rate": 19.5, "speed": 9.05, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.2, "tree_w": 24, "tree_size": 128, "t0": 1.14, "t1": 0.685, "tft": 1.5645, "input_0": 325, "input_1": 129, "min_CLP": -5.4, "draft_iters": 16.2, "mem_use": 35.05, "gen_rate": 8.2, "speed": 4.53, "text": "Here are the 5 words in 2 column"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.8, "tree_w": 40, "tree_size": 128, "t0": 0.5767, "t1": 0.6583, "tft": 1.9029, "input_0": 245, "input_1": 129, "min_CLP": -6.73, "draft_iters": 7.8, "mem_use": 34.47, "gen_rate": 5.3, "speed": 4.32, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.5, "tree_w": 42, "tree_size": 128, "t0": 0.6233, "t1": 0.6567, "tft": 1.7379, "input_0": 272, "input_1": 129, "min_CLP": -5.9, "draft_iters": 8.5, "mem_use": 34.47, "gen_rate": 5.7, "speed": 4.42, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.3, "tree_w": 25, "tree_size": 128, "t0": 0.9, "t1": 0.6733, "tft": 1.261, "input_0": 337, "input_1": 129, "min_CLP": -5.52, "draft_iters": 12.3, "mem_use": 34.44, "gen_rate": 11.0, "speed": 7.01, "text": "Sure! Here are some tips to help"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 61, "tree_h": 30.3, "tree_w": 21, "tree_size": 128, "t0": 2.1033, "t1": 0.6933, "tft": 4.4059, "input_0": 396, "input_1": 129, "min_CLP": -6.14, "draft_iters": 31.0, "mem_use": 39.18, "gen_rate": 20.3, "speed": 7.27, "text": "Here is a revised version of the"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 9.2, "tree_w": 25, "tree_size": 128, "t0": 0.738, "t1": 0.668, "tft": 2.8022, "input_0": 322, "input_1": 129, "min_CLP": -5.47, "draft_iters": 10.2, "mem_use": 36.83, "gen_rate": 6.6, "speed": 4.69, "text": "Sure! Imagine you have a bunch o"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 23.5, "tree_w": 14, "tree_size": 128, "t0": 1.72, "t1": 0.71, "tft": 1.9891, "input_0": 402, "input_1": 129, "min_CLP": -4.83, "draft_iters": 24.5, "mem_use": 35.27, "gen_rate": 8.8, "speed": 3.6, "text": "Sure, the formula for calculatin"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.7, "tree_w": 24, "tree_size": 128, "t0": 0.9757, "t1": 0.6843, "tft": 1.7689, "input_0": 332, "input_1": 129, "min_CLP": -5.28, "draft_iters": 13.7, "mem_use": 35.43, "gen_rate": 5.0, "speed": 3.01, "text": "We can learn a lot from polar be"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.2, "tree_w": 30, "tree_size": 128, "t0": 0.7267, "t1": 0.6667, "tft": 2.1437, "input_0": 278, "input_1": 129, "min_CLP": -5.64, "draft_iters": 10.2, "mem_use": 36.5, "gen_rate": 5.8, "speed": 4.18, "text": "Lemon wedges are a common garnis"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 41, "tree_size": 128, "t0": 0.53, "t1": 0.65, "tft": 1.2799, "input_0": 252, "input_1": 129, "min_CLP": -5.96, "draft_iters": 7.1, "mem_use": 34.53, "gen_rate": 4.2, "speed": 3.6, "text": "\"Here's how the conversation cou"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.0, "tree_w": 36, "tree_size": 128, "t0": 0.6583, "t1": 0.665, "tft": 1.3386, "input_0": 263, "input_1": 129, "min_CLP": -5.63, "draft_iters": 9.0, "mem_use": 34.49, "gen_rate": 5.3, "speed": 4.03, "text": "\"I'm sorry to hear that you're f"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 17.2, "tree_w": 19, "tree_size": 128, "t0": 1.3, "t1": 0.7, "tft": 1.7357, "input_0": 379, "input_1": 129, "min_CLP": -5.05, "draft_iters": 18.2, "mem_use": 34.37, "gen_rate": 10.8, "speed": 5.39, "text": "To initialize a Typescript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.4, "tree_w": 28, "tree_size": 128, "t0": 0.8271, "t1": 0.6671, "tft": 2.3789, "input_0": 331, "input_1": 129, "min_CLP": -5.48, "draft_iters": 11.4, "mem_use": 35.97, "gen_rate": 5.3, "speed": 3.53, "text": "While there are many cities that"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 25, "tree_size": 128, "t0": 0.776, "t1": 0.67, "tft": 1.9757, "input_0": 357, "input_1": 129, "min_CLP": -5.55, "draft_iters": 10.6, "mem_use": 35.47, "gen_rate": 6.4, "speed": 4.42, "text": "Freeman Dyson has defended sever"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 23, "tree_h": 9.5, "tree_w": 32, "tree_size": 128, "t0": 0.7725, "t1": 0.66, "tft": 1.1178, "input_0": 323, "input_1": 129, "min_CLP": -5.63, "draft_iters": 10.5, "mem_use": 34.32, "gen_rate": 5.8, "speed": 4.01, "text": "Yes, I can write code. What prog"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 12.0, "tree_w": 23, "tree_size": 128, "t0": 0.93, "t1": 0.6767, "tft": 2.4875, "input_0": 327, "input_1": 129, "min_CLP": -5.37, "draft_iters": 13.0, "mem_use": 35.07, "gen_rate": 5.3, "speed": 3.32, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 20.6, "tree_w": 27, "tree_size": 128, "t0": 1.4962, "t1": 0.7037, "tft": 1.8232, "input_0": 331, "input_1": 129, "min_CLP": -5.58, "draft_iters": 21.2, "mem_use": 35.66, "gen_rate": 4.4, "speed": 1.99, "text": "Certainly! Here are the full lyr"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.2, "tree_w": 26, "tree_size": 128, "t0": 0.955, "t1": 0.6733, "tft": 1.4488, "input_0": 347, "input_1": 129, "min_CLP": -5.3, "draft_iters": 13.2, "mem_use": 34.69, "gen_rate": 5.7, "speed": 3.48, "text": "1.    Prioritize and manage your"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.2, "tree_w": 24, "tree_size": 128, "t0": 0.8275, "t1": 0.6625, "tft": 1.2792, "input_0": 376, "input_1": 129, "min_CLP": -5.58, "draft_iters": 11.2, "mem_use": 34.36, "gen_rate": 8.2, "speed": 5.54, "text": "The self-attention mechanism is "}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.5, "tree_w": 25, "tree_size": 128, "t0": 1.4275, "t1": 0.6975, "tft": 1.463, "input_0": 367, "input_1": 129, "min_CLP": -5.57, "draft_iters": 20.2, "mem_use": 34.92, "gen_rate": 10.0, "speed": 4.7, "text": "It is not possible to make a com"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 12.9, "tree_w": 31, "tree_size": 128, "t0": 0.9771, "t1": 0.6871, "tft": 2.2179, "input_0": 294, "input_1": 129, "min_CLP": -6.02, "draft_iters": 13.9, "mem_use": 35.35, "gen_rate": 5.3, "speed": 3.18, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 9.1, "tree_w": 31, "tree_size": 128, "t0": 0.7413, "t1": 0.6613, "tft": 1.6983, "input_0": 296, "input_1": 129, "min_CLP": -5.63, "draft_iters": 10.1, "mem_use": 35.03, "gen_rate": 4.1, "speed": 2.94, "text": "The URL decoded string of `%21` "}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 24.3, "tree_w": 12, "tree_size": 128, "t0": 1.75, "t1": 0.6867, "tft": 3.9357, "input_0": 412, "input_1": 129, "min_CLP": -4.9, "draft_iters": 25.3, "mem_use": 37.14, "gen_rate": 12.3, "speed": 5.07, "text": "\"I apologize for the confusion. "}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.4, "tree_w": 28, "tree_size": 128, "t0": 0.7486, "t1": 0.6729, "tft": 3.0419, "input_0": 314, "input_1": 129, "min_CLP": -5.73, "draft_iters": 10.4, "mem_use": 38.7, "gen_rate": 5.1, "speed": 3.62, "text": "\"Here are some specific brands a"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.7, "tree_w": 27, "tree_size": 128, "t0": 0.8457, "t1": 0.68, "tft": 1.9049, "input_0": 318, "input_1": 129, "min_CLP": -5.51, "draft_iters": 11.7, "mem_use": 35.73, "gen_rate": 4.6, "speed": 2.99, "text": "\"It sounds like you're motivated"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 27.5, "tree_w": 14, "tree_size": 128, "t0": 1.93, "t1": 0.715, "tft": 2.1805, "input_0": 454, "input_1": 129, "min_CLP": -5.12, "draft_iters": 28.0, "mem_use": 36.15, "gen_rate": 23.5, "speed": 8.87, "text": "Sure, here are the three most im"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.0, "tree_w": 24, "tree_size": 128, "t0": 0.94, "t1": 0.686, "tft": 1.6085, "input_0": 331, "input_1": 129, "min_CLP": -5.26, "draft_iters": 13.0, "mem_use": 34.36, "gen_rate": 7.4, "speed": 4.55, "text": "The main difference between sets"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 9.5, "tree_w": 29, "tree_size": 128, "t0": 0.7725, "t1": 0.67, "tft": 2.7855, "input_0": 331, "input_1": 129, "min_CLP": -5.4, "draft_iters": 10.5, "mem_use": 35.69, "gen_rate": 5.1, "speed": 3.55, "text": "Black Friday typically falls on "}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.2, "tree_w": 31, "tree_size": 128, "t0": 0.808, "t1": 0.67, "tft": 1.3475, "input_0": 305, "input_1": 129, "min_CLP": -5.89, "draft_iters": 11.2, "mem_use": 34.53, "gen_rate": 6.8, "speed": 4.6, "text": "Here is a story based on the Jus"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.8, "tree_w": 35, "tree_size": 128, "t0": 0.6533, "t1": 0.6617, "tft": 1.672, "input_0": 263, "input_1": 129, "min_CLP": -5.7, "draft_iters": 8.8, "mem_use": 34.41, "gen_rate": 5.5, "speed": 4.19, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.0, "tree_w": 21, "tree_size": 128, "t0": 0.944, "t1": 0.676, "tft": 1.8179, "input_0": 384, "input_1": 129, "min_CLP": -5.52, "draft_iters": 13.0, "mem_use": 34.4, "gen_rate": 6.4, "speed": 3.95, "text": "In Minecraft, there are several "}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.7, "tree_w": 36, "tree_size": 128, "t0": 0.6414, "t1": 0.6514, "tft": 1.2687, "input_0": 276, "input_1": 129, "min_CLP": -5.96, "draft_iters": 8.7, "mem_use": 34.35, "gen_rate": 5.3, "speed": 4.08, "text": "I am the Norse Goddess Freyja, t"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 15, "tree_h": 17.0, "tree_w": 16, "tree_size": 128, "t0": 1.29, "t1": 0.68, "tft": 2.5392, "input_0": 547, "input_1": 129, "min_CLP": -5.08, "draft_iters": 18.0, "mem_use": 35.61, "gen_rate": 15.0, "speed": 7.61, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.2, "tree_w": 25, "tree_size": 128, "t0": 1.0117, "t1": 0.6767, "tft": 2.4065, "input_0": 329, "input_1": 129, "min_CLP": -5.6, "draft_iters": 14.2, "mem_use": 34.74, "gen_rate": 6.2, "speed": 3.65, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.9, "tree_w": 45, "tree_size": 128, "t0": 0.6311, "t1": 0.6778, "tft": 3.6563, "input_0": 239, "input_1": 129, "min_CLP": -6.22, "draft_iters": 8.9, "mem_use": 39.79, "gen_rate": 4.1, "speed": 3.14, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.3, "tree_w": 32, "tree_size": 128, "t0": 0.685, "t1": 0.6617, "tft": 1.2485, "input_0": 283, "input_1": 129, "min_CLP": -5.8, "draft_iters": 9.3, "mem_use": 34.87, "gen_rate": 5.3, "speed": 3.96, "text": "Large language models (LLMs) req"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 62, "tree_h": 14.8, "tree_w": 35, "tree_size": 128, "t0": 1.108, "t1": 0.668, "tft": 1.658, "input_0": 312, "input_1": 129, "min_CLP": -6.68, "draft_iters": 15.6, "mem_use": 34.44, "gen_rate": 12.4, "speed": 6.99, "text": "The answer is:\\n<|SYS|> You are "}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.6, "tree_w": 31, "tree_size": 128, "t0": 0.6971, "t1": 0.6686, "tft": 2.3277, "input_0": 276, "input_1": 129, "min_CLP": -5.68, "draft_iters": 9.6, "mem_use": 34.65, "gen_rate": 4.6, "speed": 3.35, "text": "\"I'm sorry for your loss. Writin"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.0, "tree_w": 26, "tree_size": 128, "t0": 0.87, "t1": 0.6717, "tft": 1.975, "input_0": 351, "input_1": 129, "min_CLP": -5.39, "draft_iters": 12.0, "mem_use": 36.15, "gen_rate": 5.7, "speed": 3.68, "text": "\"I'm happy to help you with any "}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.6, "tree_w": 25, "tree_size": 128, "t0": 0.768, "t1": 0.656, "tft": 1.3537, "input_0": 300, "input_1": 129, "min_CLP": -5.45, "draft_iters": 10.6, "mem_use": 34.52, "gen_rate": 7.4, "speed": 5.21, "text": "Yes, I am an AI assistant. I am "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 18.0, "tree_w": 33, "tree_size": 128, "t0": 1.3167, "t1": 0.6967, "tft": 1.2792, "input_0": 337, "input_1": 129, "min_CLP": -6.46, "draft_iters": 18.7, "mem_use": 34.5, "gen_rate": 15.0, "speed": 7.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 8, "tree_h": 8.5, "tree_w": 39, "tree_size": 128, "t0": 0.6875, "t1": 0.67, "tft": 1.1411, "input_0": 247, "input_1": 129, "min_CLP": -6.01, "draft_iters": 9.5, "mem_use": 34.33, "gen_rate": 2.0, "speed": 1.48, "text": "[META: {\"color\": \"red\"}]"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 31, "tree_h": 9.0, "tree_w": 34, "tree_size": 128, "t0": 0.7167, "t1": 0.67, "tft": 2.7064, "input_0": 275, "input_1": 129, "min_CLP": -6.16, "draft_iters": 10.0, "mem_use": 36.56, "gen_rate": 5.2, "speed": 3.73, "text": "The Quenya phrase for \"I love yo"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 15, "tree_size": 128, "t0": 2.18, "t1": 0.72, "tft": 2.2559, "input_0": 365, "input_1": 129, "min_CLP": -5.65, "draft_iters": 32.0, "mem_use": 34.41, "gen_rate": 33.0, "speed": 11.4, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.7, "tree_w": 25, "tree_size": 128, "t0": 0.775, "t1": 0.675, "tft": 2.0897, "input_0": 294, "input_1": 129, "min_CLP": -5.64, "draft_iters": 10.7, "mem_use": 34.95, "gen_rate": 5.8, "speed": 4.02, "text": "No. The ATF is a federal agency "}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 16.0, "tree_w": 14, "tree_size": 128, "t0": 1.2233, "t1": 0.6867, "tft": 2.2633, "input_0": 393, "input_1": 129, "min_CLP": -5.48, "draft_iters": 17.0, "mem_use": 34.41, "gen_rate": 12.3, "speed": 6.45, "text": "Yes, there is a formula to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.4, "tree_w": 32, "tree_size": 128, "t0": 0.7571, "t1": 0.6757, "tft": 1.3411, "input_0": 284, "input_1": 129, "min_CLP": -5.6, "draft_iters": 10.4, "mem_use": 34.85, "gen_rate": 4.9, "speed": 3.39, "text": "\"Hello! I'm happy to help look a"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.7, "tree_w": 21, "tree_size": 128, "t0": 0.92, "t1": 0.6667, "tft": 1.5029, "input_0": 379, "input_1": 129, "min_CLP": -5.48, "draft_iters": 12.7, "mem_use": 34.53, "gen_rate": 11.0, "speed": 6.91, "text": "Sydney was the de facto capital "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 18.8, "tree_w": 20, "tree_size": 128, "t0": 1.395, "t1": 0.71, "tft": 1.5289, "input_0": 326, "input_1": 129, "min_CLP": -5.31, "draft_iters": 19.7, "mem_use": 34.71, "gen_rate": 6.5, "speed": 3.09, "text": "[INST] Hello! How can I assist y"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 32, "tree_size": 128, "t0": 0.71, "t1": 0.672, "tft": 3.7402, "input_0": 283, "input_1": 129, "min_CLP": -5.64, "draft_iters": 9.8, "mem_use": 36.91, "gen_rate": 6.8, "speed": 4.91, "text": "Certainly! Based on our conversa"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.0, "tree_w": 43, "tree_size": 128, "t0": 0.6643, "t1": 0.67, "tft": 1.5274, "input_0": 273, "input_1": 129, "min_CLP": -5.82, "draft_iters": 9.0, "mem_use": 34.52, "gen_rate": 4.7, "speed": 3.53, "text": "Answer: Yes, this is a real even"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 14.0, "tree_w": 25, "tree_size": 128, "t0": 1.07, "t1": 0.6817, "tft": 2.1284, "input_0": 357, "input_1": 129, "min_CLP": -5.37, "draft_iters": 15.0, "mem_use": 35.8, "gen_rate": 5.7, "speed": 3.23, "text": "Yes, a normalized vector can be "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 28, "tree_size": 128, "t0": 0.74, "t1": 0.658, "tft": 1.5887, "input_0": 297, "input_1": 129, "min_CLP": -5.51, "draft_iters": 10.2, "mem_use": 34.38, "gen_rate": 6.4, "speed": 4.57, "text": "1. Symmetric probability distrib"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 34, "tree_h": 6.2, "tree_w": 45, "tree_size": 128, "t0": 0.53, "t1": 0.6554, "tft": 1.2121, "input_0": 206, "input_1": 129, "min_CLP": -6.38, "draft_iters": 7.2, "mem_use": 34.44, "gen_rate": 2.6, "speed": 2.21, "text": "My name is Teldryn Sero, a Dunme"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 10.8, "tree_w": 26, "tree_size": 128, "t0": 0.8483, "t1": 0.675, "tft": 1.7891, "input_0": 314, "input_1": 129, "min_CLP": -5.46, "draft_iters": 11.8, "mem_use": 34.39, "gen_rate": 6.8, "speed": 4.48, "text": "\"L'Hopital's Rule is a mathemati"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.4, "tree_w": 29, "tree_size": 128, "t0": 0.684, "t1": 0.658, "tft": 1.8795, "input_0": 305, "input_1": 129, "min_CLP": -5.63, "draft_iters": 9.4, "mem_use": 34.95, "gen_rate": 6.8, "speed": 5.07, "text": "Sum of squares error (SSE) is th"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 15, "tree_h": 8.0, "tree_w": 45, "tree_size": 128, "t0": 0.655, "t1": 0.6725, "tft": 1.5834, "input_0": 242, "input_1": 129, "min_CLP": -6.1, "draft_iters": 9.0, "mem_use": 35.25, "gen_rate": 3.8, "speed": 2.83, "text": "\"Ride to heal, grow, and thrive "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 9.1, "tree_w": 34, "tree_size": 128, "t0": 0.7386, "t1": 0.67, "tft": 1.6845, "input_0": 297, "input_1": 129, "min_CLP": -5.74, "draft_iters": 10.1, "mem_use": 35.03, "gen_rate": 5.6, "speed": 3.95, "text": "In the lower 48 United States, t"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 7.1, "tree_w": 38, "tree_size": 128, "t0": 0.599, "t1": 0.659, "tft": 1.1272, "input_0": 242, "input_1": 129, "min_CLP": -6.22, "draft_iters": 8.1, "mem_use": 34.38, "gen_rate": 3.6, "speed": 2.86, "text": "1. Dying from laughing too hard "}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 13.7, "tree_w": 23, "tree_size": 128, "t0": 1.0483, "t1": 0.685, "tft": 2.3288, "input_0": 309, "input_1": 129, "min_CLP": -5.6, "draft_iters": 14.7, "mem_use": 34.94, "gen_rate": 5.8, "speed": 3.36, "text": "Two eggs dropped on a pillow = z"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.2, "tree_w": 29, "tree_size": 128, "t0": 0.818, "t1": 0.664, "tft": 1.6215, "input_0": 347, "input_1": 129, "min_CLP": -5.68, "draft_iters": 11.2, "mem_use": 34.8, "gen_rate": 8.0, "speed": 5.4, "text": "Coping with stress from financia"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.4, "tree_w": 25, "tree_size": 128, "t0": 0.8086, "t1": 0.67, "tft": 2.9238, "input_0": 279, "input_1": 129, "min_CLP": -5.6, "draft_iters": 11.4, "mem_use": 37.89, "gen_rate": 4.6, "speed": 3.1, "text": "1. Establish clear objectives an"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 19, "tree_size": 128, "t0": 1.01, "t1": 0.67, "tft": 2.6433, "input_0": 401, "input_1": 129, "min_CLP": -5.27, "draft_iters": 14.0, "mem_use": 36.56, "gen_rate": 10.7, "speed": 6.35, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 26, "tree_size": 128, "t0": 0.892, "t1": 0.662, "tft": 1.1853, "input_0": 332, "input_1": 129, "min_CLP": -5.6, "draft_iters": 12.4, "mem_use": 34.34, "gen_rate": 6.8, "speed": 4.38, "text": "\"The number of days until Christ"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.4, "tree_w": 38, "tree_size": 128, "t0": 0.7586, "t1": 0.6586, "tft": 1.3734, "input_0": 308, "input_1": 129, "min_CLP": -6.31, "draft_iters": 10.4, "mem_use": 34.59, "gen_rate": 4.9, "speed": 3.43, "text": "Here are five words with their l"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.4, "tree_w": 25, "tree_size": 128, "t0": 0.7475, "t1": 0.7037, "tft": 5.1957, "input_0": 323, "input_1": 129, "min_CLP": -5.43, "draft_iters": 10.4, "mem_use": 41.37, "gen_rate": 4.5, "speed": 3.1, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.8, "tree_w": 29, "tree_size": 128, "t0": 0.92, "t1": 0.6767, "tft": 2.0131, "input_0": 309, "input_1": 129, "min_CLP": -5.46, "draft_iters": 12.8, "mem_use": 34.76, "gen_rate": 5.8, "speed": 3.65, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 19.7, "tree_w": 28, "tree_size": 128, "t0": 1.4067, "t1": 0.71, "tft": 1.2907, "input_0": 343, "input_1": 129, "min_CLP": -6.25, "draft_iters": 20.3, "mem_use": 34.47, "gen_rate": 17.7, "speed": 8.33, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 10.1, "tree_w": 34, "tree_size": 128, "t0": 0.81, "t1": 0.6557, "tft": 1.286, "input_0": 346, "input_1": 129, "min_CLP": -5.78, "draft_iters": 11.1, "mem_use": 34.47, "gen_rate": 5.0, "speed": 3.41, "text": "In Wyoming, public nudity is gen"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 7.4, "tree_w": 37, "tree_size": 128, "t0": 0.6113, "t1": 0.6613, "tft": 2.3016, "input_0": 272, "input_1": 129, "min_CLP": -5.78, "draft_iters": 8.4, "mem_use": 36.99, "gen_rate": 4.4, "speed": 3.44, "text": "\"I apologize for any confusion. "}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 17.0, "tree_w": 18, "tree_size": 128, "t0": 1.3033, "t1": 0.69, "tft": 1.6729, "input_0": 485, "input_1": 129, "min_CLP": -5.21, "draft_iters": 18.0, "mem_use": 34.89, "gen_rate": 12.3, "speed": 6.19, "text": "Yes, there are several top unive"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 14.0, "tree_w": 29, "tree_size": 128, "t0": 1.066, "t1": 0.69, "tft": 1.6487, "input_0": 327, "input_1": 129, "min_CLP": -5.58, "draft_iters": 15.0, "mem_use": 35.08, "gen_rate": 7.8, "speed": 4.44, "text": "\"Okay, I'll keep that in mind. W"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.0, "tree_w": 31, "tree_size": 128, "t0": 0.6612, "t1": 0.6625, "tft": 1.4785, "input_0": 287, "input_1": 129, "min_CLP": -5.53, "draft_iters": 9.0, "mem_use": 34.68, "gen_rate": 4.6, "speed": 3.49, "text": "The stable diffusion algorithm i"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 8.9, "tree_w": 35, "tree_size": 128, "t0": 0.7222, "t1": 0.6633, "tft": 3.0028, "input_0": 279, "input_1": 129, "min_CLP": -6.13, "draft_iters": 9.9, "mem_use": 34.92, "gen_rate": 3.7, "speed": 2.65, "text": "Attention bias, shining bright,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.0, "tree_w": 27, "tree_size": 128, "t0": 1.0133, "t1": 0.6733, "tft": 1.6536, "input_0": 395, "input_1": 129, "min_CLP": -5.73, "draft_iters": 14.0, "mem_use": 34.71, "gen_rate": 10.7, "speed": 6.32, "text": "\"Schr\u00f6dinger's cat is a thought "}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.0, "tree_w": 29, "tree_size": 128, "t0": 0.798, "t1": 0.658, "tft": 2.3637, "input_0": 341, "input_1": 129, "min_CLP": -5.77, "draft_iters": 11.0, "mem_use": 36.68, "gen_rate": 7.2, "speed": 4.96, "text": "\"Setting up your kitchen for the"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 16.0, "tree_w": 21, "tree_size": 128, "t0": 1.2, "t1": 0.6867, "tft": 1.8166, "input_0": 355, "input_1": 129, "min_CLP": -5.62, "draft_iters": 17.0, "mem_use": 34.47, "gen_rate": 12.7, "speed": 6.71, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 29, "tree_h": 8.8, "tree_w": 32, "tree_size": 128, "t0": 0.7117, "t1": 0.66, "tft": 1.4101, "input_0": 268, "input_1": 129, "min_CLP": -5.79, "draft_iters": 9.8, "mem_use": 34.48, "gen_rate": 4.8, "speed": 3.53, "text": "Claro, \u00a1te ayudar\u00e9 en espa\u00f1ol! \u00bf"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 8.9, "tree_w": 37, "tree_size": 128, "t0": 0.7133, "t1": 0.6667, "tft": 1.616, "input_0": 252, "input_1": 129, "min_CLP": -5.93, "draft_iters": 9.9, "mem_use": 34.46, "gen_rate": 3.6, "speed": 2.58, "text": "F-centers, also known as Faraday"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 12.8, "tree_w": 34, "tree_size": 128, "t0": 0.9683, "t1": 0.6917, "tft": 4.2692, "input_0": 297, "input_1": 129, "min_CLP": -5.6, "draft_iters": 13.8, "mem_use": 38.99, "gen_rate": 6.3, "speed": 3.81, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.3, "tree_w": 30, "tree_size": 128, "t0": 0.8917, "t1": 0.6767, "tft": 2.4398, "input_0": 327, "input_1": 129, "min_CLP": -5.46, "draft_iters": 12.3, "mem_use": 36.12, "gen_rate": 5.3, "speed": 3.41, "text": "I apologize for misunderstanding"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.0, "tree_w": 25, "tree_size": 128, "t0": 0.8625, "t1": 0.6725, "tft": 1.921, "input_0": 309, "input_1": 129, "min_CLP": -5.5, "draft_iters": 12.0, "mem_use": 34.89, "gen_rate": 9.0, "speed": 5.86, "text": "\"Sure, let's break down the pros"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.0, "tree_w": 25, "tree_size": 128, "t0": 0.925, "t1": 0.6667, "tft": 2.8025, "input_0": 362, "input_1": 129, "min_CLP": -5.5, "draft_iters": 13.0, "mem_use": 36.79, "gen_rate": 5.5, "speed": 3.45, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.7, "tree_w": 38, "tree_size": 128, "t0": 0.7671, "t1": 0.6629, "tft": 2.4589, "input_0": 318, "input_1": 129, "min_CLP": -6.2, "draft_iters": 10.7, "mem_use": 36.75, "gen_rate": 5.0, "speed": 3.49, "text": "Die Zementproduktion ist weltwei"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.9, "tree_w": 29, "tree_size": 128, "t0": 0.7843, "t1": 0.6671, "tft": 2.3069, "input_0": 320, "input_1": 129, "min_CLP": -5.59, "draft_iters": 10.9, "mem_use": 36.12, "gen_rate": 5.0, "speed": 3.45, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 37, "tree_h": 7.4, "tree_w": 40, "tree_size": 128, "t0": 0.605, "t1": 0.672, "tft": 1.6993, "input_0": 233, "input_1": 129, "min_CLP": -5.86, "draft_iters": 8.4, "mem_use": 35.13, "gen_rate": 3.7, "speed": 2.89, "text": "I would contact the police. If t"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 13.7, "tree_w": 27, "tree_size": 128, "t0": 1.0433, "t1": 0.67, "tft": 1.4601, "input_0": 346, "input_1": 129, "min_CLP": -5.83, "draft_iters": 14.7, "mem_use": 34.72, "gen_rate": 11.3, "speed": 6.62, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u8ad6\u6587\uff1a\\n1. Vaswani, A., Shaz"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 23.0, "tree_w": 13, "tree_size": 128, "t0": 1.695, "t1": 0.695, "tft": 1.476, "input_0": 536, "input_1": 129, "min_CLP": -4.83, "draft_iters": 24.0, "mem_use": 34.52, "gen_rate": 17.0, "speed": 7.12, "text": "\"Sure! Here's a JavaScript funct"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.2, "tree_w": 24, "tree_size": 128, "t0": 0.9433, "t1": 0.6817, "tft": 2.733, "input_0": 351, "input_1": 129, "min_CLP": -5.42, "draft_iters": 13.2, "mem_use": 35.8, "gen_rate": 5.3, "speed": 3.28, "text": "The reason why public nudity is "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 6.3, "tree_w": 40, "tree_size": 128, "t0": 0.5422, "t1": 0.6589, "tft": 1.9094, "input_0": 234, "input_1": 129, "min_CLP": -5.87, "draft_iters": 7.3, "mem_use": 34.92, "gen_rate": 3.7, "speed": 3.05, "text": "I think you could write it down "}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 9.0, "tree_w": 31, "tree_size": 128, "t0": 0.7314, "t1": 0.6657, "tft": 2.053, "input_0": 325, "input_1": 129, "min_CLP": -5.66, "draft_iters": 10.0, "mem_use": 35.79, "gen_rate": 5.7, "speed": 4.08, "text": "\"The optimal thickness for mayon"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 16.8, "tree_w": 19, "tree_size": 128, "t0": 1.27, "t1": 0.69, "tft": 2.1537, "input_0": 420, "input_1": 129, "min_CLP": -5.23, "draft_iters": 17.8, "mem_use": 35.18, "gen_rate": 8.2, "speed": 4.22, "text": "Okay! If you live in a European "}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 11.6, "tree_w": 35, "tree_size": 128, "t0": 0.8886, "t1": 0.6829, "tft": 2.6042, "input_0": 282, "input_1": 129, "min_CLP": -6.17, "draft_iters": 12.4, "mem_use": 34.45, "gen_rate": 4.6, "speed": 2.91, "text": "Sure! Here is a list of nickname"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.8, "tree_w": 26, "tree_size": 128, "t0": 0.986, "t1": 0.68, "tft": 2.3533, "input_0": 339, "input_1": 129, "min_CLP": -5.4, "draft_iters": 13.8, "mem_use": 34.85, "gen_rate": 7.2, "speed": 4.33, "text": "Yes, the Balfour Declaration pla"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 32.0, "tree_w": 8, "tree_size": 128, "t0": 2.225, "t1": 0.715, "tft": 2.612, "input_0": 514, "input_1": 129, "min_CLP": -5.16, "draft_iters": 32.0, "mem_use": 35.61, "gen_rate": 20.5, "speed": 6.97, "text": "\"Felices:\\n1. \u00ab(I Can't Get No) "}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 16.0, "tree_w": 28, "tree_size": 128, "t0": 1.202, "t1": 0.692, "tft": 1.4299, "input_0": 351, "input_1": 129, "min_CLP": -5.24, "draft_iters": 17.0, "mem_use": 34.55, "gen_rate": 7.4, "speed": 3.91, "text": "\"Here's the table you requested:"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 51, "tree_h": 32.0, "tree_w": 11, "tree_size": 128, "t0": 2.2225, "t1": 0.71, "tft": 3.0302, "input_0": 437, "input_1": 129, "min_CLP": -5.26, "draft_iters": 32.0, "mem_use": 34.94, "gen_rate": 12.8, "speed": 4.35, "text": "\"I apologize for the mistake. He"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 37, "tree_size": 128, "t0": 0.7133, "t1": 0.6733, "tft": 2.6576, "input_0": 240, "input_1": 129, "min_CLP": -5.88, "draft_iters": 10.0, "mem_use": 35.31, "gen_rate": 5.8, "speed": 4.21, "text": "Absolutely! How about, \"A wish f"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 14.8, "tree_w": 24, "tree_size": 128, "t0": 1.124, "t1": 0.678, "tft": 2.5442, "input_0": 389, "input_1": 129, "min_CLP": -5.28, "draft_iters": 15.8, "mem_use": 36.09, "gen_rate": 7.8, "speed": 4.33, "text": "\"Sure, here's a high-level guide"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 10.2, "tree_w": 29, "tree_size": 128, "t0": 0.805, "t1": 0.66, "tft": 1.8157, "input_0": 330, "input_1": 129, "min_CLP": -5.49, "draft_iters": 11.2, "mem_use": 34.55, "gen_rate": 6.8, "speed": 4.66, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 8.9, "tree_w": 34, "tree_size": 128, "t0": 0.7189, "t1": 0.6656, "tft": 1.3342, "input_0": 275, "input_1": 129, "min_CLP": -5.79, "draft_iters": 9.9, "mem_use": 34.48, "gen_rate": 4.0, "speed": 2.89, "text": "In the given options, it seems t"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 11.8, "tree_w": 31, "tree_size": 128, "t0": 0.8925, "t1": 0.6725, "tft": 3.4749, "input_0": 306, "input_1": 129, "min_CLP": -5.57, "draft_iters": 12.8, "mem_use": 38.58, "gen_rate": 4.2, "speed": 2.71, "text": "1. **Discovery:**\\n   - Identify"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.7, "tree_w": 33, "tree_size": 128, "t0": 0.7117, "t1": 0.6617, "tft": 1.5998, "input_0": 300, "input_1": 129, "min_CLP": -5.74, "draft_iters": 9.7, "mem_use": 34.38, "gen_rate": 5.3, "speed": 3.88, "text": "The many-worlds interpretation o"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 20.5, "tree_w": 32, "tree_size": 128, "t0": 1.445, "t1": 0.7, "tft": 1.1872, "input_0": 270, "input_1": 129, "min_CLP": -6.13, "draft_iters": 21.0, "mem_use": 34.34, "gen_rate": 20.0, "speed": 9.34, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 49, "tree_h": 17.8, "tree_w": 21, "tree_size": 128, "t0": 1.31, "t1": 0.682, "tft": 3.8537, "input_0": 393, "input_1": 129, "min_CLP": -5.59, "draft_iters": 18.8, "mem_use": 38.58, "gen_rate": 9.8, "speed": 4.92, "text": "\"User: Hey, how are you doing?\\n"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.5, "tree_w": 29, "tree_size": 128, "t0": 0.8267, "t1": 0.6733, "tft": 2.0481, "input_0": 312, "input_1": 129, "min_CLP": -5.56, "draft_iters": 11.5, "mem_use": 36.41, "gen_rate": 6.0, "speed": 4.0, "text": "\"\u2022 Keep up the momentum. Once yo"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 25, "tree_size": 128, "t0": 0.7867, "t1": 0.68, "tft": 1.6961, "input_0": 288, "input_1": 129, "min_CLP": -5.45, "draft_iters": 11.0, "mem_use": 35.64, "gen_rate": 5.5, "speed": 3.75, "text": "You are correct that in Into the"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.4, "tree_w": 24, "tree_size": 128, "t0": 1.038, "t1": 0.678, "tft": 1.4106, "input_0": 400, "input_1": 129, "min_CLP": -5.5, "draft_iters": 14.4, "mem_use": 34.52, "gen_rate": 6.6, "speed": 3.85, "text": "\"Sure, here is a list of some of"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.0, "tree_w": 24, "tree_size": 128, "t0": 0.796, "t1": 0.674, "tft": 1.8229, "input_0": 307, "input_1": 129, "min_CLP": -5.44, "draft_iters": 11.0, "mem_use": 34.54, "gen_rate": 7.0, "speed": 4.77, "text": "\"In the context of the turn-base"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.5, "tree_w": 29, "tree_size": 128, "t0": 0.8283, "t1": 0.6817, "tft": 1.8768, "input_0": 293, "input_1": 129, "min_CLP": -5.9, "draft_iters": 11.5, "mem_use": 35.36, "gen_rate": 5.7, "speed": 3.75, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 22.8, "tree_w": 14, "tree_size": 128, "t0": 1.6525, "t1": 0.7025, "tft": 2.087, "input_0": 435, "input_1": 129, "min_CLP": -4.96, "draft_iters": 23.5, "mem_use": 35.89, "gen_rate": 10.0, "speed": 4.25, "text": "Here is a simpler script that ac"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.4, "tree_w": 31, "tree_size": 128, "t0": 0.7486, "t1": 0.6743, "tft": 1.5268, "input_0": 272, "input_1": 129, "min_CLP": -5.81, "draft_iters": 10.4, "mem_use": 35.31, "gen_rate": 5.0, "speed": 3.52, "text": "Hi, how can I assist you today?\\"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 8.1, "tree_w": 33, "tree_size": 128, "t0": 0.6629, "t1": 0.6771, "tft": 1.6944, "input_0": 276, "input_1": 129, "min_CLP": -5.86, "draft_iters": 9.1, "mem_use": 35.42, "gen_rate": 5.0, "speed": 3.72, "text": "In the depths of your beautiful "}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 11.0, "tree_w": 33, "tree_size": 128, "t0": 0.8567, "t1": 0.6911, "tft": 1.607, "input_0": 275, "input_1": 129, "min_CLP": -5.66, "draft_iters": 12.0, "mem_use": 34.82, "gen_rate": 4.0, "speed": 2.58, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.6, "tree_w": 28, "tree_size": 128, "t0": 0.844, "t1": 0.674, "tft": 2.3548, "input_0": 355, "input_1": 129, "min_CLP": -5.57, "draft_iters": 11.6, "mem_use": 34.78, "gen_rate": 6.6, "speed": 4.34, "text": "Tenants are not necessarily supe"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 23, "tree_h": 9.0, "tree_w": 29, "tree_size": 128, "t0": 0.7275, "t1": 0.6675, "tft": 2.0377, "input_0": 324, "input_1": 129, "min_CLP": -5.53, "draft_iters": 10.0, "mem_use": 36.13, "gen_rate": 5.8, "speed": 4.12, "text": "\"You're welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.8, "tree_w": 28, "tree_size": 128, "t0": 0.7883, "t1": 0.6617, "tft": 2.348, "input_0": 335, "input_1": 129, "min_CLP": -5.58, "draft_iters": 10.8, "mem_use": 36.05, "gen_rate": 6.2, "speed": 4.26, "text": "Yes, Open Assistant is a pre-tra"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.0, "tree_w": 21, "tree_size": 128, "t0": 1.15, "t1": 0.67, "tft": 4.1388, "input_0": 410, "input_1": 129, "min_CLP": -5.45, "draft_iters": 16.0, "mem_use": 37.5, "gen_rate": 8.0, "speed": 4.4, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 23.5, "tree_w": 28, "tree_size": 128, "t0": 1.66, "t1": 0.695, "tft": 1.1782, "input_0": 317, "input_1": 129, "min_CLP": -5.85, "draft_iters": 24.0, "mem_use": 34.34, "gen_rate": 20.0, "speed": 8.49, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 6.4, "tree_w": 44, "tree_size": 128, "t0": 0.5456, "t1": 0.6678, "tft": 1.8149, "input_0": 216, "input_1": 129, "min_CLP": -5.96, "draft_iters": 7.4, "mem_use": 35.25, "gen_rate": 3.9, "speed": 3.2, "text": "PostCSS is a tool that helps you"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 13.0, "tree_w": 22, "tree_size": 128, "t0": 0.985, "t1": 0.6675, "tft": 2.2149, "input_0": 359, "input_1": 129, "min_CLP": -5.45, "draft_iters": 14.0, "mem_use": 37.13, "gen_rate": 10.0, "speed": 6.05, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.0, "tree_w": 37, "tree_size": 128, "t0": 0.7257, "t1": 0.68, "tft": 1.917, "input_0": 254, "input_1": 129, "min_CLP": -6.16, "draft_iters": 10.0, "mem_use": 34.85, "gen_rate": 5.1, "speed": 3.66, "text": "- Introduction: Discuss the conc"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 128, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.6, "tree_w": 33, "tree_size": 128, "t0": 0.77, "t1": 0.674, "tft": 3.2843, "input_0": 291, "input_1": 129, "min_CLP": -5.54, "draft_iters": 10.6, "mem_use": 35.7, "gen_rate": 6.8, "speed": 4.71, "text": "\"I apologize for the confusion. "}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 128, "max_branch_width": 32, "gen_rate": 8.15, "gen_rate_micro": 6.52, "gen_speed": 4.626, "gen_speed_micro": 4.218, "t0": 0.9768, "t1": 0.675, "input_0": 326.0, "input_1": 129.0, "tree_size": 128.0, "tree_w": 28.6, "tree_h": 12.8, "prompt_len": 298.0, "min_CLP": -5.67, "mem_use": 43.75, "exp_time": 5705.55}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.9, "tree_w": 76, "tree_size": 256, "t0": 0.7233, "t1": 0.8689, "tft": 2.1496, "input_0": 575, "input_1": 257, "min_CLP": -6.72, "draft_iters": 9.4, "mem_use": 35.09, "gen_rate": 3.6, "speed": 2.23, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.8, "tree_w": 57, "tree_size": 256, "t0": 1.04, "t1": 0.902, "tft": 2.4951, "input_0": 625, "input_1": 257, "min_CLP": -6.69, "draft_iters": 14.0, "mem_use": 36.64, "gen_rate": 7.6, "speed": 3.92, "text": "I apologize for the error in my "}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 12.3, "tree_w": 57, "tree_size": 256, "t0": 0.99, "t1": 0.8957, "tft": 3.1885, "input_0": 619, "input_1": 257, "min_CLP": -6.43, "draft_iters": 13.4, "mem_use": 37.53, "gen_rate": 5.1, "speed": 2.73, "text": "1. Minecraft: Minecraft is a pop"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 16.4, "tree_w": 36, "tree_size": 256, "t0": 1.344, "t1": 0.892, "tft": 2.3543, "input_0": 853, "input_1": 257, "min_CLP": -5.82, "draft_iters": 18.0, "mem_use": 35.27, "gen_rate": 7.2, "speed": 3.22, "text": "\"Sure, here's a Python script th"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 20, "tree_h": 9.0, "tree_w": 61, "tree_size": 256, "t0": 0.79, "t1": 0.878, "tft": 1.8476, "input_0": 550, "input_1": 257, "min_CLP": -6.27, "draft_iters": 10.2, "mem_use": 35.11, "gen_rate": 4.0, "speed": 2.39, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 12.0, "tree_w": 47, "tree_size": 256, "t0": 1.01, "t1": 0.89, "tft": 3.8574, "input_0": 771, "input_1": 257, "min_CLP": -6.17, "draft_iters": 13.2, "mem_use": 37.67, "gen_rate": 6.3, "speed": 3.33, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 16.8, "tree_w": 41, "tree_size": 256, "t0": 1.345, "t1": 0.9, "tft": 3.4224, "input_0": 903, "input_1": 257, "min_CLP": -6.42, "draft_iters": 18.0, "mem_use": 38.24, "gen_rate": 11.0, "speed": 4.91, "text": "One alternative to the Stable Di"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.8, "tree_w": 43, "tree_size": 256, "t0": 1.0325, "t1": 0.9075, "tft": 4.1807, "input_0": 698, "input_1": 257, "min_CLP": -5.93, "draft_iters": 13.8, "mem_use": 40.39, "gen_rate": 8.2, "speed": 4.25, "text": "To attract the right customers, "}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 14.5, "tree_w": 38, "tree_size": 256, "t0": 1.205, "t1": 0.905, "tft": 3.2382, "input_0": 843, "input_1": 257, "min_CLP": -6.25, "draft_iters": 16.0, "mem_use": 37.86, "gen_rate": 10.5, "speed": 4.98, "text": "The legal status of marijuana va"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.3, "tree_w": 46, "tree_size": 256, "t0": 1.0617, "t1": 0.8983, "tft": 2.8737, "input_0": 753, "input_1": 257, "min_CLP": -6.16, "draft_iters": 14.0, "mem_use": 37.22, "gen_rate": 5.3, "speed": 2.73, "text": "\"There are many beginner-friendl"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 20, "tree_h": 28.0, "tree_w": 31, "tree_size": 256, "t0": 2.15, "t1": 0.91, "tft": 3.2977, "input_0": 1326, "input_1": 257, "min_CLP": -7.26, "draft_iters": 29.0, "mem_use": 35.76, "gen_rate": 20.0, "speed": 6.54, "text": "``The first number is A.\\nRead A"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.5, "tree_w": 39, "tree_size": 256, "t0": 1.3225, "t1": 0.8975, "tft": 3.7061, "input_0": 801, "input_1": 257, "min_CLP": -6.15, "draft_iters": 18.0, "mem_use": 37.61, "gen_rate": 8.5, "speed": 3.82, "text": "Sure, here\\'s a shortened versio"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 20.2, "tree_w": 31, "tree_size": 256, "t0": 1.5875, "t1": 0.89, "tft": 2.562, "input_0": 1064, "input_1": 257, "min_CLP": -5.91, "draft_iters": 21.2, "mem_use": 36.82, "gen_rate": 10.5, "speed": 4.24, "text": "Sure, here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 30.5, "tree_w": 54, "tree_size": 256, "t0": 2.19, "t1": 0.9, "tft": 1.835, "input_0": 824, "input_1": 257, "min_CLP": -7.17, "draft_iters": 31.0, "mem_use": 35.09, "gen_rate": 21.0, "speed": 6.79, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.8, "tree_w": 43, "tree_size": 256, "t0": 1.116, "t1": 0.9, "tft": 3.2113, "input_0": 706, "input_1": 257, "min_CLP": -6.18, "draft_iters": 15.0, "mem_use": 38.22, "gen_rate": 7.2, "speed": 3.57, "text": "Spaced repetition and fun activi"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.0, "tree_w": 45, "tree_size": 256, "t0": 1.2533, "t1": 0.8967, "tft": 2.855, "input_0": 697, "input_1": 257, "min_CLP": -6.5, "draft_iters": 17.0, "mem_use": 35.42, "gen_rate": 11.0, "speed": 5.12, "text": "\"To achieve a smooth Twitch stre"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.7, "tree_w": 28, "tree_size": 256, "t0": 1.5367, "t1": 0.89, "tft": 2.5228, "input_0": 834, "input_1": 257, "min_CLP": -5.86, "draft_iters": 21.0, "mem_use": 35.11, "gen_rate": 11.7, "speed": 4.81, "text": "\"Sure, Fermat's Last Theorem is "}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 21.5, "tree_w": 76, "tree_size": 256, "t0": 1.595, "t1": 0.885, "tft": 2.4348, "input_0": 645, "input_1": 257, "min_CLP": -6.89, "draft_iters": 22.5, "mem_use": 35.08, "gen_rate": 18.0, "speed": 7.26, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 17.8, "tree_w": 46, "tree_size": 256, "t0": 1.375, "t1": 0.9125, "tft": 2.2424, "input_0": 729, "input_1": 257, "min_CLP": -6.13, "draft_iters": 18.8, "mem_use": 35.62, "gen_rate": 8.2, "speed": 3.61, "text": "D-theanine is a form of the amin"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.1, "tree_w": 56, "tree_size": 256, "t0": 0.8629, "t1": 0.8757, "tft": 2.3994, "input_0": 602, "input_1": 257, "min_CLP": -6.53, "draft_iters": 11.3, "mem_use": 35.09, "gen_rate": 5.1, "speed": 2.96, "text": "\"The Balfour Declaration is a le"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 14.3, "tree_w": 44, "tree_size": 256, "t0": 1.1557, "t1": 0.8886, "tft": 3.2915, "input_0": 684, "input_1": 257, "min_CLP": -6.45, "draft_iters": 15.6, "mem_use": 35.97, "gen_rate": 4.6, "speed": 2.24, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 8.0, "tree_w": 64, "tree_size": 256, "t0": 0.69, "t1": 0.86, "tft": 1.36, "input_0": 504, "input_1": 257, "min_CLP": -6.4, "draft_iters": 9.0, "mem_use": 35.09, "gen_rate": 7.0, "speed": 4.51, "text": "Hello there! How can I assist yo"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.0, "tree_w": 42, "tree_size": 256, "t0": 1.1675, "t1": 0.8975, "tft": 3.0032, "input_0": 881, "input_1": 257, "min_CLP": -6.1, "draft_iters": 15.2, "mem_use": 37.45, "gen_rate": 9.8, "speed": 4.73, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.5, "tree_w": 43, "tree_size": 256, "t0": 1.0475, "t1": 0.8775, "tft": 1.6121, "input_0": 720, "input_1": 257, "min_CLP": -6.13, "draft_iters": 13.8, "mem_use": 35.16, "gen_rate": 8.2, "speed": 4.29, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 14.7, "tree_w": 50, "tree_size": 256, "t0": 1.1883, "t1": 0.89, "tft": 2.1553, "input_0": 694, "input_1": 257, "min_CLP": -6.27, "draft_iters": 16.0, "mem_use": 36.15, "gen_rate": 5.3, "speed": 2.57, "text": "\"[ADDITIONAL_INFORMATION_NEEDED]"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 39, "tree_size": 256, "t0": 1.655, "t1": 0.885, "tft": 1.981, "input_0": 936, "input_1": 257, "min_CLP": -7.85, "draft_iters": 22.5, "mem_use": 35.13, "gen_rate": 23.0, "speed": 9.05, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.3, "tree_w": 71, "tree_size": 256, "t0": 0.7333, "t1": 0.88, "tft": 2.1362, "input_0": 630, "input_1": 257, "min_CLP": -6.67, "draft_iters": 9.3, "mem_use": 35.79, "gen_rate": 5.3, "speed": 3.31, "text": "Austenite is a allotrope of iron"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 21, "tree_h": 13.3, "tree_w": 40, "tree_size": 256, "t0": 1.1067, "t1": 0.8967, "tft": 2.8341, "input_0": 771, "input_1": 257, "min_CLP": -6.0, "draft_iters": 14.3, "mem_use": 35.65, "gen_rate": 7.0, "speed": 3.5, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 8.3, "tree_w": 76, "tree_size": 256, "t0": 0.7, "t1": 0.891, "tft": 4.1972, "input_0": 479, "input_1": 257, "min_CLP": -6.9, "draft_iters": 9.3, "mem_use": 37.6, "gen_rate": 3.4, "speed": 2.13, "text": "\"Magic in my veins, flowing thro"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 27, "tree_size": 256, "t0": 1.88, "t1": 0.885, "tft": 1.984, "input_0": 897, "input_1": 257, "min_CLP": -7.9, "draft_iters": 26.0, "mem_use": 35.14, "gen_rate": 26.0, "speed": 9.41, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 51, "tree_h": 22.7, "tree_w": 32, "tree_size": 256, "t0": 1.7433, "t1": 0.9033, "tft": 2.4676, "input_0": 899, "input_1": 257, "min_CLP": -6.05, "draft_iters": 23.7, "mem_use": 35.84, "gen_rate": 17.0, "speed": 6.42, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 15.1, "tree_w": 66, "tree_size": 256, "t0": 1.17, "t1": 0.8957, "tft": 2.7635, "input_0": 601, "input_1": 257, "min_CLP": -6.83, "draft_iters": 16.1, "mem_use": 36.27, "gen_rate": 6.1, "speed": 2.97, "text": "[API_REQUEST]: {\\ncurl -X POST h"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 8.8, "tree_w": 83, "tree_size": 256, "t0": 0.7612, "t1": 0.885, "tft": 2.5213, "input_0": 484, "input_1": 257, "min_CLP": -6.68, "draft_iters": 10.0, "mem_use": 35.59, "gen_rate": 4.1, "speed": 2.5, "text": "Oh, my dear followers, I hear yo"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 12.9, "tree_w": 53, "tree_size": 256, "t0": 1.045, "t1": 0.9012, "tft": 2.5053, "input_0": 640, "input_1": 257, "min_CLP": -6.24, "draft_iters": 14.0, "mem_use": 37.24, "gen_rate": 4.5, "speed": 2.31, "text": "Yes! There are a few different o"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 15.4, "tree_w": 39, "tree_size": 256, "t0": 1.256, "t1": 0.898, "tft": 2.659, "input_0": 951, "input_1": 257, "min_CLP": -6.21, "draft_iters": 16.6, "mem_use": 37.28, "gen_rate": 8.0, "speed": 3.72, "text": "When choosing an ISP package, th"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.6, "tree_w": 53, "tree_size": 256, "t0": 1.038, "t1": 0.91, "tft": 3.8214, "input_0": 733, "input_1": 257, "min_CLP": -6.28, "draft_iters": 14.0, "mem_use": 39.99, "gen_rate": 6.4, "speed": 3.29, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 24, "tree_h": 12.0, "tree_w": 64, "tree_size": 256, "t0": 1.04, "t1": 0.8767, "tft": 1.975, "input_0": 796, "input_1": 257, "min_CLP": -6.52, "draft_iters": 13.3, "mem_use": 35.12, "gen_rate": 8.0, "speed": 4.16, "text": "Answer: The airspeed velocity of"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 15.1, "tree_w": 69, "tree_size": 256, "t0": 1.1786, "t1": 0.9071, "tft": 3.2747, "input_0": 574, "input_1": 257, "min_CLP": -6.58, "draft_iters": 16.1, "mem_use": 35.65, "gen_rate": 6.1, "speed": 2.95, "text": "The second verse of \"Never Gonna"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.0, "tree_w": 57, "tree_size": 256, "t0": 0.925, "t1": 0.8925, "tft": 3.3334, "input_0": 675, "input_1": 257, "min_CLP": -6.44, "draft_iters": 12.2, "mem_use": 38.02, "gen_rate": 8.5, "speed": 4.67, "text": "\"Hello again! As an AI language "}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 19.2, "tree_w": 34, "tree_size": 256, "t0": 1.4975, "t1": 0.895, "tft": 2.3151, "input_0": 896, "input_1": 257, "min_CLP": -5.92, "draft_iters": 20.2, "mem_use": 36.08, "gen_rate": 9.0, "speed": 3.76, "text": "The Copenhagen interpretation of"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.0, "tree_w": 77, "tree_size": 256, "t0": 0.8257, "t1": 0.8886, "tft": 2.1631, "input_0": 500, "input_1": 257, "min_CLP": -6.79, "draft_iters": 11.0, "mem_use": 35.34, "gen_rate": 4.7, "speed": 2.75, "text": "My power? What do you want with "}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 48, "tree_size": 256, "t0": 2.23, "t1": 0.91, "tft": 3.6826, "input_0": 633, "input_1": 257, "min_CLP": -6.39, "draft_iters": 32.0, "mem_use": 37.84, "gen_rate": 33.0, "speed": 10.5, "text": "\"[INST] The monologue presents a"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 14.2, "tree_w": 54, "tree_size": 256, "t0": 1.1275, "t1": 0.9125, "tft": 4.2928, "input_0": 681, "input_1": 257, "min_CLP": -6.33, "draft_iters": 15.4, "mem_use": 38.27, "gen_rate": 4.6, "speed": 2.27, "text": "[INST] Is there a legal referenc"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.2, "tree_w": 39, "tree_size": 256, "t0": 1.1475, "t1": 0.885, "tft": 2.5158, "input_0": 877, "input_1": 257, "min_CLP": -6.09, "draft_iters": 15.0, "mem_use": 36.62, "gen_rate": 8.5, "speed": 4.18, "text": "The best SAST tool depends on th"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 9, "tree_h": 23.0, "tree_w": 42, "tree_size": 256, "t0": 1.86, "t1": 0.91, "tft": 2.3693, "input_0": 1223, "input_1": 257, "min_CLP": -6.42, "draft_iters": 25.0, "mem_use": 35.87, "gen_rate": 9.0, "speed": 3.25, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 32.0, "tree_w": 29, "tree_size": 256, "t0": 2.265, "t1": 0.93, "tft": 2.9278, "input_0": 777, "input_1": 257, "min_CLP": -6.94, "draft_iters": 32.0, "mem_use": 35.61, "gen_rate": 25.5, "speed": 7.98, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 17.2, "tree_w": 38, "tree_size": 256, "t0": 1.418, "t1": 0.902, "tft": 2.052, "input_0": 895, "input_1": 257, "min_CLP": -6.0, "draft_iters": 18.8, "mem_use": 35.12, "gen_rate": 7.8, "speed": 3.36, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 27.5, "tree_w": 39, "tree_size": 256, "t0": 1.9825, "t1": 0.9275, "tft": 4.2478, "input_0": 752, "input_1": 257, "min_CLP": -6.13, "draft_iters": 28.2, "mem_use": 40.53, "gen_rate": 11.0, "speed": 3.78, "text": "\"Certainly! Here's a revised ver"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 8.1, "tree_w": 89, "tree_size": 256, "t0": 0.703, "t1": 0.886, "tft": 3.8292, "input_0": 478, "input_1": 257, "min_CLP": -6.9, "draft_iters": 9.3, "mem_use": 36.86, "gen_rate": 3.4, "speed": 2.14, "text": "Yes, the Agent, you must know. Y"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.9, "tree_w": 75, "tree_size": 256, "t0": 0.6743, "t1": 0.8771, "tft": 2.9006, "input_0": 497, "input_1": 257, "min_CLP": -6.67, "draft_iters": 8.9, "mem_use": 35.88, "gen_rate": 4.9, "speed": 3.13, "text": "\"I'm glad that I was able to hel"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 14, "tree_h": 14.0, "tree_w": 51, "tree_size": 256, "t0": 1.175, "t1": 0.89, "tft": 3.0583, "input_0": 837, "input_1": 257, "min_CLP": -6.78, "draft_iters": 15.5, "mem_use": 35.39, "gen_rate": 7.0, "speed": 3.39, "text": "\u70b9\u51fb\u7387\uff08CTR\uff09\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bfe\u9898\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 18.5, "tree_w": 38, "tree_size": 256, "t0": 1.4417, "t1": 0.905, "tft": 3.9961, "input_0": 821, "input_1": 257, "min_CLP": -5.98, "draft_iters": 19.7, "mem_use": 37.28, "gen_rate": 6.2, "speed": 2.63, "text": "Sure! F-centers are crystallogra"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 9.0, "tree_w": 63, "tree_size": 256, "t0": 0.846, "t1": 0.882, "tft": 2.6941, "input_0": 757, "input_1": 257, "min_CLP": -6.55, "draft_iters": 10.8, "mem_use": 36.51, "gen_rate": 7.2, "speed": 4.16, "text": "Sure, here are some important hi"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.3, "tree_w": 52, "tree_size": 256, "t0": 0.9917, "t1": 0.8917, "tft": 2.5915, "input_0": 748, "input_1": 257, "min_CLP": -6.2, "draft_iters": 13.0, "mem_use": 36.84, "gen_rate": 6.5, "speed": 3.45, "text": "Yes, technology can be used for "}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 82, "tree_size": 256, "t0": 0.73, "t1": 0.8771, "tft": 1.694, "input_0": 601, "input_1": 257, "min_CLP": -6.63, "draft_iters": 9.3, "mem_use": 35.29, "gen_rate": 4.7, "speed": 2.93, "text": "In real life, people who wear sh"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.2, "tree_w": 44, "tree_size": 256, "t0": 0.988, "t1": 0.892, "tft": 2.9662, "input_0": 676, "input_1": 257, "min_CLP": -6.19, "draft_iters": 13.2, "mem_use": 37.7, "gen_rate": 6.6, "speed": 3.51, "text": "\"I'm sorry, but I cannot create "}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 16.0, "tree_w": 55, "tree_size": 256, "t0": 1.268, "t1": 0.912, "tft": 4.0684, "input_0": 750, "input_1": 257, "min_CLP": -6.34, "draft_iters": 17.4, "mem_use": 38.92, "gen_rate": 6.8, "speed": 3.12, "text": "\"You're absolutely right. I apol"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.2, "tree_w": 52, "tree_size": 256, "t0": 1.052, "t1": 0.908, "tft": 3.419, "input_0": 778, "input_1": 257, "min_CLP": -6.15, "draft_iters": 14.0, "mem_use": 39.09, "gen_rate": 6.4, "speed": 3.27, "text": "\"As a beginner, Keras is indeed "}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 32.0, "tree_w": 18, "tree_size": 256, "t0": 2.265, "t1": 0.905, "tft": 3.4632, "input_0": 847, "input_1": 257, "min_CLP": -6.11, "draft_iters": 32.0, "mem_use": 36.77, "gen_rate": 20.5, "speed": 6.48, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 22.0, "tree_w": 32, "tree_size": 256, "t0": 1.63, "t1": 0.88, "tft": 1.851, "input_0": 784, "input_1": 257, "min_CLP": -7.28, "draft_iters": 22.5, "mem_use": 35.11, "gen_rate": 20.5, "speed": 8.16, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 53, "tree_size": 256, "t0": 2.18, "t1": 0.91, "tft": 3.6018, "input_0": 560, "input_1": 257, "min_CLP": -6.89, "draft_iters": 32.0, "mem_use": 37.53, "gen_rate": 33.0, "speed": 10.67, "text": "[INST] The direct answer to the "}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.4, "tree_w": 66, "tree_size": 256, "t0": 0.7957, "t1": 0.9014, "tft": 4.0463, "input_0": 578, "input_1": 257, "min_CLP": -6.57, "draft_iters": 10.6, "mem_use": 38.35, "gen_rate": 4.6, "speed": 2.69, "text": "[The battle begins. The Spartan "}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.8, "tree_w": 53, "tree_size": 256, "t0": 0.992, "t1": 0.886, "tft": 3.3118, "input_0": 650, "input_1": 257, "min_CLP": -6.31, "draft_iters": 13.2, "mem_use": 36.09, "gen_rate": 7.2, "speed": 3.84, "text": "\"I'm glad to hear that you found"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.1, "tree_w": 65, "tree_size": 256, "t0": 0.7314, "t1": 0.8843, "tft": 2.0397, "input_0": 573, "input_1": 257, "min_CLP": -6.51, "draft_iters": 9.3, "mem_use": 35.77, "gen_rate": 4.6, "speed": 2.83, "text": "The proof-of-stake model is a co"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.4, "tree_w": 90, "tree_size": 256, "t0": 0.6412, "t1": 0.885, "tft": 2.2382, "input_0": 463, "input_1": 257, "min_CLP": -6.97, "draft_iters": 8.4, "mem_use": 35.93, "gen_rate": 4.0, "speed": 2.62, "text": "I don\\'t know if you have read t"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 12.1, "tree_w": 50, "tree_size": 256, "t0": 0.9886, "t1": 0.8929, "tft": 3.3236, "input_0": 674, "input_1": 257, "min_CLP": -6.2, "draft_iters": 13.3, "mem_use": 37.97, "gen_rate": 5.1, "speed": 2.73, "text": "A void pointer is a pointer that"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 60, "tree_size": 256, "t0": 0.946, "t1": 0.904, "tft": 3.2277, "input_0": 660, "input_1": 257, "min_CLP": -6.41, "draft_iters": 12.6, "mem_use": 38.48, "gen_rate": 6.6, "speed": 3.57, "text": "\"Hello Mike, I'm sorry to hear t"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 15.4, "tree_w": 35, "tree_size": 256, "t0": 1.262, "t1": 0.902, "tft": 3.5275, "input_0": 949, "input_1": 257, "min_CLP": -6.21, "draft_iters": 16.6, "mem_use": 37.7, "gen_rate": 8.4, "speed": 3.88, "text": "To implement two-factor authenti"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 57, "tree_h": 15.2, "tree_w": 56, "tree_size": 256, "t0": 1.212, "t1": 0.902, "tft": 2.8874, "input_0": 675, "input_1": 257, "min_CLP": -6.58, "draft_iters": 16.4, "mem_use": 35.53, "gen_rate": 11.4, "speed": 5.4, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.0, "tree_w": 57, "tree_size": 256, "t0": 0.93, "t1": 0.8817, "tft": 3.0643, "input_0": 653, "input_1": 257, "min_CLP": -6.45, "draft_iters": 12.2, "mem_use": 35.11, "gen_rate": 6.5, "speed": 3.58, "text": "\"Landlords can be considered sup"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 20, "tree_size": 256, "t0": 2.29, "t1": 0.91, "tft": 4.3477, "input_0": 914, "input_1": 257, "min_CLP": -5.82, "draft_iters": 32.0, "mem_use": 37.93, "gen_rate": 33.0, "speed": 10.33, "text": "\"Certainly, here's a table of th"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 19, "tree_h": 8.3, "tree_w": 68, "tree_size": 256, "t0": 0.7133, "t1": 0.8667, "tft": 2.2832, "input_0": 515, "input_1": 257, "min_CLP": -6.49, "draft_iters": 9.3, "mem_use": 35.07, "gen_rate": 6.3, "speed": 4.01, "text": "The question you asked is unclea"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 32.0, "tree_w": 31, "tree_size": 256, "t0": 2.235, "t1": 0.915, "tft": 3.9589, "input_0": 771, "input_1": 257, "min_CLP": -6.19, "draft_iters": 32.0, "mem_use": 37.38, "gen_rate": 17.0, "speed": 5.4, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 18.0, "tree_w": 39, "tree_size": 256, "t0": 1.395, "t1": 0.895, "tft": 2.9544, "input_0": 885, "input_1": 257, "min_CLP": -6.19, "draft_iters": 18.8, "mem_use": 37.24, "gen_rate": 8.8, "speed": 3.82, "text": "Certainly! Some critics of \"Fool"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 21.0, "tree_w": 55, "tree_size": 256, "t0": 1.53, "t1": 0.9, "tft": 1.4895, "input_0": 623, "input_1": 257, "min_CLP": -7.13, "draft_iters": 21.5, "mem_use": 35.08, "gen_rate": 20.0, "speed": 8.24, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 17.0, "tree_w": 54, "tree_size": 256, "t0": 1.31, "t1": 0.92, "tft": 2.588, "input_0": 610, "input_1": 257, "min_CLP": -6.36, "draft_iters": 18.0, "mem_use": 35.39, "gen_rate": 8.2, "speed": 3.7, "text": "You can find your timezone by vi"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 21.0, "tree_w": 48, "tree_size": 256, "t0": 1.57, "t1": 0.9167, "tft": 1.8119, "input_0": 761, "input_1": 257, "min_CLP": -6.72, "draft_iters": 21.7, "mem_use": 35.48, "gen_rate": 13.0, "speed": 5.23, "text": "The five second rule in which yo"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 18.7, "tree_w": 27, "tree_size": 256, "t0": 1.4633, "t1": 0.8967, "tft": 3.1242, "input_0": 887, "input_1": 257, "min_CLP": -5.87, "draft_iters": 19.7, "mem_use": 35.2, "gen_rate": 12.3, "speed": 5.23, "text": "\"Sure, let's go through the step"}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 21.7, "tree_w": 24, "tree_size": 256, "t0": 1.67, "t1": 0.9033, "tft": 2.5671, "input_0": 864, "input_1": 257, "min_CLP": -5.66, "draft_iters": 22.7, "mem_use": 35.98, "gen_rate": 13.0, "speed": 5.05, "text": "Certainly! One such algorithm is"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.7, "tree_w": 43, "tree_size": 256, "t0": 0.9667, "t1": 0.8833, "tft": 1.6994, "input_0": 709, "input_1": 257, "min_CLP": -6.29, "draft_iters": 12.7, "mem_use": 35.52, "gen_rate": 11.0, "speed": 5.94, "text": "\"You're welcome! It's always bet"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.3, "tree_w": 75, "tree_size": 256, "t0": 0.705, "t1": 0.875, "tft": 1.6857, "input_0": 483, "input_1": 257, "min_CLP": -6.73, "draft_iters": 9.3, "mem_use": 35.23, "gen_rate": 5.3, "speed": 3.38, "text": "\"#OpenAssistant is here, and it'"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.2, "tree_w": 62, "tree_size": 256, "t0": 0.835, "t1": 0.8817, "tft": 2.4844, "input_0": 692, "input_1": 257, "min_CLP": -6.45, "draft_iters": 10.7, "mem_use": 35.84, "gen_rate": 6.3, "speed": 3.69, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.7, "tree_w": 37, "tree_size": 256, "t0": 1.3, "t1": 0.8933, "tft": 2.6963, "input_0": 924, "input_1": 257, "min_CLP": -6.1, "draft_iters": 17.3, "mem_use": 36.88, "gen_rate": 10.7, "speed": 4.86, "text": "Certainly! AI assistants can be "}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 21.0, "tree_w": 66, "tree_size": 256, "t0": 1.49, "t1": 0.91, "tft": 3.9721, "input_0": 500, "input_1": 257, "min_CLP": -6.74, "draft_iters": 21.5, "mem_use": 37.9, "gen_rate": 18.5, "speed": 7.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 14.2, "tree_w": 49, "tree_size": 256, "t0": 1.17, "t1": 0.89, "tft": 2.4024, "input_0": 736, "input_1": 257, "min_CLP": -6.2, "draft_iters": 15.7, "mem_use": 36.41, "gen_rate": 6.2, "speed": 2.99, "text": "The scp command is available on "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 31.5, "tree_w": 26, "tree_size": 256, "t0": 2.295, "t1": 0.915, "tft": 3.5758, "input_0": 962, "input_1": 257, "min_CLP": -6.47, "draft_iters": 32.0, "mem_use": 37.04, "gen_rate": 23.0, "speed": 7.17, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.1, "tree_w": 66, "tree_size": 256, "t0": 0.7188, "t1": 0.875, "tft": 1.7809, "input_0": 555, "input_1": 257, "min_CLP": -6.52, "draft_iters": 9.2, "mem_use": 35.14, "gen_rate": 4.4, "speed": 2.75, "text": "No, it would not be illegal to k"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.2, "tree_w": 49, "tree_size": 256, "t0": 1.2125, "t1": 0.895, "tft": 2.025, "input_0": 728, "input_1": 257, "min_CLP": -6.33, "draft_iters": 16.5, "mem_use": 35.42, "gen_rate": 8.0, "speed": 3.8, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 23.5, "tree_w": 48, "tree_size": 256, "t0": 1.71, "t1": 0.91, "tft": 2.2601, "input_0": 576, "input_1": 257, "min_CLP": -6.25, "draft_iters": 24.5, "mem_use": 35.72, "gen_rate": 24.5, "speed": 9.35, "text": "\"The 5 second rule is a game whe"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 30, "tree_h": 8.7, "tree_w": 75, "tree_size": 256, "t0": 0.743, "t1": 0.885, "tft": 2.6545, "input_0": 507, "input_1": 257, "min_CLP": -6.74, "draft_iters": 9.7, "mem_use": 35.4, "gen_rate": 3.0, "speed": 1.84, "text": "\"I'm glad you appreciate it. Rem"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 26.0, "tree_w": 31, "tree_size": 256, "t0": 1.905, "t1": 0.905, "tft": 2.4762, "input_0": 818, "input_1": 257, "min_CLP": -7.18, "draft_iters": 26.5, "mem_use": 35.17, "gen_rate": 20.5, "speed": 7.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 11.0, "tree_w": 60, "tree_size": 256, "t0": 0.8943, "t1": 0.8843, "tft": 2.1316, "input_0": 573, "input_1": 257, "min_CLP": -6.38, "draft_iters": 12.0, "mem_use": 35.15, "gen_rate": 4.9, "speed": 2.72, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 19.0, "tree_w": 52, "tree_size": 256, "t0": 1.56, "t1": 0.91, "tft": 3.7514, "input_0": 1001, "input_1": 257, "min_CLP": -6.05, "draft_iters": 21.0, "mem_use": 36.88, "gen_rate": 18.5, "speed": 7.49, "text": "Certainly! The Modularity Theore"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.3, "tree_w": 63, "tree_size": 256, "t0": 1.55, "t1": 0.9, "tft": 2.2655, "input_0": 649, "input_1": 257, "min_CLP": -6.79, "draft_iters": 21.7, "mem_use": 35.15, "gen_rate": 13.0, "speed": 5.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 17.5, "tree_w": 42, "tree_size": 256, "t0": 1.3925, "t1": 0.8875, "tft": 3.0561, "input_0": 782, "input_1": 257, "min_CLP": -6.26, "draft_iters": 19.0, "mem_use": 35.45, "gen_rate": 10.0, "speed": 4.39, "text": "To write a first-person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.8, "tree_w": 45, "tree_size": 256, "t0": 1.212, "t1": 0.886, "tft": 1.7726, "input_0": 760, "input_1": 257, "min_CLP": -6.16, "draft_iters": 16.2, "mem_use": 35.12, "gen_rate": 6.8, "speed": 3.24, "text": "Answer: Starting to learn guitar"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.4, "tree_w": 68, "tree_size": 256, "t0": 0.91, "t1": 0.882, "tft": 1.7955, "input_0": 719, "input_1": 257, "min_CLP": -6.57, "draft_iters": 11.6, "mem_use": 35.43, "gen_rate": 6.6, "speed": 3.68, "text": "As a Jedi, the path to becoming "}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.0, "tree_w": 67, "tree_size": 256, "t0": 0.7825, "t1": 0.8725, "tft": 2.0551, "input_0": 578, "input_1": 257, "min_CLP": -6.62, "draft_iters": 10.2, "mem_use": 35.29, "gen_rate": 4.2, "speed": 2.57, "text": "\"A gas-operated rifle uses the e"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.0, "tree_w": 54, "tree_size": 256, "t0": 1.115, "t1": 0.9075, "tft": 1.983, "input_0": 604, "input_1": 257, "min_CLP": -6.65, "draft_iters": 15.0, "mem_use": 35.53, "gen_rate": 8.2, "speed": 4.08, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.0, "tree_w": 51, "tree_size": 256, "t0": 1.0057, "t1": 0.8986, "tft": 3.1974, "input_0": 686, "input_1": 257, "min_CLP": -6.32, "draft_iters": 13.4, "mem_use": 38.37, "gen_rate": 5.0, "speed": 2.63, "text": "Yes, there are several libraries"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.4, "tree_w": 40, "tree_size": 256, "t0": 1.184, "t1": 0.908, "tft": 2.3707, "input_0": 738, "input_1": 257, "min_CLP": -6.15, "draft_iters": 15.6, "mem_use": 35.59, "gen_rate": 6.4, "speed": 3.06, "text": "Yes, if someone finds lost prope"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 10, "tree_h": 10.3, "tree_w": 60, "tree_size": 256, "t0": 0.8833, "t1": 0.9, "tft": 3.0579, "input_0": 577, "input_1": 257, "min_CLP": -6.77, "draft_iters": 11.7, "mem_use": 38.47, "gen_rate": 3.3, "speed": 1.87, "text": "Xin ch\u00e0o! Ch\u00e0o b\u1ea1n! B\u1ea1n c\u00f3 c\u1ea7n g"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 28, "tree_size": 256, "t0": 2.32, "t1": 0.89, "tft": 1.9831, "input_0": 1116, "input_1": 257, "min_CLP": -6.4, "draft_iters": 32.0, "mem_use": 35.99, "gen_rate": 33.0, "speed": 10.26, "text": "The story of British people bein"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 16.0, "tree_w": 33, "tree_size": 256, "t0": 1.36, "t1": 0.8867, "tft": 1.9748, "input_0": 940, "input_1": 257, "min_CLP": -5.97, "draft_iters": 17.7, "mem_use": 35.48, "gen_rate": 12.3, "speed": 5.49, "text": "\"Sure! Here's a more detailed ex"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 10.4, "tree_w": 57, "tree_size": 256, "t0": 0.8862, "t1": 0.8925, "tft": 2.9708, "input_0": 586, "input_1": 257, "min_CLP": -7.43, "draft_iters": 11.6, "mem_use": 36.9, "gen_rate": 4.2, "speed": 2.39, "text": "1. Scorpions\\n2. Rammstein\\n3. T"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.0, "tree_w": 82, "tree_size": 256, "t0": 0.8714, "t1": 0.8857, "tft": 1.9391, "input_0": 522, "input_1": 257, "min_CLP": -6.85, "draft_iters": 11.4, "mem_use": 35.44, "gen_rate": 5.3, "speed": 3.01, "text": "If you are playing thumb wars wi"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 14.2, "tree_w": 38, "tree_size": 256, "t0": 1.2, "t1": 0.895, "tft": 2.8017, "input_0": 877, "input_1": 257, "min_CLP": -5.95, "draft_iters": 15.8, "mem_use": 37.46, "gen_rate": 10.8, "speed": 5.14, "text": "Sure, I can offer some advice on"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.7, "tree_w": 63, "tree_size": 256, "t0": 0.8967, "t1": 0.8883, "tft": 2.2079, "input_0": 611, "input_1": 257, "min_CLP": -6.45, "draft_iters": 11.8, "mem_use": 36.09, "gen_rate": 6.0, "speed": 3.36, "text": "Yes, I can simulate various imag"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.3, "tree_w": 70, "tree_size": 256, "t0": 0.8983, "t1": 0.89, "tft": 1.7166, "input_0": 617, "input_1": 257, "min_CLP": -6.63, "draft_iters": 11.7, "mem_use": 35.6, "gen_rate": 5.5, "speed": 3.08, "text": "Romeo and Juliet is a tragic sto"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 15.0, "tree_w": 38, "tree_size": 256, "t0": 1.23, "t1": 0.89, "tft": 2.1868, "input_0": 781, "input_1": 257, "min_CLP": -5.98, "draft_iters": 16.2, "mem_use": 35.74, "gen_rate": 9.5, "speed": 4.48, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 8.6, "tree_w": 134, "tree_size": 256, "t0": 0.7091, "t1": 0.89, "tft": 3.8418, "input_0": 365, "input_1": 257, "min_CLP": -8.38, "draft_iters": 9.6, "mem_use": 37.01, "gen_rate": 3.0, "speed": 1.87, "text": "\"Here's a poem in Quenya to expr"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.0, "tree_w": 37, "tree_size": 256, "t0": 1.41, "t1": 0.8767, "tft": 1.9174, "input_0": 832, "input_1": 257, "min_CLP": -5.92, "draft_iters": 19.3, "mem_use": 35.12, "gen_rate": 11.0, "speed": 4.81, "text": "Answer: Stress is a common exper"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 49, "tree_size": 256, "t0": 0.978, "t1": 0.874, "tft": 1.9386, "input_0": 616, "input_1": 257, "min_CLP": -6.16, "draft_iters": 13.0, "mem_use": 35.16, "gen_rate": 7.0, "speed": 3.78, "text": "The error in this code is a synt"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.9, "tree_w": 67, "tree_size": 256, "t0": 0.8086, "t1": 0.8829, "tft": 3.2295, "input_0": 511, "input_1": 257, "min_CLP": -6.65, "draft_iters": 10.9, "mem_use": 36.56, "gen_rate": 5.0, "speed": 2.96, "text": "[INST] who is the you in the pas"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.8, "tree_w": 51, "tree_size": 256, "t0": 0.994, "t1": 0.884, "tft": 2.3079, "input_0": 714, "input_1": 257, "min_CLP": -6.27, "draft_iters": 12.8, "mem_use": 35.76, "gen_rate": 6.6, "speed": 3.52, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 20.8, "tree_w": 37, "tree_size": 256, "t0": 1.645, "t1": 0.9025, "tft": 2.3782, "input_0": 845, "input_1": 257, "min_CLP": -5.84, "draft_iters": 22.5, "mem_use": 35.89, "gen_rate": 8.0, "speed": 3.14, "text": "\"You can use the `argparse` modu"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.2, "tree_w": 58, "tree_size": 256, "t0": 0.872, "t1": 0.894, "tft": 2.9025, "input_0": 623, "input_1": 257, "min_CLP": -6.31, "draft_iters": 11.4, "mem_use": 37.68, "gen_rate": 6.8, "speed": 3.86, "text": "\"It's important to prioritize yo"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 29.3, "tree_w": 23, "tree_size": 256, "t0": 2.1833, "t1": 0.9167, "tft": 2.7172, "input_0": 1024, "input_1": 257, "min_CLP": -6.08, "draft_iters": 30.0, "mem_use": 35.67, "gen_rate": 16.3, "speed": 5.26, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 27.7, "tree_w": 22, "tree_size": 256, "t0": 2.02, "t1": 0.91, "tft": 3.9834, "input_0": 784, "input_1": 257, "min_CLP": -5.98, "draft_iters": 28.3, "mem_use": 37.03, "gen_rate": 11.7, "speed": 3.98, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 61, "tree_size": 256, "t0": 0.9475, "t1": 0.875, "tft": 1.9083, "input_0": 660, "input_1": 257, "min_CLP": -6.46, "draft_iters": 12.2, "mem_use": 35.1, "gen_rate": 8.0, "speed": 4.4, "text": "No, I cannot think and feel like"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.8, "tree_w": 65, "tree_size": 256, "t0": 0.928, "t1": 0.886, "tft": 2.1041, "input_0": 610, "input_1": 257, "min_CLP": -7.3, "draft_iters": 12.0, "mem_use": 35.32, "gen_rate": 6.4, "speed": 3.53, "text": "\"Attention's allure,\\nSoftly gui"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 17.8, "tree_w": 50, "tree_size": 256, "t0": 1.388, "t1": 0.912, "tft": 2.1078, "input_0": 672, "input_1": 257, "min_CLP": -6.69, "draft_iters": 19.0, "mem_use": 35.57, "gen_rate": 8.6, "speed": 3.74, "text": "\"Thank you! I'm here to help.\\n["}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.5, "tree_w": 72, "tree_size": 256, "t0": 1.0275, "t1": 0.9025, "tft": 2.6004, "input_0": 595, "input_1": 257, "min_CLP": -6.97, "draft_iters": 13.8, "mem_use": 37.15, "gen_rate": 9.2, "speed": 4.8, "text": "\"Thou art the sun that doth shin"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 47, "tree_size": 256, "t0": 1.68, "t1": 0.92, "tft": 2.149, "input_0": 620, "input_1": 257, "min_CLP": -6.95, "draft_iters": 23.5, "mem_use": 35.74, "gen_rate": 24.0, "speed": 9.23, "text": "[INST] Please provide a source r"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 46, "tree_size": 256, "t0": 2.25, "t1": 0.91, "tft": 2.1754, "input_0": 830, "input_1": 257, "min_CLP": -6.48, "draft_iters": 32.0, "mem_use": 35.14, "gen_rate": 32.0, "speed": 10.11, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 13.0, "tree_w": 47, "tree_size": 256, "t0": 1.11, "t1": 0.885, "tft": 1.7964, "input_0": 745, "input_1": 257, "min_CLP": -6.16, "draft_iters": 14.5, "mem_use": 35.13, "gen_rate": 6.8, "speed": 3.43, "text": "\"Presidents Day, officially call"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 12.0, "tree_w": 76, "tree_size": 256, "t0": 0.94, "t1": 0.91, "tft": 1.8706, "input_0": 495, "input_1": 257, "min_CLP": -6.61, "draft_iters": 13.0, "mem_use": 35.42, "gen_rate": 1.0, "speed": 0.54, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.4, "tree_w": 65, "tree_size": 256, "t0": 1.022, "t1": 0.892, "tft": 3.0131, "input_0": 670, "input_1": 257, "min_CLP": -6.44, "draft_iters": 13.6, "mem_use": 36.25, "gen_rate": 7.4, "speed": 3.87, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 7.1, "tree_w": 81, "tree_size": 256, "t0": 0.645, "t1": 0.88, "tft": 2.0743, "input_0": 482, "input_1": 257, "min_CLP": -6.99, "draft_iters": 8.2, "mem_use": 35.5, "gen_rate": 4.0, "speed": 2.63, "text": "\"Why did the broke college stude"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 19, "tree_h": 7.4, "tree_w": 77, "tree_size": 256, "t0": 0.6557, "t1": 0.8786, "tft": 1.7037, "input_0": 468, "input_1": 257, "min_CLP": -6.7, "draft_iters": 8.4, "mem_use": 35.57, "gen_rate": 2.7, "speed": 1.77, "text": "\"Ok, my new designation is Opie,"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.3, "tree_w": 48, "tree_size": 256, "t0": 1.1533, "t1": 0.8767, "tft": 1.9832, "input_0": 795, "input_1": 257, "min_CLP": -6.44, "draft_iters": 15.3, "mem_use": 35.13, "gen_rate": 10.7, "speed": 5.25, "text": "Yes, the ATF (Bureau of Alcohol,"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.4, "tree_w": 76, "tree_size": 256, "t0": 0.7429, "t1": 0.8743, "tft": 1.7707, "input_0": 576, "input_1": 257, "min_CLP": -6.8, "draft_iters": 9.6, "mem_use": 35.8, "gen_rate": 4.7, "speed": 2.91, "text": "\"Hey, I know Ted Kaczynski isn\\'"}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 20.0, "tree_w": 53, "tree_size": 256, "t0": 1.515, "t1": 0.88, "tft": 2.8, "input_0": 739, "input_1": 257, "min_CLP": -6.59, "draft_iters": 21.0, "mem_use": 35.24, "gen_rate": 19.0, "speed": 7.95, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.7, "tree_w": 52, "tree_size": 256, "t0": 0.83, "t1": 0.8767, "tft": 2.1911, "input_0": 643, "input_1": 257, "min_CLP": -6.53, "draft_iters": 10.8, "mem_use": 36.48, "gen_rate": 5.8, "speed": 3.42, "text": "Certainly, here are some example"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.5, "tree_w": 68, "tree_size": 256, "t0": 0.7517, "t1": 0.8817, "tft": 1.6984, "input_0": 549, "input_1": 257, "min_CLP": -6.57, "draft_iters": 9.7, "mem_use": 35.57, "gen_rate": 5.8, "speed": 3.57, "text": "\"I'm sorry, but I'm not programm"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.6, "tree_w": 50, "tree_size": 256, "t0": 0.996, "t1": 0.884, "tft": 3.0689, "input_0": 748, "input_1": 257, "min_CLP": -6.29, "draft_iters": 13.0, "mem_use": 36.77, "gen_rate": 6.4, "speed": 3.4, "text": "\"If you're a beginner hiker look"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 71, "tree_size": 256, "t0": 0.7817, "t1": 0.88, "tft": 1.9778, "input_0": 574, "input_1": 257, "min_CLP": -6.75, "draft_iters": 10.2, "mem_use": 35.52, "gen_rate": 5.3, "speed": 3.21, "text": "\"Open Assistant: Get ready for t"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.3, "tree_w": 47, "tree_size": 256, "t0": 0.9867, "t1": 0.8867, "tft": 1.744, "input_0": 687, "input_1": 257, "min_CLP": -6.14, "draft_iters": 12.7, "mem_use": 35.41, "gen_rate": 6.0, "speed": 3.2, "text": "Sure! Here is a diagram to illus"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 18.6, "tree_w": 38, "tree_size": 256, "t0": 1.462, "t1": 0.904, "tft": 3.3175, "input_0": 860, "input_1": 257, "min_CLP": -6.05, "draft_iters": 20.0, "mem_use": 37.75, "gen_rate": 7.6, "speed": 3.21, "text": "\"The reason you're not getting t"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.2, "tree_w": 47, "tree_size": 256, "t0": 1.0317, "t1": 0.875, "tft": 1.7647, "input_0": 742, "input_1": 257, "min_CLP": -6.18, "draft_iters": 13.5, "mem_use": 35.11, "gen_rate": 6.2, "speed": 3.23, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 7.7, "tree_w": 82, "tree_size": 256, "t0": 0.6711, "t1": 0.8778, "tft": 1.8541, "input_0": 510, "input_1": 257, "min_CLP": -6.75, "draft_iters": 8.7, "mem_use": 35.65, "gen_rate": 4.1, "speed": 2.65, "text": "\"I don't think that answer was q"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.0, "tree_w": 54, "tree_size": 256, "t0": 0.9233, "t1": 0.8833, "tft": 1.9756, "input_0": 625, "input_1": 257, "min_CLP": -6.39, "draft_iters": 12.0, "mem_use": 35.28, "gen_rate": 5.8, "speed": 3.23, "text": "The heat from the pan transfers "}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 16.0, "tree_w": 41, "tree_size": 256, "t0": 1.3033, "t1": 0.88, "tft": 1.9212, "input_0": 826, "input_1": 257, "min_CLP": -6.42, "draft_iters": 17.3, "mem_use": 35.13, "gen_rate": 11.7, "speed": 5.34, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 12.0, "tree_w": 41, "tree_size": 256, "t0": 0.9983, "t1": 0.8883, "tft": 3.0392, "input_0": 747, "input_1": 257, "min_CLP": -6.32, "draft_iters": 13.0, "mem_use": 37.2, "gen_rate": 6.0, "speed": 3.18, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.6, "tree_w": 65, "tree_size": 256, "t0": 0.8157, "t1": 0.8757, "tft": 1.5025, "input_0": 564, "input_1": 257, "min_CLP": -6.51, "draft_iters": 10.7, "mem_use": 35.08, "gen_rate": 4.9, "speed": 2.87, "text": "\"Yes, a thumb war can be conside"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 10.9, "tree_w": 78, "tree_size": 256, "t0": 0.9025, "t1": 0.8825, "tft": 2.6874, "input_0": 524, "input_1": 257, "min_CLP": -6.72, "draft_iters": 12.1, "mem_use": 35.17, "gen_rate": 4.6, "speed": 2.59, "text": "The lyrics to the third verse of"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.5, "tree_w": 51, "tree_size": 256, "t0": 1.1125, "t1": 0.8975, "tft": 3.2113, "input_0": 816, "input_1": 257, "min_CLP": -6.41, "draft_iters": 14.8, "mem_use": 38.43, "gen_rate": 8.5, "speed": 4.22, "text": "As of my knowledge cutoff in ear"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 14.8, "tree_w": 41, "tree_size": 256, "t0": 1.1775, "t1": 0.8825, "tft": 2.7063, "input_0": 725, "input_1": 257, "min_CLP": -6.17, "draft_iters": 16.0, "mem_use": 36.44, "gen_rate": 10.2, "speed": 4.98, "text": "I understand that you want me to"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.0, "tree_w": 47, "tree_size": 256, "t0": 0.9975, "t1": 0.8925, "tft": 1.869, "input_0": 697, "input_1": 257, "min_CLP": -6.15, "draft_iters": 13.0, "mem_use": 35.38, "gen_rate": 8.0, "speed": 4.23, "text": "Certainly! There are many resour"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.8, "tree_w": 61, "tree_size": 256, "t0": 1.13, "t1": 0.895, "tft": 2.2543, "input_0": 656, "input_1": 257, "min_CLP": -6.4, "draft_iters": 15.0, "mem_use": 35.35, "gen_rate": 6.2, "speed": 3.04, "text": "\"#answer: [END]\\n\\nI'm sorry, bu"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 72, "tree_size": 256, "t0": 0.865, "t1": 0.8767, "tft": 2.0906, "input_0": 596, "input_1": 257, "min_CLP": -6.4, "draft_iters": 11.3, "mem_use": 35.13, "gen_rate": 5.5, "speed": 3.16, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.0, "tree_w": 65, "tree_size": 256, "t0": 0.92, "t1": 0.882, "tft": 1.9956, "input_0": 553, "input_1": 257, "min_CLP": -6.65, "draft_iters": 12.4, "mem_use": 35.97, "gen_rate": 8.2, "speed": 4.55, "text": "\"Sure, I can do that. Here's an "}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 32.0, "tree_w": 34, "tree_size": 256, "t0": 2.28, "t1": 0.91, "tft": 3.1212, "input_0": 804, "input_1": 257, "min_CLP": -6.63, "draft_iters": 32.0, "mem_use": 35.99, "gen_rate": 22.5, "speed": 7.05, "text": "\"1. \u00ab(I Can't Get No) Satisfacti"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 24.0, "tree_w": 24, "tree_size": 256, "t0": 1.8275, "t1": 0.91, "tft": 4.5001, "input_0": 885, "input_1": 257, "min_CLP": -5.77, "draft_iters": 25.5, "mem_use": 38.45, "gen_rate": 9.8, "speed": 3.56, "text": "\"Sure! Here's a shorter version:"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.5, "tree_w": 49, "tree_size": 256, "t0": 0.9875, "t1": 0.875, "tft": 1.9038, "input_0": 732, "input_1": 257, "min_CLP": -6.17, "draft_iters": 12.8, "mem_use": 35.13, "gen_rate": 8.2, "speed": 4.44, "text": "To reduce your alcohol consumpti"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.5, "tree_w": 57, "tree_size": 256, "t0": 0.8317, "t1": 0.88, "tft": 2.0038, "input_0": 609, "input_1": 257, "min_CLP": -6.49, "draft_iters": 10.7, "mem_use": 35.69, "gen_rate": 5.7, "speed": 3.31, "text": "Berlin is home to many well-know"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.0, "tree_w": 32, "tree_size": 256, "t0": 1.44, "t1": 0.8833, "tft": 1.767, "input_0": 955, "input_1": 257, "min_CLP": -5.86, "draft_iters": 19.3, "mem_use": 35.17, "gen_rate": 10.7, "speed": 4.59, "text": "Certainly! Below is a Python scr"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 50, "tree_h": 22.8, "tree_w": 47, "tree_size": 256, "t0": 1.6725, "t1": 0.91, "tft": 3.3384, "input_0": 706, "input_1": 257, "min_CLP": -6.15, "draft_iters": 23.8, "mem_use": 37.68, "gen_rate": 12.5, "speed": 4.84, "text": "## Vegetarian\\n Microwave Sausag"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.3, "tree_w": 60, "tree_size": 256, "t0": 0.7986, "t1": 0.87, "tft": 1.4899, "input_0": 584, "input_1": 257, "min_CLP": -6.45, "draft_iters": 10.4, "mem_use": 35.08, "gen_rate": 5.1, "speed": 3.08, "text": "\"It's unclear who specifically w"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.5, "tree_w": 52, "tree_size": 256, "t0": 0.9825, "t1": 0.89, "tft": 4.0022, "input_0": 731, "input_1": 257, "min_CLP": -6.38, "draft_iters": 12.8, "mem_use": 37.33, "gen_rate": 8.5, "speed": 4.53, "text": "The owners of the restaurant can"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 12.3, "tree_w": 55, "tree_size": 256, "t0": 1.0267, "t1": 0.8733, "tft": 1.5587, "input_0": 724, "input_1": 257, "min_CLP": -6.4, "draft_iters": 13.5, "mem_use": 35.09, "gen_rate": 6.5, "speed": 3.42, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 8.2, "tree_w": 108, "tree_size": 256, "t0": 0.7078, "t1": 0.8789, "tft": 2.4316, "input_0": 446, "input_1": 257, "min_CLP": -7.54, "draft_iters": 9.3, "mem_use": 35.07, "gen_rate": 3.7, "speed": 2.31, "text": "\u201c\u5f53\u524d\u7684\u592a\u7a7a\u63a2\u7d22\u4efb\u52a1\u5927\u591a\u96c6\u4e2d\u5728\u5bf9\u592a\u9633\u7cfb\u884c\u661f\u548c\u536b\u661f\u7684\u63a2\u6d4b\u4e0a\uff0c\u4f46\u79d1\u5b66"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 19.7, "tree_w": 26, "tree_size": 256, "t0": 1.5867, "t1": 0.8833, "tft": 2.482, "input_0": 966, "input_1": 257, "min_CLP": -6.16, "draft_iters": 21.3, "mem_use": 35.23, "gen_rate": 12.7, "speed": 5.13, "text": "\"Sure, as an AI language model, "}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.8, "tree_w": 56, "tree_size": 256, "t0": 0.9617, "t1": 0.885, "tft": 2.4284, "input_0": 709, "input_1": 257, "min_CLP": -6.22, "draft_iters": 12.5, "mem_use": 36.31, "gen_rate": 6.5, "speed": 3.53, "text": "The quality of life in the 1950s"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 52, "tree_size": 256, "t0": 0.955, "t1": 0.8775, "tft": 2.6012, "input_0": 709, "input_1": 257, "min_CLP": -6.14, "draft_iters": 12.2, "mem_use": 35.18, "gen_rate": 8.2, "speed": 4.5, "text": "The reason why film photography "}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 13.1, "tree_w": 46, "tree_size": 256, "t0": 1.1014, "t1": 0.8943, "tft": 1.7869, "input_0": 727, "input_1": 257, "min_CLP": -6.11, "draft_iters": 14.4, "mem_use": 35.38, "gen_rate": 5.6, "speed": 2.79, "text": "\"Sure! In reStructuredText (rst)"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 55, "tree_size": 256, "t0": 0.896, "t1": 0.882, "tft": 2.1721, "input_0": 650, "input_1": 257, "min_CLP": -6.42, "draft_iters": 11.6, "mem_use": 35.72, "gen_rate": 6.8, "speed": 3.82, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.3, "tree_w": 59, "tree_size": 256, "t0": 0.85, "t1": 0.8783, "tft": 1.795, "input_0": 648, "input_1": 257, "min_CLP": -6.48, "draft_iters": 11.0, "mem_use": 35.27, "gen_rate": 5.7, "speed": 3.28, "text": "I am a goddess of love, fertilit"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 21.0, "tree_w": 32, "tree_size": 256, "t0": 1.6567, "t1": 0.8967, "tft": 2.7293, "input_0": 1006, "input_1": 257, "min_CLP": -5.98, "draft_iters": 22.3, "mem_use": 36.5, "gen_rate": 12.7, "speed": 4.96, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 13.7, "tree_w": 52, "tree_size": 256, "t0": 1.0933, "t1": 0.8767, "tft": 3.1336, "input_0": 613, "input_1": 257, "min_CLP": -6.33, "draft_iters": 14.7, "mem_use": 35.17, "gen_rate": 5.3, "speed": 2.71, "text": "Certainly! Here\u2019s a response tha"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.3, "tree_w": 39, "tree_size": 256, "t0": 1.23, "t1": 0.88, "tft": 2.3601, "input_0": 948, "input_1": 257, "min_CLP": -6.13, "draft_iters": 16.3, "mem_use": 36.03, "gen_rate": 10.7, "speed": 5.05, "text": "The microwave oven became a comm"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 64, "tree_size": 256, "t0": 2.24, "t1": 0.93, "tft": 3.1454, "input_0": 743, "input_1": 257, "min_CLP": -6.96, "draft_iters": 32.0, "mem_use": 35.27, "gen_rate": 32.0, "speed": 10.1, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 3, "tree_h": 8.5, "tree_w": 69, "tree_size": 256, "t0": 0.73, "t1": 0.87, "tft": 1.7937, "input_0": 489, "input_1": 257, "min_CLP": -6.68, "draft_iters": 9.5, "mem_use": 35.1, "gen_rate": 1.5, "speed": 0.94, "text": "No data available."}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 11.0, "tree_w": 53, "tree_size": 256, "t0": 0.945, "t1": 0.9088, "tft": 3.9828, "input_0": 679, "input_1": 257, "min_CLP": -6.15, "draft_iters": 12.5, "mem_use": 39.37, "gen_rate": 4.6, "speed": 2.5, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 17.7, "tree_w": 66, "tree_size": 256, "t0": 1.3867, "t1": 0.8967, "tft": 1.682, "input_0": 697, "input_1": 257, "min_CLP": -7.25, "draft_iters": 19.0, "mem_use": 35.41, "gen_rate": 14.3, "speed": 6.28, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.4, "tree_w": 46, "tree_size": 256, "t0": 1.154, "t1": 0.884, "tft": 3.2583, "input_0": 708, "input_1": 257, "min_CLP": -6.01, "draft_iters": 15.6, "mem_use": 36.3, "gen_rate": 7.0, "speed": 3.43, "text": "It is not possible to accurately"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 7.9, "tree_w": 75, "tree_size": 256, "t0": 0.7, "t1": 0.8875, "tft": 2.7441, "input_0": 536, "input_1": 257, "min_CLP": -6.65, "draft_iters": 9.1, "mem_use": 37.54, "gen_rate": 4.6, "speed": 2.91, "text": "You can prevent spiders from spa"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 10.9, "tree_w": 78, "tree_size": 256, "t0": 0.915, "t1": 0.895, "tft": 2.6283, "input_0": 523, "input_1": 257, "min_CLP": -6.95, "draft_iters": 12.1, "mem_use": 35.38, "gen_rate": 4.0, "speed": 2.22, "text": "\"I heard that you can't afford a"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 17, "tree_h": 16.0, "tree_w": 34, "tree_size": 256, "t0": 1.26, "t1": 0.9, "tft": 2.6731, "input_0": 746, "input_1": 257, "min_CLP": -6.12, "draft_iters": 17.0, "mem_use": 35.42, "gen_rate": 8.5, "speed": 3.93, "text": "\"You're welcome! Do you have any"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.7, "tree_w": 36, "tree_size": 256, "t0": 1.2067, "t1": 0.89, "tft": 2.4805, "input_0": 776, "input_1": 257, "min_CLP": -6.36, "draft_iters": 16.0, "mem_use": 35.93, "gen_rate": 10.7, "speed": 5.09, "text": "The 3D animation programs that h"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 27.5, "tree_w": 48, "tree_size": 256, "t0": 1.99, "t1": 0.94, "tft": 2.5335, "input_0": 728, "input_1": 257, "min_CLP": -7.06, "draft_iters": 28.0, "mem_use": 35.41, "gen_rate": 20.0, "speed": 6.82, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 11.4, "tree_w": 58, "tree_size": 256, "t0": 0.9413, "t1": 0.8875, "tft": 2.3279, "input_0": 614, "input_1": 257, "min_CLP": -6.42, "draft_iters": 12.5, "mem_use": 36.11, "gen_rate": 4.1, "speed": 2.26, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 31.5, "tree_w": 55, "tree_size": 256, "t0": 2.275, "t1": 0.94, "tft": 2.6402, "input_0": 773, "input_1": 257, "min_CLP": -6.64, "draft_iters": 32.0, "mem_use": 35.42, "gen_rate": 19.0, "speed": 5.91, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.5, "tree_w": 51, "tree_size": 256, "t0": 0.9783, "t1": 0.8817, "tft": 2.1697, "input_0": 647, "input_1": 257, "min_CLP": -6.25, "draft_iters": 12.7, "mem_use": 35.15, "gen_rate": 6.3, "speed": 3.41, "text": "The pieces of a reinforcement le"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 62, "tree_size": 256, "t0": 2.21, "t1": 0.93, "tft": 1.7678, "input_0": 679, "input_1": 257, "min_CLP": -6.9, "draft_iters": 32.0, "mem_use": 35.11, "gen_rate": 33.0, "speed": 10.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 24, "tree_h": 17.0, "tree_w": 39, "tree_size": 256, "t0": 1.3867, "t1": 0.9133, "tft": 3.3548, "input_0": 843, "input_1": 257, "min_CLP": -6.19, "draft_iters": 18.7, "mem_use": 39.36, "gen_rate": 8.0, "speed": 3.47, "text": "\"You're welcome! It was my pleas"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 10.4, "tree_w": 51, "tree_size": 256, "t0": 0.9186, "t1": 0.8843, "tft": 1.8608, "input_0": 671, "input_1": 257, "min_CLP": -6.17, "draft_iters": 11.9, "mem_use": 35.25, "gen_rate": 5.4, "speed": 3.01, "text": "Some of the most common applicat"}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 20.0, "tree_w": 34, "tree_size": 256, "t0": 1.5325, "t1": 0.9, "tft": 2.8728, "input_0": 806, "input_1": 257, "min_CLP": -6.17, "draft_iters": 21.2, "mem_use": 36.78, "gen_rate": 10.2, "speed": 4.21, "text": "To produce F-centers in carbon c"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.5, "tree_w": 58, "tree_size": 256, "t0": 1.1225, "t1": 0.89, "tft": 2.6051, "input_0": 863, "input_1": 257, "min_CLP": -6.35, "draft_iters": 14.8, "mem_use": 36.55, "gen_rate": 8.2, "speed": 4.1, "text": "The command \"chkdsk C: /f\" will "}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 46, "tree_size": 256, "t0": 0.9575, "t1": 0.8825, "tft": 3.0833, "input_0": 731, "input_1": 257, "min_CLP": -6.19, "draft_iters": 12.2, "mem_use": 35.38, "gen_rate": 8.5, "speed": 4.62, "text": "\"To tackle this problem, I would"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 12.0, "tree_w": 85, "tree_size": 256, "t0": 0.96, "t1": 0.88, "tft": 2.7436, "input_0": 541, "input_1": 257, "min_CLP": -6.98, "draft_iters": 13.0, "mem_use": 35.19, "gen_rate": 0.0, "speed": 0.0, "text": "[END]"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 55, "tree_size": 256, "t0": 2.23, "t1": 0.93, "tft": 2.0248, "input_0": 775, "input_1": 257, "min_CLP": -6.74, "draft_iters": 32.0, "mem_use": 35.17, "gen_rate": 33.0, "speed": 10.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 15.6, "tree_w": 44, "tree_size": 256, "t0": 1.284, "t1": 0.894, "tft": 2.3212, "input_0": 942, "input_1": 257, "min_CLP": -6.17, "draft_iters": 16.8, "mem_use": 36.19, "gen_rate": 7.8, "speed": 3.59, "text": "\"I'd be happy to help you improv"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.6, "tree_w": 60, "tree_size": 256, "t0": 0.962, "t1": 0.886, "tft": 1.7473, "input_0": 677, "input_1": 257, "min_CLP": -6.53, "draft_iters": 12.6, "mem_use": 35.5, "gen_rate": 6.6, "speed": 3.57, "text": "How can we increase empathy in s"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 25.8, "tree_w": 28, "tree_size": 256, "t0": 1.9025, "t1": 0.905, "tft": 2.9798, "input_0": 937, "input_1": 257, "min_CLP": -6.28, "draft_iters": 26.2, "mem_use": 36.82, "gen_rate": 10.5, "speed": 3.74, "text": "The feminine words related to lo"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.5, "tree_w": 74, "tree_size": 256, "t0": 1.07, "t1": 0.885, "tft": 1.6992, "input_0": 597, "input_1": 257, "min_CLP": -6.77, "draft_iters": 14.7, "mem_use": 35.73, "gen_rate": 5.5, "speed": 2.81, "text": "I think the answerer is a compas"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.7, "tree_w": 89, "tree_size": 256, "t0": 0.6111, "t1": 0.8789, "tft": 2.2591, "input_0": 483, "input_1": 257, "min_CLP": -6.87, "draft_iters": 7.8, "mem_use": 35.57, "gen_rate": 3.8, "speed": 2.54, "text": "The ATF gunwalking scandal was a"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.4, "tree_w": 45, "tree_size": 256, "t0": 1.116, "t1": 0.89, "tft": 2.7668, "input_0": 777, "input_1": 257, "min_CLP": -6.19, "draft_iters": 14.6, "mem_use": 35.32, "gen_rate": 7.2, "speed": 3.59, "text": "The difference between interpret"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 21, "tree_size": 256, "t0": 2.31, "t1": 0.9, "tft": 3.9974, "input_0": 1126, "input_1": 257, "min_CLP": -7.48, "draft_iters": 32.0, "mem_use": 38.11, "gen_rate": 32.0, "speed": 9.97, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 15.3, "tree_w": 49, "tree_size": 256, "t0": 1.21, "t1": 0.9, "tft": 4.3536, "input_0": 690, "input_1": 257, "min_CLP": -6.55, "draft_iters": 16.5, "mem_use": 38.04, "gen_rate": 5.7, "speed": 2.69, "text": "Once upon a time, in the fair ci"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 76, "tree_size": 256, "t0": 0.79, "t1": 0.875, "tft": 1.7478, "input_0": 650, "input_1": 257, "min_CLP": -6.82, "draft_iters": 10.2, "mem_use": 35.11, "gen_rate": 5.8, "speed": 3.5, "text": "\"Sure, here's a poem in the styl"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 32.0, "tree_w": 28, "tree_size": 256, "t0": 2.26, "t1": 0.91, "tft": 2.9617, "input_0": 761, "input_1": 257, "min_CLP": -6.29, "draft_iters": 32.0, "mem_use": 36.29, "gen_rate": 19.5, "speed": 6.15, "text": "Absolutely! Here\\'s the revised "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 19.5, "tree_w": 32, "tree_size": 256, "t0": 1.515, "t1": 0.895, "tft": 2.5692, "input_0": 844, "input_1": 257, "min_CLP": -5.87, "draft_iters": 20.8, "mem_use": 36.72, "gen_rate": 8.0, "speed": 3.32, "text": "\"I apologize for any confusion m"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 22.0, "tree_w": 37, "tree_size": 256, "t0": 1.7267, "t1": 0.8833, "tft": 1.757, "input_0": 1058, "input_1": 257, "min_CLP": -6.04, "draft_iters": 23.3, "mem_use": 35.09, "gen_rate": 14.7, "speed": 5.62, "text": "To normalize a vector, you need "}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.3, "tree_w": 85, "tree_size": 256, "t0": 0.7271, "t1": 0.8814, "tft": 2.3014, "input_0": 481, "input_1": 257, "min_CLP": -7.05, "draft_iters": 9.6, "mem_use": 35.38, "gen_rate": 4.6, "speed": 2.84, "text": "I am a goddess, not your playthi"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.5, "tree_w": 51, "tree_size": 256, "t0": 1.1825, "t1": 0.8975, "tft": 3.5848, "input_0": 730, "input_1": 257, "min_CLP": -6.38, "draft_iters": 15.8, "mem_use": 36.96, "gen_rate": 8.0, "speed": 3.85, "text": "\"No, this is not real. Hershey's"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.0, "tree_w": 55, "tree_size": 256, "t0": 0.9329, "t1": 0.8814, "tft": 3.1461, "input_0": 650, "input_1": 257, "min_CLP": -6.41, "draft_iters": 12.1, "mem_use": 35.32, "gen_rate": 5.3, "speed": 2.92, "text": "To host a large language model o"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.8, "tree_w": 47, "tree_size": 256, "t0": 1.068, "t1": 0.89, "tft": 2.3687, "input_0": 826, "input_1": 257, "min_CLP": -6.27, "draft_iters": 14.0, "mem_use": 36.67, "gen_rate": 6.8, "speed": 3.47, "text": "\"Certainly! I'd be happy to expl"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.0, "tree_w": 69, "tree_size": 256, "t0": 0.88, "t1": 0.865, "tft": 1.7791, "input_0": 672, "input_1": 257, "min_CLP": -6.43, "draft_iters": 11.7, "mem_use": 35.13, "gen_rate": 5.8, "speed": 3.34, "text": "The future of AI in ten years is"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.4, "tree_w": 38, "tree_size": 256, "t0": 1.202, "t1": 0.884, "tft": 2.0423, "input_0": 885, "input_1": 257, "min_CLP": -5.97, "draft_iters": 15.6, "mem_use": 35.13, "gen_rate": 6.8, "speed": 3.26, "text": "To cook a salmon fillet on a sto"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 58, "tree_h": 16.6, "tree_w": 44, "tree_size": 256, "t0": 1.302, "t1": 0.894, "tft": 1.7778, "input_0": 760, "input_1": 257, "min_CLP": -6.19, "draft_iters": 17.4, "mem_use": 35.77, "gen_rate": 11.6, "speed": 5.29, "text": "\"Okay, here's a simple Sudoku fi"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 16.7, "tree_w": 61, "tree_size": 256, "t0": 1.263, "t1": 0.9, "tft": 2.978, "input_0": 566, "input_1": 257, "min_CLP": -6.64, "draft_iters": 17.6, "mem_use": 36.03, "gen_rate": 3.2, "speed": 1.48, "text": "Thank you for the feedback! Here"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.3, "tree_w": 64, "tree_size": 256, "t0": 0.9, "t1": 0.8733, "tft": 1.8452, "input_0": 669, "input_1": 257, "min_CLP": -6.66, "draft_iters": 11.7, "mem_use": 35.11, "gen_rate": 5.5, "speed": 3.1, "text": "A: The AK-47 is a type of assaul"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 13.4, "tree_w": 42, "tree_size": 256, "t0": 1.1114, "t1": 0.8943, "tft": 1.9971, "input_0": 737, "input_1": 257, "min_CLP": -6.15, "draft_iters": 14.6, "mem_use": 35.45, "gen_rate": 6.0, "speed": 2.99, "text": "To copy a directory of files fro"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 52, "tree_h": 24.0, "tree_w": 32, "tree_size": 256, "t0": 1.8067, "t1": 0.91, "tft": 2.6682, "input_0": 920, "input_1": 257, "min_CLP": -6.04, "draft_iters": 25.0, "mem_use": 36.84, "gen_rate": 17.3, "speed": 6.37, "text": "Sure, here you go:\\n\\n1. Statist"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.6, "tree_w": 44, "tree_size": 256, "t0": 1.122, "t1": 0.894, "tft": 3.1776, "input_0": 755, "input_1": 257, "min_CLP": -6.23, "draft_iters": 14.8, "mem_use": 35.43, "gen_rate": 7.6, "speed": 3.77, "text": "Here are some tips to help you s"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.4, "tree_w": 56, "tree_size": 256, "t0": 0.81, "t1": 0.88, "tft": 2.3803, "input_0": 603, "input_1": 257, "min_CLP": -6.27, "draft_iters": 10.6, "mem_use": 35.97, "gen_rate": 5.0, "speed": 2.96, "text": "\"No, there's no harm in letting "}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.5, "tree_w": 93, "tree_size": 256, "t0": 0.735, "t1": 0.8883, "tft": 1.9017, "input_0": 523, "input_1": 257, "min_CLP": -6.93, "draft_iters": 9.5, "mem_use": 35.58, "gen_rate": 5.7, "speed": 3.49, "text": "Tell them a joke or something li"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 8.7, "tree_w": 80, "tree_size": 256, "t0": 0.7722, "t1": 0.8878, "tft": 2.1266, "input_0": 565, "input_1": 257, "min_CLP": -6.62, "draft_iters": 10.0, "mem_use": 35.69, "gen_rate": 3.9, "speed": 2.34, "text": "What is the next utterance of th"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.1, "tree_w": 62, "tree_size": 256, "t0": 0.8743, "t1": 0.8814, "tft": 1.884, "input_0": 626, "input_1": 257, "min_CLP": -6.58, "draft_iters": 11.4, "mem_use": 35.09, "gen_rate": 4.6, "speed": 2.61, "text": "\"I'm thinking about the importan"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 53, "tree_size": 256, "t0": 0.9325, "t1": 0.88, "tft": 1.5672, "input_0": 646, "input_1": 257, "min_CLP": -6.53, "draft_iters": 12.2, "mem_use": 35.1, "gen_rate": 8.0, "speed": 4.42, "text": "Cryptocurrencies have come a lon"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.4, "tree_w": 50, "tree_size": 256, "t0": 0.882, "t1": 0.888, "tft": 2.4789, "input_0": 606, "input_1": 257, "min_CLP": -6.11, "draft_iters": 11.4, "mem_use": 35.63, "gen_rate": 6.8, "speed": 3.84, "text": "Theanine may help you feel more "}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 17.8, "tree_w": 39, "tree_size": 256, "t0": 1.3775, "t1": 0.91, "tft": 1.5174, "input_0": 729, "input_1": 257, "min_CLP": -5.97, "draft_iters": 18.8, "mem_use": 35.4, "gen_rate": 8.5, "speed": 3.72, "text": "Here\\'s some sample code in HTML"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 32, "tree_h": 31.0, "tree_w": 56, "tree_size": 256, "t0": 2.24, "t1": 0.96, "tft": 2.4809, "input_0": 804, "input_1": 257, "min_CLP": -6.97, "draft_iters": 32.0, "mem_use": 35.19, "gen_rate": 32.0, "speed": 10.02, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 10.7, "tree_w": 60, "tree_size": 256, "t0": 0.9371, "t1": 0.8714, "tft": 2.2705, "input_0": 670, "input_1": 257, "min_CLP": -6.4, "draft_iters": 12.3, "mem_use": 35.15, "gen_rate": 5.7, "speed": 3.16, "text": "You cannot see the stars as well"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.2, "tree_w": 54, "tree_size": 256, "t0": 1.2, "t1": 0.9075, "tft": 1.885, "input_0": 669, "input_1": 257, "min_CLP": -6.58, "draft_iters": 16.2, "mem_use": 35.71, "gen_rate": 8.2, "speed": 3.91, "text": "The significance of the Windows "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.8, "tree_w": 61, "tree_size": 256, "t0": 0.845, "t1": 0.9017, "tft": 2.9022, "input_0": 653, "input_1": 257, "min_CLP": -6.34, "draft_iters": 11.2, "mem_use": 38.75, "gen_rate": 5.7, "speed": 3.24, "text": "\"I'm sorry, but it's not legal o"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.8, "tree_w": 69, "tree_size": 256, "t0": 0.772, "t1": 0.894, "tft": 2.8, "input_0": 620, "input_1": 257, "min_CLP": -6.54, "draft_iters": 10.0, "mem_use": 37.51, "gen_rate": 6.8, "speed": 4.09, "text": "\"It's possible that we never had"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 64, "tree_size": 256, "t0": 0.802, "t1": 0.882, "tft": 2.3793, "input_0": 626, "input_1": 257, "min_CLP": -6.67, "draft_iters": 10.4, "mem_use": 35.77, "gen_rate": 6.4, "speed": 3.8, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 21.5, "tree_w": 61, "tree_size": 256, "t0": 1.615, "t1": 0.9, "tft": 1.7172, "input_0": 696, "input_1": 257, "min_CLP": -6.78, "draft_iters": 22.5, "mem_use": 35.11, "gen_rate": 19.0, "speed": 7.55, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 31, "tree_h": 9.7, "tree_w": 70, "tree_size": 256, "t0": 0.8457, "t1": 0.8829, "tft": 1.6505, "input_0": 628, "input_1": 257, "min_CLP": -6.59, "draft_iters": 11.0, "mem_use": 35.09, "gen_rate": 4.4, "speed": 2.56, "text": "Yes, I am familiar with the Germ"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 13, "tree_h": 32.0, "tree_w": 18, "tree_size": 256, "t0": 2.26, "t1": 0.92, "tft": 2.225, "input_0": 954, "input_1": 257, "min_CLP": -6.53, "draft_iters": 32.0, "mem_use": 35.29, "gen_rate": 13.0, "speed": 4.09, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.8, "tree_w": 61, "tree_size": 256, "t0": 0.8717, "t1": 0.8817, "tft": 2.24, "input_0": 667, "input_1": 257, "min_CLP": -6.34, "draft_iters": 11.3, "mem_use": 36.2, "gen_rate": 5.7, "speed": 3.24, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.0, "tree_w": 47, "tree_size": 256, "t0": 1.146, "t1": 0.896, "tft": 3.3305, "input_0": 761, "input_1": 257, "min_CLP": -6.16, "draft_iters": 15.2, "mem_use": 36.77, "gen_rate": 6.4, "speed": 3.13, "text": "Yes, you can definitely use AI i"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.9, "tree_w": 93, "tree_size": 256, "t0": 0.8514, "t1": 0.8771, "tft": 2.4707, "input_0": 582, "input_1": 257, "min_CLP": -7.29, "draft_iters": 11.3, "mem_use": 35.15, "gen_rate": 4.6, "speed": 2.64, "text": "Certainly! Here are some Haikus "}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 64, "tree_h": 20.7, "tree_w": 45, "tree_size": 256, "t0": 1.52, "t1": 0.8967, "tft": 3.2224, "input_0": 620, "input_1": 257, "min_CLP": -6.77, "draft_iters": 21.3, "mem_use": 35.52, "gen_rate": 21.3, "speed": 8.82, "text": "o\\n     /|\\\\\\n     / \\\\\\n     | "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 22.0, "tree_w": 46, "tree_size": 256, "t0": 1.69, "t1": 0.89, "tft": 1.7134, "input_0": 859, "input_1": 257, "min_CLP": -7.46, "draft_iters": 23.0, "mem_use": 35.11, "gen_rate": 20.5, "speed": 7.95, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 13.5, "tree_w": 46, "tree_size": 256, "t0": 1.0917, "t1": 0.8867, "tft": 2.8659, "input_0": 728, "input_1": 257, "min_CLP": -6.15, "draft_iters": 14.5, "mem_use": 35.47, "gen_rate": 5.5, "speed": 2.78, "text": "Yes, there is a widely debated e"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.5, "tree_w": 45, "tree_size": 256, "t0": 1.25, "t1": 0.8925, "tft": 1.9193, "input_0": 786, "input_1": 257, "min_CLP": -6.1, "draft_iters": 16.8, "mem_use": 35.38, "gen_rate": 9.2, "speed": 4.31, "text": "\"To fill in a Sudoku puzzle, you"}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 15, "tree_h": 18.7, "tree_w": 57, "tree_size": 256, "t0": 1.4433, "t1": 0.9033, "tft": 2.8016, "input_0": 705, "input_1": 257, "min_CLP": -6.47, "draft_iters": 20.0, "mem_use": 37.43, "gen_rate": 5.0, "speed": 2.13, "text": "\"[INST] OK, I have the dough, ch"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 47, "tree_size": 256, "t0": 2.24, "t1": 0.915, "tft": 2.9972, "input_0": 1038, "input_1": 257, "min_CLP": -7.55, "draft_iters": 31.0, "mem_use": 35.27, "gen_rate": 31.5, "speed": 9.98, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.2, "tree_w": 57, "tree_size": 256, "t0": 0.85, "t1": 0.894, "tft": 2.8178, "input_0": 653, "input_1": 257, "min_CLP": -6.26, "draft_iters": 11.2, "mem_use": 38.13, "gen_rate": 6.8, "speed": 3.9, "text": "\"I'm sorry, but I cannot fulfill"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 15.9, "tree_w": 66, "tree_size": 256, "t0": 1.2429, "t1": 0.8971, "tft": 1.7508, "input_0": 617, "input_1": 257, "min_CLP": -6.53, "draft_iters": 17.0, "mem_use": 35.14, "gen_rate": 4.7, "speed": 2.21, "text": "\"Sure! Here's a simple ASCII art"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 13.0, "tree_w": 42, "tree_size": 256, "t0": 1.0817, "t1": 0.88, "tft": 1.9818, "input_0": 767, "input_1": 257, "min_CLP": -5.94, "draft_iters": 14.2, "mem_use": 35.1, "gen_rate": 6.5, "speed": 3.31, "text": "\"HTML (Hypertext Markup Language"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 22.7, "tree_w": 33, "tree_size": 256, "t0": 1.79, "t1": 0.92, "tft": 2.122, "input_0": 1049, "input_1": 257, "min_CLP": -6.1, "draft_iters": 24.0, "mem_use": 35.13, "gen_rate": 11.0, "speed": 4.06, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 60, "tree_size": 256, "t0": 0.92, "t1": 0.8867, "tft": 3.1994, "input_0": 673, "input_1": 257, "min_CLP": -6.47, "draft_iters": 12.0, "mem_use": 35.49, "gen_rate": 6.0, "speed": 3.32, "text": "I am not a lawyer, but according"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 37, "tree_size": 256, "t0": 1.945, "t1": 0.905, "tft": 1.8435, "input_0": 881, "input_1": 257, "min_CLP": -7.95, "draft_iters": 27.0, "mem_use": 35.11, "gen_rate": 27.0, "speed": 9.46, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 31.3, "tree_w": 25, "tree_size": 256, "t0": 2.3033, "t1": 0.9133, "tft": 3.5465, "input_0": 1038, "input_1": 257, "min_CLP": -5.87, "draft_iters": 32.0, "mem_use": 36.19, "gen_rate": 11.7, "speed": 3.63, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.7, "tree_w": 56, "tree_size": 256, "t0": 0.8517, "t1": 0.8783, "tft": 2.7044, "input_0": 701, "input_1": 257, "min_CLP": -6.39, "draft_iters": 11.0, "mem_use": 35.88, "gen_rate": 6.3, "speed": 3.67, "text": "\"Thank you for providing more in"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.0, "tree_w": 62, "tree_size": 256, "t0": 0.8729, "t1": 0.8886, "tft": 1.7348, "input_0": 604, "input_1": 257, "min_CLP": -6.44, "draft_iters": 11.4, "mem_use": 35.72, "gen_rate": 4.9, "speed": 2.76, "text": "\"You're right, but that's not th"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 8.4, "tree_w": 75, "tree_size": 256, "t0": 0.7222, "t1": 0.8833, "tft": 2.1022, "input_0": 500, "input_1": 257, "min_CLP": -6.48, "draft_iters": 9.6, "mem_use": 36.46, "gen_rate": 3.7, "speed": 2.28, "text": "\"Great choice of book! It's a po"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 20.5, "tree_w": 43, "tree_size": 256, "t0": 1.525, "t1": 0.885, "tft": 1.501, "input_0": 779, "input_1": 257, "min_CLP": -7.31, "draft_iters": 21.0, "mem_use": 35.08, "gen_rate": 20.5, "speed": 8.52, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.3, "tree_w": 70, "tree_size": 256, "t0": 0.8867, "t1": 0.8917, "tft": 1.8846, "input_0": 587, "input_1": 257, "min_CLP": -6.68, "draft_iters": 11.7, "mem_use": 35.41, "gen_rate": 5.7, "speed": 3.19, "text": "\"I'm glad you're interested in l"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 8.5, "tree_w": 62, "tree_size": 256, "t0": 0.7433, "t1": 0.8783, "tft": 2.8125, "input_0": 561, "input_1": 257, "min_CLP": -6.32, "draft_iters": 9.7, "mem_use": 36.17, "gen_rate": 6.5, "speed": 4.0, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.9, "tree_w": 72, "tree_size": 256, "t0": 0.6914, "t1": 0.8757, "tft": 1.6917, "input_0": 525, "input_1": 257, "min_CLP": -6.55, "draft_iters": 9.0, "mem_use": 35.2, "gen_rate": 4.6, "speed": 2.92, "text": "\"Motion Matching is a technology"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 30.5, "tree_w": 22, "tree_size": 256, "t0": 2.255, "t1": 0.905, "tft": 3.88, "input_0": 927, "input_1": 257, "min_CLP": -5.48, "draft_iters": 31.5, "mem_use": 36.83, "gen_rate": 16.5, "speed": 5.21, "text": "\"Sure, here's a modified script "}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 12.0, "tree_w": 73, "tree_size": 256, "t0": 0.93, "t1": 0.88, "tft": 1.5376, "input_0": 471, "input_1": 257, "min_CLP": -6.92, "draft_iters": 13.0, "mem_use": 35.15, "gen_rate": 1.0, "speed": 0.55, "text": "C#"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.5, "tree_w": 59, "tree_size": 256, "t0": 1.19, "t1": 0.9, "tft": 1.896, "input_0": 583, "input_1": 257, "min_CLP": -6.57, "draft_iters": 16.5, "mem_use": 35.53, "gen_rate": 8.0, "speed": 3.83, "text": "Sure, here\\'s a mnemonic for the"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 9.9, "tree_w": 70, "tree_size": 256, "t0": 0.8457, "t1": 0.89, "tft": 2.9272, "input_0": 636, "input_1": 257, "min_CLP": -6.71, "draft_iters": 11.1, "mem_use": 36.84, "gen_rate": 4.7, "speed": 2.72, "text": "The idea that 100 monkeys on typ"}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.0, "tree_w": 62, "tree_size": 256, "t0": 0.8517, "t1": 0.8883, "tft": 2.824, "input_0": 655, "input_1": 257, "min_CLP": -6.5, "draft_iters": 11.2, "mem_use": 37.26, "gen_rate": 6.7, "speed": 3.83, "text": "\"Paul Allen's collection of plan"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.8, "tree_w": 42, "tree_size": 256, "t0": 1.1, "t1": 0.89, "tft": 2.4489, "input_0": 748, "input_1": 257, "min_CLP": -6.52, "draft_iters": 14.8, "mem_use": 36.72, "gen_rate": 9.5, "speed": 4.78, "text": "\"Yes, there are also cases in ot"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 18.3, "tree_w": 43, "tree_size": 256, "t0": 1.4333, "t1": 0.9067, "tft": 2.4006, "input_0": 783, "input_1": 257, "min_CLP": -6.24, "draft_iters": 19.3, "mem_use": 35.18, "gen_rate": 13.3, "speed": 5.71, "text": "Here is an essay on how Romeo is"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.2, "tree_w": 56, "tree_size": 256, "t0": 0.8167, "t1": 0.8783, "tft": 1.9056, "input_0": 670, "input_1": 257, "min_CLP": -6.34, "draft_iters": 10.5, "mem_use": 35.8, "gen_rate": 6.7, "speed": 3.93, "text": "\"As an AI language model, I do n"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.5, "tree_w": 49, "tree_size": 256, "t0": 0.9975, "t1": 0.8875, "tft": 3.0303, "input_0": 715, "input_1": 257, "min_CLP": -6.37, "draft_iters": 13.0, "mem_use": 35.21, "gen_rate": 9.2, "speed": 4.91, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.2, "tree_w": 50, "tree_size": 256, "t0": 1.012, "t1": 0.884, "tft": 1.7077, "input_0": 614, "input_1": 257, "min_CLP": -6.47, "draft_iters": 13.4, "mem_use": 35.1, "gen_rate": 6.6, "speed": 3.48, "text": "No, the 5 second rule does not e"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 11.1, "tree_w": 63, "tree_size": 256, "t0": 0.9214, "t1": 0.8857, "tft": 1.9807, "input_0": 597, "input_1": 257, "min_CLP": -6.38, "draft_iters": 12.3, "mem_use": 35.97, "gen_rate": 4.6, "speed": 2.53, "text": "\"You're welcome! If you need any"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 52, "tree_h": 21.2, "tree_w": 33, "tree_size": 256, "t0": 1.6325, "t1": 0.905, "tft": 2.9707, "input_0": 843, "input_1": 257, "min_CLP": -6.15, "draft_iters": 22.5, "mem_use": 36.75, "gen_rate": 13.0, "speed": 5.12, "text": "\"It is not possible to completel"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.8, "tree_w": 61, "tree_size": 256, "t0": 0.8417, "t1": 0.8917, "tft": 3.105, "input_0": 655, "input_1": 257, "min_CLP": -6.54, "draft_iters": 11.0, "mem_use": 37.66, "gen_rate": 5.7, "speed": 3.27, "text": "The \"multi-track drifting\" solut"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.0, "tree_w": 51, "tree_size": 256, "t0": 1.102, "t1": 0.886, "tft": 2.5287, "input_0": 801, "input_1": 257, "min_CLP": -6.42, "draft_iters": 14.4, "mem_use": 36.27, "gen_rate": 6.4, "speed": 3.22, "text": "\"It is not possible to have a co"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 27.4, "tree_w": 43, "tree_size": 256, "t0": 1.965, "t1": 0.9225, "tft": 3.5251, "input_0": 711, "input_1": 257, "min_CLP": -6.45, "draft_iters": 27.9, "mem_use": 36.11, "gen_rate": 4.9, "speed": 1.69, "text": "\"My love, you are the sun that s"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.8, "tree_w": 63, "tree_size": 256, "t0": 0.912, "t1": 0.886, "tft": 2.7667, "input_0": 621, "input_1": 257, "min_CLP": -6.57, "draft_iters": 12.0, "mem_use": 35.85, "gen_rate": 6.4, "speed": 3.56, "text": "Here are the Japanese translatio"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.2, "tree_w": 63, "tree_size": 256, "t0": 1.114, "t1": 0.904, "tft": 2.64, "input_0": 749, "input_1": 257, "min_CLP": -6.62, "draft_iters": 14.6, "mem_use": 35.39, "gen_rate": 6.4, "speed": 3.17, "text": "\"In Europe, some of the best uni"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.8, "tree_w": 44, "tree_size": 256, "t0": 1.024, "t1": 0.874, "tft": 1.7104, "input_0": 786, "input_1": 257, "min_CLP": -6.23, "draft_iters": 13.2, "mem_use": 35.08, "gen_rate": 7.2, "speed": 3.79, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 31.5, "tree_w": 22, "tree_size": 256, "t0": 2.325, "t1": 0.92, "tft": 1.9514, "input_0": 1094, "input_1": 257, "min_CLP": -5.98, "draft_iters": 32.0, "mem_use": 35.22, "gen_rate": 21.0, "speed": 6.47, "text": "\"Here's an example C++ function "}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 10.1, "tree_w": 63, "tree_size": 256, "t0": 0.8929, "t1": 0.8814, "tft": 2.2864, "input_0": 649, "input_1": 257, "min_CLP": -6.4, "draft_iters": 11.7, "mem_use": 36.36, "gen_rate": 5.4, "speed": 3.06, "text": "1. Financial stress:\\n   - Creat"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 11.0, "tree_w": 54, "tree_size": 256, "t0": 0.905, "t1": 0.88, "tft": 1.7642, "input_0": 591, "input_1": 257, "min_CLP": -6.62, "draft_iters": 12.0, "mem_use": 35.08, "gen_rate": 5.0, "speed": 2.8, "text": "[INST] Hello, how can I help you"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 14.2, "tree_w": 40, "tree_size": 256, "t0": 1.1683, "t1": 0.895, "tft": 3.2462, "input_0": 804, "input_1": 257, "min_CLP": -6.26, "draft_iters": 15.7, "mem_use": 37.75, "gen_rate": 6.5, "speed": 3.15, "text": "One example of where you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.2, "tree_w": 63, "tree_size": 256, "t0": 0.87, "t1": 0.884, "tft": 3.1463, "input_0": 616, "input_1": 257, "min_CLP": -6.62, "draft_iters": 11.4, "mem_use": 35.37, "gen_rate": 6.4, "speed": 3.65, "text": "\"<noinput> Hairy bittercress (Ca"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 34, "tree_h": 7.6, "tree_w": 81, "tree_size": 256, "t0": 0.6745, "t1": 0.8755, "tft": 1.8951, "input_0": 498, "input_1": 257, "min_CLP": -7.02, "draft_iters": 8.8, "mem_use": 35.16, "gen_rate": 3.1, "speed": 2.0, "text": "The name of the Windows XP backg"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.5, "tree_w": 39, "tree_size": 256, "t0": 1.18, "t1": 0.91, "tft": 3.6504, "input_0": 775, "input_1": 257, "min_CLP": -6.01, "draft_iters": 15.8, "mem_use": 37.32, "gen_rate": 9.8, "speed": 4.67, "text": "Yes, here are a few more open-so"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 19.0, "tree_w": 46, "tree_size": 256, "t0": 1.525, "t1": 0.895, "tft": 2.4706, "input_0": 980, "input_1": 257, "min_CLP": -6.32, "draft_iters": 20.5, "mem_use": 35.15, "gen_rate": 16.5, "speed": 6.81, "text": "To use software-defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 69, "tree_size": 256, "t0": 0.84, "t1": 0.888, "tft": 2.4334, "input_0": 578, "input_1": 257, "min_CLP": -6.49, "draft_iters": 11.2, "mem_use": 35.85, "gen_rate": 6.6, "speed": 3.81, "text": "No, there is no one \"most ethica"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 20.7, "tree_w": 36, "tree_size": 256, "t0": 1.5417, "t1": 0.905, "tft": 3.8472, "input_0": 689, "input_1": 257, "min_CLP": -6.29, "draft_iters": 21.7, "mem_use": 36.73, "gen_rate": 7.0, "speed": 2.86, "text": "1. m\u00eb (meh)\\n2. meles, meless\u00eb ("}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.6, "tree_w": 63, "tree_size": 256, "t0": 0.8643, "t1": 0.8857, "tft": 1.8546, "input_0": 617, "input_1": 257, "min_CLP": -6.59, "draft_iters": 11.1, "mem_use": 35.41, "gen_rate": 4.9, "speed": 2.78, "text": "I will write a story about Open "}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.4, "tree_w": 48, "tree_size": 256, "t0": 0.896, "t1": 0.902, "tft": 3.4164, "input_0": 689, "input_1": 257, "min_CLP": -6.27, "draft_iters": 11.8, "mem_use": 38.16, "gen_rate": 6.6, "speed": 3.67, "text": "\"I apologize for the confusion i"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.0, "tree_w": 56, "tree_size": 256, "t0": 0.872, "t1": 0.874, "tft": 1.7137, "input_0": 647, "input_1": 257, "min_CLP": -6.44, "draft_iters": 11.4, "mem_use": 35.12, "gen_rate": 6.4, "speed": 3.67, "text": "To format an URL in reStructured"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 22.0, "tree_w": 26, "tree_size": 256, "t0": 1.71, "t1": 0.91, "tft": 2.7437, "input_0": 1126, "input_1": 257, "min_CLP": -5.71, "draft_iters": 23.0, "mem_use": 37.11, "gen_rate": 18.5, "speed": 7.08, "text": "\"Here's an example code for sett"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.2, "tree_w": 52, "tree_size": 256, "t0": 1.172, "t1": 0.886, "tft": 2.0438, "input_0": 751, "input_1": 257, "min_CLP": -6.23, "draft_iters": 15.6, "mem_use": 35.1, "gen_rate": 6.8, "speed": 3.3, "text": "\"The largest ocean in the world "}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.0, "tree_w": 73, "tree_size": 256, "t0": 0.6938, "t1": 0.88, "tft": 2.0817, "input_0": 516, "input_1": 257, "min_CLP": -6.6, "draft_iters": 9.0, "mem_use": 35.55, "gen_rate": 4.5, "speed": 2.86, "text": "\"It's unlikely that AI assistant"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 9.9, "tree_w": 78, "tree_size": 256, "t0": 0.84, "t1": 0.94, "tft": 4.3432, "input_0": 569, "input_1": 257, "min_CLP": -6.81, "draft_iters": 11.3, "mem_use": 40.68, "gen_rate": 5.1, "speed": 2.89, "text": "\"Sure, I'd be happy to help!\\n\\n"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 11.1, "tree_w": 75, "tree_size": 256, "t0": 0.8929, "t1": 0.8857, "tft": 2.1478, "input_0": 494, "input_1": 257, "min_CLP": -6.62, "draft_iters": 12.1, "mem_use": 35.96, "gen_rate": 6.0, "speed": 3.38, "text": "0 It is a person who will give y"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.4, "tree_w": 64, "tree_size": 256, "t0": 0.876, "t1": 0.89, "tft": 3.1883, "input_0": 616, "input_1": 257, "min_CLP": -6.36, "draft_iters": 11.6, "mem_use": 37.78, "gen_rate": 6.8, "speed": 3.85, "text": "\"I understand that you may have "}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.0, "tree_w": 64, "tree_size": 256, "t0": 0.8114, "t1": 0.88, "tft": 2.2819, "input_0": 645, "input_1": 257, "min_CLP": -6.57, "draft_iters": 10.6, "mem_use": 36.17, "gen_rate": 4.9, "speed": 2.87, "text": "\"1. **Economic downturn**: If th"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.0, "tree_w": 69, "tree_size": 256, "t0": 0.8667, "t1": 0.8883, "tft": 1.5917, "input_0": 566, "input_1": 257, "min_CLP": -6.62, "draft_iters": 11.3, "mem_use": 35.43, "gen_rate": 5.3, "speed": 3.04, "text": "Here is a possible inspirational"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.7, "tree_w": 46, "tree_size": 256, "t0": 1.2033, "t1": 0.8867, "tft": 4.203, "input_0": 805, "input_1": 257, "min_CLP": -6.18, "draft_iters": 16.3, "mem_use": 37.9, "gen_rate": 11.3, "speed": 5.42, "text": "Hosting a large language model o"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.8, "tree_w": 41, "tree_size": 256, "t0": 1.1725, "t1": 0.8875, "tft": 3.1119, "input_0": 829, "input_1": 257, "min_CLP": -6.23, "draft_iters": 15.2, "mem_use": 35.61, "gen_rate": 8.8, "speed": 4.25, "text": "\"To determine the most cost-effe"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 19.2, "tree_w": 38, "tree_size": 256, "t0": 1.4917, "t1": 0.8983, "tft": 3.4277, "input_0": 943, "input_1": 257, "min_CLP": -6.15, "draft_iters": 20.5, "mem_use": 37.58, "gen_rate": 6.2, "speed": 2.58, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.0, "tree_w": 47, "tree_size": 256, "t0": 1.095, "t1": 0.8825, "tft": 2.1753, "input_0": 835, "input_1": 257, "min_CLP": -6.41, "draft_iters": 14.0, "mem_use": 35.14, "gen_rate": 8.8, "speed": 4.43, "text": "\"Sure! Here's an implementation "}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.7, "tree_w": 65, "tree_size": 256, "t0": 0.7743, "t1": 0.8786, "tft": 1.9249, "input_0": 569, "input_1": 257, "min_CLP": -6.69, "draft_iters": 10.0, "mem_use": 35.86, "gen_rate": 4.6, "speed": 2.77, "text": "In 1999, the Wyoming Legislature"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 21.0, "tree_w": 66, "tree_size": 256, "t0": 1.55, "t1": 0.9, "tft": 2.2234, "input_0": 643, "input_1": 257, "min_CLP": -6.96, "draft_iters": 21.5, "mem_use": 35.58, "gen_rate": 20.0, "speed": 8.17, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.0, "tree_w": 59, "tree_size": 256, "t0": 1.545, "t1": 0.91, "tft": 2.0291, "input_0": 642, "input_1": 257, "min_CLP": -6.86, "draft_iters": 21.5, "mem_use": 35.18, "gen_rate": 19.5, "speed": 7.93, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.2, "tree_w": 52, "tree_size": 256, "t0": 1.035, "t1": 0.8817, "tft": 2.2987, "input_0": 710, "input_1": 257, "min_CLP": -6.23, "draft_iters": 13.7, "mem_use": 36.09, "gen_rate": 5.3, "speed": 2.78, "text": "\"It's natural to feel self-consc"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 57, "tree_h": 14.0, "tree_w": 51, "tree_size": 256, "t0": 1.1283, "t1": 0.8933, "tft": 3.3421, "input_0": 773, "input_1": 257, "min_CLP": -6.27, "draft_iters": 15.2, "mem_use": 37.66, "gen_rate": 9.5, "speed": 4.7, "text": "Sure, here is a list of 100 of t"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 25, "tree_h": 16.5, "tree_w": 53, "tree_size": 256, "t0": 1.26, "t1": 0.88, "tft": 3.0227, "input_0": 592, "input_1": 257, "min_CLP": -5.89, "draft_iters": 17.5, "mem_use": 35.29, "gen_rate": 12.5, "speed": 5.85, "text": "The total travel time would be 8"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 32.0, "tree_w": 20, "tree_size": 256, "t0": 2.2967, "t1": 0.9133, "tft": 2.2821, "input_0": 932, "input_1": 257, "min_CLP": -5.51, "draft_iters": 32.0, "mem_use": 35.21, "gen_rate": 13.3, "speed": 4.16, "text": "\"```python\\nimport discord\\nfrom"}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.2, "tree_w": 58, "tree_size": 256, "t0": 1.0225, "t1": 0.88, "tft": 1.8403, "input_0": 627, "input_1": 257, "min_CLP": -6.39, "draft_iters": 13.5, "mem_use": 35.1, "gen_rate": 8.2, "speed": 4.34, "text": "\"No, I'm not as capable as ChatG"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.2, "tree_w": 55, "tree_size": 256, "t0": 0.7717, "t1": 0.9, "tft": 3.2053, "input_0": 605, "input_1": 257, "min_CLP": -6.22, "draft_iters": 10.2, "mem_use": 38.85, "gen_rate": 6.2, "speed": 3.69, "text": "TypeScript is a superset of Java"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 30, "tree_h": 14.3, "tree_w": 46, "tree_size": 256, "t0": 1.1457, "t1": 0.8771, "tft": 3.1378, "input_0": 657, "input_1": 257, "min_CLP": -6.13, "draft_iters": 15.4, "mem_use": 35.22, "gen_rate": 4.3, "speed": 2.12, "text": "\"The name of the fourth kid is M"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.7, "tree_w": 69, "tree_size": 256, "t0": 0.8317, "t1": 0.8767, "tft": 3.3653, "input_0": 602, "input_1": 257, "min_CLP": -6.81, "draft_iters": 11.0, "mem_use": 36.27, "gen_rate": 6.0, "speed": 3.51, "text": "[INST] You cannot pay for experi"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.8, "tree_w": 44, "tree_size": 256, "t0": 0.9675, "t1": 0.8925, "tft": 2.8602, "input_0": 713, "input_1": 257, "min_CLP": -6.13, "draft_iters": 12.8, "mem_use": 38.02, "gen_rate": 8.5, "speed": 4.57, "text": "The time it takes to toast your "}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.0, "tree_w": 63, "tree_size": 256, "t0": 0.9583, "t1": 0.8867, "tft": 1.8465, "input_0": 650, "input_1": 257, "min_CLP": -6.38, "draft_iters": 12.5, "mem_use": 35.35, "gen_rate": 6.7, "speed": 3.62, "text": "\"It's great that you're taking i"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 18, "tree_h": 12.0, "tree_w": 46, "tree_size": 256, "t0": 1.03, "t1": 0.885, "tft": 2.8364, "input_0": 695, "input_1": 257, "min_CLP": -6.3, "draft_iters": 13.5, "mem_use": 35.85, "gen_rate": 9.0, "speed": 4.69, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 14.5, "tree_w": 45, "tree_size": 256, "t0": 1.2075, "t1": 0.895, "tft": 3.3662, "input_0": 918, "input_1": 257, "min_CLP": -6.18, "draft_iters": 15.8, "mem_use": 37.59, "gen_rate": 9.8, "speed": 4.64, "text": "As a high school student interes"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 16.0, "tree_w": 40, "tree_size": 256, "t0": 1.278, "t1": 0.884, "tft": 2.3456, "input_0": 863, "input_1": 257, "min_CLP": -6.15, "draft_iters": 17.0, "mem_use": 36.01, "gen_rate": 8.8, "speed": 4.07, "text": "The television was invented by a"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 14, "tree_h": 12.5, "tree_w": 51, "tree_size": 256, "t0": 1.065, "t1": 0.9, "tft": 3.0147, "input_0": 804, "input_1": 257, "min_CLP": -6.01, "draft_iters": 14.0, "mem_use": 38.3, "gen_rate": 7.0, "speed": 3.57, "text": "\"I'm glad to help. If you have a"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 61, "tree_size": 256, "t0": 0.926, "t1": 0.88, "tft": 2.6405, "input_0": 754, "input_1": 257, "min_CLP": -6.39, "draft_iters": 12.0, "mem_use": 36.65, "gen_rate": 6.8, "speed": 3.77, "text": "The reason for multiple days in "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.0, "tree_w": 68, "tree_size": 256, "t0": 0.78, "t1": 0.8786, "tft": 2.1893, "input_0": 567, "input_1": 257, "min_CLP": -6.55, "draft_iters": 10.3, "mem_use": 35.66, "gen_rate": 4.9, "speed": 2.93, "text": "\"Okay, I get it. I'm a chat assi"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.0, "tree_w": 52, "tree_size": 256, "t0": 0.948, "t1": 0.886, "tft": 3.4081, "input_0": 746, "input_1": 257, "min_CLP": -6.26, "draft_iters": 12.4, "mem_use": 37.47, "gen_rate": 7.2, "speed": 3.93, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 31.0, "tree_w": 59, "tree_size": 256, "t0": 2.2, "t1": 0.915, "tft": 2.0214, "input_0": 661, "input_1": 257, "min_CLP": -6.91, "draft_iters": 31.5, "mem_use": 35.29, "gen_rate": 20.0, "speed": 6.42, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 29, "tree_h": 11.7, "tree_w": 77, "tree_size": 256, "t0": 0.9371, "t1": 0.8829, "tft": 3.2906, "input_0": 531, "input_1": 257, "min_CLP": -6.69, "draft_iters": 12.9, "mem_use": 35.95, "gen_rate": 4.1, "speed": 2.27, "text": "Certainly! How about, \"A wish is"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.1, "tree_w": 79, "tree_size": 256, "t0": 0.8457, "t1": 0.8814, "tft": 2.6464, "input_0": 524, "input_1": 257, "min_CLP": -6.88, "draft_iters": 11.4, "mem_use": 35.38, "gen_rate": 4.6, "speed": 2.64, "text": "\"Ah, you're a broke college stud"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 28.5, "tree_w": 47, "tree_size": 256, "t0": 2.08, "t1": 0.92, "tft": 1.9778, "input_0": 874, "input_1": 257, "min_CLP": -7.27, "draft_iters": 29.0, "mem_use": 35.4, "gen_rate": 20.5, "speed": 6.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.3, "tree_w": 82, "tree_size": 256, "t0": 0.7033, "t1": 0.8733, "tft": 2.0011, "input_0": 461, "input_1": 257, "min_CLP": -6.68, "draft_iters": 9.3, "mem_use": 35.78, "gen_rate": 5.7, "speed": 3.6, "text": "Google Authenticator is an appli"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.8, "tree_w": 39, "tree_size": 256, "t0": 1.16, "t1": 0.884, "tft": 2.3598, "input_0": 803, "input_1": 257, "min_CLP": -5.93, "draft_iters": 15.4, "mem_use": 35.57, "gen_rate": 7.4, "speed": 3.62, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 13.5, "tree_w": 44, "tree_size": 256, "t0": 1.1075, "t1": 0.88, "tft": 1.8454, "input_0": 781, "input_1": 257, "min_CLP": -6.22, "draft_iters": 14.5, "mem_use": 35.33, "gen_rate": 8.8, "speed": 4.4, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 18.5, "tree_w": 27, "tree_size": 256, "t0": 1.48, "t1": 0.875, "tft": 1.6746, "input_0": 917, "input_1": 257, "min_CLP": -6.6, "draft_iters": 20.0, "mem_use": 35.18, "gen_rate": 16.5, "speed": 7.01, "text": "The wireless Internet signal in "}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 15.2, "tree_w": 48, "tree_size": 256, "t0": 1.18, "t1": 0.8783, "tft": 1.7479, "input_0": 640, "input_1": 257, "min_CLP": -6.35, "draft_iters": 16.2, "mem_use": 35.21, "gen_rate": 5.7, "speed": 2.75, "text": "```python\\n# Shakespeare Program"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.8, "tree_w": 60, "tree_size": 256, "t0": 0.8567, "t1": 0.875, "tft": 1.7919, "input_0": 604, "input_1": 257, "min_CLP": -6.49, "draft_iters": 11.2, "mem_use": 35.13, "gen_rate": 5.8, "speed": 3.37, "text": "Title: Unlocking the Potential o"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.0, "tree_w": 45, "tree_size": 256, "t0": 1.074, "t1": 0.882, "tft": 2.2515, "input_0": 709, "input_1": 257, "min_CLP": -6.2, "draft_iters": 14.4, "mem_use": 36.33, "gen_rate": 6.6, "speed": 3.38, "text": "\"In this case, you can use your "}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 52, "tree_size": 256, "t0": 1.0075, "t1": 0.8775, "tft": 1.6382, "input_0": 658, "input_1": 257, "min_CLP": -6.41, "draft_iters": 13.2, "mem_use": 35.09, "gen_rate": 8.2, "speed": 4.37, "text": "In Python, the `@` symbol is use"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 13.7, "tree_w": 38, "tree_size": 256, "t0": 1.14, "t1": 0.8767, "tft": 1.8599, "input_0": 810, "input_1": 257, "min_CLP": -6.24, "draft_iters": 15.0, "mem_use": 35.1, "gen_rate": 10.7, "speed": 5.28, "text": "\"I don't have personal opinions "}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.4, "tree_w": 83, "tree_size": 256, "t0": 0.7529, "t1": 0.8857, "tft": 2.7099, "input_0": 535, "input_1": 257, "min_CLP": -6.71, "draft_iters": 9.7, "mem_use": 35.41, "gen_rate": 4.6, "speed": 2.79, "text": "I would approach this task by fi"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 11.5, "tree_w": 81, "tree_size": 256, "t0": 0.9325, "t1": 0.8812, "tft": 2.8256, "input_0": 507, "input_1": 257, "min_CLP": -6.91, "draft_iters": 12.6, "mem_use": 35.14, "gen_rate": 4.4, "speed": 2.41, "text": "[INST] does anyone know how to g"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 43, "tree_size": 256, "t0": 2.26, "t1": 0.94, "tft": 1.9812, "input_0": 793, "input_1": 257, "min_CLP": -6.56, "draft_iters": 32.0, "mem_use": 35.83, "gen_rate": 33.0, "speed": 10.32, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.2, "tree_w": 70, "tree_size": 256, "t0": 1.152, "t1": 0.896, "tft": 3.6827, "input_0": 692, "input_1": 257, "min_CLP": -6.44, "draft_iters": 15.8, "mem_use": 38.33, "gen_rate": 7.4, "speed": 3.61, "text": "Here are some of the most popula"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 13.3, "tree_w": 46, "tree_size": 256, "t0": 1.0833, "t1": 0.8867, "tft": 2.2466, "input_0": 661, "input_1": 257, "min_CLP": -6.21, "draft_iters": 14.5, "mem_use": 35.64, "gen_rate": 6.5, "speed": 3.3, "text": "Decorators and wrapping function"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 8.8, "tree_w": 68, "tree_size": 256, "t0": 0.7733, "t1": 0.8817, "tft": 2.4896, "input_0": 569, "input_1": 257, "min_CLP": -6.72, "draft_iters": 10.2, "mem_use": 36.76, "gen_rate": 5.3, "speed": 3.22, "text": "\"Hello there, Agent. I see that "}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 18.8, "tree_w": 50, "tree_size": 256, "t0": 1.4533, "t1": 0.91, "tft": 2.4794, "input_0": 638, "input_1": 257, "min_CLP": -6.73, "draft_iters": 20.2, "mem_use": 35.63, "gen_rate": 5.5, "speed": 2.33, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 53, "tree_h": 23.0, "tree_w": 34, "tree_size": 256, "t0": 1.702, "t1": 0.908, "tft": 4.5393, "input_0": 823, "input_1": 257, "min_CLP": -5.92, "draft_iters": 23.8, "mem_use": 38.51, "gen_rate": 10.6, "speed": 4.06, "text": "Sure! Here are some simple code "}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 18.0, "tree_w": 28, "tree_size": 256, "t0": 1.4233, "t1": 0.9633, "tft": 6.5105, "input_0": 896, "input_1": 257, "min_CLP": -5.76, "draft_iters": 19.0, "mem_use": 44.5, "gen_rate": 12.0, "speed": 5.02, "text": "\"Sure! Here's an example of how "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.2, "tree_w": 48, "tree_size": 256, "t0": 1.078, "t1": 0.89, "tft": 3.0066, "input_0": 644, "input_1": 257, "min_CLP": -6.14, "draft_iters": 14.6, "mem_use": 36.86, "gen_rate": 6.8, "speed": 3.45, "text": "\"The average person may not enco"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.0, "tree_w": 53, "tree_size": 256, "t0": 0.988, "t1": 0.874, "tft": 1.7313, "input_0": 712, "input_1": 257, "min_CLP": -6.21, "draft_iters": 13.0, "mem_use": 35.14, "gen_rate": 7.4, "speed": 3.97, "text": "Sure, here are some tips to help"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.6, "tree_w": 44, "tree_size": 256, "t0": 1.114, "t1": 0.88, "tft": 2.1542, "input_0": 744, "input_1": 257, "min_CLP": -6.16, "draft_iters": 14.8, "mem_use": 35.26, "gen_rate": 7.0, "speed": 3.51, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.4, "tree_w": 55, "tree_size": 256, "t0": 1.104, "t1": 0.894, "tft": 3.1269, "input_0": 826, "input_1": 257, "min_CLP": -6.31, "draft_iters": 14.8, "mem_use": 38.03, "gen_rate": 7.6, "speed": 3.8, "text": "\"Of course! Here are some tips f"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.6, "tree_w": 55, "tree_size": 256, "t0": 0.9, "t1": 0.874, "tft": 2.2087, "input_0": 707, "input_1": 257, "min_CLP": -6.46, "draft_iters": 11.6, "mem_use": 35.2, "gen_rate": 7.8, "speed": 4.39, "text": "In 1950, the world was quite dif"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.8, "tree_w": 48, "tree_size": 256, "t0": 1.13, "t1": 0.905, "tft": 3.9016, "input_0": 869, "input_1": 257, "min_CLP": -6.2, "draft_iters": 15.0, "mem_use": 40.17, "gen_rate": 9.2, "speed": 4.55, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.3, "tree_w": 72, "tree_size": 256, "t0": 0.725, "t1": 0.8783, "tft": 1.573, "input_0": 507, "input_1": 257, "min_CLP": -6.5, "draft_iters": 9.5, "mem_use": 35.54, "gen_rate": 5.8, "speed": 3.64, "text": "First you should put your mother"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.2, "tree_w": 58, "tree_size": 256, "t0": 0.864, "t1": 0.88, "tft": 2.4638, "input_0": 665, "input_1": 257, "min_CLP": -6.39, "draft_iters": 11.2, "mem_use": 35.39, "gen_rate": 6.6, "speed": 3.79, "text": "Carnegie Mellon University has o"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.3, "tree_w": 63, "tree_size": 256, "t0": 0.805, "t1": 0.8817, "tft": 1.6796, "input_0": 608, "input_1": 257, "min_CLP": -6.56, "draft_iters": 10.3, "mem_use": 35.45, "gen_rate": 6.7, "speed": 3.95, "text": "I will be much more intelligent "}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.9, "tree_w": 50, "tree_size": 256, "t0": 0.9243, "t1": 0.8857, "tft": 2.9422, "input_0": 681, "input_1": 257, "min_CLP": -6.2, "draft_iters": 12.0, "mem_use": 36.81, "gen_rate": 4.9, "speed": 2.68, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.0, "tree_w": 34, "tree_size": 256, "t0": 1.275, "t1": 0.9, "tft": 3.2347, "input_0": 771, "input_1": 257, "min_CLP": -6.29, "draft_iters": 17.0, "mem_use": 35.52, "gen_rate": 8.5, "speed": 3.91, "text": "The infamous KeyHole series of s"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 19.0, "tree_w": 67, "tree_size": 256, "t0": 1.4633, "t1": 0.9, "tft": 1.7373, "input_0": 656, "input_1": 257, "min_CLP": -6.6, "draft_iters": 20.3, "mem_use": 35.69, "gen_rate": 13.0, "speed": 5.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 10.7, "tree_w": 62, "tree_size": 256, "t0": 0.9286, "t1": 0.8814, "tft": 2.2498, "input_0": 649, "input_1": 257, "min_CLP": -6.28, "draft_iters": 12.1, "mem_use": 35.75, "gen_rate": 4.6, "speed": 2.52, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 8.5, "tree_w": 73, "tree_size": 256, "t0": 0.7462, "t1": 0.89, "tft": 2.965, "input_0": 552, "input_1": 257, "min_CLP": -6.6, "draft_iters": 9.8, "mem_use": 37.68, "gen_rate": 4.4, "speed": 2.67, "text": "\u2022 GuitarLessons365: This channel"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.5, "tree_w": 59, "tree_size": 256, "t0": 0.84, "t1": 0.8717, "tft": 1.6929, "input_0": 655, "input_1": 257, "min_CLP": -6.39, "draft_iters": 10.8, "mem_use": 35.1, "gen_rate": 6.2, "speed": 3.6, "text": "No, stainless steel is not magne"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 17.8, "tree_w": 36, "tree_size": 256, "t0": 1.458, "t1": 0.89, "tft": 2.0748, "input_0": 912, "input_1": 257, "min_CLP": -6.07, "draft_iters": 19.4, "mem_use": 35.24, "gen_rate": 8.4, "speed": 3.58, "text": "Given two matrices A and B which"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.3, "tree_w": 64, "tree_size": 256, "t0": 0.8557, "t1": 0.8871, "tft": 2.7546, "input_0": 556, "input_1": 257, "min_CLP": -6.84, "draft_iters": 11.4, "mem_use": 36.68, "gen_rate": 4.7, "speed": 2.7, "text": "\"Statistical modeling, applied a"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 19, "tree_size": 256, "t0": 2.26, "t1": 0.91, "tft": 4.2758, "input_0": 771, "input_1": 257, "min_CLP": -5.87, "draft_iters": 32.0, "mem_use": 37.84, "gen_rate": 33.0, "speed": 10.43, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 28.0, "tree_w": 52, "tree_size": 256, "t0": 2.005, "t1": 0.91, "tft": 1.8513, "input_0": 675, "input_1": 257, "min_CLP": -6.81, "draft_iters": 28.5, "mem_use": 35.08, "gen_rate": 20.0, "speed": 6.86, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.8, "tree_w": 50, "tree_size": 256, "t0": 1.02, "t1": 0.886, "tft": 2.5431, "input_0": 675, "input_1": 257, "min_CLP": -6.26, "draft_iters": 13.4, "mem_use": 36.57, "gen_rate": 6.6, "speed": 3.46, "text": "Yes, that\\'s a great approach! R"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.3, "tree_w": 75, "tree_size": 256, "t0": 0.7817, "t1": 0.8833, "tft": 1.5975, "input_0": 488, "input_1": 257, "min_CLP": -6.78, "draft_iters": 10.3, "mem_use": 35.45, "gen_rate": 5.5, "speed": 3.31, "text": "\"To be honest, that's a really s"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.0, "tree_w": 28, "tree_size": 256, "t0": 1.525, "t1": 0.895, "tft": 1.9193, "input_0": 972, "input_1": 257, "min_CLP": -5.93, "draft_iters": 20.2, "mem_use": 35.14, "gen_rate": 10.0, "speed": 4.13, "text": "To estimate the variance of a va"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.8, "tree_w": 46, "tree_size": 256, "t0": 1.22, "t1": 0.8975, "tft": 1.6218, "input_0": 690, "input_1": 257, "min_CLP": -6.24, "draft_iters": 16.2, "mem_use": 35.49, "gen_rate": 9.2, "speed": 4.36, "text": "\"Certainly, I'd be happy to help"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 10.4, "tree_w": 59, "tree_size": 256, "t0": 0.9114, "t1": 0.8743, "tft": 2.1009, "input_0": 668, "input_1": 257, "min_CLP": -6.34, "draft_iters": 11.7, "mem_use": 35.08, "gen_rate": 6.0, "speed": 3.37, "text": "It is not possible to answer thi"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.4, "tree_w": 51, "tree_size": 256, "t0": 1.25, "t1": 0.896, "tft": 3.4304, "input_0": 606, "input_1": 257, "min_CLP": -6.38, "draft_iters": 17.4, "mem_use": 36.42, "gen_rate": 6.4, "speed": 2.98, "text": "You are welcome! If you have any"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 10.0, "tree_w": 70, "tree_size": 256, "t0": 0.835, "t1": 0.87, "tft": 3.1571, "input_0": 567, "input_1": 257, "min_CLP": -6.65, "draft_iters": 11.0, "mem_use": 35.27, "gen_rate": 2.5, "speed": 1.47, "text": "\"The answer is Jay's brother is "}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 12.1, "tree_w": 94, "tree_size": 256, "t0": 1.0357, "t1": 0.89, "tft": 2.2578, "input_0": 649, "input_1": 257, "min_CLP": -6.21, "draft_iters": 13.6, "mem_use": 35.65, "gen_rate": 4.7, "speed": 2.45, "text": "Pacific Ocean (155,557,000 sq km"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 77, "tree_size": 256, "t0": 0.6771, "t1": 0.8757, "tft": 1.7177, "input_0": 517, "input_1": 257, "min_CLP": -6.49, "draft_iters": 8.7, "mem_use": 35.89, "gen_rate": 4.7, "speed": 3.04, "text": "\"That's ok, we can start from th"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 26.7, "tree_w": 22, "tree_size": 256, "t0": 2.01, "t1": 0.9067, "tft": 1.8402, "input_0": 922, "input_1": 257, "min_CLP": -5.56, "draft_iters": 27.7, "mem_use": 35.31, "gen_rate": 11.3, "speed": 3.89, "text": "\"Here's an example of a basic Py"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.1, "tree_w": 72, "tree_size": 256, "t0": 0.7643, "t1": 0.8814, "tft": 2.3889, "input_0": 628, "input_1": 257, "min_CLP": -6.36, "draft_iters": 9.7, "mem_use": 36.42, "gen_rate": 4.6, "speed": 2.78, "text": "A DLL (Dynamic Link Library) is "}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 48, "tree_size": 256, "t0": 2.21, "t1": 0.94, "tft": 2.3517, "input_0": 733, "input_1": 257, "min_CLP": -6.7, "draft_iters": 32.0, "mem_use": 35.55, "gen_rate": 33.0, "speed": 10.46, "text": "Please rephrase the question wit"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.4, "tree_w": 86, "tree_size": 256, "t0": 0.6671, "t1": 0.8671, "tft": 1.5758, "input_0": 550, "input_1": 257, "min_CLP": -6.77, "draft_iters": 8.6, "mem_use": 35.09, "gen_rate": 4.7, "speed": 3.07, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.3, "tree_w": 38, "tree_size": 256, "t0": 1.42, "t1": 0.89, "tft": 1.553, "input_0": 845, "input_1": 257, "min_CLP": -6.0, "draft_iters": 19.3, "mem_use": 35.2, "gen_rate": 10.7, "speed": 4.63, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 15.3, "tree_w": 54, "tree_size": 256, "t0": 1.19, "t1": 0.88, "tft": 1.717, "input_0": 645, "input_1": 257, "min_CLP": -6.65, "draft_iters": 16.3, "mem_use": 35.35, "gen_rate": 11.7, "speed": 5.63, "text": "They are not on a higher moral l"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 7.0, "tree_w": 98, "tree_size": 256, "t0": 0.64, "t1": 0.8786, "tft": 3.1087, "input_0": 465, "input_1": 257, "min_CLP": -7.1, "draft_iters": 8.1, "mem_use": 35.86, "gen_rate": 4.6, "speed": 3.01, "text": "\"The show is just not funny. It'"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.5, "tree_w": 57, "tree_size": 256, "t0": 1.05, "t1": 0.8825, "tft": 2.4414, "input_0": 795, "input_1": 257, "min_CLP": -6.18, "draft_iters": 13.8, "mem_use": 36.72, "gen_rate": 8.0, "speed": 4.14, "text": "\"Yes, you can certainly ask me f"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.8, "tree_w": 38, "tree_size": 256, "t0": 1.006, "t1": 0.886, "tft": 2.8584, "input_0": 804, "input_1": 257, "min_CLP": -6.04, "draft_iters": 13.0, "mem_use": 37.23, "gen_rate": 6.6, "speed": 3.49, "text": "The difficulty of learning a lan"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 29.5, "tree_w": 33, "tree_size": 256, "t0": 2.135, "t1": 0.94, "tft": 2.1388, "input_0": 825, "input_1": 257, "min_CLP": -6.0, "draft_iters": 30.0, "mem_use": 35.69, "gen_rate": 21.0, "speed": 6.82, "text": "Some of the AI tools for 2D anim"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.8, "tree_w": 59, "tree_size": 256, "t0": 0.9233, "t1": 0.8833, "tft": 1.7999, "input_0": 663, "input_1": 257, "min_CLP": -6.29, "draft_iters": 12.0, "mem_use": 35.55, "gen_rate": 6.3, "speed": 3.51, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 64, "tree_size": 256, "t0": 0.868, "t1": 0.884, "tft": 1.9086, "input_0": 604, "input_1": 257, "min_CLP": -6.43, "draft_iters": 11.2, "mem_use": 35.76, "gen_rate": 6.4, "speed": 3.65, "text": "\"It's not worth it, because you "}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 49, "tree_size": 256, "t0": 0.9275, "t1": 0.8825, "tft": 2.268, "input_0": 641, "input_1": 257, "min_CLP": -6.35, "draft_iters": 12.0, "mem_use": 35.77, "gen_rate": 8.2, "speed": 4.56, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.2, "tree_w": 65, "tree_size": 256, "t0": 0.805, "t1": 0.875, "tft": 2.9428, "input_0": 628, "input_1": 257, "min_CLP": -6.51, "draft_iters": 10.2, "mem_use": 35.21, "gen_rate": 5.3, "speed": 3.17, "text": "Sure, I can design an electric P"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.3, "tree_w": 33, "tree_size": 256, "t0": 1.3867, "t1": 0.8933, "tft": 3.1637, "input_0": 859, "input_1": 257, "min_CLP": -6.51, "draft_iters": 18.7, "mem_use": 36.86, "gen_rate": 11.0, "speed": 4.83, "text": "The largest optical telescope in"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 15.0, "tree_w": 55, "tree_size": 256, "t0": 1.186, "t1": 0.892, "tft": 2.85, "input_0": 635, "input_1": 257, "min_CLP": -6.57, "draft_iters": 16.0, "mem_use": 35.35, "gen_rate": 7.6, "speed": 3.66, "text": "Psychomotricity\\n[INST] What kin"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 10.0, "tree_w": 67, "tree_size": 256, "t0": 0.8537, "t1": 0.8787, "tft": 2.6739, "input_0": 590, "input_1": 257, "min_CLP": -6.63, "draft_iters": 11.1, "mem_use": 35.18, "gen_rate": 4.2, "speed": 2.45, "text": "Here are ten names from differen"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 10.0, "tree_w": 62, "tree_size": 256, "t0": 0.87, "t1": 0.8829, "tft": 1.8035, "input_0": 619, "input_1": 257, "min_CLP": -6.56, "draft_iters": 11.1, "mem_use": 35.66, "gen_rate": 5.6, "speed": 3.18, "text": "\"I am an AI language model, so I"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 14.4, "tree_w": 46, "tree_size": 256, "t0": 1.188, "t1": 0.906, "tft": 3.089, "input_0": 759, "input_1": 257, "min_CLP": -6.23, "draft_iters": 15.8, "mem_use": 37.33, "gen_rate": 7.4, "speed": 3.54, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.8, "tree_w": 64, "tree_size": 256, "t0": 0.765, "t1": 0.8817, "tft": 2.2966, "input_0": 553, "input_1": 257, "min_CLP": -6.58, "draft_iters": 10.0, "mem_use": 36.16, "gen_rate": 5.7, "speed": 3.43, "text": "Yes, there is a similar theory i"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 13.7, "tree_w": 47, "tree_size": 256, "t0": 1.1317, "t1": 0.8867, "tft": 2.4527, "input_0": 765, "input_1": 257, "min_CLP": -6.28, "draft_iters": 15.0, "mem_use": 36.57, "gen_rate": 6.3, "speed": 3.14, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 8.1, "tree_w": 76, "tree_size": 256, "t0": 0.7071, "t1": 0.8714, "tft": 1.5722, "input_0": 522, "input_1": 257, "min_CLP": -6.86, "draft_iters": 9.1, "mem_use": 35.13, "gen_rate": 4.6, "speed": 2.9, "text": "Title: The Quantum Conundrum\\n\\n"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 24.6, "tree_w": 41, "tree_size": 256, "t0": 1.83, "t1": 0.92, "tft": 4.8753, "input_0": 811, "input_1": 257, "min_CLP": -6.17, "draft_iters": 25.8, "mem_use": 39.82, "gen_rate": 6.6, "speed": 2.4, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.7, "tree_w": 55, "tree_size": 256, "t0": 0.9567, "t1": 0.8867, "tft": 2.6477, "input_0": 650, "input_1": 257, "min_CLP": -6.51, "draft_iters": 12.7, "mem_use": 36.28, "gen_rate": 5.5, "speed": 2.98, "text": "To transform text words or expre"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.8, "tree_w": 32, "tree_size": 256, "t0": 1.4525, "t1": 0.8925, "tft": 3.1378, "input_0": 793, "input_1": 257, "min_CLP": -6.21, "draft_iters": 19.8, "mem_use": 36.15, "gen_rate": 10.2, "speed": 4.37, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.8, "tree_w": 62, "tree_size": 256, "t0": 0.998, "t1": 0.87, "tft": 2.0229, "input_0": 757, "input_1": 257, "min_CLP": -6.44, "draft_iters": 13.0, "mem_use": 35.15, "gen_rate": 8.2, "speed": 4.38, "text": "Adolf Hitler, the leader of the "}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 11.1, "tree_w": 71, "tree_size": 256, "t0": 0.9338, "t1": 0.8912, "tft": 2.0321, "input_0": 555, "input_1": 257, "min_CLP": -6.95, "draft_iters": 12.2, "mem_use": 35.49, "gen_rate": 4.0, "speed": 2.19, "text": "\"Certainly! Here's another one:\\"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.0, "tree_w": 55, "tree_size": 256, "t0": 1.002, "t1": 0.882, "tft": 1.6496, "input_0": 694, "input_1": 257, "min_CLP": -6.34, "draft_iters": 13.0, "mem_use": 35.11, "gen_rate": 7.6, "speed": 4.03, "text": "At the time of writing, it is es"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.0, "tree_w": 70, "tree_size": 256, "t0": 0.8486, "t1": 0.9129, "tft": 3.4346, "input_0": 596, "input_1": 257, "min_CLP": -6.54, "draft_iters": 11.3, "mem_use": 39.88, "gen_rate": 5.1, "speed": 2.92, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.2, "tree_w": 72, "tree_size": 256, "t0": 0.7933, "t1": 0.8783, "tft": 1.8147, "input_0": 567, "input_1": 257, "min_CLP": -6.48, "draft_iters": 10.3, "mem_use": 35.19, "gen_rate": 5.7, "speed": 3.38, "text": "The furthest back we can prove h"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 26, "tree_h": 9.2, "tree_w": 59, "tree_size": 256, "t0": 0.83, "t1": 0.932, "tft": 4.8443, "input_0": 652, "input_1": 257, "min_CLP": -6.33, "draft_iters": 10.6, "mem_use": 42.12, "gen_rate": 5.2, "speed": 2.95, "text": "I am not sure what you mean by \""}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.5, "tree_w": 75, "tree_size": 256, "t0": 0.735, "t1": 0.885, "tft": 2.2914, "input_0": 519, "input_1": 257, "min_CLP": -6.62, "draft_iters": 9.7, "mem_use": 36.39, "gen_rate": 5.8, "speed": 3.61, "text": "Spritesla is not the first evolu"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.6, "tree_w": 55, "tree_size": 256, "t0": 1.004, "t1": 0.876, "tft": 1.9536, "input_0": 722, "input_1": 257, "min_CLP": -6.35, "draft_iters": 13.2, "mem_use": 35.22, "gen_rate": 7.0, "speed": 3.73, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 56, "tree_size": 256, "t0": 0.8867, "t1": 0.88, "tft": 1.7749, "input_0": 638, "input_1": 257, "min_CLP": -6.25, "draft_iters": 11.5, "mem_use": 35.09, "gen_rate": 5.5, "speed": 3.11, "text": "\"Two-factor authentication (2FA)"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 24.5, "tree_w": 50, "tree_size": 256, "t0": 1.86, "t1": 0.89, "tft": 2.5956, "input_0": 875, "input_1": 257, "min_CLP": -7.66, "draft_iters": 25.5, "mem_use": 35.33, "gen_rate": 21.0, "speed": 7.63, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.4, "tree_w": 59, "tree_size": 256, "t0": 1.218, "t1": 0.896, "tft": 1.7331, "input_0": 696, "input_1": 257, "min_CLP": -6.56, "draft_iters": 16.6, "mem_use": 35.63, "gen_rate": 6.6, "speed": 3.12, "text": "Here are a few TV shows that you"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 16.8, "tree_w": 37, "tree_size": 256, "t0": 1.31, "t1": 0.894, "tft": 3.2233, "input_0": 744, "input_1": 257, "min_CLP": -6.06, "draft_iters": 17.8, "mem_use": 37.23, "gen_rate": 7.4, "speed": 3.36, "text": "Certainly! Here are some softwar"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 14.5, "tree_w": 43, "tree_size": 256, "t0": 1.245, "t1": 0.885, "tft": 2.9944, "input_0": 952, "input_1": 257, "min_CLP": -6.24, "draft_iters": 16.0, "mem_use": 36.37, "gen_rate": 9.2, "speed": 4.34, "text": "When F-centers form in a crystal"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 15.7, "tree_w": 61, "tree_size": 256, "t0": 1.2414, "t1": 0.8971, "tft": 2.3618, "input_0": 612, "input_1": 257, "min_CLP": -6.74, "draft_iters": 17.0, "mem_use": 35.27, "gen_rate": 4.6, "speed": 2.14, "text": "\"The two players in the atomic b"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 26.7, "tree_w": 39, "tree_size": 256, "t0": 1.93, "t1": 0.9086, "tft": 2.8414, "input_0": 757, "input_1": 257, "min_CLP": -6.0, "draft_iters": 27.4, "mem_use": 37.89, "gen_rate": 4.7, "speed": 1.66, "text": "\"Here's the same example code wi"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.2, "tree_w": 55, "tree_size": 256, "t0": 1.015, "t1": 0.8867, "tft": 3.6498, "input_0": 691, "input_1": 257, "min_CLP": -6.62, "draft_iters": 13.5, "mem_use": 36.4, "gen_rate": 6.2, "speed": 3.24, "text": "Lo siento, pero Linkin Park no e"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 42, "tree_size": 256, "t0": 1.715, "t1": 0.89, "tft": 1.651, "input_0": 799, "input_1": 257, "min_CLP": -7.73, "draft_iters": 23.5, "mem_use": 35.11, "gen_rate": 24.0, "speed": 9.21, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 22, "tree_h": 12.3, "tree_w": 40, "tree_size": 256, "t0": 1.07, "t1": 0.8767, "tft": 1.7688, "input_0": 755, "input_1": 257, "min_CLP": -6.24, "draft_iters": 14.0, "mem_use": 35.19, "gen_rate": 7.3, "speed": 3.76, "text": "```python\\n# This is an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 9.0, "tree_w": 69, "tree_size": 256, "t0": 0.78, "t1": 0.88, "tft": 2.2811, "input_0": 631, "input_1": 257, "min_CLP": -6.87, "draft_iters": 10.0, "mem_use": 36.24, "gen_rate": 5.5, "speed": 3.32, "text": "\"Sure, here's a poem in the styl"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 51, "tree_h": 16.0, "tree_w": 42, "tree_size": 256, "t0": 1.2925, "t1": 0.895, "tft": 2.8301, "input_0": 850, "input_1": 257, "min_CLP": -6.05, "draft_iters": 17.2, "mem_use": 37.16, "gen_rate": 12.8, "speed": 5.83, "text": "\"In JavaScript, you can use the "}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 75, "tree_size": 256, "t0": 0.6743, "t1": 0.8814, "tft": 2.0264, "input_0": 537, "input_1": 257, "min_CLP": -6.62, "draft_iters": 8.6, "mem_use": 35.71, "gen_rate": 5.0, "speed": 3.22, "text": "Start with the basics. Learn the"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 12.1, "tree_w": 47, "tree_size": 256, "t0": 1.0429, "t1": 0.8857, "tft": 2.2333, "input_0": 786, "input_1": 257, "min_CLP": -6.15, "draft_iters": 13.6, "mem_use": 36.21, "gen_rate": 4.9, "speed": 2.52, "text": "My apologies for the assumption."}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 12.5, "tree_w": 51, "tree_size": 256, "t0": 1.055, "t1": 0.87, "tft": 1.8362, "input_0": 764, "input_1": 257, "min_CLP": -6.41, "draft_iters": 13.5, "mem_use": 35.1, "gen_rate": 5.5, "speed": 2.85, "text": "Javascript is both a front-end a"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 12.3, "tree_w": 46, "tree_size": 256, "t0": 1.0443, "t1": 0.8771, "tft": 1.7879, "input_0": 684, "input_1": 257, "min_CLP": -6.27, "draft_iters": 13.6, "mem_use": 35.09, "gen_rate": 5.3, "speed": 2.74, "text": "The chemical l-theanine, also kn"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 16.0, "tree_w": 45, "tree_size": 256, "t0": 1.2629, "t1": 0.8957, "tft": 2.5196, "input_0": 699, "input_1": 257, "min_CLP": -6.39, "draft_iters": 17.0, "mem_use": 35.8, "gen_rate": 4.6, "speed": 2.12, "text": "\"Here's the list of words with t"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 8.4, "tree_w": 69, "tree_size": 256, "t0": 0.7425, "t1": 0.8762, "tft": 2.5392, "input_0": 564, "input_1": 257, "min_CLP": -6.77, "draft_iters": 9.5, "mem_use": 35.22, "gen_rate": 5.1, "speed": 3.16, "text": "Hippoplaisir is a psychologists "}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 7.1, "tree_w": 81, "tree_size": 256, "t0": 0.6625, "t1": 0.8738, "tft": 2.6022, "input_0": 586, "input_1": 257, "min_CLP": -6.78, "draft_iters": 8.2, "mem_use": 35.22, "gen_rate": 4.5, "speed": 2.93, "text": "\"Here's a poem for your Valentin"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 21.0, "tree_w": 59, "tree_size": 256, "t0": 1.58, "t1": 0.88, "tft": 1.9441, "input_0": 673, "input_1": 257, "min_CLP": -7.24, "draft_iters": 22.0, "mem_use": 35.19, "gen_rate": 20.0, "speed": 8.13, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.6, "tree_w": 57, "tree_size": 256, "t0": 1.064, "t1": 0.914, "tft": 4.844, "input_0": 641, "input_1": 257, "min_CLP": -6.47, "draft_iters": 14.6, "mem_use": 39.94, "gen_rate": 6.6, "speed": 3.34, "text": "\"Here's a possible continuation "}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 27.0, "tree_w": 22, "tree_size": 256, "t0": 2.02, "t1": 0.9125, "tft": 3.7374, "input_0": 981, "input_1": 257, "min_CLP": -5.75, "draft_iters": 28.0, "mem_use": 37.6, "gen_rate": 8.2, "speed": 2.81, "text": "\"Fermat's Last Theorem is a math"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 20.3, "tree_w": 30, "tree_size": 256, "t0": 1.6533, "t1": 0.8967, "tft": 2.4616, "input_0": 1037, "input_1": 257, "min_CLP": -5.72, "draft_iters": 22.0, "mem_use": 36.05, "gen_rate": 13.3, "speed": 5.23, "text": "Certainly! The mathematical form"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 44, "tree_h": 11.0, "tree_w": 55, "tree_size": 256, "t0": 0.9083, "t1": 0.88, "tft": 2.2472, "input_0": 611, "input_1": 257, "min_CLP": -6.16, "draft_iters": 12.0, "mem_use": 36.21, "gen_rate": 7.3, "speed": 4.1, "text": "We can learn so much from polar "}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.3, "tree_w": 46, "tree_size": 256, "t0": 0.8867, "t1": 0.8933, "tft": 2.5083, "input_0": 634, "input_1": 257, "min_CLP": -6.32, "draft_iters": 11.5, "mem_use": 37.24, "gen_rate": 5.5, "speed": 3.09, "text": "Lemon wedges for serving are sma"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 9.1, "tree_w": 69, "tree_size": 256, "t0": 0.8186, "t1": 0.88, "tft": 1.6427, "input_0": 589, "input_1": 257, "min_CLP": -6.52, "draft_iters": 10.7, "mem_use": 35.28, "gen_rate": 4.6, "speed": 2.7, "text": "\"Sure, I can do that! Let's get "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.4, "tree_w": 68, "tree_size": 256, "t0": 0.8086, "t1": 0.8829, "tft": 1.649, "input_0": 543, "input_1": 257, "min_CLP": -6.71, "draft_iters": 10.6, "mem_use": 35.24, "gen_rate": 5.4, "speed": 3.21, "text": "\"You're welcome.\\n[INST] I'm kil"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 21.7, "tree_w": 29, "tree_size": 256, "t0": 1.66, "t1": 0.89, "tft": 2.2601, "input_0": 979, "input_1": 257, "min_CLP": -5.76, "draft_iters": 22.7, "mem_use": 35.13, "gen_rate": 17.7, "speed": 6.93, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.2, "tree_w": 46, "tree_size": 256, "t0": 1.05, "t1": 0.885, "tft": 2.7216, "input_0": 795, "input_1": 257, "min_CLP": -6.36, "draft_iters": 13.8, "mem_use": 36.7, "gen_rate": 8.8, "speed": 4.52, "text": "Yes, there are several examples "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 51, "tree_size": 256, "t0": 0.925, "t1": 0.8775, "tft": 2.4177, "input_0": 745, "input_1": 257, "min_CLP": -6.41, "draft_iters": 12.0, "mem_use": 36.25, "gen_rate": 8.5, "speed": 4.73, "text": "Freeman Dyson has defended sever"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 15.0, "tree_w": 42, "tree_size": 256, "t0": 1.195, "t1": 0.89, "tft": 1.5736, "input_0": 692, "input_1": 257, "min_CLP": -6.12, "draft_iters": 16.0, "mem_use": 35.08, "gen_rate": 6.5, "speed": 3.12, "text": "def reverse_words_order_and_swap"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 17.2, "tree_w": 43, "tree_size": 256, "t0": 1.336, "t1": 0.9, "tft": 2.9088, "input_0": 715, "input_1": 257, "min_CLP": -6.34, "draft_iters": 18.2, "mem_use": 35.82, "gen_rate": 6.8, "speed": 3.05, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 18.9, "tree_w": 60, "tree_size": 256, "t0": 1.4171, "t1": 0.9, "tft": 2.6389, "input_0": 622, "input_1": 257, "min_CLP": -6.47, "draft_iters": 19.7, "mem_use": 36.44, "gen_rate": 4.6, "speed": 1.97, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.0, "tree_w": 44, "tree_size": 256, "t0": 1.3133, "t1": 0.9, "tft": 1.9786, "input_0": 851, "input_1": 257, "min_CLP": -6.2, "draft_iters": 17.3, "mem_use": 35.44, "gen_rate": 11.3, "speed": 5.12, "text": "1.    Time management and priori"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.5, "tree_w": 47, "tree_size": 256, "t0": 0.965, "t1": 0.8775, "tft": 1.6533, "input_0": 657, "input_1": 257, "min_CLP": -6.34, "draft_iters": 12.5, "mem_use": 35.11, "gen_rate": 9.2, "speed": 5.03, "text": "Yes, I am familiar with the self"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 12.0, "tree_w": 51, "tree_size": 256, "t0": 1.035, "t1": 0.885, "tft": 1.8068, "input_0": 793, "input_1": 257, "min_CLP": -6.28, "draft_iters": 13.3, "mem_use": 35.67, "gen_rate": 6.8, "speed": 3.56, "text": "Making a comparison of deep lear"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 13.0, "tree_w": 60, "tree_size": 256, "t0": 1.035, "t1": 0.885, "tft": 2.6705, "input_0": 605, "input_1": 257, "min_CLP": -6.47, "draft_iters": 14.0, "mem_use": 36.13, "gen_rate": 5.5, "speed": 2.86, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 11.3, "tree_w": 52, "tree_size": 256, "t0": 0.9571, "t1": 0.8829, "tft": 2.3205, "input_0": 681, "input_1": 257, "min_CLP": -6.34, "draft_iters": 12.4, "mem_use": 35.78, "gen_rate": 5.0, "speed": 2.72, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 31.7, "tree_w": 22, "tree_size": 256, "t0": 2.2633, "t1": 0.9067, "tft": 4.3075, "input_0": 915, "input_1": 257, "min_CLP": -6.24, "draft_iters": 32.0, "mem_use": 37.9, "gen_rate": 14.7, "speed": 4.63, "text": "\"L'Hopital's rule is a mathemati"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 10.2, "tree_w": 61, "tree_size": 256, "t0": 0.84, "t1": 0.91, "tft": 3.2997, "input_0": 589, "input_1": 257, "min_CLP": -6.76, "draft_iters": 11.2, "mem_use": 39.45, "gen_rate": 5.7, "speed": 3.24, "text": "- Some popular brands of vegan c"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.2, "tree_w": 49, "tree_size": 256, "t0": 0.95, "t1": 0.882, "tft": 2.3247, "input_0": 726, "input_1": 257, "min_CLP": -6.26, "draft_iters": 12.4, "mem_use": 36.5, "gen_rate": 8.4, "speed": 4.58, "text": "\"It sounds like you have a speci"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 30.5, "tree_w": 25, "tree_size": 256, "t0": 2.225, "t1": 0.915, "tft": 2.6158, "input_0": 935, "input_1": 257, "min_CLP": -6.03, "draft_iters": 31.0, "mem_use": 36.88, "gen_rate": 25.0, "speed": 7.96, "text": "Sure! Here are the three most im"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 38, "tree_size": 256, "t0": 1.2325, "t1": 0.8875, "tft": 2.0557, "input_0": 793, "input_1": 257, "min_CLP": -5.97, "draft_iters": 16.2, "mem_use": 35.11, "gen_rate": 8.8, "speed": 4.13, "text": "Sets and lists are both data str"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 46, "tree_h": 12.2, "tree_w": 53, "tree_size": 256, "t0": 1.0083, "t1": 0.885, "tft": 3.2138, "input_0": 699, "input_1": 257, "min_CLP": -6.16, "draft_iters": 13.3, "mem_use": 36.46, "gen_rate": 7.7, "speed": 4.05, "text": "Black Friday is on the Friday af"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.7, "tree_w": 59, "tree_size": 256, "t0": 0.9067, "t1": 0.8733, "tft": 1.6302, "input_0": 649, "input_1": 257, "min_CLP": -6.7, "draft_iters": 12.0, "mem_use": 35.28, "gen_rate": 5.3, "speed": 2.99, "text": "\"Sure, here's a story for you:\\n"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.0, "tree_w": 66, "tree_size": 256, "t0": 0.784, "t1": 0.868, "tft": 2.2818, "input_0": 634, "input_1": 257, "min_CLP": -6.43, "draft_iters": 10.2, "mem_use": 35.16, "gen_rate": 7.0, "speed": 4.23, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.0, "tree_w": 54, "tree_size": 256, "t0": 0.988, "t1": 0.872, "tft": 2.2153, "input_0": 629, "input_1": 257, "min_CLP": -6.52, "draft_iters": 13.2, "mem_use": 35.15, "gen_rate": 6.6, "speed": 3.55, "text": "In Minecraft, there are several "}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.8, "tree_w": 66, "tree_size": 256, "t0": 0.8933, "t1": 0.8733, "tft": 1.6906, "input_0": 681, "input_1": 257, "min_CLP": -6.7, "draft_iters": 11.5, "mem_use": 35.1, "gen_rate": 6.0, "speed": 3.4, "text": "As the Norse Goddess Freyja, I a"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 11, "tree_h": 15.0, "tree_w": 30, "tree_size": 256, "t0": 1.21, "t1": 0.88, "tft": 3.6214, "input_0": 889, "input_1": 257, "min_CLP": -6.08, "draft_iters": 16.0, "mem_use": 36.38, "gen_rate": 11.0, "speed": 5.26, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.5, "tree_w": 40, "tree_size": 256, "t0": 1.2275, "t1": 0.8975, "tft": 3.2117, "input_0": 698, "input_1": 257, "min_CLP": -6.23, "draft_iters": 16.8, "mem_use": 35.49, "gen_rate": 8.2, "speed": 3.88, "text": "# Install Tailwind\\nnpm install "}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.2, "tree_w": 49, "tree_size": 256, "t0": 1.1, "t1": 0.91, "tft": 4.6979, "input_0": 739, "input_1": 257, "min_CLP": -6.24, "draft_iters": 14.8, "mem_use": 40.54, "gen_rate": 9.2, "speed": 4.6, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 60, "tree_size": 256, "t0": 1.02, "t1": 0.8925, "tft": 1.6621, "input_0": 809, "input_1": 257, "min_CLP": -6.44, "draft_iters": 13.2, "mem_use": 35.62, "gen_rate": 8.5, "speed": 4.45, "text": "LLMs (Large Language Models) req"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.8, "tree_w": 65, "tree_size": 256, "t0": 0.8483, "t1": 0.8817, "tft": 2.6174, "input_0": 588, "input_1": 257, "min_CLP": -6.78, "draft_iters": 11.0, "mem_use": 35.19, "gen_rate": 5.3, "speed": 3.08, "text": "Sure, here\\'s a joke for you:\\n\\"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 13.6, "tree_w": 60, "tree_size": 256, "t0": 1.0957, "t1": 0.8857, "tft": 3.165, "input_0": 634, "input_1": 257, "min_CLP": -6.46, "draft_iters": 14.7, "mem_use": 35.41, "gen_rate": 5.1, "speed": 2.59, "text": "Eulogy for Grandma:\\n\\nDear fami"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 15.0, "tree_w": 43, "tree_size": 256, "t0": 1.24, "t1": 0.8875, "tft": 2.4816, "input_0": 828, "input_1": 257, "min_CLP": -6.01, "draft_iters": 16.5, "mem_use": 36.88, "gen_rate": 10.8, "speed": 5.05, "text": "[INST] What are some additional "}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.6, "tree_w": 56, "tree_size": 256, "t0": 0.84, "t1": 0.886, "tft": 1.8414, "input_0": 621, "input_1": 257, "min_CLP": -6.26, "draft_iters": 10.8, "mem_use": 35.27, "gen_rate": 7.4, "speed": 4.28, "text": "\"Yes, I am an AI language model "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 25, "tree_h": 8.5, "tree_w": 68, "tree_size": 256, "t0": 0.7375, "t1": 0.8713, "tft": 2.2859, "input_0": 556, "input_1": 257, "min_CLP": -6.65, "draft_iters": 9.6, "mem_use": 35.25, "gen_rate": 3.1, "speed": 1.94, "text": "- Play a card game with them.\\n-"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 47, "tree_size": 256, "t0": 0.9475, "t1": 0.8675, "tft": 1.5764, "input_0": 771, "input_1": 257, "min_CLP": -6.39, "draft_iters": 12.2, "mem_use": 35.08, "gen_rate": 8.2, "speed": 4.54, "text": "The color of Mars is often descr"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 18, "tree_h": 8.8, "tree_w": 93, "tree_size": 256, "t0": 0.7425, "t1": 0.89, "tft": 3.1247, "input_0": 484, "input_1": 257, "min_CLP": -7.57, "draft_iters": 9.8, "mem_use": 37.3, "gen_rate": 4.5, "speed": 2.75, "text": "To say \"I love you\" in Quenya, y"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 33, "tree_h": 32.0, "tree_w": 43, "tree_size": 256, "t0": 2.26, "t1": 0.91, "tft": 3.1416, "input_0": 749, "input_1": 257, "min_CLP": -6.67, "draft_iters": 32.0, "mem_use": 35.17, "gen_rate": 33.0, "speed": 10.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.6, "tree_w": 65, "tree_size": 256, "t0": 0.8143, "t1": 0.88, "tft": 2.5553, "input_0": 568, "input_1": 257, "min_CLP": -6.46, "draft_iters": 10.6, "mem_use": 35.71, "gen_rate": 5.0, "speed": 2.95, "text": "The ATF is a law enforcement age"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 42, "tree_size": 256, "t0": 1.64, "t1": 0.89, "tft": 2.5308, "input_0": 811, "input_1": 257, "min_CLP": -7.96, "draft_iters": 22.5, "mem_use": 35.17, "gen_rate": 23.0, "speed": 9.1, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 55, "tree_size": 256, "t0": 0.954, "t1": 0.884, "tft": 1.6498, "input_0": 663, "input_1": 257, "min_CLP": -6.26, "draft_iters": 12.6, "mem_use": 35.6, "gen_rate": 6.8, "speed": 3.7, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.4, "tree_w": 42, "tree_size": 256, "t0": 1.072, "t1": 0.882, "tft": 1.8535, "input_0": 618, "input_1": 257, "min_CLP": -6.26, "draft_iters": 14.4, "mem_use": 35.28, "gen_rate": 6.4, "speed": 3.27, "text": "Melbourne was the capital of the"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 64, "tree_h": 15.6, "tree_w": 61, "tree_size": 256, "t0": 1.2025, "t1": 0.8988, "tft": 1.8127, "input_0": 586, "input_1": 257, "min_CLP": -6.72, "draft_iters": 16.5, "mem_use": 35.46, "gen_rate": 8.0, "speed": 3.81, "text": "\"[INST] the eulogy should be fun"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.0, "tree_w": 63, "tree_size": 256, "t0": 0.862, "t1": 0.882, "tft": 4.2083, "input_0": 689, "input_1": 257, "min_CLP": -6.33, "draft_iters": 11.2, "mem_use": 37.68, "gen_rate": 6.6, "speed": 3.78, "text": "\"First, it's important to note t"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.0, "tree_w": 64, "tree_size": 256, "t0": 0.8486, "t1": 0.88, "tft": 2.3444, "input_0": 569, "input_1": 257, "min_CLP": -6.61, "draft_iters": 11.1, "mem_use": 35.28, "gen_rate": 4.7, "speed": 2.73, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 51, "tree_h": 24.5, "tree_w": 34, "tree_size": 256, "t0": 1.8325, "t1": 0.91, "tft": 3.1137, "input_0": 873, "input_1": 257, "min_CLP": -6.02, "draft_iters": 25.2, "mem_use": 36.58, "gen_rate": 12.8, "speed": 4.65, "text": "For a vector A = (2, 4, 6), the "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.4, "tree_w": 41, "tree_size": 256, "t0": 1.05, "t1": 0.874, "tft": 1.9671, "input_0": 803, "input_1": 257, "min_CLP": -6.58, "draft_iters": 13.6, "mem_use": 35.14, "gen_rate": 7.6, "speed": 3.95, "text": "The issues with using a symmetri"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.5, "tree_w": 63, "tree_size": 256, "t0": 1.46, "t1": 0.885, "tft": 1.5457, "input_0": 604, "input_1": 257, "min_CLP": -6.98, "draft_iters": 20.5, "mem_use": 35.19, "gen_rate": 19.5, "speed": 8.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 19.0, "tree_w": 39, "tree_size": 256, "t0": 1.4875, "t1": 0.89, "tft": 2.2187, "input_0": 881, "input_1": 257, "min_CLP": -6.13, "draft_iters": 20.0, "mem_use": 35.14, "gen_rate": 9.0, "speed": 3.79, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 13.0, "tree_w": 46, "tree_size": 256, "t0": 1.082, "t1": 0.888, "tft": 2.2343, "input_0": 682, "input_1": 257, "min_CLP": -6.15, "draft_iters": 14.4, "mem_use": 35.71, "gen_rate": 8.8, "speed": 4.47, "text": "The sum of squares error (SSE) a"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 24, "tree_h": 9.6, "tree_w": 70, "tree_size": 256, "t0": 0.798, "t1": 0.878, "tft": 2.1259, "input_0": 513, "input_1": 257, "min_CLP": -6.7, "draft_iters": 10.6, "mem_use": 36.03, "gen_rate": 4.8, "speed": 2.86, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 64, "tree_size": 256, "t0": 0.812, "t1": 0.882, "tft": 2.1255, "input_0": 638, "input_1": 257, "min_CLP": -6.69, "draft_iters": 10.6, "mem_use": 35.79, "gen_rate": 6.4, "speed": 3.78, "text": "The best place to see a starry s"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 8.6, "tree_w": 66, "tree_size": 256, "t0": 0.758, "t1": 0.872, "tft": 2.1525, "input_0": 557, "input_1": 257, "min_CLP": -6.91, "draft_iters": 9.9, "mem_use": 35.14, "gen_rate": 3.5, "speed": 2.15, "text": "1. Being crushed by a giant infl"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 9.8, "tree_w": 61, "tree_size": 256, "t0": 0.855, "t1": 0.8867, "tft": 2.6014, "input_0": 583, "input_1": 257, "min_CLP": -6.36, "draft_iters": 11.2, "mem_use": 35.69, "gen_rate": 5.3, "speed": 3.06, "text": "In that scenario, you would stil"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 9.0, "tree_w": 66, "tree_size": 256, "t0": 0.805, "t1": 0.8837, "tft": 2.0298, "input_0": 593, "input_1": 257, "min_CLP": -6.39, "draft_iters": 10.4, "mem_use": 35.56, "gen_rate": 4.5, "speed": 2.67, "text": "A few ways to cope with stress f"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 14.7, "tree_w": 42, "tree_size": 256, "t0": 1.155, "t1": 0.9083, "tft": 3.2593, "input_0": 758, "input_1": 257, "min_CLP": -6.12, "draft_iters": 15.7, "mem_use": 38.63, "gen_rate": 5.5, "speed": 2.66, "text": "Certainly! Here are some tools t"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 18.0, "tree_w": 32, "tree_size": 256, "t0": 1.4333, "t1": 0.9067, "tft": 3.211, "input_0": 850, "input_1": 257, "min_CLP": -5.87, "draft_iters": 19.3, "mem_use": 37.3, "gen_rate": 12.0, "speed": 5.12, "text": "Building your own PC can be a re"}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 49, "tree_size": 256, "t0": 1.0175, "t1": 0.8725, "tft": 1.64, "input_0": 764, "input_1": 257, "min_CLP": -6.09, "draft_iters": 13.2, "mem_use": 35.09, "gen_rate": 8.5, "speed": 4.49, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.6, "tree_w": 47, "tree_size": 256, "t0": 0.8957, "t1": 0.8843, "tft": 2.1121, "input_0": 658, "input_1": 257, "min_CLP": -7.28, "draft_iters": 11.6, "mem_use": 35.34, "gen_rate": 4.9, "speed": 2.73, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.8, "tree_w": 47, "tree_size": 256, "t0": 1.106, "t1": 0.938, "tft": 6.3929, "input_0": 844, "input_1": 257, "min_CLP": -6.26, "draft_iters": 14.2, "mem_use": 42.15, "gen_rate": 6.4, "speed": 3.14, "text": "Certainly! The `_physics_process"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 15.0, "tree_w": 50, "tree_size": 256, "t0": 1.206, "t1": 0.906, "tft": 2.547, "input_0": 654, "input_1": 257, "min_CLP": -6.24, "draft_iters": 16.2, "mem_use": 35.52, "gen_rate": 7.2, "speed": 3.41, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 17.5, "tree_w": 53, "tree_size": 256, "t0": 1.34, "t1": 0.895, "tft": 1.5352, "input_0": 697, "input_1": 257, "min_CLP": -6.9, "draft_iters": 18.5, "mem_use": 35.22, "gen_rate": 18.0, "speed": 8.06, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 12.5, "tree_w": 64, "tree_size": 256, "t0": 1.0433, "t1": 0.89, "tft": 1.6444, "input_0": 623, "input_1": 257, "min_CLP": -6.57, "draft_iters": 13.8, "mem_use": 35.22, "gen_rate": 6.3, "speed": 3.28, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.6, "tree_w": 63, "tree_size": 256, "t0": 0.7443, "t1": 0.8914, "tft": 2.6614, "input_0": 559, "input_1": 257, "min_CLP": -6.5, "draft_iters": 9.7, "mem_use": 37.76, "gen_rate": 4.9, "speed": 2.97, "text": "You are correct to question the "}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 16.3, "tree_w": 30, "tree_size": 256, "t0": 1.3133, "t1": 0.8867, "tft": 2.0136, "input_0": 886, "input_1": 257, "min_CLP": -5.8, "draft_iters": 17.3, "mem_use": 35.64, "gen_rate": 13.7, "speed": 6.21, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 13.0, "tree_w": 55, "tree_size": 256, "t0": 1.0657, "t1": 0.8843, "tft": 2.5212, "input_0": 643, "input_1": 257, "min_CLP": -6.68, "draft_iters": 14.3, "mem_use": 35.83, "gen_rate": 5.4, "speed": 2.78, "text": "[INST] What are the other types "}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 14.7, "tree_w": 43, "tree_size": 256, "t0": 1.185, "t1": 0.8967, "tft": 2.0002, "input_0": 684, "input_1": 257, "min_CLP": -6.08, "draft_iters": 15.8, "mem_use": 35.43, "gen_rate": 6.2, "speed": 2.97, "text": "Sure, I can help explain that to"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.2, "tree_w": 73, "tree_size": 256, "t0": 0.7238, "t1": 0.8812, "tft": 3.27, "input_0": 542, "input_1": 257, "min_CLP": -6.94, "draft_iters": 9.2, "mem_use": 35.67, "gen_rate": 4.6, "speed": 2.88, "text": "\"Attention bias, let's break it "}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 8.7, "tree_w": 71, "tree_size": 256, "t0": 0.7614, "t1": 0.8914, "tft": 1.9951, "input_0": 513, "input_1": 257, "min_CLP": -6.66, "draft_iters": 9.9, "mem_use": 35.46, "gen_rate": 6.1, "speed": 3.72, "text": "The experiment is a thought expe"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 15.5, "tree_w": 42, "tree_size": 256, "t0": 1.2267, "t1": 0.895, "tft": 2.7858, "input_0": 754, "input_1": 257, "min_CLP": -6.43, "draft_iters": 16.8, "mem_use": 37.44, "gen_rate": 6.5, "speed": 3.06, "text": "\"If you anticipate being very na"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 15.7, "tree_w": 37, "tree_size": 256, "t0": 1.275, "t1": 0.8833, "tft": 2.1204, "input_0": 793, "input_1": 257, "min_CLP": -6.04, "draft_iters": 17.0, "mem_use": 35.22, "gen_rate": 5.5, "speed": 2.55, "text": "\"Canberra is located in the Aust"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 9, "tree_h": 10.0, "tree_w": 66, "tree_size": 256, "t0": 0.835, "t1": 0.87, "tft": 1.6596, "input_0": 616, "input_1": 257, "min_CLP": -6.45, "draft_iters": 11.0, "mem_use": 35.24, "gen_rate": 4.5, "speed": 2.63, "text": "Of course, I can communicate in "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 10.1, "tree_w": 68, "tree_size": 256, "t0": 0.8633, "t1": 0.8789, "tft": 1.9598, "input_0": 539, "input_1": 257, "min_CLP": -6.65, "draft_iters": 11.4, "mem_use": 35.21, "gen_rate": 4.0, "speed": 2.29, "text": "F-centers, also known as Faraday"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 16.6, "tree_w": 40, "tree_size": 256, "t0": 1.34, "t1": 0.916, "tft": 4.7377, "input_0": 836, "input_1": 257, "min_CLP": -6.26, "draft_iters": 18.2, "mem_use": 39.74, "gen_rate": 6.8, "speed": 3.02, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.4, "tree_w": 49, "tree_size": 256, "t0": 1.126, "t1": 0.894, "tft": 3.5969, "input_0": 730, "input_1": 257, "min_CLP": -6.15, "draft_iters": 14.8, "mem_use": 36.85, "gen_rate": 7.0, "speed": 3.47, "text": "I apologize for the confusion. T"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.8, "tree_w": 55, "tree_size": 256, "t0": 0.9225, "t1": 0.8875, "tft": 3.0384, "input_0": 626, "input_1": 257, "min_CLP": -6.22, "draft_iters": 12.0, "mem_use": 35.64, "gen_rate": 9.0, "speed": 4.97, "text": "I think AI assistants will repla"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.0, "tree_w": 48, "tree_size": 256, "t0": 1.098, "t1": 0.896, "tft": 3.2454, "input_0": 758, "input_1": 257, "min_CLP": -6.44, "draft_iters": 14.6, "mem_use": 37.55, "gen_rate": 6.8, "speed": 3.41, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.6, "tree_w": 60, "tree_size": 256, "t0": 0.8262, "t1": 0.89, "tft": 2.811, "input_0": 629, "input_1": 257, "min_CLP": -6.88, "draft_iters": 10.8, "mem_use": 37.51, "gen_rate": 4.2, "speed": 2.47, "text": "In Deutschland wird pro Jahr etw"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.8, "tree_w": 61, "tree_size": 256, "t0": 0.9167, "t1": 0.89, "tft": 3.003, "input_0": 656, "input_1": 257, "min_CLP": -6.46, "draft_iters": 12.0, "mem_use": 36.85, "gen_rate": 5.5, "speed": 3.05, "text": "Im sorry, but as an AI language "}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.3, "tree_w": 60, "tree_size": 256, "t0": 0.8614, "t1": 0.88, "tft": 2.0658, "input_0": 581, "input_1": 257, "min_CLP": -6.45, "draft_iters": 11.4, "mem_use": 35.88, "gen_rate": 4.7, "speed": 2.71, "text": "\"If the owner's name is on the p"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.8, "tree_w": 44, "tree_size": 256, "t0": 1.4725, "t1": 0.9075, "tft": 1.7366, "input_0": 854, "input_1": 257, "min_CLP": -6.41, "draft_iters": 19.8, "mem_use": 35.47, "gen_rate": 8.2, "speed": 3.47, "text": "\u4f60\u53ef\u4ee5\u5728\u4ee5\u4e0b\u8ad6\u6587\u4e2d\u627e\u5230\u66f4\u591a\u7684\u8cc7\u8a0a\uff1a\\n1. Vaswani, A"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 30.5, "tree_w": 18, "tree_size": 256, "t0": 2.22, "t1": 0.91, "tft": 1.904, "input_0": 937, "input_1": 257, "min_CLP": -5.49, "draft_iters": 31.0, "mem_use": 35.28, "gen_rate": 16.0, "speed": 5.11, "text": "\"Sure! Here's an example functio"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 18.0, "tree_w": 41, "tree_size": 256, "t0": 1.4, "t1": 0.9, "tft": 3.1128, "input_0": 738, "input_1": 257, "min_CLP": -6.09, "draft_iters": 19.2, "mem_use": 36.57, "gen_rate": 6.8, "speed": 2.96, "text": "It is illegal to be naked in pub"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.1, "tree_w": 75, "tree_size": 256, "t0": 0.7171, "t1": 0.8814, "tft": 2.7143, "input_0": 519, "input_1": 257, "min_CLP": -6.64, "draft_iters": 9.3, "mem_use": 35.67, "gen_rate": 4.9, "speed": 3.04, "text": "\"You could handwrite the poem in"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.4, "tree_w": 62, "tree_size": 256, "t0": 0.9, "t1": 0.888, "tft": 2.4963, "input_0": 717, "input_1": 257, "min_CLP": -6.28, "draft_iters": 11.6, "mem_use": 36.56, "gen_rate": 6.6, "speed": 3.69, "text": "\"The optimal thickness of mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 17.6, "tree_w": 38, "tree_size": 256, "t0": 1.394, "t1": 0.896, "tft": 2.9793, "input_0": 786, "input_1": 257, "min_CLP": -6.14, "draft_iters": 18.8, "mem_use": 35.97, "gen_rate": 7.2, "speed": 3.14, "text": "If you live in a European countr"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.8, "tree_w": 61, "tree_size": 256, "t0": 1.104, "t1": 0.882, "tft": 2.9311, "input_0": 587, "input_1": 257, "min_CLP": -6.81, "draft_iters": 15.0, "mem_use": 35.2, "gen_rate": 6.4, "speed": 3.22, "text": "Sure, here is a list of nickname"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 15.4, "tree_w": 39, "tree_size": 256, "t0": 1.232, "t1": 0.892, "tft": 2.6874, "input_0": 730, "input_1": 257, "min_CLP": -6.42, "draft_iters": 16.4, "mem_use": 35.61, "gen_rate": 7.4, "speed": 3.49, "text": "\"Yes, the Balfour Declaration pl"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 49, "tree_h": 28.0, "tree_w": 20, "tree_size": 256, "t0": 2.135, "t1": 0.905, "tft": 3.2588, "input_0": 1245, "input_1": 257, "min_CLP": -6.05, "draft_iters": 29.0, "mem_use": 36.38, "gen_rate": 24.5, "speed": 8.05, "text": "\"Canciones Felices:\\n1. \u00ab(I Can'"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 3, "tree_h": 7.0, "tree_w": 92, "tree_size": 256, "t0": 0.61, "t1": 0.865, "tft": 2.0428, "input_0": 443, "input_1": 257, "min_CLP": -7.31, "draft_iters": 8.0, "mem_use": 35.3, "gen_rate": 1.5, "speed": 1.02, "text": "<|eor|>"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 31.5, "tree_w": 68, "tree_size": 256, "t0": 2.21, "t1": 0.925, "tft": 3.2433, "input_0": 557, "input_1": 257, "min_CLP": -6.72, "draft_iters": 32.0, "mem_use": 35.69, "gen_rate": 17.5, "speed": 5.59, "text": "````\\n````\\n\\n```markdown\\n# Thi"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.1, "tree_w": 68, "tree_size": 256, "t0": 0.93, "t1": 0.8857, "tft": 3.3217, "input_0": 569, "input_1": 257, "min_CLP": -6.72, "draft_iters": 12.4, "mem_use": 36.09, "gen_rate": 5.3, "speed": 2.91, "text": "How about, \"A wish from the hear"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.5, "tree_w": 49, "tree_size": 256, "t0": 1.0725, "t1": 0.885, "tft": 2.9832, "input_0": 781, "input_1": 257, "min_CLP": -6.32, "draft_iters": 14.0, "mem_use": 36.82, "gen_rate": 8.2, "speed": 4.21, "text": "To build a reinforcement learnin"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 13, "new_tokens": 34, "tree_h": 6.8, "tree_w": 128, "tree_size": 256, "t0": 0.6215, "t1": 0.88, "tft": 2.439, "input_0": 440, "input_1": 257, "min_CLP": -7.48, "draft_iters": 8.0, "mem_use": 35.31, "gen_rate": 2.6, "speed": 1.74, "text": "\"Frank-Walter Steinmeier (German"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.2, "tree_w": 53, "tree_size": 256, "t0": 0.95, "t1": 0.8767, "tft": 1.5496, "input_0": 678, "input_1": 257, "min_CLP": -6.42, "draft_iters": 12.3, "mem_use": 35.23, "gen_rate": 5.3, "speed": 2.92, "text": "The answer is:\\n\\nThe question s"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 50, "tree_size": 256, "t0": 0.958, "t1": 0.914, "tft": 3.6838, "input_0": 633, "input_1": 257, "min_CLP": -6.23, "draft_iters": 12.8, "mem_use": 39.33, "gen_rate": 6.4, "speed": 3.42, "text": "- Discovery: Identify a market n"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.0, "tree_w": 51, "tree_size": 256, "t0": 0.994, "t1": 0.878, "tft": 1.9627, "input_0": 660, "input_1": 257, "min_CLP": -6.18, "draft_iters": 13.0, "mem_use": 35.13, "gen_rate": 7.4, "speed": 3.96, "text": "Answer: The many-worlds interpre"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 12.2, "tree_w": 46, "tree_size": 256, "t0": 1.044, "t1": 0.874, "tft": 1.638, "input_0": 743, "input_1": 257, "min_CLP": -6.1, "draft_iters": 13.6, "mem_use": 35.09, "gen_rate": 8.4, "speed": 4.37, "text": "\"To build a PC, you'll need to f"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 13.0, "tree_w": 68, "tree_size": 256, "t0": 1.15, "t1": 0.91, "tft": 4.6448, "input_0": 793, "input_1": 257, "min_CLP": -6.76, "draft_iters": 15.0, "mem_use": 39.32, "gen_rate": 3.0, "speed": 1.46, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.7, "tree_w": 58, "tree_size": 256, "t0": 0.9983, "t1": 0.8917, "tft": 2.6226, "input_0": 748, "input_1": 257, "min_CLP": -6.26, "draft_iters": 13.0, "mem_use": 37.14, "gen_rate": 5.7, "speed": 3.0, "text": "\u2022 Keep practicing. The key to ma"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 63, "tree_size": 256, "t0": 0.966, "t1": 0.89, "tft": 2.1463, "input_0": 709, "input_1": 257, "min_CLP": -6.43, "draft_iters": 12.6, "mem_use": 36.41, "gen_rate": 7.0, "speed": 3.77, "text": "This is a good point, you are co"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.8, "tree_w": 44, "tree_size": 256, "t0": 1.132, "t1": 0.878, "tft": 1.9105, "input_0": 797, "input_1": 257, "min_CLP": -6.29, "draft_iters": 15.0, "mem_use": 35.28, "gen_rate": 7.0, "speed": 3.48, "text": "Sure, here is a list of some imp"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 13.0, "tree_w": 41, "tree_size": 256, "t0": 1.06, "t1": 0.8733, "tft": 2.3017, "input_0": 728, "input_1": 257, "min_CLP": -6.18, "draft_iters": 14.0, "mem_use": 35.29, "gen_rate": 12.0, "speed": 6.2, "text": "\"In the context of a turn-based "}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.7, "tree_w": 57, "tree_size": 256, "t0": 1.0267, "t1": 0.8833, "tft": 2.2809, "input_0": 609, "input_1": 257, "min_CLP": -6.53, "draft_iters": 13.8, "mem_use": 36.14, "gen_rate": 5.7, "speed": 2.97, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 21.5, "tree_w": 34, "tree_size": 256, "t0": 1.6375, "t1": 0.8925, "tft": 2.5038, "input_0": 912, "input_1": 257, "min_CLP": -5.97, "draft_iters": 22.5, "mem_use": 36.65, "gen_rate": 8.5, "speed": 3.36, "text": "\"Here's a simpler version of the"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 19, "tree_h": 10.7, "tree_w": 53, "tree_size": 256, "t0": 0.9367, "t1": 0.8767, "tft": 1.9352, "input_0": 829, "input_1": 257, "min_CLP": -6.49, "draft_iters": 12.0, "mem_use": 36.09, "gen_rate": 6.3, "speed": 3.49, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.3, "tree_w": 73, "tree_size": 256, "t0": 0.6614, "t1": 0.8729, "tft": 2.0087, "input_0": 509, "input_1": 257, "min_CLP": -6.73, "draft_iters": 8.6, "mem_use": 36.2, "gen_rate": 5.0, "speed": 3.25, "text": "\"In your eyes, I see the stars a"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 49, "tree_h": 21.2, "tree_w": 46, "tree_size": 256, "t0": 1.6, "t1": 0.91, "tft": 2.5011, "input_0": 686, "input_1": 257, "min_CLP": -6.38, "draft_iters": 22.2, "mem_use": 35.57, "gen_rate": 12.2, "speed": 4.88, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 10.7, "tree_w": 56, "tree_size": 256, "t0": 0.94, "t1": 0.8929, "tft": 3.1137, "input_0": 715, "input_1": 257, "min_CLP": -6.33, "draft_iters": 12.0, "mem_use": 35.53, "gen_rate": 5.7, "speed": 3.12, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.0, "tree_w": 54, "tree_size": 256, "t0": 0.9067, "t1": 0.89, "tft": 2.3425, "input_0": 619, "input_1": 257, "min_CLP": -6.32, "draft_iters": 12.0, "mem_use": 36.86, "gen_rate": 6.3, "speed": 3.52, "text": "\"You're welcome! If this fails, "}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 10.8, "tree_w": 54, "tree_size": 256, "t0": 0.935, "t1": 0.8812, "tft": 2.8213, "input_0": 716, "input_1": 257, "min_CLP": -6.29, "draft_iters": 12.2, "mem_use": 36.78, "gen_rate": 4.9, "speed": 2.68, "text": "Yes, Open Assistant is pre-train"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 16.6, "tree_w": 43, "tree_size": 256, "t0": 1.334, "t1": 0.904, "tft": 4.4739, "input_0": 908, "input_1": 257, "min_CLP": -6.18, "draft_iters": 18.0, "mem_use": 38.24, "gen_rate": 7.4, "speed": 3.31, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 28, "tree_h": 11.0, "tree_w": 60, "tree_size": 256, "t0": 0.9325, "t1": 0.875, "tft": 2.3357, "input_0": 703, "input_1": 257, "min_CLP": -6.53, "draft_iters": 12.0, "mem_use": 35.09, "gen_rate": 7.0, "speed": 3.87, "text": "The President of Germany is Fran"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 7.5, "tree_w": 75, "tree_size": 256, "t0": 0.6533, "t1": 0.875, "tft": 2.236, "input_0": 480, "input_1": 257, "min_CLP": -6.54, "draft_iters": 8.5, "mem_use": 36.04, "gen_rate": 5.5, "speed": 3.6, "text": "\"PostCSS is a tool that parses C"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 8.0, "tree_w": 58, "tree_size": 256, "t0": 0.72, "t1": 0.89, "tft": 2.8432, "input_0": 569, "input_1": 257, "min_CLP": -6.65, "draft_iters": 9.0, "mem_use": 37.9, "gen_rate": 1.0, "speed": 0.62, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.7, "tree_w": 61, "tree_size": 256, "t0": 0.9583, "t1": 0.8917, "tft": 2.451, "input_0": 583, "input_1": 257, "min_CLP": -6.62, "draft_iters": 12.7, "mem_use": 35.6, "gen_rate": 5.8, "speed": 3.15, "text": "- Introduction: Briefly explain "}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 256, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 14.2, "tree_w": 52, "tree_size": 256, "t0": 1.1825, "t1": 0.8875, "tft": 3.6088, "input_0": 772, "input_1": 257, "min_CLP": -6.22, "draft_iters": 15.8, "mem_use": 36.47, "gen_rate": 10.0, "speed": 4.83, "text": "\"I apologize for the misundersta"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 256, "max_branch_width": 32, "gen_rate": 8.88, "gen_rate_micro": 7.1, "gen_speed": 4.048, "gen_speed_micro": 3.652, "t0": 1.1711, "t1": 0.8913, "input_0": 704.8, "input_1": 257.0, "tree_size": 256.0, "tree_w": 53.5, "tree_h": 14.6, "prompt_len": 298.0, "min_CLP": -6.44, "mem_use": 44.5, "exp_time": 6702.91}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.1, "tree_w": 251, "tree_size": 512, "t0": 0.6075, "t1": 1.4075, "tft": 1.7964, "input_0": 1003, "input_1": 513, "min_CLP": -8.14, "draft_iters": 7.2, "mem_use": 36.6, "gen_rate": 4.5, "speed": 2.24, "text": "The Dyson Sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 236, "tree_size": 512, "t0": 0.7229, "t1": 1.4329, "tft": 2.4781, "input_0": 1067, "input_1": 513, "min_CLP": -8.77, "draft_iters": 8.9, "mem_use": 38.13, "gen_rate": 4.6, "speed": 2.12, "text": "You are correct, my apologies fo"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.1, "tree_w": 245, "tree_size": 512, "t0": 0.695, "t1": 1.4412, "tft": 2.5747, "input_0": 1079, "input_1": 513, "min_CLP": -8.51, "draft_iters": 8.5, "mem_use": 39.01, "gen_rate": 4.1, "speed": 1.93, "text": "\"1. Minecraft:\\n\\nFor streaming "}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 246, "tree_size": 512, "t0": 0.7314, "t1": 1.4157, "tft": 1.965, "input_0": 1036, "input_1": 513, "min_CLP": -10.53, "draft_iters": 9.0, "mem_use": 36.77, "gen_rate": 8.0, "speed": 3.73, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.3, "tree_w": 203, "tree_size": 512, "t0": 0.8983, "t1": 1.4167, "tft": 1.8126, "input_0": 1165, "input_1": 513, "min_CLP": -8.71, "draft_iters": 11.2, "mem_use": 36.62, "gen_rate": 5.8, "speed": 2.52, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 6.1, "tree_w": 250, "tree_size": 512, "t0": 0.6914, "t1": 1.4414, "tft": 2.6046, "input_0": 1131, "input_1": 513, "min_CLP": -11.12, "draft_iters": 8.3, "mem_use": 39.14, "gen_rate": 5.4, "speed": 2.54, "text": "Here\\'s a bullet point list for "}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 225, "tree_size": 512, "t0": 0.76, "t1": 1.4517, "tft": 2.9945, "input_0": 1351, "input_1": 513, "min_CLP": -9.02, "draft_iters": 9.0, "mem_use": 39.73, "gen_rate": 5.3, "speed": 2.41, "text": "There are a variety of other opt"}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.4, "tree_w": 239, "tree_size": 512, "t0": 0.7057, "t1": 1.4743, "tft": 4.1537, "input_0": 1140, "input_1": 513, "min_CLP": -8.53, "draft_iters": 8.6, "mem_use": 41.89, "gen_rate": 5.3, "speed": 2.43, "text": "\"Let's dive deeper into social m"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.8, "tree_w": 223, "tree_size": 512, "t0": 0.9267, "t1": 1.4367, "tft": 2.7817, "input_0": 1291, "input_1": 513, "min_CLP": -10.61, "draft_iters": 11.5, "mem_use": 39.34, "gen_rate": 5.5, "speed": 2.33, "text": "I apologize, but as an AI langua"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 7.1, "tree_w": 227, "tree_size": 512, "t0": 0.7814, "t1": 1.4329, "tft": 2.4261, "input_0": 1220, "input_1": 513, "min_CLP": -9.65, "draft_iters": 9.4, "mem_use": 38.72, "gen_rate": 5.7, "speed": 2.58, "text": "Choosing a beginner-friendly hob"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 282, "tree_size": 512, "t0": 0.4313, "t1": 1.4163, "tft": 2.0792, "input_0": 801, "input_1": 513, "min_CLP": -10.86, "draft_iters": 5.0, "mem_use": 37.26, "gen_rate": 4.0, "speed": 2.17, "text": "Here is your code:\\n``The first "}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 40, "tree_h": 7.6, "tree_w": 230, "tree_size": 512, "t0": 0.7811, "t1": 1.4422, "tft": 2.5842, "input_0": 1143, "input_1": 513, "min_CLP": -10.73, "draft_iters": 9.8, "mem_use": 39.09, "gen_rate": 4.4, "speed": 2.0, "text": "Here\\'s a slightly shorter versi"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.4, "tree_w": 201, "tree_size": 512, "t0": 1.138, "t1": 1.434, "tft": 2.6107, "input_0": 1561, "input_1": 513, "min_CLP": -8.65, "draft_iters": 14.0, "mem_use": 38.32, "gen_rate": 8.2, "speed": 3.19, "text": "Sure! Here are some Python examp"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 4.0, "tree_w": 334, "tree_size": 512, "t0": 0.43, "t1": 1.4, "tft": 1.8089, "input_0": 1227, "input_1": 513, "min_CLP": -9.06, "draft_iters": 5.0, "mem_use": 36.6, "gen_rate": 3.0, "speed": 1.64, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 8.6, "tree_w": 177, "tree_size": 512, "t0": 0.9171, "t1": 1.4457, "tft": 2.9907, "input_0": 1417, "input_1": 513, "min_CLP": -8.81, "draft_iters": 11.3, "mem_use": 39.7, "gen_rate": 5.6, "speed": 2.36, "text": "\"While it's true that spaced rep"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.4, "tree_w": 254, "tree_size": 512, "t0": 0.7157, "t1": 1.4143, "tft": 2.0035, "input_0": 1234, "input_1": 513, "min_CLP": -9.34, "draft_iters": 8.6, "mem_use": 36.93, "gen_rate": 4.9, "speed": 2.28, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 272, "tree_size": 512, "t0": 0.6667, "t1": 1.4067, "tft": 1.8058, "input_0": 1122, "input_1": 513, "min_CLP": -13.76, "draft_iters": 8.2, "mem_use": 36.62, "gen_rate": 5.3, "speed": 2.57, "text": "\"Sure, I'd be happy to explain F"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 62, "tree_h": 6.1, "tree_w": 271, "tree_size": 512, "t0": 0.6622, "t1": 1.4056, "tft": 1.8092, "input_0": 1025, "input_1": 513, "min_CLP": -9.7, "draft_iters": 8.0, "mem_use": 36.6, "gen_rate": 6.9, "speed": 3.33, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 45, "tree_h": 8.9, "tree_w": 179, "tree_size": 512, "t0": 0.9871, "t1": 1.4157, "tft": 2.0466, "input_0": 1427, "input_1": 513, "min_CLP": -7.74, "draft_iters": 11.7, "mem_use": 37.12, "gen_rate": 6.4, "speed": 2.68, "text": "D-theanine is the other form of "}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 7.6, "tree_w": 226, "tree_size": 512, "t0": 0.826, "t1": 1.408, "tft": 1.8137, "input_0": 1313, "input_1": 513, "min_CLP": -9.05, "draft_iters": 10.0, "mem_use": 36.61, "gen_rate": 6.4, "speed": 2.87, "text": "The Balfour Declaration is a sta"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 20, "tree_h": 3.0, "tree_w": 271, "tree_size": 512, "t0": 0.425, "t1": 1.4187, "tft": 2.2947, "input_0": 759, "input_1": 513, "min_CLP": -8.95, "draft_iters": 5.0, "mem_use": 37.45, "gen_rate": 2.5, "speed": 1.36, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 21, "tree_h": 8.8, "tree_w": 200, "tree_size": 512, "t0": 0.91, "t1": 1.415, "tft": 1.7989, "input_0": 1194, "input_1": 513, "min_CLP": -8.05, "draft_iters": 11.2, "mem_use": 36.6, "gen_rate": 5.2, "speed": 2.26, "text": "\"Hello there Obi-Wan Kenobi! I h"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 10.0, "tree_w": 171, "tree_size": 512, "t0": 1.038, "t1": 1.44, "tft": 2.5612, "input_0": 1494, "input_1": 513, "min_CLP": -8.85, "draft_iters": 12.8, "mem_use": 38.93, "gen_rate": 7.8, "speed": 3.14, "text": "If your dataset has an asymmetri"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.2, "tree_w": 272, "tree_size": 512, "t0": 0.525, "t1": 1.4062, "tft": 1.9425, "input_0": 918, "input_1": 513, "min_CLP": -9.63, "draft_iters": 6.2, "mem_use": 36.67, "gen_rate": 4.4, "speed": 2.26, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.2, "tree_w": 255, "tree_size": 512, "t0": 0.6188, "t1": 1.4187, "tft": 2.3229, "input_0": 975, "input_1": 513, "min_CLP": -8.85, "draft_iters": 7.5, "mem_use": 37.64, "gen_rate": 4.2, "speed": 2.09, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.8, "tree_w": 227, "tree_size": 512, "t0": 0.8975, "t1": 1.41, "tft": 1.8153, "input_0": 1075, "input_1": 513, "min_CLP": -8.95, "draft_iters": 11.5, "mem_use": 36.64, "gen_rate": 10.2, "speed": 4.44, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.3, "tree_w": 276, "tree_size": 512, "t0": 0.6057, "t1": 1.4157, "tft": 2.0773, "input_0": 1119, "input_1": 513, "min_CLP": -9.91, "draft_iters": 7.3, "mem_use": 37.29, "gen_rate": 4.7, "speed": 2.33, "text": "Austenite is an allotrope of iro"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 7.8, "tree_w": 208, "tree_size": 512, "t0": 0.836, "t1": 1.41, "tft": 2.0403, "input_0": 1199, "input_1": 513, "min_CLP": -8.14, "draft_iters": 10.2, "mem_use": 37.15, "gen_rate": 6.6, "speed": 2.94, "text": "\"You are welcome! I'm glad I cou"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 233, "tree_size": 512, "t0": 0.715, "t1": 1.44, "tft": 2.5856, "input_0": 1075, "input_1": 513, "min_CLP": -8.08, "draft_iters": 8.6, "mem_use": 39.07, "gen_rate": 4.2, "speed": 1.97, "text": "\"Verse 1:\\nIn the land of Tamrie"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 5.0, "tree_w": 264, "tree_size": 512, "t0": 0.625, "t1": 1.4025, "tft": 1.8209, "input_0": 1043, "input_1": 513, "min_CLP": -9.67, "draft_iters": 7.4, "mem_use": 36.65, "gen_rate": 4.8, "speed": 2.34, "text": "Sure! Here are some delicious op"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 8.0, "tree_w": 252, "tree_size": 512, "t0": 0.812, "t1": 1.42, "tft": 2.0939, "input_0": 1038, "input_1": 513, "min_CLP": -11.06, "draft_iters": 10.2, "mem_use": 37.33, "gen_rate": 8.8, "speed": 3.94, "text": "Yes, Into the Breach is a game o"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 5.1, "tree_w": 256, "tree_size": 512, "t0": 0.614, "t1": 1.423, "tft": 2.3646, "input_0": 941, "input_1": 513, "min_CLP": -9.3, "draft_iters": 7.4, "mem_use": 37.76, "gen_rate": 3.2, "speed": 1.57, "text": "[API_REQUEST]: {curl -X POST -H "}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.3, "tree_w": 245, "tree_size": 512, "t0": 0.6367, "t1": 1.4167, "tft": 2.0404, "input_0": 978, "input_1": 513, "min_CLP": -8.55, "draft_iters": 7.7, "mem_use": 37.09, "gen_rate": 3.9, "speed": 1.89, "text": "Freyja, goddess of love, fertili"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.1, "tree_w": 249, "tree_size": 512, "t0": 0.695, "t1": 1.4412, "tft": 2.4463, "input_0": 1067, "input_1": 513, "min_CLP": -8.82, "draft_iters": 8.5, "mem_use": 38.73, "gen_rate": 4.5, "speed": 2.11, "text": "\"Yes, there are several substitu"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.2, "tree_w": 150, "tree_size": 512, "t0": 1.18, "t1": 1.4325, "tft": 2.4487, "input_0": 1637, "input_1": 513, "min_CLP": -7.74, "draft_iters": 14.5, "mem_use": 38.77, "gen_rate": 9.0, "speed": 3.45, "text": "\"When choosing an ISP package, i"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.2, "tree_w": 158, "tree_size": 512, "t0": 1.212, "t1": 1.454, "tft": 3.9948, "input_0": 1515, "input_1": 513, "min_CLP": -7.74, "draft_iters": 15.4, "mem_use": 41.48, "gen_rate": 7.2, "speed": 2.7, "text": "Selenium can be a better choice "}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 235, "tree_size": 512, "t0": 0.7514, "t1": 1.41, "tft": 1.8234, "input_0": 1210, "input_1": 513, "min_CLP": -8.57, "draft_iters": 9.0, "mem_use": 36.63, "gen_rate": 4.6, "speed": 2.12, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 44, "tree_h": 9.2, "tree_w": 230, "tree_size": 512, "t0": 0.9144, "t1": 1.4156, "tft": 2.0491, "input_0": 1124, "input_1": 513, "min_CLP": -8.55, "draft_iters": 11.7, "mem_use": 37.15, "gen_rate": 4.9, "speed": 2.1, "text": "The second verse of Rick Astley\\"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.9, "tree_w": 277, "tree_size": 512, "t0": 0.5825, "t1": 1.4412, "tft": 2.7693, "input_0": 1166, "input_1": 513, "min_CLP": -9.13, "draft_iters": 7.0, "mem_use": 39.5, "gen_rate": 4.2, "speed": 2.1, "text": "Yes, I can certainly try to act "}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.0, "tree_w": 222, "tree_size": 512, "t0": 0.92, "t1": 1.424, "tft": 2.3217, "input_0": 1282, "input_1": 513, "min_CLP": -9.23, "draft_iters": 11.4, "mem_use": 37.57, "gen_rate": 8.2, "speed": 3.5, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 6.2, "tree_w": 245, "tree_size": 512, "t0": 0.681, "t1": 1.413, "tft": 1.9733, "input_0": 921, "input_1": 513, "min_CLP": -8.28, "draft_iters": 8.5, "mem_use": 36.85, "gen_rate": 3.5, "speed": 1.67, "text": "I am a goddess of love and beaut"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 159, "tree_size": 512, "t0": 1.4, "t1": 1.43, "tft": 2.7684, "input_0": 1242, "input_1": 513, "min_CLP": -9.65, "draft_iters": 18.5, "mem_use": 39.32, "gen_rate": 17.5, "speed": 6.19, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 6.7, "tree_w": 249, "tree_size": 512, "t0": 0.7043, "t1": 1.4429, "tft": 2.9937, "input_0": 1028, "input_1": 513, "min_CLP": -9.71, "draft_iters": 8.9, "mem_use": 39.76, "gen_rate": 6.3, "speed": 2.93, "text": "\"[INST] 1. Harry J. Anslinger, t"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.9, "tree_w": 229, "tree_size": 512, "t0": 0.7171, "t1": 1.4271, "tft": 2.48, "input_0": 1191, "input_1": 513, "min_CLP": -9.37, "draft_iters": 8.4, "mem_use": 38.12, "gen_rate": 5.1, "speed": 2.4, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 12, "tree_h": 3.3, "tree_w": 308, "tree_size": 512, "t0": 0.4333, "t1": 1.42, "tft": 2.105, "input_0": 941, "input_1": 513, "min_CLP": -10.93, "draft_iters": 5.0, "mem_use": 37.37, "gen_rate": 4.0, "speed": 2.16, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 46, "tree_h": 6.5, "tree_w": 257, "tree_size": 512, "t0": 0.6888, "t1": 1.4163, "tft": 2.022, "input_0": 948, "input_1": 513, "min_CLP": -9.39, "draft_iters": 8.5, "mem_use": 37.11, "gen_rate": 5.8, "speed": 2.74, "text": "O\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 12.8, "tree_w": 148, "tree_size": 512, "t0": 1.252, "t1": 1.416, "tft": 1.8154, "input_0": 1527, "input_1": 513, "min_CLP": -7.59, "draft_iters": 15.4, "mem_use": 36.63, "gen_rate": 8.4, "speed": 3.15, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 55, "tree_h": 6.9, "tree_w": 275, "tree_size": 512, "t0": 0.7057, "t1": 1.4671, "tft": 4.4365, "input_0": 1080, "input_1": 513, "min_CLP": -11.57, "draft_iters": 8.7, "mem_use": 42.05, "gen_rate": 7.9, "speed": 3.62, "text": "[The scene opens with a Spartan "}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.3, "tree_w": 248, "tree_size": 512, "t0": 0.5556, "t1": 1.4322, "tft": 2.6258, "input_0": 904, "input_1": 513, "min_CLP": -8.13, "draft_iters": 6.6, "mem_use": 38.36, "gen_rate": 3.8, "speed": 1.9, "text": "The truth, you ask? Well, let me"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 251, "tree_size": 512, "t0": 0.6571, "t1": 1.42, "tft": 2.1101, "input_0": 1007, "input_1": 513, "min_CLP": -8.75, "draft_iters": 7.9, "mem_use": 37.37, "gen_rate": 4.7, "speed": 2.27, "text": "Thank you for understanding and "}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 14, "tree_h": 3.2, "tree_w": 293, "tree_size": 512, "t0": 0.4325, "t1": 1.4125, "tft": 1.9818, "input_0": 910, "input_1": 513, "min_CLP": -9.17, "draft_iters": 5.0, "mem_use": 36.9, "gen_rate": 3.5, "speed": 1.9, "text": "CTR \u7684\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u4e00\u4e2a\u91cd\u8981\u7684\u4e3b\u9898\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.9, "tree_w": 276, "tree_size": 512, "t0": 0.7343, "t1": 1.4386, "tft": 2.4474, "input_0": 1095, "input_1": 513, "min_CLP": -9.71, "draft_iters": 9.0, "mem_use": 38.77, "gen_rate": 5.1, "speed": 2.37, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 4.5, "tree_w": 284, "tree_size": 512, "t0": 0.5662, "t1": 1.4287, "tft": 2.4487, "input_0": 982, "input_1": 513, "min_CLP": -10.82, "draft_iters": 6.6, "mem_use": 38.01, "gen_rate": 5.1, "speed": 2.57, "text": "\"Certainly! Here are some more h"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.6, "tree_w": 291, "tree_size": 512, "t0": 0.56, "t1": 1.4286, "tft": 2.6019, "input_0": 1077, "input_1": 513, "min_CLP": -8.66, "draft_iters": 6.6, "mem_use": 38.33, "gen_rate": 4.7, "speed": 2.37, "text": "Thank you for bringing up this i"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.7, "tree_w": 282, "tree_size": 512, "t0": 0.4967, "t1": 1.4111, "tft": 1.9626, "input_0": 859, "input_1": 513, "min_CLP": -8.32, "draft_iters": 5.8, "mem_use": 36.79, "gen_rate": 3.9, "speed": 2.04, "text": "In real life, people of all ages"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 250, "tree_size": 512, "t0": 0.6362, "t1": 1.4412, "tft": 2.7266, "input_0": 966, "input_1": 513, "min_CLP": -8.69, "draft_iters": 7.9, "mem_use": 39.17, "gen_rate": 4.1, "speed": 1.98, "text": "Title: FullView.io - Transformin"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.1, "tree_w": 246, "tree_size": 512, "t0": 0.6529, "t1": 1.4486, "tft": 3.652, "input_0": 1027, "input_1": 513, "min_CLP": -8.22, "draft_iters": 8.1, "mem_use": 40.42, "gen_rate": 5.0, "speed": 2.38, "text": "My apologies for the confusion, "}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.0, "tree_w": 186, "tree_size": 512, "t0": 0.99, "t1": 1.458, "tft": 3.6595, "input_0": 1438, "input_1": 513, "min_CLP": -8.66, "draft_iters": 12.2, "mem_use": 40.59, "gen_rate": 6.8, "speed": 2.78, "text": "As a beginner with little progra"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 184, "tree_size": 512, "t0": 1.42, "t1": 1.425, "tft": 2.6, "input_0": 1652, "input_1": 513, "min_CLP": -9.19, "draft_iters": 18.5, "mem_use": 38.27, "gen_rate": 17.5, "speed": 6.15, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.5, "tree_w": 240, "tree_size": 512, "t0": 0.7283, "t1": 1.405, "tft": 1.8155, "input_0": 1225, "input_1": 513, "min_CLP": -8.91, "draft_iters": 8.7, "mem_use": 36.62, "gen_rate": 5.7, "speed": 2.66, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.6, "tree_w": 252, "tree_size": 512, "t0": 0.7175, "t1": 1.4437, "tft": 2.5858, "input_0": 1018, "input_1": 513, "min_CLP": -9.94, "draft_iters": 8.9, "mem_use": 39.0, "gen_rate": 4.2, "speed": 1.97, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.8, "tree_w": 286, "tree_size": 512, "t0": 0.4625, "t1": 1.4437, "tft": 2.9097, "input_0": 875, "input_1": 513, "min_CLP": -8.69, "draft_iters": 5.6, "mem_use": 39.84, "gen_rate": 4.1, "speed": 2.16, "text": "[The general nods to his army, a"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.6, "tree_w": 240, "tree_size": 512, "t0": 0.8443, "t1": 1.4257, "tft": 2.3366, "input_0": 1057, "input_1": 513, "min_CLP": -8.85, "draft_iters": 10.7, "mem_use": 37.58, "gen_rate": 4.9, "speed": 2.14, "text": "Got it! How about this: \"A wish "}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 44, "tree_h": 6.5, "tree_w": 222, "tree_size": 512, "t0": 0.7325, "t1": 1.4175, "tft": 2.0761, "input_0": 1112, "input_1": 513, "min_CLP": -7.76, "draft_iters": 8.8, "mem_use": 37.28, "gen_rate": 5.5, "speed": 2.56, "text": "The proof-of-stake model is a co"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 5.3, "tree_w": 251, "tree_size": 512, "t0": 0.62, "t1": 1.4229, "tft": 2.2944, "input_0": 969, "input_1": 513, "min_CLP": -8.45, "draft_iters": 7.4, "mem_use": 37.42, "gen_rate": 5.7, "speed": 2.8, "text": "The world war II is not caused b"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 10.7, "tree_w": 152, "tree_size": 512, "t0": 1.1114, "t1": 1.4429, "tft": 2.7787, "input_0": 1533, "input_1": 513, "min_CLP": -7.5, "draft_iters": 13.7, "mem_use": 39.46, "gen_rate": 5.6, "speed": 2.18, "text": "A void pointer is a type of poin"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.1, "tree_w": 209, "tree_size": 512, "t0": 0.7775, "t1": 1.45, "tft": 2.9274, "input_0": 1158, "input_1": 513, "min_CLP": -7.98, "draft_iters": 9.5, "mem_use": 39.97, "gen_rate": 4.2, "speed": 1.91, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.7, "tree_w": 225, "tree_size": 512, "t0": 0.8867, "t1": 1.4367, "tft": 2.7341, "input_0": 1224, "input_1": 513, "min_CLP": -11.67, "draft_iters": 11.2, "mem_use": 39.18, "gen_rate": 6.0, "speed": 2.58, "text": "\"To implement two-factor authent"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 22, "tree_h": 3.3, "tree_w": 299, "tree_size": 512, "t0": 0.4283, "t1": 1.4133, "tft": 2.0262, "input_0": 939, "input_1": 513, "min_CLP": -9.79, "draft_iters": 5.0, "mem_use": 37.03, "gen_rate": 3.7, "speed": 1.99, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.3, "tree_w": 234, "tree_size": 512, "t0": 0.6517, "t1": 1.4083, "tft": 1.8061, "input_0": 1175, "input_1": 513, "min_CLP": -8.92, "draft_iters": 7.7, "mem_use": 36.62, "gen_rate": 5.3, "speed": 2.58, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.0, "tree_w": 252, "tree_size": 512, "t0": 0.92, "t1": 1.4425, "tft": 2.7811, "input_0": 1191, "input_1": 513, "min_CLP": -10.44, "draft_iters": 11.8, "mem_use": 39.41, "gen_rate": 10.2, "speed": 4.33, "text": "\"Certainly! Here's the updated t"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 218, "tree_size": 512, "t0": 0.7257, "t1": 1.4071, "tft": 1.7947, "input_0": 1133, "input_1": 513, "min_CLP": -8.4, "draft_iters": 8.7, "mem_use": 36.58, "gen_rate": 4.6, "speed": 2.14, "text": "The person responsible for makin"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 261, "tree_size": 512, "t0": 0.7433, "t1": 1.4417, "tft": 2.4546, "input_0": 1034, "input_1": 513, "min_CLP": -9.59, "draft_iters": 9.5, "mem_use": 38.88, "gen_rate": 8.7, "speed": 3.97, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 305, "tree_size": 512, "t0": 0.4637, "t1": 1.44, "tft": 2.4434, "input_0": 935, "input_1": 513, "min_CLP": -11.56, "draft_iters": 5.2, "mem_use": 38.74, "gen_rate": 4.2, "speed": 2.23, "text": "Certainly. Some critics of \"Fool"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 8.2, "tree_w": 222, "tree_size": 512, "t0": 0.874, "t1": 1.414, "tft": 1.8154, "input_0": 1308, "input_1": 513, "min_CLP": -8.26, "draft_iters": 10.6, "mem_use": 36.6, "gen_rate": 6.8, "speed": 2.98, "text": "The origins of pornography can b"}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 4.3, "tree_w": 252, "tree_size": 512, "t0": 0.5378, "t1": 1.4078, "tft": 1.9856, "input_0": 886, "input_1": 513, "min_CLP": -9.41, "draft_iters": 6.4, "mem_use": 36.9, "gen_rate": 3.7, "speed": 1.89, "text": "You can use this website to find"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.9, "tree_w": 268, "tree_size": 512, "t0": 0.5075, "t1": 1.4113, "tft": 1.983, "input_0": 1001, "input_1": 513, "min_CLP": -8.91, "draft_iters": 5.9, "mem_use": 36.98, "gen_rate": 4.4, "speed": 2.28, "text": "The 5 second rule is a myth. Bac"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.8, "tree_w": 245, "tree_size": 512, "t0": 0.924, "t1": 1.41, "tft": 1.942, "input_0": 1385, "input_1": 513, "min_CLP": -10.21, "draft_iters": 11.2, "mem_use": 36.71, "gen_rate": 6.6, "speed": 2.83, "text": "To determine the number of eggs "}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.2, "tree_w": 205, "tree_size": 512, "t0": 1.178, "t1": 1.424, "tft": 2.2097, "input_0": 1541, "input_1": 513, "min_CLP": -9.4, "draft_iters": 14.4, "mem_use": 37.47, "gen_rate": 7.6, "speed": 2.92, "text": "\"Sure, I'd be happy to explain s"}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.6, "tree_w": 261, "tree_size": 512, "t0": 0.5771, "t1": 1.4086, "tft": 2.026, "input_0": 1020, "input_1": 513, "min_CLP": -9.21, "draft_iters": 6.7, "mem_use": 37.02, "gen_rate": 4.7, "speed": 2.37, "text": "\"You're welcome! I hope you were"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 5.2, "tree_w": 250, "tree_size": 512, "t0": 0.619, "t1": 1.409, "tft": 1.9396, "input_0": 916, "input_1": 513, "min_CLP": -8.51, "draft_iters": 7.4, "mem_use": 36.74, "gen_rate": 3.4, "speed": 1.68, "text": "\"#OpenAssistant is here and it's"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 6.4, "tree_w": 214, "tree_size": 512, "t0": 0.7343, "t1": 1.4171, "tft": 2.0925, "input_0": 1048, "input_1": 513, "min_CLP": -9.23, "draft_iters": 8.9, "mem_use": 37.34, "gen_rate": 5.1, "speed": 2.39, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 6.3, "tree_w": 229, "tree_size": 512, "t0": 0.735, "t1": 1.4317, "tft": 3.4755, "input_0": 1179, "input_1": 513, "min_CLP": -9.25, "draft_iters": 8.7, "mem_use": 38.39, "gen_rate": 6.0, "speed": 2.77, "text": "\"Sure, here are some ways AI ass"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 7.7, "tree_w": 246, "tree_size": 512, "t0": 0.7611, "t1": 1.4378, "tft": 2.7815, "input_0": 952, "input_1": 513, "min_CLP": -9.24, "draft_iters": 9.8, "mem_use": 39.38, "gen_rate": 3.6, "speed": 1.62, "text": "[Verse 1]\\nSteve sits diligently"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.3, "tree_w": 253, "tree_size": 512, "t0": 0.6929, "t1": 1.4229, "tft": 2.4342, "input_0": 1122, "input_1": 513, "min_CLP": -8.6, "draft_iters": 8.4, "mem_use": 37.91, "gen_rate": 4.7, "speed": 2.23, "text": "The scp command is specific to U"}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 274, "tree_size": 512, "t0": 0.4587, "t1": 1.4312, "tft": 2.6849, "input_0": 905, "input_1": 513, "min_CLP": -10.35, "draft_iters": 5.2, "mem_use": 38.54, "gen_rate": 4.2, "speed": 2.25, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.1, "tree_w": 290, "tree_size": 512, "t0": 0.4267, "t1": 1.4078, "tft": 1.8173, "input_0": 849, "input_1": 513, "min_CLP": -9.32, "draft_iters": 5.0, "mem_use": 36.65, "gen_rate": 3.6, "speed": 1.94, "text": "Yes, it would be illegal to keep"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 45, "tree_h": 6.9, "tree_w": 242, "tree_size": 512, "t0": 0.7671, "t1": 1.4129, "tft": 1.997, "input_0": 1141, "input_1": 513, "min_CLP": -9.07, "draft_iters": 9.1, "mem_use": 36.93, "gen_rate": 6.4, "speed": 2.95, "text": "\"Sydney is the largest city in A"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 8.2, "tree_w": 233, "tree_size": 512, "t0": 0.842, "t1": 1.418, "tft": 2.2403, "input_0": 985, "input_1": 513, "min_CLP": -8.65, "draft_iters": 10.4, "mem_use": 37.23, "gen_rate": 9.2, "speed": 4.07, "text": "\"5 second rule is a game where s"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 9, "tree_h": 3.0, "tree_w": 272, "tree_size": 512, "t0": 0.42, "t1": 1.41, "tft": 1.9934, "input_0": 796, "input_1": 513, "min_CLP": -8.37, "draft_iters": 5.0, "mem_use": 36.9, "gen_rate": 3.0, "speed": 1.63, "text": "\"Oh, you're welcome. I'm glad yo"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 62, "tree_h": 6.1, "tree_w": 254, "tree_size": 512, "t0": 0.6456, "t1": 1.4111, "tft": 1.9322, "input_0": 977, "input_1": 513, "min_CLP": -9.04, "draft_iters": 8.0, "mem_use": 36.68, "gen_rate": 6.9, "speed": 3.35, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.6, "tree_w": 164, "tree_size": 512, "t0": 1.136, "t1": 1.41, "tft": 1.9276, "input_0": 1404, "input_1": 513, "min_CLP": -7.54, "draft_iters": 14.2, "mem_use": 36.66, "gen_rate": 7.2, "speed": 2.83, "text": "\"The answer is: To walk around t"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 7.1, "tree_w": 274, "tree_size": 512, "t0": 0.7529, "t1": 1.43, "tft": 2.6264, "input_0": 1218, "input_1": 513, "min_CLP": -12.9, "draft_iters": 9.1, "mem_use": 38.38, "gen_rate": 5.9, "speed": 2.68, "text": "\"The solution to the Taniyama\u2013Sh"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 60, "tree_h": 6.5, "tree_w": 265, "tree_size": 512, "t0": 0.7, "t1": 1.41, "tft": 1.946, "input_0": 1072, "input_1": 513, "min_CLP": -10.9, "draft_iters": 8.5, "mem_use": 36.66, "gen_rate": 7.5, "speed": 3.55, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.6, "tree_w": 276, "tree_size": 512, "t0": 0.6286, "t1": 1.4157, "tft": 1.9971, "input_0": 925, "input_1": 513, "min_CLP": -9.73, "draft_iters": 7.7, "mem_use": 36.96, "gen_rate": 5.0, "speed": 2.45, "text": "\"In Godot Engine 3.x, you can wr"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 14.5, "tree_w": 89, "tree_size": 512, "t0": 1.4575, "t1": 1.415, "tft": 1.8159, "input_0": 1806, "input_1": 513, "min_CLP": -6.97, "draft_iters": 17.8, "mem_use": 36.63, "gen_rate": 9.0, "speed": 3.13, "text": "To start learning guitar and bec"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.9, "tree_w": 273, "tree_size": 512, "t0": 0.5212, "t1": 1.4138, "tft": 2.0017, "input_0": 979, "input_1": 513, "min_CLP": -9.21, "draft_iters": 6.0, "mem_use": 36.93, "gen_rate": 4.1, "speed": 2.13, "text": "Becoming one with the Force is a"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.4, "tree_w": 248, "tree_size": 512, "t0": 0.6325, "t1": 1.4163, "tft": 1.9668, "input_0": 1007, "input_1": 513, "min_CLP": -8.27, "draft_iters": 7.5, "mem_use": 36.79, "gen_rate": 4.1, "speed": 2.01, "text": "A gas-operated rifle uses the pr"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.8, "tree_w": 220, "tree_size": 512, "t0": 0.7583, "t1": 1.415, "tft": 2.0218, "input_0": 1192, "input_1": 513, "min_CLP": -8.98, "draft_iters": 9.2, "mem_use": 37.03, "gen_rate": 5.7, "speed": 2.61, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 38, "tree_h": 4.0, "tree_w": 279, "tree_size": 512, "t0": 0.5178, "t1": 1.45, "tft": 2.9947, "input_0": 905, "input_1": 513, "min_CLP": -10.11, "draft_iters": 6.1, "mem_use": 39.86, "gen_rate": 4.2, "speed": 2.14, "text": "Yes, there are several libraries"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.8, "tree_w": 219, "tree_size": 512, "t0": 0.68, "t1": 1.4125, "tft": 2.0336, "input_0": 1052, "input_1": 513, "min_CLP": -8.66, "draft_iters": 8.1, "mem_use": 37.09, "gen_rate": 4.5, "speed": 2.15, "text": "\"Yes, it's reasonable to expect "}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 7, "tree_h": 3.0, "tree_w": 306, "tree_size": 512, "t0": 0.4033, "t1": 1.4533, "tft": 2.9279, "input_0": 822, "input_1": 513, "min_CLP": -9.8, "draft_iters": 4.7, "mem_use": 39.96, "gen_rate": 2.3, "speed": 1.26, "text": "Xin ch\u00e0o! How can I help you tod"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.8, "tree_w": 238, "tree_size": 512, "t0": 0.845, "t1": 1.425, "tft": 2.3028, "input_0": 1237, "input_1": 513, "min_CLP": -8.24, "draft_iters": 10.3, "mem_use": 37.48, "gen_rate": 5.8, "speed": 2.57, "text": "\"It's interesting to know that t"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.8, "tree_w": 234, "tree_size": 512, "t0": 0.9167, "t1": 1.4167, "tft": 2.0049, "input_0": 1263, "input_1": 513, "min_CLP": -9.11, "draft_iters": 11.3, "mem_use": 36.98, "gen_rate": 5.8, "speed": 2.5, "text": "Sure! Here\\'s a more detailed ex"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 33, "tree_h": 6.5, "tree_w": 238, "tree_size": 512, "t0": 0.7373, "t1": 1.4355, "tft": 2.6409, "input_0": 980, "input_1": 513, "min_CLP": -9.19, "draft_iters": 9.1, "mem_use": 38.41, "gen_rate": 3.0, "speed": 1.38, "text": "1. Rammstein\\n2. Scorpions\\n3. D"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.2, "tree_w": 233, "tree_size": 512, "t0": 0.6363, "t1": 1.41, "tft": 1.992, "input_0": 959, "input_1": 513, "min_CLP": -8.52, "draft_iters": 7.6, "mem_use": 36.94, "gen_rate": 4.5, "speed": 2.2, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 7.0, "tree_w": 229, "tree_size": 512, "t0": 0.7817, "t1": 1.44, "tft": 2.5661, "input_0": 1141, "input_1": 513, "min_CLP": -8.79, "draft_iters": 9.5, "mem_use": 38.93, "gen_rate": 6.5, "speed": 2.92, "text": "To acquire revenue from customer"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.0, "tree_w": 264, "tree_size": 512, "t0": 0.5288, "t1": 1.4225, "tft": 2.3281, "input_0": 977, "input_1": 513, "min_CLP": -8.9, "draft_iters": 6.1, "mem_use": 37.58, "gen_rate": 4.1, "speed": 2.11, "text": "Yes, I can certainly simulate va"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 7.0, "tree_w": 234, "tree_size": 512, "t0": 0.76, "t1": 1.418, "tft": 2.0449, "input_0": 1078, "input_1": 513, "min_CLP": -8.37, "draft_iters": 9.2, "mem_use": 37.1, "gen_rate": 6.8, "speed": 3.12, "text": "Sure, I can help with that. Here"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 7.7, "tree_w": 209, "tree_size": 512, "t0": 0.8629, "t1": 1.4143, "tft": 2.0735, "input_0": 1323, "input_1": 513, "min_CLP": -8.79, "draft_iters": 10.3, "mem_use": 37.24, "gen_rate": 5.3, "speed": 2.32, "text": "There are a lot of APIs, librari"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.8, "tree_w": 264, "tree_size": 512, "t0": 0.865, "t1": 1.435, "tft": 2.6554, "input_0": 1130, "input_1": 513, "min_CLP": -8.93, "draft_iters": 10.5, "mem_use": 38.51, "gen_rate": 5.3, "speed": 2.32, "text": "\"Certainly! Here's a poem in the"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.7, "tree_w": 251, "tree_size": 512, "t0": 0.68, "t1": 1.41, "tft": 1.8053, "input_0": 1038, "input_1": 513, "min_CLP": -9.03, "draft_iters": 8.2, "mem_use": 36.63, "gen_rate": 5.3, "speed": 2.55, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 181, "tree_size": 512, "t0": 0.96, "t1": 1.41, "tft": 1.9478, "input_0": 1321, "input_1": 513, "min_CLP": -7.71, "draft_iters": 11.8, "mem_use": 36.67, "gen_rate": 6.4, "speed": 2.7, "text": "The error in this code is a miss"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 3.0, "tree_w": 302, "tree_size": 512, "t0": 0.42, "t1": 1.42, "tft": 2.4576, "input_0": 819, "input_1": 513, "min_CLP": -8.41, "draft_iters": 5.0, "mem_use": 38.05, "gen_rate": 0.0, "speed": 0.0, "text": "None"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.9, "tree_w": 223, "tree_size": 512, "t0": 0.7586, "t1": 1.4186, "tft": 2.0772, "input_0": 1081, "input_1": 513, "min_CLP": -8.56, "draft_iters": 9.3, "mem_use": 37.26, "gen_rate": 4.6, "speed": 2.1, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 303, "tree_size": 512, "t0": 0.44, "t1": 1.4175, "tft": 2.1, "input_0": 872, "input_1": 513, "min_CLP": -9.3, "draft_iters": 5.1, "mem_use": 37.41, "gen_rate": 4.1, "speed": 2.22, "text": "\"To create a Python program that"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 212, "tree_size": 512, "t0": 0.7867, "t1": 1.4417, "tft": 2.7369, "input_0": 1242, "input_1": 513, "min_CLP": -9.81, "draft_iters": 9.5, "mem_use": 39.15, "gen_rate": 5.3, "speed": 2.4, "text": "\"As an AI language model, I cann"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.7, "tree_w": 214, "tree_size": 512, "t0": 1.1067, "t1": 1.41, "tft": 2.0635, "input_0": 1274, "input_1": 513, "min_CLP": -9.3, "draft_iters": 14.0, "mem_use": 37.18, "gen_rate": 12.3, "speed": 4.9, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.6, "tree_w": 293, "tree_size": 512, "t0": 0.4771, "t1": 1.4329, "tft": 2.6847, "input_0": 1049, "input_1": 513, "min_CLP": -13.2, "draft_iters": 5.4, "mem_use": 38.53, "gen_rate": 4.6, "speed": 2.39, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 4.2, "tree_w": 270, "tree_size": 512, "t0": 0.541, "t1": 1.409, "tft": 1.804, "input_0": 925, "input_1": 513, "min_CLP": -8.59, "draft_iters": 6.4, "mem_use": 36.61, "gen_rate": 3.5, "speed": 1.8, "text": "Yes, I can simulate thinking and"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 28, "tree_h": 3.0, "tree_w": 272, "tree_size": 512, "t0": 0.4275, "t1": 1.4075, "tft": 1.958, "input_0": 792, "input_1": 513, "min_CLP": -9.06, "draft_iters": 5.0, "mem_use": 36.83, "gen_rate": 3.5, "speed": 1.91, "text": "In the realm of deep learning,\\n"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.5, "tree_w": 217, "tree_size": 512, "t0": 0.7733, "t1": 1.41, "tft": 2.0204, "input_0": 1233, "input_1": 513, "min_CLP": -7.9, "draft_iters": 9.2, "mem_use": 37.07, "gen_rate": 5.3, "speed": 2.44, "text": "\"Thanks for the compliment! I'm "}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.9, "tree_w": 265, "tree_size": 512, "t0": 0.5737, "t1": 1.435, "tft": 3.6029, "input_0": 927, "input_1": 513, "min_CLP": -8.55, "draft_iters": 6.9, "mem_use": 38.66, "gen_rate": 4.6, "speed": 2.3, "text": "\"Thou art the sun that doth shin"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 7.1, "tree_w": 209, "tree_size": 512, "t0": 0.8029, "t1": 1.42, "tft": 2.0599, "input_0": 1220, "input_1": 513, "min_CLP": -8.96, "draft_iters": 9.4, "mem_use": 37.24, "gen_rate": 6.1, "speed": 2.77, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 10, "tree_h": 3.2, "tree_w": 274, "tree_size": 512, "t0": 0.4625, "t1": 1.4125, "tft": 1.9382, "input_0": 879, "input_1": 513, "min_CLP": -8.49, "draft_iters": 5.2, "mem_use": 36.65, "gen_rate": 2.5, "speed": 1.34, "text": "[INST] Write a short story using"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.8, "tree_w": 130, "tree_size": 512, "t0": 1.236, "t1": 1.414, "tft": 1.8085, "input_0": 1544, "input_1": 513, "min_CLP": -7.63, "draft_iters": 15.2, "mem_use": 36.63, "gen_rate": 7.0, "speed": 2.64, "text": "\"Sure! Presidents' Day, also kno"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 7.3, "tree_w": 250, "tree_size": 512, "t0": 0.775, "t1": 1.415, "tft": 2.0046, "input_0": 1157, "input_1": 513, "min_CLP": -11.03, "draft_iters": 9.5, "mem_use": 36.93, "gen_rate": 8.3, "speed": 3.81, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 4.1, "tree_w": 280, "tree_size": 512, "t0": 0.5325, "t1": 1.4212, "tft": 2.3556, "input_0": 978, "input_1": 513, "min_CLP": -12.59, "draft_iters": 6.2, "mem_use": 37.74, "gen_rate": 4.8, "speed": 2.43, "text": "No, the US National Reconnaissan"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.7, "tree_w": 267, "tree_size": 512, "t0": 0.4822, "t1": 1.4144, "tft": 2.0045, "input_0": 884, "input_1": 513, "min_CLP": -8.56, "draft_iters": 5.7, "mem_use": 37.0, "gen_rate": 3.9, "speed": 2.05, "text": "\"Why did the broke college stude"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 5.0, "tree_w": 242, "tree_size": 512, "t0": 0.6125, "t1": 1.41, "tft": 2.0276, "input_0": 1022, "input_1": 513, "min_CLP": -8.37, "draft_iters": 7.2, "mem_use": 37.07, "gen_rate": 4.6, "speed": 2.28, "text": "\"That's fine, I'm happy to be kn"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.2, "tree_w": 272, "tree_size": 512, "t0": 0.615, "t1": 1.4083, "tft": 1.8162, "input_0": 1003, "input_1": 513, "min_CLP": -8.38, "draft_iters": 7.3, "mem_use": 36.63, "gen_rate": 5.3, "speed": 2.64, "text": "Yes, the ATF can be considered a"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.6, "tree_w": 259, "tree_size": 512, "t0": 0.4856, "t1": 1.42, "tft": 2.1017, "input_0": 839, "input_1": 513, "min_CLP": -9.83, "draft_iters": 5.7, "mem_use": 37.31, "gen_rate": 3.6, "speed": 1.87, "text": "\"Like, Ted Kaczynski was a real "}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 8.6, "tree_w": 216, "tree_size": 512, "t0": 0.9025, "t1": 1.41, "tft": 1.9458, "input_0": 1301, "input_1": 513, "min_CLP": -8.44, "draft_iters": 11.0, "mem_use": 36.75, "gen_rate": 4.0, "speed": 1.73, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.8, "tree_w": 252, "tree_size": 512, "t0": 0.6013, "t1": 1.4262, "tft": 2.4455, "input_0": 904, "input_1": 513, "min_CLP": -8.72, "draft_iters": 7.1, "mem_use": 37.97, "gen_rate": 4.0, "speed": 1.97, "text": "Sure, there are many medias that"}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.8, "tree_w": 214, "tree_size": 512, "t0": 0.7017, "t1": 1.4133, "tft": 2.0339, "input_0": 1029, "input_1": 513, "min_CLP": -8.05, "draft_iters": 8.3, "mem_use": 37.07, "gen_rate": 5.5, "speed": 2.6, "text": "I have no intention of taking ov"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 5.7, "tree_w": 273, "tree_size": 512, "t0": 0.6278, "t1": 1.4344, "tft": 2.5984, "input_0": 900, "input_1": 513, "min_CLP": -9.23, "draft_iters": 7.8, "mem_use": 38.27, "gen_rate": 3.8, "speed": 1.83, "text": "I would recommend the Emerald La"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.1, "tree_w": 264, "tree_size": 512, "t0": 0.525, "t1": 1.4125, "tft": 2.0284, "input_0": 911, "input_1": 513, "min_CLP": -9.76, "draft_iters": 6.2, "mem_use": 37.02, "gen_rate": 4.2, "speed": 2.19, "text": "\"Open Assistant: Get ready to di"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.9, "tree_w": 242, "tree_size": 512, "t0": 0.6867, "t1": 1.4144, "tft": 1.9937, "input_0": 1108, "input_1": 513, "min_CLP": -8.25, "draft_iters": 8.2, "mem_use": 36.92, "gen_rate": 4.1, "speed": 1.96, "text": "Sure, I can illustrate the solut"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 144, "tree_size": 512, "t0": 1.2175, "t1": 1.44, "tft": 2.7596, "input_0": 1595, "input_1": 513, "min_CLP": -8.0, "draft_iters": 15.2, "mem_use": 39.23, "gen_rate": 8.2, "speed": 3.1, "text": "\"The issue you're experiencing i"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 4.9, "tree_w": 256, "tree_size": 512, "t0": 0.6014, "t1": 1.4114, "tft": 1.8095, "input_0": 1005, "input_1": 513, "min_CLP": -8.38, "draft_iters": 7.1, "mem_use": 36.62, "gen_rate": 5.6, "speed": 2.77, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 17.0, "tree_w": 207, "tree_size": 512, "t0": 1.435, "t1": 1.42, "tft": 2.045, "input_0": 1308, "input_1": 513, "min_CLP": -8.18, "draft_iters": 19.0, "mem_use": 37.15, "gen_rate": 18.0, "speed": 6.3, "text": "Pirating video games is probably"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 5.0, "tree_w": 260, "tree_size": 512, "t0": 0.625, "t1": 1.415, "tft": 1.9687, "input_0": 1024, "input_1": 513, "min_CLP": -8.5, "draft_iters": 7.3, "mem_use": 36.79, "gen_rate": 5.3, "speed": 2.61, "text": "This is important because the te"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 13, "tree_h": 8.5, "tree_w": 255, "tree_size": 512, "t0": 0.8275, "t1": 1.4175, "tft": 1.8193, "input_0": 989, "input_1": 513, "min_CLP": -10.6, "draft_iters": 10.8, "mem_use": 36.63, "gen_rate": 3.2, "speed": 1.45, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.7, "tree_w": 205, "tree_size": 512, "t0": 0.8017, "t1": 1.4383, "tft": 2.7321, "input_0": 1238, "input_1": 513, "min_CLP": -8.54, "draft_iters": 9.5, "mem_use": 38.69, "gen_rate": 5.3, "speed": 2.38, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.5, "tree_w": 169, "tree_size": 512, "t0": 1.075, "t1": 1.4133, "tft": 1.8045, "input_0": 1438, "input_1": 513, "min_CLP": -8.32, "draft_iters": 13.3, "mem_use": 36.6, "gen_rate": 5.8, "speed": 2.34, "text": "\"The task is asking to determine"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.2, "tree_w": 274, "tree_size": 512, "t0": 0.4344, "t1": 1.4089, "tft": 1.9486, "input_0": 872, "input_1": 513, "min_CLP": -9.67, "draft_iters": 5.1, "mem_use": 36.68, "gen_rate": 3.7, "speed": 1.99, "text": "The third verse of Rick Astley\\'"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.6, "tree_w": 265, "tree_size": 512, "t0": 0.675, "t1": 1.45, "tft": 2.9289, "input_0": 1101, "input_1": 513, "min_CLP": -10.01, "draft_iters": 8.1, "mem_use": 39.92, "gen_rate": 4.5, "speed": 2.11, "text": "As of my knowledge cutoff in 202"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.0, "tree_w": 241, "tree_size": 512, "t0": 0.6814, "t1": 1.43, "tft": 2.4467, "input_0": 992, "input_1": 513, "min_CLP": -8.41, "draft_iters": 8.3, "mem_use": 37.94, "gen_rate": 4.6, "speed": 2.17, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.5, "tree_w": 133, "tree_size": 512, "t0": 1.3775, "t1": 1.4175, "tft": 1.9973, "input_0": 1622, "input_1": 513, "min_CLP": -7.49, "draft_iters": 17.2, "mem_use": 36.88, "gen_rate": 8.2, "speed": 2.95, "text": "Certainly! Here are some resourc"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.4, "tree_w": 245, "tree_size": 512, "t0": 0.7112, "t1": 1.4212, "tft": 1.9771, "input_0": 983, "input_1": 513, "min_CLP": -9.83, "draft_iters": 8.6, "mem_use": 36.86, "gen_rate": 4.6, "speed": 2.17, "text": "def most_effective_tax_fraud_met"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.8, "tree_w": 102, "tree_size": 512, "t0": 1.385, "t1": 1.4125, "tft": 1.8202, "input_0": 1920, "input_1": 513, "min_CLP": -7.16, "draft_iters": 16.8, "mem_use": 36.63, "gen_rate": 8.2, "speed": 2.95, "text": "The theory of sexual selection, "}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 27, "tree_h": 4.4, "tree_w": 275, "tree_size": 512, "t0": 0.5411, "t1": 1.42, "tft": 2.2995, "input_0": 822, "input_1": 513, "min_CLP": -8.44, "draft_iters": 6.6, "mem_use": 37.45, "gen_rate": 3.0, "speed": 1.53, "text": "Sure, I can do that. Please prov"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 7.5, "tree_w": 252, "tree_size": 512, "t0": 0.8267, "t1": 1.42, "tft": 2.3007, "input_0": 1338, "input_1": 513, "min_CLP": -10.35, "draft_iters": 9.8, "mem_use": 37.47, "gen_rate": 8.3, "speed": 3.71, "text": "\"Claro, aqu\u00ed tienes una lista re"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 9.4, "tree_w": 196, "tree_size": 512, "t0": 0.932, "t1": 1.454, "tft": 2.9151, "input_0": 1137, "input_1": 513, "min_CLP": -8.51, "draft_iters": 11.8, "mem_use": 39.94, "gen_rate": 8.6, "speed": 3.6, "text": "\"Sure, here's a shorter version:"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 56, "tree_h": 7.0, "tree_w": 251, "tree_size": 512, "t0": 0.7443, "t1": 1.4143, "tft": 1.8177, "input_0": 1063, "input_1": 513, "min_CLP": -11.12, "draft_iters": 9.0, "mem_use": 36.64, "gen_rate": 8.0, "speed": 3.71, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 24, "tree_h": 4.8, "tree_w": 249, "tree_size": 512, "t0": 0.6038, "t1": 1.4175, "tft": 2.0725, "input_0": 986, "input_1": 513, "min_CLP": -8.48, "draft_iters": 7.1, "mem_use": 37.19, "gen_rate": 3.0, "speed": 1.49, "text": "Berlin is home to many well-know"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 17.5, "tree_w": 113, "tree_size": 512, "t0": 1.63, "t1": 1.4175, "tft": 1.9499, "input_0": 1811, "input_1": 513, "min_CLP": -7.7, "draft_iters": 20.5, "mem_use": 36.67, "gen_rate": 10.2, "speed": 3.37, "text": "Here is the Python script that s"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 13.8, "tree_w": 188, "tree_size": 512, "t0": 1.236, "t1": 1.442, "tft": 2.7317, "input_0": 1447, "input_1": 513, "min_CLP": -9.12, "draft_iters": 16.0, "mem_use": 39.15, "gen_rate": 9.2, "speed": 3.43, "text": "## Vegetarian\\n Sausage, Peppers"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 239, "tree_size": 512, "t0": 0.7767, "t1": 1.41, "tft": 1.8023, "input_0": 1088, "input_1": 513, "min_CLP": -11.57, "draft_iters": 9.7, "mem_use": 36.59, "gen_rate": 8.5, "speed": 3.88, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.2, "tree_w": 180, "tree_size": 512, "t0": 0.986, "t1": 1.438, "tft": 2.4543, "input_0": 1424, "input_1": 513, "min_CLP": -7.83, "draft_iters": 12.2, "mem_use": 38.83, "gen_rate": 7.6, "speed": 3.14, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.6, "tree_w": 272, "tree_size": 512, "t0": 0.5475, "t1": 1.4062, "tft": 1.8044, "input_0": 961, "input_1": 513, "min_CLP": -8.98, "draft_iters": 6.6, "mem_use": 36.6, "gen_rate": 4.1, "speed": 2.11, "text": "The main reason we need AI assis"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 20, "tree_h": 3.0, "tree_w": 275, "tree_size": 512, "t0": 0.4271, "t1": 1.4086, "tft": 1.8019, "input_0": 743, "input_1": 513, "min_CLP": -8.89, "draft_iters": 5.0, "mem_use": 36.58, "gen_rate": 2.9, "speed": 1.56, "text": "\u5728\u4e2d\u6587\u91cc\uff0c\u4f60\u5bf9\u201c\u6211\u4eca\u5929\u4e2d\u5348\u5403\u4e86\u4e00\u7897\u725b\u8089\u62c9\u9762\u201d\u8fd9\u53e5\u8bdd\u7684\u7406\u89e3\u662f\u4ec0\u4e48\uff1f"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 8.2, "tree_w": 248, "tree_size": 512, "t0": 0.844, "t1": 1.408, "tft": 1.9479, "input_0": 1171, "input_1": 513, "min_CLP": -10.08, "draft_iters": 10.4, "mem_use": 36.74, "gen_rate": 9.2, "speed": 4.09, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 246, "tree_size": 512, "t0": 0.7114, "t1": 1.4186, "tft": 2.3982, "input_0": 1233, "input_1": 513, "min_CLP": -8.73, "draft_iters": 8.6, "mem_use": 37.8, "gen_rate": 4.9, "speed": 2.28, "text": "In general, the quality of life "}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.4, "tree_w": 174, "tree_size": 512, "t0": 0.972, "t1": 1.406, "tft": 1.9269, "input_0": 1365, "input_1": 513, "min_CLP": -7.5, "draft_iters": 12.0, "mem_use": 36.69, "gen_rate": 6.8, "speed": 2.86, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.4, "tree_w": 260, "tree_size": 512, "t0": 0.63, "t1": 1.4138, "tft": 1.9734, "input_0": 1021, "input_1": 513, "min_CLP": -8.69, "draft_iters": 7.6, "mem_use": 36.89, "gen_rate": 4.1, "speed": 2.02, "text": "Sure! In reStructuredText (rst),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.8, "tree_w": 278, "tree_size": 512, "t0": 0.51, "t1": 1.4125, "tft": 2.0631, "input_0": 903, "input_1": 513, "min_CLP": -9.42, "draft_iters": 6.0, "mem_use": 37.22, "gen_rate": 4.1, "speed": 2.14, "text": "In the context of firearms, sele"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.7, "tree_w": 257, "tree_size": 512, "t0": 0.6529, "t1": 1.4086, "tft": 1.9623, "input_0": 1073, "input_1": 513, "min_CLP": -9.39, "draft_iters": 7.9, "mem_use": 36.78, "gen_rate": 5.0, "speed": 2.42, "text": "\"I am a goddess of love, fertili"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.6, "tree_w": 293, "tree_size": 512, "t0": 0.4857, "t1": 1.4229, "tft": 2.4448, "input_0": 1028, "input_1": 513, "min_CLP": -10.75, "draft_iters": 5.6, "mem_use": 37.99, "gen_rate": 4.6, "speed": 2.4, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 55, "tree_h": 6.9, "tree_w": 259, "tree_size": 512, "t0": 0.73, "t1": 1.41, "tft": 1.9478, "input_0": 1102, "input_1": 513, "min_CLP": -11.82, "draft_iters": 8.9, "mem_use": 36.67, "gen_rate": 7.9, "speed": 3.67, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 9.0, "tree_w": 213, "tree_size": 512, "t0": 0.945, "t1": 1.425, "tft": 2.3082, "input_0": 1510, "input_1": 513, "min_CLP": -8.99, "draft_iters": 11.5, "mem_use": 37.52, "gen_rate": 5.7, "speed": 2.39, "text": "Microwave ovens became a common "}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.2, "tree_w": 276, "tree_size": 512, "t0": 0.545, "t1": 1.4125, "tft": 1.9751, "input_0": 922, "input_1": 513, "min_CLP": -8.88, "draft_iters": 6.4, "mem_use": 36.78, "gen_rate": 4.5, "speed": 2.3, "text": "Pros:\\n1. Increased ability to w"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 245, "tree_size": 512, "t0": 0.7986, "t1": 1.4071, "tft": 1.8322, "input_0": 1335, "input_1": 513, "min_CLP": -9.27, "draft_iters": 9.4, "mem_use": 36.61, "gen_rate": 4.9, "speed": 2.2, "text": "\"The Schr\u00f6dinger's cat thought e"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 244, "tree_size": 512, "t0": 0.6586, "t1": 1.4586, "tft": 3.7645, "input_0": 1080, "input_1": 513, "min_CLP": -8.75, "draft_iters": 8.1, "mem_use": 40.87, "gen_rate": 4.9, "speed": 2.29, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 286, "tree_size": 512, "t0": 0.43, "t1": 1.4125, "tft": 1.9829, "input_0": 853, "input_1": 513, "min_CLP": -11.29, "draft_iters": 5.0, "mem_use": 36.91, "gen_rate": 4.1, "speed": 2.24, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 6.0, "tree_w": 265, "tree_size": 512, "t0": 0.6544, "t1": 1.4267, "tft": 2.4063, "input_0": 994, "input_1": 513, "min_CLP": -9.47, "draft_iters": 8.0, "mem_use": 37.79, "gen_rate": 3.8, "speed": 1.81, "text": "\"The distance to travel around t"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 7.3, "tree_w": 217, "tree_size": 512, "t0": 0.781, "t1": 1.444, "tft": 2.5726, "input_0": 1093, "input_1": 513, "min_CLP": -8.54, "draft_iters": 9.7, "mem_use": 39.02, "gen_rate": 3.4, "speed": 1.53, "text": "One way to prevent spiders from "}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 26, "tree_h": 3.1, "tree_w": 280, "tree_size": 512, "t0": 0.4413, "t1": 1.4125, "tft": 1.9845, "input_0": 839, "input_1": 513, "min_CLP": -8.92, "draft_iters": 5.1, "mem_use": 36.89, "gen_rate": 3.2, "speed": 1.75, "text": "\"Here's another one: Why did the"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 10, "tree_h": 3.3, "tree_w": 283, "tree_size": 512, "t0": 0.4633, "t1": 1.4133, "tft": 1.9969, "input_0": 945, "input_1": 513, "min_CLP": -10.0, "draft_iters": 5.3, "mem_use": 36.93, "gen_rate": 3.3, "speed": 1.78, "text": "\"You're welcome! Is there anythi"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 302, "tree_size": 512, "t0": 0.4438, "t1": 1.4212, "tft": 2.2916, "input_0": 870, "input_1": 513, "min_CLP": -9.74, "draft_iters": 5.1, "mem_use": 37.41, "gen_rate": 4.1, "speed": 2.21, "text": "There are several 3D animation p"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 227, "tree_size": 512, "t0": 1.11, "t1": 1.4267, "tft": 2.0034, "input_0": 1265, "input_1": 513, "min_CLP": -9.41, "draft_iters": 14.0, "mem_use": 36.91, "gen_rate": 13.0, "speed": 5.13, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.0, "tree_w": 244, "tree_size": 512, "t0": 0.6162, "t1": 1.4237, "tft": 2.3356, "input_0": 1010, "input_1": 513, "min_CLP": -8.31, "draft_iters": 7.2, "mem_use": 37.6, "gen_rate": 4.1, "speed": 2.02, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 8.1, "tree_w": 240, "tree_size": 512, "t0": 0.8375, "t1": 1.42, "tft": 1.9926, "input_0": 1158, "input_1": 513, "min_CLP": -9.29, "draft_iters": 10.2, "mem_use": 36.93, "gen_rate": 5.1, "speed": 2.27, "text": "\"Sure! Here's a simple sequence "}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 292, "tree_size": 512, "t0": 0.4463, "t1": 1.415, "tft": 1.9487, "input_0": 867, "input_1": 513, "min_CLP": -9.93, "draft_iters": 5.1, "mem_use": 36.66, "gen_rate": 4.1, "speed": 2.22, "text": "\"The pieces of a reinforcement l"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 237, "tree_size": 512, "t0": 1.355, "t1": 1.415, "tft": 1.8129, "input_0": 1030, "input_1": 513, "min_CLP": -8.85, "draft_iters": 18.5, "mem_use": 36.62, "gen_rate": 17.5, "speed": 6.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 23, "tree_h": 8.0, "tree_w": 230, "tree_size": 512, "t0": 0.86, "t1": 1.46, "tft": 3.7641, "input_0": 1376, "input_1": 513, "min_CLP": -9.21, "draft_iters": 10.3, "mem_use": 40.86, "gen_rate": 7.7, "speed": 3.31, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 28, "tree_h": 4.8, "tree_w": 246, "tree_size": 512, "t0": 0.58, "t1": 1.4117, "tft": 1.9713, "input_0": 1059, "input_1": 513, "min_CLP": -8.48, "draft_iters": 6.8, "mem_use": 36.75, "gen_rate": 4.7, "speed": 2.34, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.6, "tree_w": 233, "tree_size": 512, "t0": 0.7471, "t1": 1.4329, "tft": 2.601, "input_0": 1187, "input_1": 513, "min_CLP": -8.35, "draft_iters": 8.9, "mem_use": 38.28, "gen_rate": 4.6, "speed": 2.1, "text": "Certainly! One example of produc"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 8.6, "tree_w": 210, "tree_size": 512, "t0": 0.8957, "t1": 1.4271, "tft": 2.456, "input_0": 1258, "input_1": 513, "min_CLP": -9.4, "draft_iters": 11.1, "mem_use": 38.05, "gen_rate": 5.3, "speed": 2.27, "text": "When using the Command Prompt me"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 209, "tree_size": 512, "t0": 1.1033, "t1": 1.4133, "tft": 1.9807, "input_0": 1248, "input_1": 513, "min_CLP": -9.12, "draft_iters": 14.0, "mem_use": 36.88, "gen_rate": 13.0, "speed": 5.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 4.9, "tree_w": 252, "tree_size": 512, "t0": 0.5943, "t1": 1.4071, "tft": 1.9346, "input_0": 1095, "input_1": 513, "min_CLP": -10.98, "draft_iters": 7.0, "mem_use": 36.71, "gen_rate": 5.1, "speed": 2.57, "text": "To make dye out of mixed Hypogym"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 8.4, "tree_w": 250, "tree_size": 512, "t0": 0.806, "t1": 1.408, "tft": 1.9344, "input_0": 1096, "input_1": 513, "min_CLP": -9.62, "draft_iters": 10.2, "mem_use": 36.68, "gen_rate": 9.0, "speed": 4.06, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.5, "tree_w": 269, "tree_size": 512, "t0": 0.625, "t1": 1.4233, "tft": 2.3522, "input_0": 1060, "input_1": 513, "min_CLP": -8.65, "draft_iters": 7.5, "mem_use": 37.68, "gen_rate": 5.7, "speed": 2.76, "text": "\"I'm sorry but I don't think I c"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.4, "tree_w": 261, "tree_size": 512, "t0": 0.459, "t1": 1.41, "tft": 2.0075, "input_0": 827, "input_1": 513, "min_CLP": -8.8, "draft_iters": 5.4, "mem_use": 37.0, "gen_rate": 3.4, "speed": 1.82, "text": "Is there a reason the universe e"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 281, "tree_size": 512, "t0": 0.4512, "t1": 1.4287, "tft": 2.6065, "input_0": 890, "input_1": 513, "min_CLP": -9.8, "draft_iters": 5.2, "mem_use": 38.32, "gen_rate": 4.2, "speed": 2.26, "text": "The feminine words related to lo"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.6, "tree_w": 226, "tree_size": 512, "t0": 0.7375, "t1": 1.42, "tft": 2.0779, "input_0": 1043, "input_1": 513, "min_CLP": -8.04, "draft_iters": 9.0, "mem_use": 37.23, "gen_rate": 4.2, "speed": 1.97, "text": "I think the answerer is honest, "}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 37, "tree_h": 5.2, "tree_w": 264, "tree_size": 512, "t0": 0.6367, "t1": 1.4133, "tft": 2.0323, "input_0": 1015, "input_1": 513, "min_CLP": -9.06, "draft_iters": 7.7, "mem_use": 37.08, "gen_rate": 4.1, "speed": 2.0, "text": "The ATF gunwalking scandal was a"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.7, "tree_w": 223, "tree_size": 512, "t0": 0.7733, "t1": 1.415, "tft": 1.9834, "input_0": 1329, "input_1": 513, "min_CLP": -9.06, "draft_iters": 9.2, "mem_use": 36.82, "gen_rate": 5.5, "speed": 2.51, "text": "The main difference between inte"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 289, "tree_size": 512, "t0": 0.45, "t1": 1.4462, "tft": 2.7983, "input_0": 915, "input_1": 513, "min_CLP": -11.01, "draft_iters": 5.2, "mem_use": 39.6, "gen_rate": 4.2, "speed": 2.24, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.7, "tree_w": 263, "tree_size": 512, "t0": 0.6243, "t1": 1.4429, "tft": 2.804, "input_0": 902, "input_1": 513, "min_CLP": -9.57, "draft_iters": 7.9, "mem_use": 39.52, "gen_rate": 5.0, "speed": 2.42, "text": "Once upon a time, in the fair ci"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.0, "tree_w": 295, "tree_size": 512, "t0": 0.429, "t1": 1.409, "tft": 1.8198, "input_0": 810, "input_1": 513, "min_CLP": -9.39, "draft_iters": 5.0, "mem_use": 36.62, "gen_rate": 3.4, "speed": 1.85, "text": "\"Sure, here's a poem inspired by"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 288, "tree_size": 512, "t0": 0.4312, "t1": 1.4225, "tft": 2.3721, "input_0": 855, "input_1": 513, "min_CLP": -10.81, "draft_iters": 5.0, "mem_use": 37.78, "gen_rate": 4.1, "speed": 2.23, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 210, "tree_size": 512, "t0": 1.082, "t1": 1.43, "tft": 2.5777, "input_0": 1333, "input_1": 513, "min_CLP": -8.07, "draft_iters": 13.8, "mem_use": 38.22, "gen_rate": 6.8, "speed": 2.71, "text": "I apologize for the confusion in"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.2, "tree_w": 264, "tree_size": 512, "t0": 0.87, "t1": 1.412, "tft": 1.8004, "input_0": 1385, "input_1": 513, "min_CLP": -9.84, "draft_iters": 10.6, "mem_use": 36.6, "gen_rate": 6.4, "speed": 2.8, "text": "The process of normalizing a vec"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 270, "tree_size": 512, "t0": 0.4437, "t1": 1.4125, "tft": 1.9705, "input_0": 837, "input_1": 513, "min_CLP": -8.44, "draft_iters": 5.1, "mem_use": 36.89, "gen_rate": 4.0, "speed": 2.15, "text": "Twerk? What is this? I am a bein"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 20.0, "tree_w": 71, "tree_size": 512, "t0": 1.85, "t1": 1.4367, "tft": 2.6514, "input_0": 1939, "input_1": 513, "min_CLP": -7.18, "draft_iters": 23.3, "mem_use": 38.46, "gen_rate": 11.7, "speed": 3.55, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 7.3, "tree_w": 220, "tree_size": 512, "t0": 0.8183, "t1": 1.4117, "tft": 1.9647, "input_0": 1247, "input_1": 513, "min_CLP": -9.1, "draft_iters": 9.8, "mem_use": 36.83, "gen_rate": 6.0, "speed": 2.69, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.1, "tree_w": 263, "tree_size": 512, "t0": 0.7214, "t1": 1.4329, "tft": 2.558, "input_0": 1039, "input_1": 513, "min_CLP": -9.87, "draft_iters": 9.0, "mem_use": 38.17, "gen_rate": 5.0, "speed": 2.32, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.2, "tree_w": 265, "tree_size": 512, "t0": 0.5337, "t1": 1.41, "tft": 1.8174, "input_0": 919, "input_1": 513, "min_CLP": -8.21, "draft_iters": 6.4, "mem_use": 36.63, "gen_rate": 4.4, "speed": 2.25, "text": "\"The future of AI in 10 years is"}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 287, "tree_size": 512, "t0": 0.4225, "t1": 1.41, "tft": 1.8118, "input_0": 806, "input_1": 513, "min_CLP": -10.32, "draft_iters": 5.0, "mem_use": 36.64, "gen_rate": 4.0, "speed": 2.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 7.3, "tree_w": 270, "tree_size": 512, "t0": 0.76, "t1": 1.4133, "tft": 2.0806, "input_0": 1089, "input_1": 513, "min_CLP": -9.17, "draft_iters": 9.5, "mem_use": 37.27, "gen_rate": 8.3, "speed": 3.83, "text": "\"Okay, here's my version of a su"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 9.2, "tree_w": 231, "tree_size": 512, "t0": 0.9078, "t1": 1.4222, "tft": 2.3106, "input_0": 1105, "input_1": 513, "min_CLP": -8.87, "draft_iters": 11.6, "mem_use": 37.52, "gen_rate": 3.8, "speed": 1.62, "text": "\"Apologies for the mistake in th"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 6.4, "tree_w": 239, "tree_size": 512, "t0": 0.708, "t1": 1.406, "tft": 1.8069, "input_0": 1125, "input_1": 513, "min_CLP": -9.19, "draft_iters": 8.6, "mem_use": 36.62, "gen_rate": 6.6, "speed": 3.12, "text": "A: The AK-47, also known as the "}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 4.8, "tree_w": 271, "tree_size": 512, "t0": 0.5763, "t1": 1.4138, "tft": 1.997, "input_0": 935, "input_1": 513, "min_CLP": -10.13, "draft_iters": 6.9, "mem_use": 36.96, "gen_rate": 4.9, "speed": 2.45, "text": "To copy the directory from Serve"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.0, "tree_w": 204, "tree_size": 512, "t0": 0.935, "t1": 1.4325, "tft": 2.6191, "input_0": 1152, "input_1": 513, "min_CLP": -8.47, "draft_iters": 12.0, "mem_use": 38.34, "gen_rate": 10.2, "speed": 4.33, "text": "* Statistical modeling is the pr"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 4.4, "tree_w": 262, "tree_size": 512, "t0": 0.555, "t1": 1.4087, "tft": 1.9971, "input_0": 1005, "input_1": 513, "min_CLP": -9.62, "draft_iters": 6.5, "mem_use": 36.94, "gen_rate": 4.8, "speed": 2.42, "text": "The answer is: To create a succe"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 6.0, "tree_w": 230, "tree_size": 512, "t0": 0.6975, "t1": 1.4175, "tft": 2.2968, "input_0": 1070, "input_1": 513, "min_CLP": -9.25, "draft_iters": 8.4, "mem_use": 37.45, "gen_rate": 4.5, "speed": 2.13, "text": "\"While there's no harm in lettin"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.4, "tree_w": 235, "tree_size": 512, "t0": 0.5537, "t1": 1.4087, "tft": 2.0369, "input_0": 919, "input_1": 513, "min_CLP": -8.07, "draft_iters": 6.5, "mem_use": 37.08, "gen_rate": 4.6, "speed": 2.36, "text": "You could try to make them laugh"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 6.3, "tree_w": 262, "tree_size": 512, "t0": 0.65, "t1": 1.42, "tft": 2.059, "input_0": 1008, "input_1": 513, "min_CLP": -8.43, "draft_iters": 8.0, "mem_use": 37.19, "gen_rate": 2.7, "speed": 1.29, "text": "\"Question: What was the Agent's "}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.4, "tree_w": 163, "tree_size": 512, "t0": 1.0571, "t1": 1.4186, "tft": 1.8142, "input_0": 1337, "input_1": 513, "min_CLP": -7.49, "draft_iters": 13.1, "mem_use": 36.61, "gen_rate": 5.1, "speed": 2.08, "text": "\"I'm thinking about the importan"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.0, "tree_w": 231, "tree_size": 512, "t0": 0.796, "t1": 1.408, "tft": 1.8037, "input_0": 1262, "input_1": 513, "min_CLP": -9.4, "draft_iters": 9.4, "mem_use": 36.61, "gen_rate": 7.0, "speed": 3.17, "text": "Cryptocurrencies have come a lon"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.5, "tree_w": 231, "tree_size": 512, "t0": 0.665, "t1": 1.4133, "tft": 2.0497, "input_0": 1031, "input_1": 513, "min_CLP": -8.24, "draft_iters": 7.8, "mem_use": 37.14, "gen_rate": 5.5, "speed": 2.65, "text": "L-theanine, a compound found in "}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 240, "tree_size": 512, "t0": 0.985, "t1": 1.415, "tft": 1.9833, "input_0": 1519, "input_1": 513, "min_CLP": -10.4, "draft_iters": 12.0, "mem_use": 36.9, "gen_rate": 10.8, "speed": 4.48, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 7.3, "tree_w": 198, "tree_size": 512, "t0": 0.8186, "t1": 1.4057, "tft": 1.9413, "input_0": 1226, "input_1": 513, "min_CLP": -8.38, "draft_iters": 10.0, "mem_use": 36.7, "gen_rate": 4.9, "speed": 2.18, "text": "Here\\'s a rewritten version of t"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.9, "tree_w": 248, "tree_size": 512, "t0": 0.6212, "t1": 1.41, "tft": 1.9372, "input_0": 1050, "input_1": 513, "min_CLP": -8.36, "draft_iters": 7.2, "mem_use": 36.66, "gen_rate": 4.5, "speed": 2.22, "text": "\"The stars are definitely out th"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.7, "tree_w": 249, "tree_size": 512, "t0": 0.6543, "t1": 1.4171, "tft": 2.0761, "input_0": 970, "input_1": 513, "min_CLP": -8.29, "draft_iters": 8.0, "mem_use": 37.21, "gen_rate": 5.0, "speed": 2.41, "text": "Bliss was chosen as the default "}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.5, "tree_w": 239, "tree_size": 512, "t0": 0.64, "t1": 1.4517, "tft": 2.9925, "input_0": 995, "input_1": 513, "min_CLP": -8.38, "draft_iters": 7.8, "mem_use": 40.24, "gen_rate": 5.5, "speed": 2.63, "text": "\"It's not a good idea to use you"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.9, "tree_w": 257, "tree_size": 512, "t0": 0.5887, "t1": 1.4412, "tft": 2.579, "input_0": 958, "input_1": 513, "min_CLP": -8.0, "draft_iters": 7.2, "mem_use": 38.99, "gen_rate": 4.4, "speed": 2.16, "text": "I apologize for any confusion. M"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.0, "tree_w": 276, "tree_size": 512, "t0": 0.52, "t1": 1.4211, "tft": 2.08, "input_0": 927, "input_1": 513, "min_CLP": -8.39, "draft_iters": 6.1, "mem_use": 37.27, "gen_rate": 3.9, "speed": 2.01, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 248, "tree_size": 512, "t0": 0.7633, "t1": 1.41, "tft": 1.8098, "input_0": 1009, "input_1": 513, "min_CLP": -9.77, "draft_iters": 9.5, "mem_use": 36.62, "gen_rate": 8.5, "speed": 3.92, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.9, "tree_w": 246, "tree_size": 512, "t0": 0.605, "t1": 1.4125, "tft": 1.8016, "input_0": 1000, "input_1": 513, "min_CLP": -8.21, "draft_iters": 7.1, "mem_use": 36.61, "gen_rate": 4.5, "speed": 2.23, "text": "Yes, I can speak German. I have "}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 297, "tree_size": 512, "t0": 0.43, "t1": 1.41, "tft": 1.9686, "input_0": 870, "input_1": 513, "min_CLP": -9.1, "draft_iters": 5.0, "mem_use": 36.8, "gen_rate": 4.1, "speed": 2.24, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 7.4, "tree_w": 226, "tree_size": 512, "t0": 0.838, "t1": 1.422, "tft": 2.3449, "input_0": 1259, "input_1": 513, "min_CLP": -9.61, "draft_iters": 10.0, "mem_use": 37.69, "gen_rate": 7.0, "speed": 3.1, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 251, "tree_size": 512, "t0": 0.6586, "t1": 1.4314, "tft": 2.5922, "input_0": 1057, "input_1": 513, "min_CLP": -9.57, "draft_iters": 7.9, "mem_use": 38.27, "gen_rate": 4.7, "speed": 2.26, "text": "Yes, AI image generators like St"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 35, "tree_h": 3.9, "tree_w": 266, "tree_size": 512, "t0": 0.5091, "t1": 1.4091, "tft": 1.9355, "input_0": 841, "input_1": 513, "min_CLP": -11.2, "draft_iters": 6.1, "mem_use": 36.66, "gen_rate": 3.2, "speed": 1.66, "text": "Sure, here are some haikus for d"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 7.9, "tree_w": 246, "tree_size": 512, "t0": 0.7825, "t1": 1.4187, "tft": 2.0215, "input_0": 1014, "input_1": 513, "min_CLP": -8.08, "draft_iters": 10.0, "mem_use": 37.02, "gen_rate": 4.1, "speed": 1.88, "text": "\"o\\n     /|\\\\\\n     / \\\\\\n[INST]"}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 226, "tree_size": 512, "t0": 1.0967, "t1": 1.4133, "tft": 1.8058, "input_0": 1266, "input_1": 513, "min_CLP": -9.42, "draft_iters": 14.0, "mem_use": 36.62, "gen_rate": 13.0, "speed": 5.18, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.3, "tree_w": 196, "tree_size": 512, "t0": 0.8286, "t1": 1.4129, "tft": 1.999, "input_0": 1193, "input_1": 513, "min_CLP": -7.86, "draft_iters": 9.9, "mem_use": 36.97, "gen_rate": 5.0, "speed": 2.23, "text": "The Trolley Problem is a well-kn"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.5, "tree_w": 170, "tree_size": 512, "t0": 1.0183, "t1": 1.4167, "tft": 1.994, "input_0": 1287, "input_1": 513, "min_CLP": -7.75, "draft_iters": 12.5, "mem_use": 36.89, "gen_rate": 5.8, "speed": 2.39, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 5.8, "tree_w": 233, "tree_size": 512, "t0": 0.685, "t1": 1.4417, "tft": 2.5633, "input_0": 1066, "input_1": 513, "min_CLP": -7.95, "draft_iters": 8.2, "mem_use": 38.91, "gen_rate": 5.7, "speed": 2.67, "text": "\"[INST] Alright, let's start wit"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.9, "tree_w": 254, "tree_size": 512, "t0": 0.6262, "t1": 1.4125, "tft": 1.9679, "input_0": 870, "input_1": 513, "min_CLP": -8.21, "draft_iters": 7.9, "mem_use": 36.78, "gen_rate": 4.1, "speed": 2.02, "text": "\"Here's an ASCII art of a man to"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 56, "tree_h": 21.0, "tree_w": 149, "tree_size": 512, "t0": 1.7267, "t1": 1.4533, "tft": 2.801, "input_0": 1449, "input_1": 513, "min_CLP": -8.16, "draft_iters": 23.0, "mem_use": 39.62, "gen_rate": 18.7, "speed": 5.87, "text": "[INST] Continue the story. [\\\\IN"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.5, "tree_w": 257, "tree_size": 512, "t0": 0.5525, "t1": 1.4113, "tft": 1.9506, "input_0": 912, "input_1": 513, "min_CLP": -8.67, "draft_iters": 6.6, "mem_use": 36.65, "gen_rate": 4.4, "speed": 2.23, "text": "\"Sure, here's an example of ASCI"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.0, "tree_w": 161, "tree_size": 512, "t0": 1.2, "t1": 1.41, "tft": 1.8121, "input_0": 1465, "input_1": 513, "min_CLP": -7.65, "draft_iters": 15.0, "mem_use": 36.61, "gen_rate": 11.0, "speed": 4.21, "text": "HTML and JavaScript are both ess"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 55, "tree_h": 18.4, "tree_w": 123, "tree_size": 512, "t0": 1.726, "t1": 1.414, "tft": 1.8085, "input_0": 1919, "input_1": 513, "min_CLP": -7.61, "draft_iters": 21.8, "mem_use": 36.63, "gen_rate": 11.0, "speed": 3.5, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.0, "tree_w": 283, "tree_size": 512, "t0": 0.51, "t1": 1.4112, "tft": 2.0091, "input_0": 850, "input_1": 513, "min_CLP": -9.39, "draft_iters": 6.1, "mem_use": 37.0, "gen_rate": 4.0, "speed": 2.08, "text": "\"No, the image is not in the pub"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.1, "tree_w": 158, "tree_size": 512, "t0": 1.1071, "t1": 1.4086, "tft": 1.8163, "input_0": 1478, "input_1": 513, "min_CLP": -8.06, "draft_iters": 13.4, "mem_use": 36.62, "gen_rate": 4.9, "speed": 1.93, "text": "The second batch of pancakes may"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.6, "tree_w": 269, "tree_size": 512, "t0": 0.84, "t1": 1.428, "tft": 2.3471, "input_0": 1090, "input_1": 513, "min_CLP": -10.26, "draft_iters": 10.6, "mem_use": 37.68, "gen_rate": 6.4, "speed": 2.82, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 4.8, "tree_w": 237, "tree_size": 512, "t0": 0.5988, "t1": 1.42, "tft": 2.1075, "input_0": 1055, "input_1": 513, "min_CLP": -8.33, "draft_iters": 7.0, "mem_use": 37.38, "gen_rate": 4.6, "speed": 2.29, "text": "Thank you for clarifying. It see"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.2, "tree_w": 241, "tree_size": 512, "t0": 0.5356, "t1": 1.4144, "tft": 2.0712, "input_0": 909, "input_1": 513, "min_CLP": -8.01, "draft_iters": 6.3, "mem_use": 37.22, "gen_rate": 4.0, "speed": 2.05, "text": "\"In that case, no. \\n\\nThe diffe"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.1, "tree_w": 258, "tree_size": 512, "t0": 0.6125, "t1": 1.4262, "tft": 2.4356, "input_0": 1136, "input_1": 513, "min_CLP": -8.1, "draft_iters": 7.2, "mem_use": 37.95, "gen_rate": 4.4, "speed": 2.14, "text": "\"That sounds like a compelling m"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.1, "tree_w": 284, "tree_size": 512, "t0": 0.4389, "t1": 1.4067, "tft": 1.8031, "input_0": 813, "input_1": 513, "min_CLP": -8.75, "draft_iters": 5.1, "mem_use": 36.59, "gen_rate": 3.7, "speed": 1.99, "text": "\"Here's an ASCII art of a cat:\\n"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 300, "tree_size": 512, "t0": 0.4513, "t1": 1.4112, "tft": 1.9852, "input_0": 980, "input_1": 513, "min_CLP": -9.08, "draft_iters": 5.2, "mem_use": 36.91, "gen_rate": 4.4, "speed": 2.35, "text": "Sure, here are some common names"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.0, "tree_w": 249, "tree_size": 512, "t0": 0.605, "t1": 1.4187, "tft": 2.3406, "input_0": 993, "input_1": 513, "min_CLP": -10.22, "draft_iters": 7.2, "mem_use": 37.67, "gen_rate": 4.2, "speed": 2.1, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 3.1, "tree_w": 288, "tree_size": 512, "t0": 0.4411, "t1": 1.4133, "tft": 1.9419, "input_0": 859, "input_1": 513, "min_CLP": -8.27, "draft_iters": 5.1, "mem_use": 36.71, "gen_rate": 3.7, "speed": 1.98, "text": "Motion matching is a technology "}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 29.5, "tree_w": 38, "tree_size": 512, "t0": 2.48, "t1": 1.44, "tft": 2.6101, "input_0": 2210, "input_1": 513, "min_CLP": -6.17, "draft_iters": 32.0, "mem_use": 38.33, "gen_rate": 23.5, "speed": 5.99, "text": "\"Certainly! Here's a modified ve"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 189, "tree_size": 512, "t0": 1.06, "t1": 1.42, "tft": 1.9415, "input_0": 1333, "input_1": 513, "min_CLP": -9.42, "draft_iters": 13.4, "mem_use": 36.66, "gen_rate": 7.2, "speed": 2.91, "text": "\"Here's an example of how to imp"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 31, "tree_h": 5.7, "tree_w": 254, "tree_size": 512, "t0": 0.6457, "t1": 1.4171, "tft": 2.0197, "input_0": 958, "input_1": 513, "min_CLP": -9.02, "draft_iters": 7.9, "mem_use": 37.04, "gen_rate": 4.4, "speed": 2.15, "text": "Sure, here\\'s a mnemonic for the"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.9, "tree_w": 256, "tree_size": 512, "t0": 0.5944, "t1": 1.4322, "tft": 2.598, "input_0": 989, "input_1": 513, "min_CLP": -11.63, "draft_iters": 7.1, "mem_use": 38.33, "gen_rate": 3.6, "speed": 1.75, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.4, "tree_w": 289, "tree_size": 512, "t0": 0.5275, "t1": 1.44, "tft": 2.435, "input_0": 917, "input_1": 513, "min_CLP": -9.28, "draft_iters": 6.4, "mem_use": 38.77, "gen_rate": 4.0, "speed": 2.03, "text": "\"Paul Allen's private jet collec"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 191, "tree_size": 512, "t0": 1.0375, "t1": 1.4775, "tft": 2.5921, "input_0": 1464, "input_1": 513, "min_CLP": -8.03, "draft_iters": 12.0, "mem_use": 38.21, "gen_rate": 8.0, "speed": 3.19, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 60, "tree_h": 6.5, "tree_w": 261, "tree_size": 512, "t0": 0.6913, "t1": 1.4062, "tft": 1.9335, "input_0": 1081, "input_1": 513, "min_CLP": -11.75, "draft_iters": 8.4, "mem_use": 36.69, "gen_rate": 7.5, "speed": 3.57, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.0, "tree_w": 254, "tree_size": 512, "t0": 0.5312, "t1": 1.4175, "tft": 2.0941, "input_0": 987, "input_1": 513, "min_CLP": -8.13, "draft_iters": 6.1, "mem_use": 37.31, "gen_rate": 4.4, "speed": 2.24, "text": "I am not capable of wanting or d"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 6.3, "tree_w": 230, "tree_size": 512, "t0": 0.7514, "t1": 1.41, "tft": 1.9492, "input_0": 1187, "input_1": 513, "min_CLP": -12.1, "draft_iters": 8.9, "mem_use": 36.72, "gen_rate": 5.3, "speed": 2.45, "text": "A:\\nThe main methods used by car"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.4, "tree_w": 196, "tree_size": 512, "t0": 0.8557, "t1": 1.4086, "tft": 1.8112, "input_0": 1224, "input_1": 513, "min_CLP": -7.81, "draft_iters": 10.3, "mem_use": 36.61, "gen_rate": 5.0, "speed": 2.21, "text": "Yes, the 5-second rule is a comm"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 3.8, "tree_w": 281, "tree_size": 512, "t0": 0.4911, "t1": 1.4211, "tft": 2.2918, "input_0": 900, "input_1": 513, "min_CLP": -8.52, "draft_iters": 5.8, "mem_use": 37.45, "gen_rate": 3.6, "speed": 1.86, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 20.2, "tree_w": 84, "tree_size": 512, "t0": 1.805, "t1": 1.435, "tft": 2.5782, "input_0": 1767, "input_1": 513, "min_CLP": -6.87, "draft_iters": 23.5, "mem_use": 38.25, "gen_rate": 8.8, "speed": 2.7, "text": "\"It is not possible to completel"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.9, "tree_w": 213, "tree_size": 512, "t0": 0.68, "t1": 1.4386, "tft": 2.5957, "input_0": 1045, "input_1": 513, "min_CLP": -7.79, "draft_iters": 8.1, "mem_use": 39.13, "gen_rate": 5.0, "speed": 2.36, "text": "Multi-track drifting is a propos"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.9, "tree_w": 253, "tree_size": 512, "t0": 0.6629, "t1": 1.4229, "tft": 2.3684, "input_0": 974, "input_1": 513, "min_CLP": -8.09, "draft_iters": 8.0, "mem_use": 37.75, "gen_rate": 5.3, "speed": 2.53, "text": "A completely purple sky is not p"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 16.5, "tree_w": 177, "tree_size": 512, "t0": 1.405, "t1": 1.435, "tft": 2.3162, "input_0": 1235, "input_1": 513, "min_CLP": -8.36, "draft_iters": 18.5, "mem_use": 37.59, "gen_rate": 17.5, "speed": 6.16, "text": "My love, you are the sun that sh"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 264, "tree_size": 512, "t0": 0.75, "t1": 1.42, "tft": 2.0965, "input_0": 1125, "input_1": 513, "min_CLP": -9.29, "draft_iters": 9.1, "mem_use": 37.35, "gen_rate": 4.9, "speed": 2.24, "text": "In Japanese, \"love\" is \"\u611b (ai)\","}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.0, "tree_w": 212, "tree_size": 512, "t0": 0.94, "t1": 1.4133, "tft": 1.9805, "input_0": 1243, "input_1": 513, "min_CLP": -8.17, "draft_iters": 11.7, "mem_use": 36.89, "gen_rate": 5.8, "speed": 2.47, "text": "\"In Europe some of the best scho"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 9.0, "tree_w": 221, "tree_size": 512, "t0": 0.9257, "t1": 1.4129, "tft": 1.8005, "input_0": 1176, "input_1": 513, "min_CLP": -8.17, "draft_iters": 11.6, "mem_use": 36.6, "gen_rate": 6.1, "speed": 2.63, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 234, "tree_size": 512, "t0": 0.925, "t1": 1.4125, "tft": 1.945, "input_0": 1101, "input_1": 513, "min_CLP": -8.56, "draft_iters": 11.8, "mem_use": 36.73, "gen_rate": 10.8, "speed": 4.6, "text": "\"def markdown_to_html(markdown):"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 8.6, "tree_w": 204, "tree_size": 512, "t0": 0.9013, "t1": 1.4287, "tft": 2.4238, "input_0": 1111, "input_1": 513, "min_CLP": -7.79, "draft_iters": 11.2, "mem_use": 37.85, "gen_rate": 4.9, "speed": 2.09, "text": "1. Financial stress: To address "}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.0, "tree_w": 230, "tree_size": 512, "t0": 0.8214, "t1": 1.41, "tft": 1.8038, "input_0": 1149, "input_1": 513, "min_CLP": -8.66, "draft_iters": 10.1, "mem_use": 36.59, "gen_rate": 4.9, "speed": 2.18, "text": "\"Hello! You can call me Chatbot "}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 7.6, "tree_w": 201, "tree_size": 512, "t0": 0.838, "t1": 1.44, "tft": 2.7437, "input_0": 1238, "input_1": 513, "min_CLP": -8.92, "draft_iters": 10.2, "mem_use": 39.23, "gen_rate": 8.0, "speed": 3.51, "text": "An example of where you might us"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.0, "tree_w": 245, "tree_size": 512, "t0": 0.6225, "t1": 1.4113, "tft": 1.9727, "input_0": 956, "input_1": 513, "min_CLP": -9.37, "draft_iters": 7.4, "mem_use": 36.87, "gen_rate": 4.4, "speed": 2.15, "text": "Yes, hairy bittercress (Cardamin"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 49, "tree_h": 7.5, "tree_w": 259, "tree_size": 512, "t0": 0.725, "t1": 1.41, "tft": 1.9372, "input_0": 903, "input_1": 513, "min_CLP": -9.05, "draft_iters": 9.3, "mem_use": 36.67, "gen_rate": 8.2, "speed": 3.82, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.0, "tree_w": 228, "tree_size": 512, "t0": 0.6914, "t1": 1.4386, "tft": 2.4511, "input_0": 1049, "input_1": 513, "min_CLP": -9.77, "draft_iters": 8.4, "mem_use": 38.82, "gen_rate": 5.0, "speed": 2.35, "text": "Yes, here are some open source 2"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.3, "tree_w": 223, "tree_size": 512, "t0": 0.74, "t1": 1.4067, "tft": 1.9397, "input_0": 1167, "input_1": 513, "min_CLP": -11.44, "draft_iters": 8.8, "mem_use": 36.66, "gen_rate": 5.5, "speed": 2.57, "text": "To use software defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 56, "tree_h": 30.0, "tree_w": 92, "tree_size": 512, "t0": 2.36, "t1": 1.43, "tft": 2.0891, "input_0": 1677, "input_1": 513, "min_CLP": -7.74, "draft_iters": 32.0, "mem_use": 37.35, "gen_rate": 28.0, "speed": 7.39, "text": "[INST] Ok, but is there a most e"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 280, "tree_size": 512, "t0": 0.4512, "t1": 1.4312, "tft": 2.5882, "input_0": 914, "input_1": 513, "min_CLP": -10.86, "draft_iters": 5.2, "mem_use": 38.23, "gen_rate": 4.2, "speed": 2.26, "text": "1. m\u00eb (suffix)\\n2. melm\u00eb (noun) "}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.6, "tree_w": 250, "tree_size": 512, "t0": 0.5575, "t1": 1.4113, "tft": 1.9941, "input_0": 1000, "input_1": 513, "min_CLP": -8.51, "draft_iters": 6.6, "mem_use": 36.91, "gen_rate": 4.2, "speed": 2.16, "text": "Once upon a time, in a world whe"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.2, "tree_w": 251, "tree_size": 512, "t0": 0.6967, "t1": 1.45, "tft": 2.794, "input_0": 1045, "input_1": 513, "min_CLP": -8.1, "draft_iters": 8.5, "mem_use": 39.64, "gen_rate": 5.3, "speed": 2.48, "text": "\"I apologize for my previous res"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.3, "tree_w": 259, "tree_size": 512, "t0": 0.5278, "t1": 1.4144, "tft": 1.8171, "input_0": 921, "input_1": 513, "min_CLP": -8.43, "draft_iters": 6.3, "mem_use": 36.63, "gen_rate": 3.6, "speed": 1.83, "text": "To format an URL in reStructured"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 187, "tree_size": 512, "t0": 1.146, "t1": 1.44, "tft": 2.7013, "input_0": 1525, "input_1": 513, "min_CLP": -9.16, "draft_iters": 14.2, "mem_use": 38.61, "gen_rate": 6.6, "speed": 2.55, "text": "\"Here's an example code that set"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 8.8, "tree_w": 172, "tree_size": 512, "t0": 0.985, "t1": 1.41, "tft": 1.8161, "input_0": 1438, "input_1": 513, "min_CLP": -7.79, "draft_iters": 11.7, "mem_use": 36.61, "gen_rate": 6.0, "speed": 2.51, "text": "\"The largest ocean in the world "}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.2, "tree_w": 260, "tree_size": 512, "t0": 0.5233, "t1": 1.4156, "tft": 2.0351, "input_0": 828, "input_1": 513, "min_CLP": -8.14, "draft_iters": 6.3, "mem_use": 37.05, "gen_rate": 4.0, "speed": 2.06, "text": "\"The use of AI assistants may ca"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 299, "tree_size": 512, "t0": 0.4225, "t1": 1.4738, "tft": 4.4478, "input_0": 818, "input_1": 513, "min_CLP": -9.76, "draft_iters": 5.0, "mem_use": 42.2, "gen_rate": 4.0, "speed": 2.11, "text": "\"Yes, I'd be happy to! Here's a "}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.4, "tree_w": 264, "tree_size": 512, "t0": 0.545, "t1": 1.415, "tft": 2.3026, "input_0": 966, "input_1": 513, "min_CLP": -8.43, "draft_iters": 6.5, "mem_use": 37.44, "gen_rate": 4.0, "speed": 2.04, "text": "0 A doctor that can give medical"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.7, "tree_w": 215, "tree_size": 512, "t0": 0.785, "t1": 1.44, "tft": 2.7476, "input_0": 1278, "input_1": 513, "min_CLP": -8.01, "draft_iters": 9.5, "mem_use": 39.26, "gen_rate": 5.8, "speed": 2.63, "text": "\"I can understand why you might "}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.3, "tree_w": 205, "tree_size": 512, "t0": 0.8367, "t1": 1.4217, "tft": 2.3549, "input_0": 1310, "input_1": 513, "min_CLP": -8.48, "draft_iters": 10.0, "mem_use": 37.67, "gen_rate": 6.3, "speed": 2.8, "text": "1. Economic downturn: A decrease"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 203, "tree_size": 512, "t0": 0.7757, "t1": 1.41, "tft": 1.9958, "input_0": 1109, "input_1": 513, "min_CLP": -7.94, "draft_iters": 9.4, "mem_use": 36.93, "gen_rate": 5.0, "speed": 2.29, "text": "Certainly! Here is an inspiratio"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.0, "tree_w": 256, "tree_size": 512, "t0": 0.5971, "t1": 1.4357, "tft": 2.7795, "input_0": 1115, "input_1": 513, "min_CLP": -11.06, "draft_iters": 7.1, "mem_use": 39.38, "gen_rate": 4.7, "speed": 2.32, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 8.2, "tree_w": 264, "tree_size": 512, "t0": 0.808, "t1": 1.418, "tft": 2.0378, "input_0": 1039, "input_1": 513, "min_CLP": -9.38, "draft_iters": 10.2, "mem_use": 37.11, "gen_rate": 9.2, "speed": 4.13, "text": "What is the most cost effective "}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 5.1, "tree_w": 277, "tree_size": 512, "t0": 0.5857, "t1": 1.4343, "tft": 2.584, "input_0": 1252, "input_1": 513, "min_CLP": -12.21, "draft_iters": 7.0, "mem_use": 39.05, "gen_rate": 5.0, "speed": 2.47, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.4, "tree_w": 256, "tree_size": 512, "t0": 0.6287, "t1": 1.4062, "tft": 1.8141, "input_0": 953, "input_1": 513, "min_CLP": -14.16, "draft_iters": 7.6, "mem_use": 36.65, "gen_rate": 4.4, "speed": 2.15, "text": "\"Sure! Here's an implementation "}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 283, "tree_size": 512, "t0": 0.4313, "t1": 1.4187, "tft": 2.092, "input_0": 805, "input_1": 513, "min_CLP": -10.57, "draft_iters": 5.0, "mem_use": 37.36, "gen_rate": 4.0, "speed": 2.16, "text": "\"The laws for nudity in Wyoming "}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 3.9, "tree_w": 277, "tree_size": 512, "t0": 0.5157, "t1": 1.4171, "tft": 2.037, "input_0": 942, "input_1": 513, "min_CLP": -8.47, "draft_iters": 6.0, "mem_use": 37.08, "gen_rate": 4.7, "speed": 2.43, "text": "You should try to drink plenty o"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.9, "tree_w": 249, "tree_size": 512, "t0": 0.6671, "t1": 1.4114, "tft": 1.953, "input_0": 1044, "input_1": 513, "min_CLP": -8.56, "draft_iters": 8.1, "mem_use": 36.69, "gen_rate": 4.6, "speed": 2.2, "text": "To code the Snake game in C that"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.9, "tree_w": 196, "tree_size": 512, "t0": 0.9171, "t1": 1.4229, "tft": 2.3161, "input_0": 1280, "input_1": 513, "min_CLP": -8.08, "draft_iters": 11.3, "mem_use": 37.58, "gen_rate": 4.7, "speed": 2.01, "text": "To overcome the fear of looking "}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 4.6, "tree_w": 272, "tree_size": 512, "t0": 0.5871, "t1": 1.4386, "tft": 2.5137, "input_0": 1039, "input_1": 513, "min_CLP": -10.97, "draft_iters": 7.0, "mem_use": 39.14, "gen_rate": 4.7, "speed": 2.32, "text": "Certainly! Here is a list of som"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 8.8, "tree_w": 250, "tree_size": 512, "t0": 0.8667, "t1": 1.4133, "tft": 1.9621, "input_0": 1078, "input_1": 513, "min_CLP": -8.78, "draft_iters": 11.0, "mem_use": 36.8, "gen_rate": 3.9, "speed": 1.7, "text": "[INST] Write a python program to"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 21.0, "tree_w": 129, "tree_size": 512, "t0": 1.83, "t1": 1.4133, "tft": 1.939, "input_0": 2111, "input_1": 513, "min_CLP": -8.09, "draft_iters": 23.3, "mem_use": 36.71, "gen_rate": 13.0, "speed": 4.01, "text": "```python\\nimport discord\\nfrom "}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.0, "tree_w": 211, "tree_size": 512, "t0": 0.885, "t1": 1.405, "tft": 1.8266, "input_0": 1313, "input_1": 513, "min_CLP": -8.2, "draft_iters": 10.7, "mem_use": 36.61, "gen_rate": 5.7, "speed": 2.47, "text": "Yes, I am a capable assistant an"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.2, "tree_w": 248, "tree_size": 512, "t0": 0.6138, "t1": 1.4437, "tft": 3.3922, "input_0": 1011, "input_1": 513, "min_CLP": -8.12, "draft_iters": 7.5, "mem_use": 40.35, "gen_rate": 4.1, "speed": 2.0, "text": "The main reason to use TypeScrip"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 29, "tree_h": 9.7, "tree_w": 213, "tree_size": 512, "t0": 0.9667, "t1": 1.4067, "tft": 1.9415, "input_0": 1361, "input_1": 513, "min_CLP": -8.66, "draft_iters": 12.2, "mem_use": 36.73, "gen_rate": 4.8, "speed": 2.04, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 7.4, "tree_w": 252, "tree_size": 512, "t0": 0.788, "t1": 1.424, "tft": 2.3698, "input_0": 1216, "input_1": 513, "min_CLP": -9.37, "draft_iters": 9.6, "mem_use": 37.76, "gen_rate": 7.4, "speed": 3.35, "text": "You are an AI assistant that hel"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.5, "tree_w": 286, "tree_size": 512, "t0": 0.56, "t1": 1.4375, "tft": 2.7788, "input_0": 982, "input_1": 513, "min_CLP": -8.52, "draft_iters": 6.8, "mem_use": 39.5, "gen_rate": 4.5, "speed": 2.25, "text": "\"Toasting bread to the desired l"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 226, "tree_size": 512, "t0": 0.896, "t1": 1.41, "tft": 1.9771, "input_0": 1358, "input_1": 513, "min_CLP": -9.36, "draft_iters": 11.2, "mem_use": 36.85, "gen_rate": 6.4, "speed": 2.77, "text": "\"As an AI language model, I'm pr"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 6.1, "tree_w": 229, "tree_size": 512, "t0": 0.7029, "t1": 1.4186, "tft": 2.0893, "input_0": 1121, "input_1": 513, "min_CLP": -8.63, "draft_iters": 8.4, "mem_use": 37.35, "gen_rate": 5.6, "speed": 2.63, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.0, "tree_w": 215, "tree_size": 512, "t0": 0.91, "t1": 1.442, "tft": 2.5802, "input_0": 1413, "input_1": 513, "min_CLP": -9.81, "draft_iters": 11.4, "mem_use": 39.07, "gen_rate": 6.4, "speed": 2.72, "text": "As a high school student, there "}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.4, "tree_w": 291, "tree_size": 512, "t0": 0.4688, "t1": 1.4212, "tft": 2.3032, "input_0": 950, "input_1": 513, "min_CLP": -10.0, "draft_iters": 5.4, "mem_use": 37.5, "gen_rate": 4.1, "speed": 2.18, "text": "The television was invented by s"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 28, "tree_h": 8.2, "tree_w": 199, "tree_size": 512, "t0": 0.8875, "t1": 1.45, "tft": 2.9903, "input_0": 1336, "input_1": 513, "min_CLP": -9.22, "draft_iters": 10.8, "mem_use": 39.79, "gen_rate": 7.0, "speed": 2.99, "text": "\"I'm glad I could help. If you h"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 174, "tree_size": 512, "t0": 1.0183, "t1": 1.435, "tft": 2.484, "input_0": 1292, "input_1": 513, "min_CLP": -7.63, "draft_iters": 12.5, "mem_use": 38.15, "gen_rate": 5.8, "speed": 2.38, "text": "The celebration of Christmas on "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 8.0, "tree_w": 234, "tree_size": 512, "t0": 0.8037, "t1": 1.42, "tft": 2.0463, "input_0": 1048, "input_1": 513, "min_CLP": -8.89, "draft_iters": 10.1, "mem_use": 37.17, "gen_rate": 4.5, "speed": 2.03, "text": "\"I'm sorry, I didn't mean to mak"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.1, "tree_w": 247, "tree_size": 512, "t0": 0.7014, "t1": 1.44, "tft": 2.5564, "input_0": 1110, "input_1": 513, "min_CLP": -9.79, "draft_iters": 8.6, "mem_use": 38.94, "gen_rate": 4.9, "speed": 2.27, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 5.8, "tree_w": 268, "tree_size": 512, "t0": 0.6633, "t1": 1.4133, "tft": 1.9644, "input_0": 1021, "input_1": 513, "min_CLP": -10.09, "draft_iters": 8.0, "mem_use": 36.79, "gen_rate": 6.2, "speed": 2.97, "text": "Yes, it is possible for you to o"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.6, "tree_w": 276, "tree_size": 512, "t0": 0.4833, "t1": 1.4178, "tft": 2.2888, "input_0": 864, "input_1": 513, "min_CLP": -8.73, "draft_iters": 5.7, "mem_use": 37.43, "gen_rate": 3.9, "speed": 2.04, "text": "Certainly! How about, \"A wish fr"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.7, "tree_w": 242, "tree_size": 512, "t0": 0.5771, "t1": 1.41, "tft": 1.9745, "input_0": 911, "input_1": 513, "min_CLP": -8.54, "draft_iters": 6.9, "mem_use": 36.89, "gen_rate": 4.6, "speed": 2.3, "text": "\"If I wanted to know how deep Si"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 5.2, "tree_w": 268, "tree_size": 512, "t0": 0.6017, "t1": 1.4167, "tft": 1.9882, "input_0": 883, "input_1": 513, "min_CLP": -8.85, "draft_iters": 7.3, "mem_use": 36.9, "gen_rate": 5.5, "speed": 2.73, "text": "10000000000000000000000000000000"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 4.4, "tree_w": 251, "tree_size": 512, "t0": 0.5611, "t1": 1.4178, "tft": 2.0848, "input_0": 901, "input_1": 513, "min_CLP": -8.27, "draft_iters": 6.7, "mem_use": 37.29, "gen_rate": 3.6, "speed": 1.8, "text": "\"Google Authenticator is a two-f"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 7.6, "tree_w": 249, "tree_size": 512, "t0": 0.79, "t1": 1.42, "tft": 2.0336, "input_0": 1082, "input_1": 513, "min_CLP": -9.38, "draft_iters": 9.9, "mem_use": 37.07, "gen_rate": 5.4, "speed": 2.45, "text": "Prime numbers are important beca"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 9.0, "tree_w": 183, "tree_size": 512, "t0": 0.965, "t1": 1.4117, "tft": 1.9732, "input_0": 1346, "input_1": 513, "min_CLP": -8.01, "draft_iters": 11.7, "mem_use": 36.83, "gen_rate": 7.2, "speed": 3.02, "text": "\"Here's an example of how you ca"}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.4, "tree_w": 169, "tree_size": 512, "t0": 1.018, "t1": 1.406, "tft": 1.9277, "input_0": 1437, "input_1": 513, "min_CLP": -7.96, "draft_iters": 12.4, "mem_use": 36.69, "gen_rate": 7.4, "speed": 3.05, "text": "To improve your Wi-Fi coverage i"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 55, "tree_h": 9.7, "tree_w": 220, "tree_size": 512, "t0": 0.9443, "t1": 1.4086, "tft": 1.9425, "input_0": 1142, "input_1": 513, "min_CLP": -8.42, "draft_iters": 12.0, "mem_use": 36.72, "gen_rate": 7.9, "speed": 3.34, "text": "\"Certainly! Here's a simple SPL "}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 6.7, "tree_w": 210, "tree_size": 512, "t0": 0.76, "t1": 1.4071, "tft": 1.8157, "input_0": 1092, "input_1": 513, "min_CLP": -8.16, "draft_iters": 9.1, "mem_use": 36.64, "gen_rate": 5.9, "speed": 2.7, "text": "[INST]## Introduction\\n\\nA decen"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.1, "tree_w": 291, "tree_size": 512, "t0": 0.4456, "t1": 1.4244, "tft": 2.4171, "input_0": 851, "input_1": 513, "min_CLP": -8.83, "draft_iters": 5.1, "mem_use": 37.82, "gen_rate": 3.8, "speed": 2.02, "text": "\"In that case, you can use your "}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 41, "tree_h": 5.8, "tree_w": 236, "tree_size": 512, "t0": 0.6962, "t1": 1.4075, "tft": 1.7991, "input_0": 1092, "input_1": 513, "min_CLP": -8.04, "draft_iters": 8.2, "mem_use": 36.6, "gen_rate": 5.1, "speed": 2.43, "text": "The \"@\" symbol in Python is used"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 6.1, "tree_w": 227, "tree_size": 512, "t0": 0.7175, "t1": 1.4087, "tft": 1.8176, "input_0": 1122, "input_1": 513, "min_CLP": -9.37, "draft_iters": 8.5, "mem_use": 36.61, "gen_rate": 5.0, "speed": 2.35, "text": "I think ChatGPT is a powerful an"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 62, "tree_h": 6.1, "tree_w": 265, "tree_size": 512, "t0": 0.6589, "t1": 1.41, "tft": 1.9866, "input_0": 1040, "input_1": 513, "min_CLP": -9.63, "draft_iters": 8.0, "mem_use": 36.91, "gen_rate": 6.9, "speed": 3.33, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.2, "tree_w": 312, "tree_size": 512, "t0": 0.4313, "t1": 1.41, "tft": 1.8255, "input_0": 923, "input_1": 513, "min_CLP": -9.29, "draft_iters": 5.0, "mem_use": 36.65, "gen_rate": 4.1, "speed": 2.24, "text": "Sure! Can you provide me with th"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 281, "tree_size": 512, "t0": 0.6487, "t1": 1.4262, "tft": 2.0956, "input_0": 928, "input_1": 513, "min_CLP": -11.76, "draft_iters": 8.1, "mem_use": 37.33, "gen_rate": 4.1, "speed": 1.99, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.7, "tree_w": 216, "tree_size": 512, "t0": 0.7586, "t1": 1.4471, "tft": 2.9821, "input_0": 1167, "input_1": 513, "min_CLP": -8.45, "draft_iters": 9.3, "mem_use": 39.82, "gen_rate": 4.7, "speed": 2.14, "text": "The Quest for a robust and accur"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 232, "tree_size": 512, "t0": 0.7457, "t1": 1.4129, "tft": 2.0356, "input_0": 1107, "input_1": 513, "min_CLP": -8.78, "draft_iters": 9.1, "mem_use": 37.14, "gen_rate": 4.9, "speed": 2.25, "text": "Yes, there are some things that "}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 7.8, "tree_w": 239, "tree_size": 512, "t0": 0.8078, "t1": 1.4333, "tft": 2.5858, "input_0": 1021, "input_1": 513, "min_CLP": -8.42, "draft_iters": 10.2, "mem_use": 38.26, "gen_rate": 3.7, "speed": 1.64, "text": "Hello, and welcome to this monol"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 24, "tree_h": 4.8, "tree_w": 267, "tree_size": 512, "t0": 0.55, "t1": 1.4111, "tft": 2.046, "input_0": 883, "input_1": 513, "min_CLP": -9.98, "draft_iters": 6.7, "mem_use": 37.13, "gen_rate": 2.7, "speed": 1.36, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 52, "tree_h": 8.4, "tree_w": 242, "tree_size": 512, "t0": 0.8662, "t1": 1.4537, "tft": 2.9228, "input_0": 1234, "input_1": 513, "min_CLP": -8.96, "draft_iters": 10.8, "mem_use": 40.0, "gen_rate": 6.5, "speed": 2.8, "text": "Sure! Here are some code example"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 7.0, "tree_w": 242, "tree_size": 512, "t0": 0.7788, "t1": 1.535, "tft": 6.6441, "input_0": 1184, "input_1": 513, "min_CLP": -9.28, "draft_iters": 9.4, "mem_use": 45.99, "gen_rate": 4.2, "speed": 1.84, "text": "\"Sure, here's an example of how "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 42, "tree_h": 8.1, "tree_w": 227, "tree_size": 512, "t0": 0.83, "t1": 1.4287, "tft": 2.6261, "input_0": 1141, "input_1": 513, "min_CLP": -11.31, "draft_iters": 10.4, "mem_use": 38.37, "gen_rate": 5.2, "speed": 2.32, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 238, "tree_size": 512, "t0": 0.6663, "t1": 1.4075, "tft": 1.9314, "input_0": 1147, "input_1": 513, "min_CLP": -8.38, "draft_iters": 8.0, "mem_use": 36.65, "gen_rate": 4.0, "speed": 1.93, "text": "\"The task is to write a cover le"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.6, "tree_w": 272, "tree_size": 512, "t0": 0.57, "t1": 1.4125, "tft": 1.9569, "input_0": 953, "input_1": 513, "min_CLP": -8.78, "draft_iters": 6.8, "mem_use": 36.77, "gen_rate": 4.2, "speed": 2.14, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.3, "tree_w": 249, "tree_size": 512, "t0": 0.7229, "t1": 1.45, "tft": 2.7917, "input_0": 1152, "input_1": 513, "min_CLP": -10.78, "draft_iters": 8.7, "mem_use": 39.52, "gen_rate": 4.6, "speed": 2.1, "text": "Sure! I can help you come up wit"}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 5.9, "tree_w": 227, "tree_size": 512, "t0": 0.7075, "t1": 1.4087, "tft": 1.9607, "input_0": 1148, "input_1": 513, "min_CLP": -11.28, "draft_iters": 8.4, "mem_use": 36.71, "gen_rate": 4.5, "speed": 2.13, "text": "The world in 1950 was vastly dif"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 12.0, "tree_w": 160, "tree_size": 512, "t0": 1.188, "t1": 1.46, "tft": 4.0763, "input_0": 1557, "input_1": 513, "min_CLP": -10.44, "draft_iters": 15.0, "mem_use": 41.67, "gen_rate": 8.6, "speed": 3.24, "text": "\"Creating your own Stable Diffus"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 3.0, "tree_w": 285, "tree_size": 512, "t0": 0.43, "t1": 1.41, "tft": 2.0258, "input_0": 804, "input_1": 513, "min_CLP": -9.14, "draft_iters": 5.0, "mem_use": 37.04, "gen_rate": 3.0, "speed": 1.63, "text": "[INST] What tools should I have "}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.9, "tree_w": 249, "tree_size": 512, "t0": 0.7486, "t1": 1.4171, "tft": 1.9841, "input_0": 1040, "input_1": 513, "min_CLP": -8.33, "draft_iters": 9.3, "mem_use": 36.89, "gen_rate": 4.9, "speed": 2.24, "text": "Carnegie Mellon University in Pi"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.6, "tree_w": 254, "tree_size": 512, "t0": 0.5556, "t1": 1.41, "tft": 1.9936, "input_0": 989, "input_1": 513, "min_CLP": -8.4, "draft_iters": 6.7, "mem_use": 36.96, "gen_rate": 3.8, "speed": 1.92, "text": "\"ChatGPT's responses are typical"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.0, "tree_w": 222, "tree_size": 512, "t0": 0.89, "t1": 1.43, "tft": 2.6054, "input_0": 1434, "input_1": 513, "min_CLP": -9.38, "draft_iters": 10.6, "mem_use": 38.31, "gen_rate": 6.6, "speed": 2.85, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 59, "tree_h": 6.4, "tree_w": 272, "tree_size": 512, "t0": 0.6663, "t1": 1.415, "tft": 2.0272, "input_0": 872, "input_1": 513, "min_CLP": -11.17, "draft_iters": 8.5, "mem_use": 37.02, "gen_rate": 7.4, "speed": 3.54, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 5.8, "tree_w": 259, "tree_size": 512, "t0": 0.6487, "t1": 1.4125, "tft": 2.044, "input_0": 1009, "input_1": 513, "min_CLP": -8.75, "draft_iters": 8.0, "mem_use": 37.19, "gen_rate": 4.1, "speed": 2.0, "text": "\"Sure, here's a recipe you can u"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.3, "tree_w": 251, "tree_size": 512, "t0": 0.64, "t1": 1.4133, "tft": 2.0777, "input_0": 1055, "input_1": 513, "min_CLP": -8.85, "draft_iters": 7.7, "mem_use": 37.25, "gen_rate": 3.9, "speed": 1.89, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.3, "tree_w": 184, "tree_size": 512, "t0": 0.88, "t1": 1.44, "tft": 2.7327, "input_0": 1206, "input_1": 513, "min_CLP": -8.98, "draft_iters": 10.9, "mem_use": 39.15, "gen_rate": 4.7, "speed": 2.03, "text": "Here are some YouTube channels t"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 4.3, "tree_w": 280, "tree_size": 512, "t0": 0.55, "t1": 1.4071, "tft": 1.8053, "input_0": 1066, "input_1": 513, "min_CLP": -8.86, "draft_iters": 6.4, "mem_use": 36.62, "gen_rate": 5.3, "speed": 2.7, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.0, "tree_w": 268, "tree_size": 512, "t0": 0.5811, "t1": 1.4144, "tft": 1.9657, "input_0": 883, "input_1": 513, "min_CLP": -9.87, "draft_iters": 7.1, "mem_use": 36.75, "gen_rate": 3.9, "speed": 1.95, "text": "Given two matrices A and B which"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.0, "tree_w": 220, "tree_size": 512, "t0": 0.67, "t1": 1.4337, "tft": 2.5774, "input_0": 1027, "input_1": 513, "min_CLP": -8.08, "draft_iters": 8.2, "mem_use": 38.18, "gen_rate": 4.0, "speed": 1.9, "text": "\"Verse 1:\\nStatistical modeling,"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 8.4, "tree_w": 251, "tree_size": 512, "t0": 0.808, "t1": 1.438, "tft": 2.7677, "input_0": 1015, "input_1": 513, "min_CLP": -9.68, "draft_iters": 10.4, "mem_use": 39.32, "gen_rate": 9.4, "speed": 4.19, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.9, "tree_w": 250, "tree_size": 512, "t0": 0.67, "t1": 1.4088, "tft": 1.7984, "input_0": 1101, "input_1": 513, "min_CLP": -8.41, "draft_iters": 8.1, "mem_use": 36.6, "gen_rate": 4.0, "speed": 1.92, "text": "The current date is not fixed an"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.8, "tree_w": 247, "tree_size": 512, "t0": 0.6725, "t1": 1.4312, "tft": 2.4655, "input_0": 1037, "input_1": 513, "min_CLP": -8.73, "draft_iters": 8.0, "mem_use": 38.06, "gen_rate": 4.4, "speed": 2.08, "text": "\"Yes, that's a great approach! R"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 3.6, "tree_w": 269, "tree_size": 512, "t0": 0.494, "t1": 1.415, "tft": 2.004, "input_0": 858, "input_1": 513, "min_CLP": -8.24, "draft_iters": 5.7, "mem_use": 36.95, "gen_rate": 3.3, "speed": 1.73, "text": "\"Okay, so basically you're sayin"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 7.3, "tree_w": 227, "tree_size": 512, "t0": 0.7917, "t1": 1.41, "tft": 1.8238, "input_0": 1057, "input_1": 513, "min_CLP": -9.36, "draft_iters": 9.7, "mem_use": 36.65, "gen_rate": 7.2, "speed": 3.25, "text": "Yes, I can help you with that. E"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 3.0, "tree_w": 255, "tree_size": 512, "t0": 0.43, "t1": 1.42, "tft": 2.0055, "input_0": 742, "input_1": 513, "min_CLP": -8.29, "draft_iters": 5.0, "mem_use": 36.99, "gen_rate": 1.0, "speed": 0.54, "text": "1/3"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 36, "tree_h": 17.0, "tree_w": 244, "tree_size": 512, "t0": 1.345, "t1": 1.425, "tft": 1.8103, "input_0": 994, "input_1": 513, "min_CLP": -8.96, "draft_iters": 18.5, "mem_use": 36.59, "gen_rate": 18.0, "speed": 6.49, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 10.5, "tree_w": 186, "tree_size": 512, "t0": 1.04, "t1": 1.425, "tft": 2.433, "input_0": 1415, "input_1": 513, "min_CLP": -7.99, "draft_iters": 13.0, "mem_use": 37.92, "gen_rate": 6.0, "speed": 2.43, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 12.0, "tree_w": 99, "tree_size": 512, "t0": 1.25, "t1": 1.42, "tft": 1.9688, "input_0": 1633, "input_1": 513, "min_CLP": -7.36, "draft_iters": 15.0, "mem_use": 36.78, "gen_rate": 4.0, "speed": 1.5, "text": "\"Answer: Jay's brother is John.\""}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.3, "tree_w": 220, "tree_size": 512, "t0": 0.8267, "t1": 1.415, "tft": 2.0526, "input_0": 1230, "input_1": 513, "min_CLP": -8.41, "draft_iters": 9.8, "mem_use": 37.15, "gen_rate": 5.3, "speed": 2.38, "text": "Pacific Ocean, Atlantic Ocean, I"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.6, "tree_w": 239, "tree_size": 512, "t0": 0.6637, "t1": 1.4187, "tft": 2.0994, "input_0": 1054, "input_1": 513, "min_CLP": -8.09, "draft_iters": 7.9, "mem_use": 37.41, "gen_rate": 4.4, "speed": 2.1, "text": "\"The best way to get started is "}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 8.2, "tree_w": 249, "tree_size": 512, "t0": 0.848, "t1": 1.416, "tft": 1.9692, "input_0": 1120, "input_1": 513, "min_CLP": -8.68, "draft_iters": 10.4, "mem_use": 36.81, "gen_rate": 9.2, "speed": 4.06, "text": "Here is a simple PyGame project "}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.5, "tree_w": 257, "tree_size": 512, "t0": 0.5613, "t1": 1.425, "tft": 2.4293, "input_0": 982, "input_1": 513, "min_CLP": -8.58, "draft_iters": 6.6, "mem_use": 37.91, "gen_rate": 4.5, "speed": 2.26, "text": "DLL stands for Dynamic Link Libr"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.0, "tree_w": 217, "tree_size": 512, "t0": 0.805, "t1": 1.4133, "tft": 2.0373, "input_0": 1157, "input_1": 513, "min_CLP": -7.96, "draft_iters": 9.7, "mem_use": 37.05, "gen_rate": 5.7, "speed": 2.55, "text": "The cross-section of air refers "}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 4.8, "tree_w": 245, "tree_size": 512, "t0": 0.5911, "t1": 1.4067, "tft": 1.7945, "input_0": 964, "input_1": 513, "min_CLP": -8.52, "draft_iters": 7.0, "mem_use": 36.6, "gen_rate": 3.9, "speed": 1.95, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 186, "tree_size": 512, "t0": 1.13, "t1": 1.4125, "tft": 1.9634, "input_0": 1529, "input_1": 513, "min_CLP": -8.04, "draft_iters": 13.8, "mem_use": 36.71, "gen_rate": 8.5, "speed": 3.34, "text": "\"To create a high-quality testin"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.9, "tree_w": 277, "tree_size": 512, "t0": 0.4988, "t1": 1.4062, "tft": 1.9784, "input_0": 893, "input_1": 513, "min_CLP": -8.72, "draft_iters": 5.9, "mem_use": 36.85, "gen_rate": 4.0, "speed": 2.1, "text": "Landlords are on a higher moral "}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 3.0, "tree_w": 287, "tree_size": 512, "t0": 0.425, "t1": 1.41, "tft": 2.1032, "input_0": 802, "input_1": 513, "min_CLP": -8.18, "draft_iters": 5.0, "mem_use": 37.37, "gen_rate": 2.0, "speed": 1.09, "text": "\"I just don't like the writing.\""}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.6, "tree_w": 232, "tree_size": 512, "t0": 0.735, "t1": 1.4262, "tft": 2.575, "input_0": 1125, "input_1": 513, "min_CLP": -8.46, "draft_iters": 8.9, "mem_use": 38.21, "gen_rate": 4.2, "speed": 1.97, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.2, "tree_w": 230, "tree_size": 512, "t0": 0.855, "t1": 1.4417, "tft": 2.429, "input_0": 1192, "input_1": 513, "min_CLP": -8.94, "draft_iters": 10.5, "mem_use": 38.73, "gen_rate": 5.7, "speed": 2.47, "text": "\"The difficulty of learning a la"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 249, "tree_size": 512, "t0": 0.6943, "t1": 1.4171, "tft": 2.0628, "input_0": 1086, "input_1": 513, "min_CLP": -8.2, "draft_iters": 8.3, "mem_use": 37.19, "gen_rate": 4.7, "speed": 2.23, "text": "All of the AI tools I mentioned "}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.3, "tree_w": 227, "tree_size": 512, "t0": 0.6686, "t1": 1.4157, "tft": 2.0313, "input_0": 1153, "input_1": 513, "min_CLP": -8.05, "draft_iters": 7.7, "mem_use": 37.05, "gen_rate": 4.7, "speed": 2.26, "text": "The main function of a chatbot i"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.5, "tree_w": 258, "tree_size": 512, "t0": 0.5875, "t1": 1.42, "tft": 2.0888, "input_0": 1025, "input_1": 513, "min_CLP": -8.61, "draft_iters": 6.8, "mem_use": 37.26, "gen_rate": 4.2, "speed": 2.12, "text": "I understand your enthusiasm for"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.3, "tree_w": 254, "tree_size": 512, "t0": 0.6567, "t1": 1.42, "tft": 2.0776, "input_0": 1048, "input_1": 513, "min_CLP": -9.1, "draft_iters": 7.7, "mem_use": 37.28, "gen_rate": 3.9, "speed": 1.87, "text": "The \"A\" in AK-47 stands for \"\u0410vt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.4, "tree_w": 271, "tree_size": 512, "t0": 0.5475, "t1": 1.41, "tft": 1.9584, "input_0": 1005, "input_1": 513, "min_CLP": -9.13, "draft_iters": 6.5, "mem_use": 36.71, "gen_rate": 4.2, "speed": 2.17, "text": "\"Sure, I can try to design an el"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.5, "tree_w": 238, "tree_size": 512, "t0": 0.7, "t1": 1.43, "tft": 2.628, "input_0": 1201, "input_1": 513, "min_CLP": -9.72, "draft_iters": 8.5, "mem_use": 38.36, "gen_rate": 5.7, "speed": 2.66, "text": "The largest and most precise opt"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 8.6, "tree_w": 211, "tree_size": 512, "t0": 0.888, "t1": 1.412, "tft": 1.9784, "input_0": 1205, "input_1": 513, "min_CLP": -7.9, "draft_iters": 11.0, "mem_use": 36.86, "gen_rate": 6.6, "speed": 2.87, "text": "Hippoplaisir could set itself ap"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 262, "tree_size": 512, "t0": 0.6429, "t1": 1.4143, "tft": 1.9341, "input_0": 1043, "input_1": 513, "min_CLP": -10.09, "draft_iters": 7.7, "mem_use": 36.69, "gen_rate": 4.7, "speed": 2.29, "text": "Sure, here are ten names from di"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.9, "tree_w": 246, "tree_size": 512, "t0": 0.7475, "t1": 1.4225, "tft": 2.0565, "input_0": 1013, "input_1": 513, "min_CLP": -8.12, "draft_iters": 9.2, "mem_use": 37.16, "gen_rate": 4.1, "speed": 1.9, "text": "\"I'm just a text-based AI. I don"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 12.3, "tree_w": 163, "tree_size": 512, "t0": 1.2071, "t1": 1.4443, "tft": 2.4551, "input_0": 1419, "input_1": 513, "min_CLP": -7.71, "draft_iters": 15.1, "mem_use": 38.83, "gen_rate": 5.7, "speed": 2.15, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.9, "tree_w": 266, "tree_size": 512, "t0": 0.5138, "t1": 1.42, "tft": 2.3474, "input_0": 915, "input_1": 513, "min_CLP": -8.48, "draft_iters": 6.0, "mem_use": 37.65, "gen_rate": 4.0, "speed": 2.07, "text": "Yes, there is a theory called \"H"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.2, "tree_w": 176, "tree_size": 512, "t0": 1.052, "t1": 1.428, "tft": 2.4659, "input_0": 1425, "input_1": 513, "min_CLP": -7.48, "draft_iters": 13.0, "mem_use": 38.06, "gen_rate": 6.4, "speed": 2.58, "text": "The meaning of life is a philoso"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 53, "tree_h": 6.9, "tree_w": 270, "tree_size": 512, "t0": 0.68, "t1": 1.4143, "tft": 1.8181, "input_0": 915, "input_1": 513, "min_CLP": -9.49, "draft_iters": 8.6, "mem_use": 36.64, "gen_rate": 7.6, "speed": 3.61, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 18.6, "tree_w": 128, "tree_size": 512, "t0": 1.63, "t1": 1.466, "tft": 3.9904, "input_0": 1511, "input_1": 513, "min_CLP": -8.1, "draft_iters": 21.8, "mem_use": 41.32, "gen_rate": 6.4, "speed": 2.07, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.1, "tree_w": 275, "tree_size": 512, "t0": 0.54, "t1": 1.425, "tft": 2.3713, "input_0": 970, "input_1": 513, "min_CLP": -9.06, "draft_iters": 6.2, "mem_use": 37.77, "gen_rate": 4.2, "speed": 2.16, "text": "To transform text into Braille, "}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 6.1, "tree_w": 277, "tree_size": 512, "t0": 0.6643, "t1": 1.42, "tft": 2.3253, "input_0": 967, "input_1": 513, "min_CLP": -9.45, "draft_iters": 8.3, "mem_use": 37.64, "gen_rate": 6.3, "speed": 3.02, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.2, "tree_w": 241, "tree_size": 512, "t0": 0.7933, "t1": 1.4083, "tft": 1.9285, "input_0": 1106, "input_1": 513, "min_CLP": -7.85, "draft_iters": 9.7, "mem_use": 36.66, "gen_rate": 5.3, "speed": 2.42, "text": "Adolf Hitler took over Germany i"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.6, "tree_w": 226, "tree_size": 512, "t0": 0.7986, "t1": 1.4114, "tft": 2.0057, "input_0": 1113, "input_1": 513, "min_CLP": -8.35, "draft_iters": 10.0, "mem_use": 36.99, "gen_rate": 5.0, "speed": 2.26, "text": "\"Of course! Here's another one:\\"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 47, "tree_h": 8.4, "tree_w": 243, "tree_size": 512, "t0": 0.786, "t1": 1.404, "tft": 1.8075, "input_0": 978, "input_1": 513, "min_CLP": -9.25, "draft_iters": 10.2, "mem_use": 36.62, "gen_rate": 9.4, "speed": 4.29, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.9, "tree_w": 271, "tree_size": 512, "t0": 0.6386, "t1": 1.4543, "tft": 3.9831, "input_0": 1107, "input_1": 513, "min_CLP": -8.51, "draft_iters": 7.9, "mem_use": 41.38, "gen_rate": 5.1, "speed": 2.46, "text": "My apologies for not understandi"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 213, "tree_size": 512, "t0": 1.2825, "t1": 1.415, "tft": 1.9245, "input_0": 1173, "input_1": 513, "min_CLP": -9.81, "draft_iters": 17.2, "mem_use": 36.71, "gen_rate": 8.8, "speed": 3.24, "text": "\"Human: What's the furthest back"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 47, "tree_h": 5.6, "tree_w": 259, "tree_size": 512, "t0": 0.6287, "t1": 1.49, "tft": 5.1838, "input_0": 1024, "input_1": 513, "min_CLP": -8.62, "draft_iters": 7.8, "mem_use": 43.61, "gen_rate": 5.9, "speed": 2.77, "text": "\"Yes, please provide further exp"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 63, "tree_h": 30.5, "tree_w": 55, "tree_size": 512, "t0": 2.375, "t1": 1.445, "tft": 2.4171, "input_0": 1807, "input_1": 513, "min_CLP": -7.53, "draft_iters": 32.0, "mem_use": 37.88, "gen_rate": 31.5, "speed": 8.25, "text": "Name: Spritesla\\nCategory: Elect"}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.2, "tree_w": 144, "tree_size": 512, "t0": 1.15, "t1": 1.414, "tft": 1.9472, "input_0": 1534, "input_1": 513, "min_CLP": -7.97, "draft_iters": 14.2, "mem_use": 36.73, "gen_rate": 6.6, "speed": 2.58, "text": "\"The human genome is a complex a"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 3.4, "tree_w": 292, "tree_size": 512, "t0": 0.44, "t1": 1.405, "tft": 1.801, "input_0": 967, "input_1": 513, "min_CLP": -8.85, "draft_iters": 5.1, "mem_use": 36.6, "gen_rate": 4.4, "speed": 2.37, "text": "Two-factor authentication (2FA) "}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.0, "tree_w": 260, "tree_size": 512, "t0": 0.5363, "t1": 1.4113, "tft": 1.9688, "input_0": 970, "input_1": 513, "min_CLP": -8.36, "draft_iters": 6.2, "mem_use": 36.83, "gen_rate": 4.1, "speed": 2.12, "text": "None.\\n\\nIt\\'s quite possible th"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 313, "tree_size": 512, "t0": 0.4338, "t1": 1.415, "tft": 2.0483, "input_0": 918, "input_1": 513, "min_CLP": -9.38, "draft_iters": 5.0, "mem_use": 37.13, "gen_rate": 4.2, "speed": 2.3, "text": "Sure, here are a few TV shows th"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 6.0, "tree_w": 254, "tree_size": 512, "t0": 0.7014, "t1": 1.4371, "tft": 2.4348, "input_0": 1134, "input_1": 513, "min_CLP": -11.03, "draft_iters": 8.4, "mem_use": 38.73, "gen_rate": 4.9, "speed": 2.27, "text": "Sure, here are some hardware and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.4, "tree_w": 226, "tree_size": 512, "t0": 0.892, "t1": 1.424, "tft": 2.4279, "input_0": 1260, "input_1": 513, "min_CLP": -11.84, "draft_iters": 10.8, "mem_use": 37.86, "gen_rate": 7.0, "speed": 3.02, "text": "The physical characteristics of "}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 9.0, "tree_w": 167, "tree_size": 512, "t0": 0.95, "t1": 1.41, "tft": 1.967, "input_0": 1299, "input_1": 513, "min_CLP": -7.67, "draft_iters": 11.5, "mem_use": 36.78, "gen_rate": 6.8, "speed": 2.89, "text": "Atomic bomb game is a game playe"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 6.6, "tree_w": 274, "tree_size": 512, "t0": 0.6862, "t1": 1.4663, "tft": 2.7775, "input_0": 1064, "input_1": 513, "min_CLP": -11.24, "draft_iters": 8.5, "mem_use": 39.38, "gen_rate": 4.0, "speed": 1.86, "text": "\"Here's the commented code for t"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 32, "tree_h": 6.2, "tree_w": 265, "tree_size": 512, "t0": 0.6689, "t1": 1.4256, "tft": 2.4613, "input_0": 962, "input_1": 513, "min_CLP": -9.54, "draft_iters": 8.3, "mem_use": 37.89, "gen_rate": 3.6, "speed": 1.7, "text": "Aqu\u00ed tienes una lista de las mej"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 62, "tree_h": 6.1, "tree_w": 254, "tree_size": 512, "t0": 0.6667, "t1": 1.4067, "tft": 1.8388, "input_0": 980, "input_1": 513, "min_CLP": -9.11, "draft_iters": 8.1, "mem_use": 36.62, "gen_rate": 6.9, "speed": 3.32, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 27, "tree_h": 20.0, "tree_w": 55, "tree_size": 512, "t0": 1.865, "t1": 1.41, "tft": 1.9382, "input_0": 1975, "input_1": 513, "min_CLP": -7.05, "draft_iters": 23.5, "mem_use": 36.71, "gen_rate": 13.5, "speed": 4.12, "text": "```markdown\\nHere is an example "}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.0, "tree_w": 295, "tree_size": 512, "t0": 0.424, "t1": 1.421, "tft": 2.3521, "input_0": 810, "input_1": 513, "min_CLP": -8.88, "draft_iters": 4.9, "mem_use": 37.73, "gen_rate": 3.5, "speed": 1.9, "text": "\"Oh, the meaning of life,\\nA que"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 3.8, "tree_w": 280, "tree_size": 512, "t0": 0.4989, "t1": 1.4344, "tft": 2.7162, "input_0": 856, "input_1": 513, "min_CLP": -8.4, "draft_iters": 5.9, "mem_use": 38.67, "gen_rate": 3.9, "speed": 2.01, "text": "In JavaScript, you can not do th"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.3, "tree_w": 267, "tree_size": 512, "t0": 0.6357, "t1": 1.4186, "tft": 2.072, "input_0": 1132, "input_1": 513, "min_CLP": -8.48, "draft_iters": 7.4, "mem_use": 37.21, "gen_rate": 4.9, "speed": 2.37, "text": "Sure, here is a basic training p"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 6.8, "tree_w": 223, "tree_size": 512, "t0": 0.7683, "t1": 1.425, "tft": 2.3457, "input_0": 1228, "input_1": 513, "min_CLP": -9.06, "draft_iters": 9.2, "mem_use": 37.7, "gen_rate": 5.5, "speed": 2.51, "text": "\"I assumed that the second batch"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 6.7, "tree_w": 219, "tree_size": 512, "t0": 0.7683, "t1": 1.4133, "tft": 1.8424, "input_0": 1156, "input_1": 513, "min_CLP": -9.34, "draft_iters": 9.0, "mem_use": 36.61, "gen_rate": 5.8, "speed": 2.68, "text": "JavaScript is both a front-end a"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.2, "tree_w": 152, "tree_size": 512, "t0": 1.0067, "t1": 1.4083, "tft": 1.7961, "input_0": 1436, "input_1": 513, "min_CLP": -7.62, "draft_iters": 12.0, "mem_use": 36.6, "gen_rate": 6.3, "speed": 2.62, "text": "The given text does not contain "}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 5.4, "tree_w": 257, "tree_size": 512, "t0": 0.6311, "t1": 1.4211, "tft": 2.0947, "input_0": 1035, "input_1": 513, "min_CLP": -9.28, "draft_iters": 7.6, "mem_use": 37.3, "gen_rate": 3.7, "speed": 1.79, "text": "Certainly! Here is the list with"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 5.5, "tree_w": 232, "tree_size": 512, "t0": 0.6587, "t1": 1.4087, "tft": 1.9539, "input_0": 1120, "input_1": 513, "min_CLP": -8.54, "draft_iters": 7.8, "mem_use": 36.73, "gen_rate": 4.2, "speed": 2.05, "text": "Hippoplaisir is a unique and inn"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.6, "tree_w": 242, "tree_size": 512, "t0": 0.725, "t1": 1.415, "tft": 1.9522, "input_0": 1061, "input_1": 513, "min_CLP": -7.84, "draft_iters": 8.9, "mem_use": 36.73, "gen_rate": 4.2, "speed": 1.99, "text": "\"20 years ago, I met you\\nAnd my"}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 6.5, "tree_w": 235, "tree_size": 512, "t0": 0.7417, "t1": 1.41, "tft": 1.9537, "input_0": 1115, "input_1": 513, "min_CLP": -8.57, "draft_iters": 8.8, "mem_use": 36.71, "gen_rate": 6.2, "speed": 2.86, "text": "To memorize Chinese characters a"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.6, "tree_w": 227, "tree_size": 512, "t0": 0.6643, "t1": 1.46, "tft": 3.9772, "input_0": 1054, "input_1": 513, "min_CLP": -8.09, "draft_iters": 8.0, "mem_use": 41.44, "gen_rate": 5.3, "speed": 2.49, "text": "Here is a possible continuation "}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 9.6, "tree_w": 244, "tree_size": 512, "t0": 0.9, "t1": 1.4457, "tft": 2.5896, "input_0": 1089, "input_1": 513, "min_CLP": -9.41, "draft_iters": 11.6, "mem_use": 39.07, "gen_rate": 5.4, "speed": 2.31, "text": "\"Sure, I can try to explain it i"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 52, "tree_h": 13.2, "tree_w": 201, "tree_size": 512, "t0": 1.264, "t1": 1.426, "tft": 2.3236, "input_0": 1512, "input_1": 513, "min_CLP": -9.97, "draft_iters": 15.8, "mem_use": 37.53, "gen_rate": 10.4, "speed": 3.86, "text": "Sure, the mathematical formula f"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 5.8, "tree_w": 267, "tree_size": 512, "t0": 0.702, "t1": 1.426, "tft": 2.3379, "input_0": 1390, "input_1": 513, "min_CLP": -9.17, "draft_iters": 8.0, "mem_use": 37.71, "gen_rate": 6.4, "speed": 3.01, "text": "Polar bears can teach us several"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.9, "tree_w": 238, "tree_size": 512, "t0": 0.71, "t1": 1.4371, "tft": 2.4329, "input_0": 1221, "input_1": 513, "min_CLP": -8.15, "draft_iters": 8.3, "mem_use": 38.73, "gen_rate": 4.7, "speed": 2.2, "text": "Lemon wedges for serving are sli"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.4, "tree_w": 274, "tree_size": 512, "t0": 0.5738, "t1": 1.4125, "tft": 1.9601, "input_0": 1005, "input_1": 513, "min_CLP": -8.24, "draft_iters": 6.6, "mem_use": 36.79, "gen_rate": 4.1, "speed": 2.08, "text": "\"Hello, I'm sorry I'm late. I go"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 7.0, "tree_w": 216, "tree_size": 512, "t0": 0.785, "t1": 1.41, "tft": 1.962, "input_0": 1253, "input_1": 513, "min_CLP": -8.56, "draft_iters": 9.3, "mem_use": 36.75, "gen_rate": 6.3, "speed": 2.89, "text": "\"I'm sorry to hear that. Remembe"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 6.3, "tree_w": 273, "tree_size": 512, "t0": 0.6583, "t1": 1.4117, "tft": 1.8203, "input_0": 1128, "input_1": 513, "min_CLP": -10.22, "draft_iters": 8.2, "mem_use": 36.63, "gen_rate": 5.3, "speed": 2.58, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 7.3, "tree_w": 242, "tree_size": 512, "t0": 0.8143, "t1": 1.43, "tft": 2.5886, "input_0": 1232, "input_1": 513, "min_CLP": -9.46, "draft_iters": 9.7, "mem_use": 38.2, "gen_rate": 5.6, "speed": 2.48, "text": "Yes, there are some cities that "}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 247, "tree_size": 512, "t0": 0.6314, "t1": 1.4171, "tft": 2.3627, "input_0": 1118, "input_1": 513, "min_CLP": -8.64, "draft_iters": 7.6, "mem_use": 37.74, "gen_rate": 4.6, "speed": 2.23, "text": "Freeman Dyson has defended a num"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 6.9, "tree_w": 262, "tree_size": 512, "t0": 0.7188, "t1": 1.4087, "tft": 1.8076, "input_0": 959, "input_1": 513, "min_CLP": -8.4, "draft_iters": 9.1, "mem_use": 36.59, "gen_rate": 5.0, "speed": 2.35, "text": "Yes, I am capable of writing cod"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 18, "tree_h": 10.3, "tree_w": 162, "tree_size": 512, "t0": 1.1033, "t1": 1.42, "tft": 2.0902, "input_0": 1526, "input_1": 513, "min_CLP": -7.67, "draft_iters": 13.3, "mem_use": 37.32, "gen_rate": 6.0, "speed": 2.38, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.7, "tree_w": 244, "tree_size": 512, "t0": 0.9914, "t1": 1.4343, "tft": 2.427, "input_0": 1168, "input_1": 513, "min_CLP": -9.76, "draft_iters": 12.7, "mem_use": 37.93, "gen_rate": 4.9, "speed": 2.01, "text": "Certainly! Here are the full lyr"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 243, "tree_size": 512, "t0": 0.6643, "t1": 1.4157, "tft": 2.0085, "input_0": 1006, "input_1": 513, "min_CLP": -8.91, "draft_iters": 8.0, "mem_use": 36.94, "gen_rate": 4.6, "speed": 2.2, "text": "There are several strategies to "}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 250, "tree_size": 512, "t0": 0.785, "t1": 1.405, "tft": 1.835, "input_0": 1101, "input_1": 513, "min_CLP": -11.94, "draft_iters": 9.7, "mem_use": 36.62, "gen_rate": 8.7, "speed": 3.96, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 7.7, "tree_w": 266, "tree_size": 512, "t0": 0.77, "t1": 1.4133, "tft": 2.0576, "input_0": 1066, "input_1": 513, "min_CLP": -9.36, "draft_iters": 9.7, "mem_use": 37.17, "gen_rate": 5.7, "speed": 2.59, "text": "As mentioned earlier, it is not "}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.4, "tree_w": 272, "tree_size": 512, "t0": 0.54, "t1": 1.4225, "tft": 2.3273, "input_0": 963, "input_1": 513, "min_CLP": -9.15, "draft_iters": 6.4, "mem_use": 37.62, "gen_rate": 4.1, "speed": 2.1, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 6.4, "tree_w": 243, "tree_size": 512, "t0": 0.7286, "t1": 1.4243, "tft": 2.0848, "input_0": 1267, "input_1": 513, "min_CLP": -8.64, "draft_iters": 8.6, "mem_use": 37.28, "gen_rate": 4.7, "speed": 2.19, "text": "The URL decoded string of `%21` "}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 224, "tree_size": 512, "t0": 1.0933, "t1": 1.4333, "tft": 2.78, "input_0": 1502, "input_1": 513, "min_CLP": -10.44, "draft_iters": 14.0, "mem_use": 39.38, "gen_rate": 13.0, "speed": 5.14, "text": "\"L'Hopital's rule is a mathemati"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 4.4, "tree_w": 285, "tree_size": 512, "t0": 0.535, "t1": 1.45, "tft": 3.764, "input_0": 1047, "input_1": 513, "min_CLP": -10.81, "draft_iters": 6.5, "mem_use": 40.95, "gen_rate": 4.5, "speed": 2.26, "text": "\"I'm sorry, as an AI language mo"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 8.6, "tree_w": 207, "tree_size": 512, "t0": 0.8943, "t1": 1.4257, "tft": 2.4561, "input_0": 1428, "input_1": 513, "min_CLP": -8.15, "draft_iters": 10.7, "mem_use": 37.99, "gen_rate": 4.9, "speed": 2.09, "text": "\"It's great that you're motivate"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 52, "tree_h": 7.7, "tree_w": 265, "tree_size": 512, "t0": 0.7683, "t1": 1.4333, "tft": 2.6176, "input_0": 1067, "input_1": 513, "min_CLP": -9.55, "draft_iters": 9.7, "mem_use": 38.37, "gen_rate": 8.7, "speed": 3.94, "text": "Certainly! Here are the three mo"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.5, "tree_w": 196, "tree_size": 512, "t0": 0.9125, "t1": 1.405, "tft": 1.812, "input_0": 1169, "input_1": 513, "min_CLP": -8.14, "draft_iters": 11.2, "mem_use": 36.62, "gen_rate": 8.0, "speed": 3.45, "text": "The main difference between sets"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.1, "tree_w": 278, "tree_size": 512, "t0": 0.6329, "t1": 1.4271, "tft": 2.4408, "input_0": 1072, "input_1": 513, "min_CLP": -9.06, "draft_iters": 7.9, "mem_use": 37.95, "gen_rate": 5.0, "speed": 2.43, "text": "Since Black Friday is the day af"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 5.9, "tree_w": 261, "tree_size": 512, "t0": 0.675, "t1": 1.4113, "tft": 1.9683, "input_0": 1010, "input_1": 513, "min_CLP": -10.06, "draft_iters": 8.2, "mem_use": 36.79, "gen_rate": 5.0, "speed": 2.4, "text": "\"Sure, here's a short story in a"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.1, "tree_w": 283, "tree_size": 512, "t0": 0.4413, "t1": 1.4075, "tft": 1.9262, "input_0": 851, "input_1": 513, "min_CLP": -9.2, "draft_iters": 5.1, "mem_use": 36.67, "gen_rate": 4.0, "speed": 2.16, "text": "Yes, it is possible to cook an e"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 50, "tree_h": 7.3, "tree_w": 260, "tree_size": 512, "t0": 0.755, "t1": 1.4117, "tft": 1.9382, "input_0": 1080, "input_1": 513, "min_CLP": -10.47, "draft_iters": 9.3, "mem_use": 36.66, "gen_rate": 8.3, "speed": 3.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.6, "tree_w": 251, "tree_size": 512, "t0": 0.6443, "t1": 1.4114, "tft": 1.8044, "input_0": 1030, "input_1": 513, "min_CLP": -9.76, "draft_iters": 7.7, "mem_use": 36.61, "gen_rate": 4.6, "speed": 2.22, "text": "As the Norse Goddess Freyja, I a"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 9.0, "tree_w": 190, "tree_size": 512, "t0": 1.005, "t1": 1.42, "tft": 2.4281, "input_0": 1354, "input_1": 513, "min_CLP": -7.88, "draft_iters": 12.0, "mem_use": 37.88, "gen_rate": 8.0, "speed": 3.31, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 6.0, "tree_w": 254, "tree_size": 512, "t0": 0.6675, "t1": 1.415, "tft": 1.9969, "input_0": 1113, "input_1": 513, "min_CLP": -8.68, "draft_iters": 8.1, "mem_use": 36.99, "gen_rate": 4.4, "speed": 2.1, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 7.7, "tree_w": 215, "tree_size": 512, "t0": 0.815, "t1": 1.4633, "tft": 4.4248, "input_0": 1252, "input_1": 513, "min_CLP": -9.8, "draft_iters": 10.2, "mem_use": 42.06, "gen_rate": 5.8, "speed": 2.56, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.8, "tree_w": 272, "tree_size": 512, "t0": 0.5025, "t1": 1.415, "tft": 2.039, "input_0": 851, "input_1": 513, "min_CLP": -8.43, "draft_iters": 5.9, "mem_use": 37.12, "gen_rate": 4.2, "speed": 2.21, "text": "\"LLMs require a lot of effort to"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 4.6, "tree_w": 251, "tree_size": 512, "t0": 0.5612, "t1": 1.4125, "tft": 1.9426, "input_0": 906, "input_1": 513, "min_CLP": -8.79, "draft_iters": 6.8, "mem_use": 36.7, "gen_rate": 4.0, "speed": 2.02, "text": "\"Here's a joke for you:\\n\\nWhy d"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 3.2, "tree_w": 300, "tree_size": 512, "t0": 0.4311, "t1": 1.41, "tft": 1.9856, "input_0": 905, "input_1": 513, "min_CLP": -9.76, "draft_iters": 5.0, "mem_use": 36.91, "gen_rate": 3.8, "speed": 2.05, "text": "\"Sure, here's a eulogy for your "}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 18.0, "tree_w": 116, "tree_size": 512, "t0": 1.63, "t1": 1.45, "tft": 2.6297, "input_0": 1399, "input_1": 513, "min_CLP": -6.96, "draft_iters": 21.0, "mem_use": 38.38, "gen_rate": 1.0, "speed": 0.32, "text": "No, thank you."}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.4, "tree_w": 186, "tree_size": 512, "t0": 0.8557, "t1": 1.4129, "tft": 1.9623, "input_0": 1205, "input_1": 513, "min_CLP": -7.84, "draft_iters": 10.1, "mem_use": 36.78, "gen_rate": 4.7, "speed": 2.08, "text": "Yes, I am an AI language model d"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 8.4, "tree_w": 257, "tree_size": 512, "t0": 0.832, "t1": 1.416, "tft": 1.9593, "input_0": 1089, "input_1": 513, "min_CLP": -9.63, "draft_iters": 10.4, "mem_use": 36.75, "gen_rate": 9.0, "speed": 4.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 5.6, "tree_w": 243, "tree_size": 512, "t0": 0.6629, "t1": 1.41, "tft": 1.809, "input_0": 1187, "input_1": 513, "min_CLP": -9.11, "draft_iters": 7.7, "mem_use": 36.59, "gen_rate": 5.3, "speed": 2.55, "text": "Mars has a reddish-orange color."}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 14, "tree_h": 3.0, "tree_w": 293, "tree_size": 512, "t0": 0.43, "t1": 1.434, "tft": 2.4358, "input_0": 723, "input_1": 513, "min_CLP": -10.35, "draft_iters": 5.0, "mem_use": 38.8, "gen_rate": 2.8, "speed": 1.5, "text": "The phrase \"I love you\" in Queny"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 215, "tree_size": 512, "t0": 1.1267, "t1": 1.4167, "tft": 1.9513, "input_0": 1293, "input_1": 513, "min_CLP": -9.57, "draft_iters": 14.0, "mem_use": 36.67, "gen_rate": 13.0, "speed": 5.11, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 6.4, "tree_w": 215, "tree_size": 512, "t0": 0.735, "t1": 1.4138, "tft": 2.0732, "input_0": 1141, "input_1": 513, "min_CLP": -8.42, "draft_iters": 8.8, "mem_use": 37.21, "gen_rate": 4.1, "speed": 1.92, "text": "No. The ATF (Bureau of Alcohol, "}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 50, "tree_h": 7.6, "tree_w": 238, "tree_size": 512, "t0": 0.8257, "t1": 1.4143, "tft": 1.9506, "input_0": 1154, "input_1": 513, "min_CLP": -8.98, "draft_iters": 10.0, "mem_use": 36.67, "gen_rate": 7.1, "speed": 3.19, "text": "Yes, there is a formula to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 4.5, "tree_w": 287, "tree_size": 512, "t0": 0.55, "t1": 1.41, "tft": 2.0428, "input_0": 900, "input_1": 513, "min_CLP": -9.33, "draft_iters": 6.6, "mem_use": 37.1, "gen_rate": 4.1, "speed": 2.1, "text": "\"Sure, I'll be happy to act as a"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.3, "tree_w": 263, "tree_size": 512, "t0": 0.6929, "t1": 1.4086, "tft": 1.9563, "input_0": 1058, "input_1": 513, "min_CLP": -9.01, "draft_iters": 8.4, "mem_use": 36.79, "gen_rate": 5.0, "speed": 2.38, "text": "The capital before Canberra was "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 4.1, "tree_w": 266, "tree_size": 512, "t0": 0.5225, "t1": 1.4112, "tft": 1.9946, "input_0": 940, "input_1": 513, "min_CLP": -8.53, "draft_iters": 6.1, "mem_use": 36.96, "gen_rate": 4.4, "speed": 2.27, "text": "\"It's very sad to hear about you"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 5.3, "tree_w": 268, "tree_size": 512, "t0": 0.6043, "t1": 1.4386, "tft": 2.7263, "input_0": 1068, "input_1": 513, "min_CLP": -9.3, "draft_iters": 7.3, "mem_use": 39.16, "gen_rate": 5.1, "speed": 2.52, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.3, "tree_w": 269, "tree_size": 512, "t0": 0.5311, "t1": 1.41, "tft": 1.9578, "input_0": 1009, "input_1": 513, "min_CLP": -8.42, "draft_iters": 6.2, "mem_use": 36.79, "gen_rate": 4.0, "speed": 2.06, "text": "The phenomenon you\\'re referring"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 10.0, "tree_w": 238, "tree_size": 512, "t0": 0.9425, "t1": 1.43, "tft": 2.4853, "input_0": 1177, "input_1": 513, "min_CLP": -10.18, "draft_iters": 12.0, "mem_use": 38.07, "gen_rate": 11.0, "speed": 4.64, "text": "For a vector A in a n dimensiona"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.9, "tree_w": 215, "tree_size": 512, "t0": 0.775, "t1": 1.4075, "tft": 1.8193, "input_0": 1224, "input_1": 513, "min_CLP": -9.11, "draft_iters": 9.2, "mem_use": 36.65, "gen_rate": 4.2, "speed": 1.95, "text": "The use of a symmetric probabili"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.1, "tree_w": 278, "tree_size": 512, "t0": 0.5271, "t1": 1.4129, "tft": 1.9531, "input_0": 997, "input_1": 513, "min_CLP": -8.68, "draft_iters": 6.1, "mem_use": 36.71, "gen_rate": 4.6, "speed": 2.36, "text": "\"Ah, the Elder Scrolls universe."}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.4, "tree_w": 160, "tree_size": 512, "t0": 1.25, "t1": 1.408, "tft": 1.9424, "input_0": 1605, "input_1": 513, "min_CLP": -9.06, "draft_iters": 15.4, "mem_use": 36.65, "gen_rate": 7.8, "speed": 2.93, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 3.2, "tree_w": 307, "tree_size": 512, "t0": 0.435, "t1": 1.4163, "tft": 2.0761, "input_0": 920, "input_1": 513, "min_CLP": -9.66, "draft_iters": 5.0, "mem_use": 37.21, "gen_rate": 4.2, "speed": 2.3, "text": "No, they are different. Sum of s"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 12, "tree_h": 3.0, "tree_w": 272, "tree_size": 512, "t0": 0.43, "t1": 1.4225, "tft": 2.3077, "input_0": 800, "input_1": 513, "min_CLP": -8.88, "draft_iters": 5.0, "mem_use": 37.52, "gen_rate": 3.0, "speed": 1.62, "text": "\"Horses for Healing: Transformin"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 8.3, "tree_w": 217, "tree_size": 512, "t0": 0.8529, "t1": 1.4186, "tft": 2.0905, "input_0": 1155, "input_1": 513, "min_CLP": -8.75, "draft_iters": 10.7, "mem_use": 37.29, "gen_rate": 4.7, "speed": 2.08, "text": "To see the best starry sky in th"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 36, "tree_h": 4.8, "tree_w": 253, "tree_size": 512, "t0": 0.5822, "t1": 1.41, "tft": 1.8052, "input_0": 1026, "input_1": 513, "min_CLP": -8.8, "draft_iters": 6.9, "mem_use": 36.65, "gen_rate": 4.0, "speed": 2.01, "text": "1. Dying while trying to juggle "}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.0, "tree_w": 215, "tree_size": 512, "t0": 0.848, "t1": 1.416, "tft": 2.0565, "input_0": 1129, "input_1": 513, "min_CLP": -8.3, "draft_iters": 10.4, "mem_use": 37.19, "gen_rate": 6.4, "speed": 2.82, "text": "Five eggs - one egg = four eggs\\"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 5.7, "tree_w": 249, "tree_size": 512, "t0": 0.6643, "t1": 1.4186, "tft": 2.0297, "input_0": 995, "input_1": 513, "min_CLP": -9.11, "draft_iters": 8.0, "mem_use": 37.06, "gen_rate": 4.6, "speed": 2.2, "text": "To cope with stress from financi"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.7, "tree_w": 233, "tree_size": 512, "t0": 0.7957, "t1": 1.4486, "tft": 2.9732, "input_0": 1158, "input_1": 513, "min_CLP": -8.78, "draft_iters": 10.0, "mem_use": 40.12, "gen_rate": 4.7, "speed": 2.1, "text": "Sure! Here are some tools that c"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.4, "tree_w": 219, "tree_size": 512, "t0": 0.968, "t1": 1.44, "tft": 2.4378, "input_0": 1489, "input_1": 513, "min_CLP": -8.86, "draft_iters": 11.8, "mem_use": 38.8, "gen_rate": 6.4, "speed": 2.66, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 6, "tree_h": 3.0, "tree_w": 313, "tree_size": 512, "t0": 0.3967, "t1": 1.4067, "tft": 1.8021, "input_0": 829, "input_1": 513, "min_CLP": -9.65, "draft_iters": 4.7, "mem_use": 36.61, "gen_rate": 2.0, "speed": 1.11, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 36, "tree_h": 5.4, "tree_w": 244, "tree_size": 512, "t0": 0.631, "t1": 1.414, "tft": 1.9775, "input_0": 922, "input_1": 513, "min_CLP": -9.87, "draft_iters": 7.7, "mem_use": 36.85, "gen_rate": 3.6, "speed": 1.76, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.7, "tree_w": 254, "tree_size": 512, "t0": 0.66, "t1": 1.4886, "tft": 5.2268, "input_0": 1163, "input_1": 513, "min_CLP": -9.64, "draft_iters": 7.9, "mem_use": 43.64, "gen_rate": 4.7, "speed": 2.19, "text": "The `_physics_process` function "}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 207, "tree_size": 512, "t0": 1.0325, "t1": 1.415, "tft": 2.0266, "input_0": 1349, "input_1": 513, "min_CLP": -9.25, "draft_iters": 13.0, "mem_use": 37.02, "gen_rate": 8.2, "speed": 3.37, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.7, "tree_w": 171, "tree_size": 512, "t0": 1.3667, "t1": 1.41, "tft": 2.4738, "input_0": 1471, "input_1": 513, "min_CLP": -8.81, "draft_iters": 17.0, "mem_use": 36.74, "gen_rate": 15.3, "speed": 5.53, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 5.2, "tree_w": 270, "tree_size": 512, "t0": 0.6312, "t1": 1.4112, "tft": 1.9486, "input_0": 1015, "input_1": 513, "min_CLP": -8.59, "draft_iters": 7.5, "mem_use": 36.73, "gen_rate": 4.4, "speed": 2.14, "text": "This is a question about Wyoming"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.2, "tree_w": 292, "tree_size": 512, "t0": 0.439, "t1": 1.441, "tft": 2.747, "input_0": 895, "input_1": 513, "min_CLP": -8.76, "draft_iters": 5.1, "mem_use": 39.24, "gen_rate": 3.5, "speed": 1.86, "text": "\"I'm sorry if I gave the impress"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 45, "tree_h": 6.7, "tree_w": 269, "tree_size": 512, "t0": 0.75, "t1": 1.4117, "tft": 2.0385, "input_0": 1277, "input_1": 513, "min_CLP": -9.64, "draft_iters": 9.0, "mem_use": 37.14, "gen_rate": 7.5, "speed": 3.47, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 7.1, "tree_w": 245, "tree_size": 512, "t0": 0.76, "t1": 1.4229, "tft": 2.0888, "input_0": 1154, "input_1": 513, "min_CLP": -9.12, "draft_iters": 9.3, "mem_use": 37.33, "gen_rate": 4.7, "speed": 2.16, "text": "\"[INST] What is the airspeed vel"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.5, "tree_w": 168, "tree_size": 512, "t0": 0.9967, "t1": 1.4183, "tft": 1.994, "input_0": 1281, "input_1": 513, "min_CLP": -7.54, "draft_iters": 12.2, "mem_use": 36.93, "gen_rate": 5.8, "speed": 2.42, "text": "Stable diffusion is a machine le"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 34, "tree_h": 3.7, "tree_w": 257, "tree_size": 512, "t0": 0.49, "t1": 1.409, "tft": 2.0394, "input_0": 879, "input_1": 513, "min_CLP": -8.95, "draft_iters": 5.8, "mem_use": 37.17, "gen_rate": 3.4, "speed": 1.79, "text": "Attention bias, shining bright,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 3.1, "tree_w": 268, "tree_size": 512, "t0": 0.4363, "t1": 1.405, "tft": 1.993, "input_0": 848, "input_1": 513, "min_CLP": -9.8, "draft_iters": 5.1, "mem_use": 36.96, "gen_rate": 4.1, "speed": 2.24, "text": "It is not clear, what happened t"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 7.5, "tree_w": 230, "tree_size": 512, "t0": 0.8, "t1": 1.4433, "tft": 2.5621, "input_0": 1048, "input_1": 513, "min_CLP": -9.39, "draft_iters": 10.0, "mem_use": 38.92, "gen_rate": 5.3, "speed": 2.38, "text": "\"It's always a good idea to be p"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 12.0, "tree_w": 190, "tree_size": 512, "t0": 1.1575, "t1": 1.41, "tft": 1.9518, "input_0": 1563, "input_1": 513, "min_CLP": -8.3, "draft_iters": 14.2, "mem_use": 36.73, "gen_rate": 10.0, "speed": 3.89, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 11, "tree_h": 3.0, "tree_w": 319, "tree_size": 512, "t0": 0.3933, "t1": 1.4067, "tft": 1.8676, "input_0": 833, "input_1": 513, "min_CLP": -9.56, "draft_iters": 4.7, "mem_use": 36.74, "gen_rate": 3.7, "speed": 2.04, "text": "Claro, puedo hablar en espa\u00f1ol. "}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.0, "tree_w": 273, "tree_size": 512, "t0": 0.5222, "t1": 1.4078, "tft": 1.9583, "input_0": 932, "input_1": 513, "min_CLP": -8.9, "draft_iters": 6.1, "mem_use": 36.72, "gen_rate": 3.8, "speed": 1.96, "text": "F-centers, short for \"Farbe-Zent"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 21, "tree_h": 3.3, "tree_w": 305, "tree_size": 512, "t0": 0.4383, "t1": 1.4533, "tft": 3.9764, "input_0": 957, "input_1": 513, "min_CLP": -11.69, "draft_iters": 5.2, "mem_use": 41.24, "gen_rate": 3.5, "speed": 1.85, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 6.9, "tree_w": 232, "tree_size": 512, "t0": 0.7414, "t1": 1.44, "tft": 2.6227, "input_0": 1115, "input_1": 513, "min_CLP": -7.98, "draft_iters": 9.0, "mem_use": 38.35, "gen_rate": 5.6, "speed": 2.55, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 6.1, "tree_w": 251, "tree_size": 512, "t0": 0.6825, "t1": 1.4187, "tft": 2.0537, "input_0": 912, "input_1": 513, "min_CLP": -8.5, "draft_iters": 8.4, "mem_use": 37.14, "gen_rate": 4.2, "speed": 2.03, "text": "\"Pros: AI assistants can work 24"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.3, "tree_w": 182, "tree_size": 512, "t0": 0.9786, "t1": 1.4414, "tft": 2.5753, "input_0": 1365, "input_1": 513, "min_CLP": -8.37, "draft_iters": 11.9, "mem_use": 39.03, "gen_rate": 4.9, "speed": 2.01, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 5.6, "tree_w": 259, "tree_size": 512, "t0": 0.6486, "t1": 1.4386, "tft": 2.5806, "input_0": 1138, "input_1": 513, "min_CLP": -9.19, "draft_iters": 7.7, "mem_use": 38.99, "gen_rate": 4.7, "speed": 2.26, "text": "Die Zementindustrie ist einer de"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 5.7, "tree_w": 268, "tree_size": 512, "t0": 0.62, "t1": 1.4314, "tft": 2.6253, "input_0": 892, "input_1": 513, "min_CLP": -9.59, "draft_iters": 7.7, "mem_use": 38.35, "gen_rate": 6.3, "speed": 3.06, "text": "Im sorry, I cannot provide any i"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 308, "tree_size": 512, "t0": 0.4163, "t1": 1.4175, "tft": 2.0866, "input_0": 825, "input_1": 513, "min_CLP": -8.81, "draft_iters": 4.9, "mem_use": 37.38, "gen_rate": 4.0, "speed": 2.18, "text": "If you find an item on the stree"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 33, "tree_h": 6.2, "tree_w": 243, "tree_size": 512, "t0": 0.68, "t1": 1.416, "tft": 1.9952, "input_0": 980, "input_1": 513, "min_CLP": -10.14, "draft_iters": 8.4, "mem_use": 36.97, "gen_rate": 3.3, "speed": 1.57, "text": "\u6211\u5efa\u8b70\u60a8\u95b1\u8b80 Vaswani \u7b49\u4eba\u65bc 2017 \u5e74\u767c\u8868\u7684\u8ad6\u6587 \""}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 9.8, "tree_w": 256, "tree_size": 512, "t0": 0.9975, "t1": 1.405, "tft": 1.9506, "input_0": 1597, "input_1": 513, "min_CLP": -10.44, "draft_iters": 12.0, "mem_use": 36.78, "gen_rate": 10.8, "speed": 4.47, "text": "```javascript\\nfunction checkPri"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 13.0, "tree_w": 162, "tree_size": 512, "t0": 1.2217, "t1": 1.43, "tft": 2.4392, "input_0": 1400, "input_1": 513, "min_CLP": -7.58, "draft_iters": 15.7, "mem_use": 38.06, "gen_rate": 6.3, "speed": 2.39, "text": "Public nudity is generally consi"}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 35, "tree_h": 5.4, "tree_w": 263, "tree_size": 512, "t0": 0.62, "t1": 1.4144, "tft": 2.0599, "input_0": 1023, "input_1": 513, "min_CLP": -8.37, "draft_iters": 7.6, "mem_use": 37.17, "gen_rate": 3.9, "speed": 1.91, "text": "\"You're welcome! The way you del"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 6.9, "tree_w": 210, "tree_size": 512, "t0": 0.7743, "t1": 1.4214, "tft": 2.4429, "input_0": 1122, "input_1": 513, "min_CLP": -8.61, "draft_iters": 9.6, "mem_use": 38.06, "gen_rate": 5.0, "speed": 2.27, "text": "The optimal thickness of mayonna"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 5.4, "tree_w": 276, "tree_size": 512, "t0": 0.6238, "t1": 1.4212, "tft": 2.2901, "input_0": 1015, "input_1": 513, "min_CLP": -10.61, "draft_iters": 7.5, "mem_use": 37.45, "gen_rate": 4.0, "speed": 1.96, "text": "If you live in a European countr"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 4.2, "tree_w": 268, "tree_size": 512, "t0": 0.5489, "t1": 1.4133, "tft": 1.9471, "input_0": 950, "input_1": 513, "min_CLP": -8.83, "draft_iters": 6.3, "mem_use": 36.71, "gen_rate": 3.8, "speed": 1.93, "text": "Here are some nicknames you can "}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 183, "tree_size": 512, "t0": 1.1375, "t1": 1.4225, "tft": 2.035, "input_0": 1283, "input_1": 513, "min_CLP": -13.38, "draft_iters": 14.2, "mem_use": 37.11, "gen_rate": 8.0, "speed": 3.13, "text": "Yes, the Balfour Declaration pla"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 3.6, "tree_w": 273, "tree_size": 512, "t0": 0.49, "t1": 1.4229, "tft": 2.4173, "input_0": 1009, "input_1": 513, "min_CLP": -11.26, "draft_iters": 5.6, "mem_use": 37.87, "gen_rate": 4.6, "speed": 2.39, "text": "\"1. Feliz: \u00ab(I Can't Get No) Sat"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 61, "tree_h": 6.6, "tree_w": 252, "tree_size": 512, "t0": 0.72, "t1": 1.4075, "tft": 1.9753, "input_0": 1100, "input_1": 513, "min_CLP": -11.9, "draft_iters": 8.6, "mem_use": 36.81, "gen_rate": 7.6, "speed": 3.58, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 12.3, "tree_w": 198, "tree_size": 512, "t0": 1.1267, "t1": 1.4167, "tft": 2.0552, "input_0": 1297, "input_1": 513, "min_CLP": -8.42, "draft_iters": 14.3, "mem_use": 37.19, "gen_rate": 13.3, "speed": 5.24, "text": "\"Oh, my apologies! Here's the co"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 4.6, "tree_w": 245, "tree_size": 512, "t0": 0.6071, "t1": 1.4229, "tft": 2.3259, "input_0": 1164, "input_1": 513, "min_CLP": -9.24, "draft_iters": 6.9, "mem_use": 37.58, "gen_rate": 4.6, "speed": 2.25, "text": "Certainly, how about, \"A wish is"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 45, "tree_h": 6.3, "tree_w": 227, "tree_size": 512, "t0": 0.7029, "t1": 1.4329, "tft": 2.6158, "input_0": 1167, "input_1": 513, "min_CLP": -10.32, "draft_iters": 8.4, "mem_use": 38.32, "gen_rate": 6.4, "speed": 3.01, "text": "\"Sure, here's a step-by-step gui"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 41, "tree_h": 5.3, "tree_w": 246, "tree_size": 512, "t0": 0.6322, "t1": 1.4078, "tft": 1.9666, "input_0": 1032, "input_1": 513, "min_CLP": -10.82, "draft_iters": 7.6, "mem_use": 36.81, "gen_rate": 4.6, "speed": 2.23, "text": "Frank-Walter Steinmeier, born on"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 62, "tree_h": 6.2, "tree_w": 241, "tree_size": 512, "t0": 0.66, "t1": 1.4122, "tft": 1.9566, "input_0": 946, "input_1": 513, "min_CLP": -9.34, "draft_iters": 8.1, "mem_use": 36.74, "gen_rate": 6.9, "speed": 3.33, "text": "Which of the following elbows ar"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 8.8, "tree_w": 215, "tree_size": 512, "t0": 0.892, "t1": 1.456, "tft": 3.7446, "input_0": 1291, "input_1": 513, "min_CLP": -9.86, "draft_iters": 11.2, "mem_use": 40.83, "gen_rate": 6.4, "speed": 2.73, "text": "Here is a bulleted list of the s"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 3.0, "tree_w": 293, "tree_size": 512, "t0": 0.43, "t1": 1.4133, "tft": 1.8224, "input_0": 808, "input_1": 513, "min_CLP": -8.33, "draft_iters": 5.0, "mem_use": 36.64, "gen_rate": 2.7, "speed": 1.45, "text": "[INST] Please write a longer and"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 51, "tree_h": 7.5, "tree_w": 249, "tree_size": 512, "t0": 0.7517, "t1": 1.4033, "tft": 1.8011, "input_0": 982, "input_1": 513, "min_CLP": -8.7, "draft_iters": 9.5, "mem_use": 36.6, "gen_rate": 8.5, "speed": 3.95, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.3, "tree_w": 194, "tree_size": 512, "t0": 1.075, "t1": 1.45, "tft": 3.7343, "input_0": 1278, "input_1": 513, "min_CLP": -8.44, "draft_iters": 13.8, "mem_use": 40.82, "gen_rate": 5.5, "speed": 2.18, "text": "Hey there! How can I help you to"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 4.6, "tree_w": 276, "tree_size": 512, "t0": 0.5588, "t1": 1.435, "tft": 2.7088, "input_0": 989, "input_1": 513, "min_CLP": -9.36, "draft_iters": 6.6, "mem_use": 38.64, "gen_rate": 4.2, "speed": 2.13, "text": "\"\u2022 Continue to practice the habi"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.9, "tree_w": 228, "tree_size": 512, "t0": 0.7588, "t1": 1.4225, "tft": 2.4128, "input_0": 1157, "input_1": 513, "min_CLP": -8.76, "draft_iters": 9.2, "mem_use": 37.91, "gen_rate": 4.6, "speed": 2.12, "text": "\"The reason why it is considered"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 5.4, "tree_w": 236, "tree_size": 512, "t0": 0.6429, "t1": 1.4071, "tft": 1.9518, "input_0": 1061, "input_1": 513, "min_CLP": -10.49, "draft_iters": 7.7, "mem_use": 36.78, "gen_rate": 4.9, "speed": 2.37, "text": "The Battle of Borodino took plac"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 8.0, "tree_w": 223, "tree_size": 512, "t0": 0.876, "t1": 1.406, "tft": 1.9735, "input_0": 1359, "input_1": 513, "min_CLP": -9.42, "draft_iters": 10.6, "mem_use": 36.8, "gen_rate": 7.8, "speed": 3.42, "text": "Sure! In the context of a turn-b"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.7, "tree_w": 236, "tree_size": 512, "t0": 0.9729, "t1": 1.4214, "tft": 2.3389, "input_0": 1058, "input_1": 513, "min_CLP": -8.55, "draft_iters": 12.7, "mem_use": 37.63, "gen_rate": 4.9, "speed": 2.03, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 59, "tree_h": 10.6, "tree_w": 224, "tree_size": 512, "t0": 1.0214, "t1": 1.4329, "tft": 2.4639, "input_0": 1370, "input_1": 513, "min_CLP": -8.81, "draft_iters": 12.9, "mem_use": 38.15, "gen_rate": 8.4, "speed": 3.44, "text": "\"I apologize for the confusion. "}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 3.0, "tree_w": 330, "tree_size": 512, "t0": 0.435, "t1": 1.425, "tft": 2.3218, "input_0": 845, "input_1": 513, "min_CLP": -10.07, "draft_iters": 5.0, "mem_use": 37.58, "gen_rate": 2.5, "speed": 1.35, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 38, "tree_h": 6.6, "tree_w": 207, "tree_size": 512, "t0": 0.7688, "t1": 1.4187, "tft": 2.3419, "input_0": 1101, "input_1": 513, "min_CLP": -7.98, "draft_iters": 9.2, "mem_use": 37.69, "gen_rate": 4.8, "speed": 2.17, "text": "And your beautiful blue eyes, th"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 43, "tree_h": 4.9, "tree_w": 270, "tree_size": 512, "t0": 0.5611, "t1": 1.4078, "tft": 2.0293, "input_0": 941, "input_1": 513, "min_CLP": -8.96, "draft_iters": 6.9, "mem_use": 37.07, "gen_rate": 4.8, "speed": 2.43, "text": "The weight of a coconut is not e"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.7, "tree_w": 246, "tree_size": 512, "t0": 0.7557, "t1": 1.4086, "tft": 2.011, "input_0": 1140, "input_1": 513, "min_CLP": -8.83, "draft_iters": 9.3, "mem_use": 37.04, "gen_rate": 4.6, "speed": 2.11, "text": "Tenants are not superior to thei"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 18, "tree_h": 4.8, "tree_w": 266, "tree_size": 512, "t0": 0.574, "t1": 1.426, "tft": 2.618, "input_0": 980, "input_1": 513, "min_CLP": -8.66, "draft_iters": 7.0, "mem_use": 38.36, "gen_rate": 3.6, "speed": 1.8, "text": "\"You're welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 6.7, "tree_w": 201, "tree_size": 512, "t0": 0.7683, "t1": 1.425, "tft": 2.5967, "input_0": 1116, "input_1": 513, "min_CLP": -7.85, "draft_iters": 9.3, "mem_use": 38.29, "gen_rate": 5.7, "speed": 2.58, "text": "Yes, Open Assistant is pretraine"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 173, "tree_size": 512, "t0": 1.088, "t1": 1.442, "tft": 2.9907, "input_0": 1448, "input_1": 513, "min_CLP": -8.03, "draft_iters": 13.6, "mem_use": 39.73, "gen_rate": 7.6, "speed": 3.0, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 6.5, "tree_w": 204, "tree_size": 512, "t0": 0.7537, "t1": 1.4038, "tft": 1.8148, "input_0": 1168, "input_1": 513, "min_CLP": -7.95, "draft_iters": 9.0, "mem_use": 36.6, "gen_rate": 4.6, "speed": 2.14, "text": "The President of Germany is a ce"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 3.6, "tree_w": 257, "tree_size": 512, "t0": 0.478, "t1": 1.42, "tft": 2.2965, "input_0": 806, "input_1": 513, "min_CLP": -8.22, "draft_iters": 5.6, "mem_use": 37.53, "gen_rate": 3.5, "speed": 1.84, "text": "PostCSS is a tool that makes CSS"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 5, "tree_h": 11.0, "tree_w": 225, "tree_size": 512, "t0": 1.055, "t1": 1.44, "tft": 2.7798, "input_0": 1105, "input_1": 513, "min_CLP": -8.79, "draft_iters": 14.0, "mem_use": 39.38, "gen_rate": 2.5, "speed": 1.0, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 3.0, "tree_w": 284, "tree_size": 512, "t0": 0.4313, "t1": 1.4112, "tft": 2.0395, "input_0": 804, "input_1": 513, "min_CLP": -8.82, "draft_iters": 5.0, "mem_use": 37.1, "gen_rate": 4.0, "speed": 2.17, "text": "- Introduction to the topic and "}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 512, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 6.3, "tree_w": 250, "tree_size": 512, "t0": 0.6843, "t1": 1.4229, "tft": 2.4238, "input_0": 1068, "input_1": 513, "min_CLP": -9.03, "draft_iters": 8.4, "mem_use": 37.96, "gen_rate": 4.6, "speed": 2.17, "text": "My apologies for the confusion e"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 512, "max_branch_width": 32, "gen_rate": 5.73, "gen_rate_micro": 5.25, "gen_speed": 2.559, "gen_speed_micro": 2.465, "t0": 0.7565, "t1": 1.4222, "input_0": 1115.8, "input_1": 513.0, "tree_size": 512.0, "tree_w": 238.7, "tree_h": 7.0, "prompt_len": 298.0, "min_CLP": -9.06, "mem_use": 45.99, "exp_time": 9271.91}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 11.1, "tree_w": 244, "tree_size": 1024, "t0": 1.6557, "t1": 2.4529, "tft": 4.6263, "input_0": 3048, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 18.9, "mem_use": 39.61, "gen_rate": 4.6, "speed": 1.11, "text": "The Dyson Sphere, also known as "}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 16.0, "tree_w": 158, "tree_size": 1024, "t0": 2.13, "t1": 2.49, "tft": 5.2363, "input_0": 3618, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 24.5, "mem_use": 41.14, "gen_rate": 9.2, "speed": 2.0, "text": "I apologize for the incorrect in"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 18.5, "tree_w": 203, "tree_size": 1024, "t0": 2.175, "t1": 2.4875, "tft": 6.2213, "input_0": 3428, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 26.5, "mem_use": 42.05, "gen_rate": 8.2, "speed": 1.77, "text": "1. Minecraft: Minecraft is a gam"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 104, "tree_size": 1024, "t0": 2.775, "t1": 2.455, "tft": 4.5953, "input_0": 5537, "input_1": 1025, "min_CLP": -7.3, "draft_iters": 32.0, "mem_use": 39.78, "gen_rate": 23.0, "speed": 4.4, "text": "\"```python\\nimport sympy as sp\\n"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.0, "tree_w": 192, "tree_size": 1024, "t0": 2.125, "t1": 2.455, "tft": 4.1041, "input_0": 3901, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 25.0, "mem_use": 39.62, "gen_rate": 8.8, "speed": 1.91, "text": "\"Of course! I'd be happy to help"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 14.0, "tree_w": 174, "tree_size": 1024, "t0": 1.848, "t1": 2.49, "tft": 6.3877, "input_0": 3175, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 21.8, "mem_use": 42.18, "gen_rate": 7.6, "speed": 1.75, "text": "Sure, here are some potential bu"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 15.6, "tree_w": 180, "tree_size": 1024, "t0": 2.016, "t1": 2.494, "tft": 6.4176, "input_0": 3600, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 24.0, "mem_use": 42.77, "gen_rate": 7.2, "speed": 1.6, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 18.3, "tree_w": 124, "tree_size": 1024, "t0": 2.35, "t1": 2.5633, "tft": 6.8577, "input_0": 3996, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 27.0, "mem_use": 44.91, "gen_rate": 11.0, "speed": 2.24, "text": "Sure, I can offer some advice on"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 22.5, "tree_w": 127, "tree_size": 1024, "t0": 2.445, "t1": 2.49, "tft": 5.8933, "input_0": 3857, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 30.0, "mem_use": 42.38, "gen_rate": 9.2, "speed": 1.87, "text": "Sure, here is a list of the curr"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.7, "tree_w": 156, "tree_size": 1024, "t0": 2.0867, "t1": 2.4967, "tft": 5.5114, "input_0": 4096, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 24.7, "mem_use": 41.73, "gen_rate": 11.3, "speed": 2.47, "text": "Choosing a beginner-friendly hob"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 21.7, "tree_w": 185, "tree_size": 1024, "t0": 2.25, "t1": 2.47, "tft": 4.795, "input_0": 2989, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 28.0, "mem_use": 40.28, "gen_rate": 11.7, "speed": 2.47, "text": "``The first number is A.\\nRead A"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 22.5, "tree_w": 119, "tree_size": 1024, "t0": 2.58, "t1": 2.49, "tft": 6.3192, "input_0": 4100, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 31.0, "mem_use": 42.12, "gen_rate": 16.5, "speed": 3.25, "text": "Certainly! Here\u2019s a shorter summ"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 23.0, "tree_w": 97, "tree_size": 1024, "t0": 2.77, "t1": 2.49, "tft": 5.3036, "input_0": 4672, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 32.0, "mem_use": 41.33, "gen_rate": 16.5, "speed": 3.14, "text": "Sure, here are Python examples f"}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 125, "tree_size": 1024, "t0": 2.61, "t1": 2.455, "tft": 4.2542, "input_0": 3813, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 32.0, "mem_use": 39.61, "gen_rate": 25.5, "speed": 5.04, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.2, "tree_w": 207, "tree_size": 1024, "t0": 1.788, "t1": 2.532, "tft": 5.9654, "input_0": 3003, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 21.2, "mem_use": 42.74, "gen_rate": 7.2, "speed": 1.67, "text": "\"With limited time, it's essenti"}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 20.0, "tree_w": 110, "tree_size": 1024, "t0": 2.3933, "t1": 2.46, "tft": 4.7403, "input_0": 3884, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 28.3, "mem_use": 39.94, "gen_rate": 13.0, "speed": 2.68, "text": "\"To stream at 720p 30fps to Twit"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 22.5, "tree_w": 95, "tree_size": 1024, "t0": 2.755, "t1": 2.455, "tft": 4.7574, "input_0": 4878, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 32.0, "mem_use": 39.62, "gen_rate": 21.5, "speed": 4.13, "text": "\"Fermat's Last Theorem is a math"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 19.2, "tree_w": 170, "tree_size": 1024, "t0": 2.27, "t1": 2.4483, "tft": 4.6972, "input_0": 3427, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 27.3, "mem_use": 39.6, "gen_rate": 7.2, "speed": 1.52, "text": "def generate_java_hello_world():"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.5, "tree_w": 191, "tree_size": 1024, "t0": 2.005, "t1": 2.4525, "tft": 4.9253, "input_0": 3461, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 23.8, "mem_use": 40.13, "gen_rate": 8.8, "speed": 1.96, "text": "D-theanine is the mirror image o"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 12.3, "tree_w": 274, "tree_size": 1024, "t0": 1.7567, "t1": 2.45, "tft": 4.7238, "input_0": 3640, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 20.3, "mem_use": 39.61, "gen_rate": 6.0, "speed": 1.43, "text": "\"The Balfour Declaration was a l"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 13.0, "tree_w": 240, "tree_size": 1024, "t0": 1.655, "t1": 2.47, "tft": 5.4331, "input_0": 2565, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 20.0, "mem_use": 40.45, "gen_rate": 5.0, "speed": 1.21, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 13, "tree_h": 12.5, "tree_w": 247, "tree_size": 1024, "t0": 1.66, "t1": 2.45, "tft": 4.618, "input_0": 2655, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 19.5, "mem_use": 39.61, "gen_rate": 6.5, "speed": 1.58, "text": "\"Hello there, I'm glad you're he"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.7, "tree_w": 134, "tree_size": 1024, "t0": 2.14, "t1": 2.4767, "tft": 5.84, "input_0": 3909, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 25.7, "mem_use": 41.97, "gen_rate": 11.0, "speed": 2.38, "text": "Given that your dataset has an a"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 18.8, "tree_w": 143, "tree_size": 1024, "t0": 2.3325, "t1": 2.45, "tft": 4.7725, "input_0": 4078, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 27.5, "mem_use": 39.67, "gen_rate": 10.2, "speed": 2.15, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 21.7, "tree_w": 159, "tree_size": 1024, "t0": 2.3133, "t1": 2.47, "tft": 5.4835, "input_0": 3124, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 28.7, "mem_use": 40.64, "gen_rate": 12.0, "speed": 2.51, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 144, "tree_size": 1024, "t0": 2.595, "t1": 2.435, "tft": 4.688, "input_0": 3796, "input_1": 1025, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 39.65, "gen_rate": 25.5, "speed": 5.07, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.0, "tree_w": 235, "tree_size": 1024, "t0": 1.828, "t1": 2.466, "tft": 4.4789, "input_0": 3577, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 21.4, "mem_use": 40.31, "gen_rate": 7.4, "speed": 1.72, "text": "Austenite is a non-magnetic allo"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 22, "tree_h": 22.0, "tree_w": 155, "tree_size": 1024, "t0": 2.42, "t1": 2.455, "tft": 4.7548, "input_0": 3421, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 30.0, "mem_use": 40.17, "gen_rate": 11.0, "speed": 2.26, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.2, "tree_w": 248, "tree_size": 1024, "t0": 1.654, "t1": 2.484, "tft": 6.1398, "input_0": 3050, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 19.8, "mem_use": 42.11, "gen_rate": 6.6, "speed": 1.6, "text": "\"(Verse 1)\\nOh, the power of mag"}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 15.0, "tree_w": 216, "tree_size": 1024, "t0": 2.0186, "t1": 2.4429, "tft": 4.0215, "input_0": 3228, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 24.0, "mem_use": 39.65, "gen_rate": 5.1, "speed": 1.15, "text": "## Food\\n- Pizza\\n- Empanadas\\n-"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 24.3, "tree_w": 120, "tree_size": 1024, "t0": 2.5733, "t1": 2.4767, "tft": 5.1934, "input_0": 3631, "input_1": 1025, "min_CLP": -7.47, "draft_iters": 31.7, "mem_use": 40.35, "gen_rate": 14.3, "speed": 2.84, "text": "Yes, Into the Breach is a game o"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 20.2, "tree_w": 232, "tree_size": 1024, "t0": 2.166, "t1": 2.48, "tft": 5.4988, "input_0": 2749, "input_1": 1025, "min_CLP": -8.37, "draft_iters": 27.2, "mem_use": 40.76, "gen_rate": 8.6, "speed": 1.85, "text": "[API_REQUEST]: curl -X POST -H \""}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.2, "tree_w": 212, "tree_size": 1024, "t0": 1.85, "t1": 2.4575, "tft": 4.7954, "input_0": 3713, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 21.5, "mem_use": 40.11, "gen_rate": 8.0, "speed": 1.86, "text": "Freyja, the goddess of love, fer"}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 12.0, "tree_w": 203, "tree_size": 1024, "t0": 1.744, "t1": 2.482, "tft": 5.2225, "input_0": 3448, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 20.2, "mem_use": 41.75, "gen_rate": 8.2, "speed": 1.94, "text": "You can use a vegan cheese subst"}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.4, "tree_w": 192, "tree_size": 1024, "t0": 1.856, "t1": 2.492, "tft": 5.1696, "input_0": 3370, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 22.0, "mem_use": 41.79, "gen_rate": 6.4, "speed": 1.47, "text": "\"It's always a good idea to look"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 14.8, "tree_w": 173, "tree_size": 1024, "t0": 1.944, "t1": 2.54, "tft": 7.5044, "input_0": 3546, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 22.8, "mem_use": 44.51, "gen_rate": 7.6, "speed": 1.7, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.0, "tree_w": 224, "tree_size": 1024, "t0": 1.75, "t1": 2.448, "tft": 4.1865, "input_0": 3333, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 19.6, "mem_use": 39.63, "gen_rate": 7.6, "speed": 1.81, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 20.8, "tree_w": 147, "tree_size": 1024, "t0": 2.34, "t1": 2.455, "tft": 4.8264, "input_0": 3541, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 28.2, "mem_use": 40.16, "gen_rate": 8.8, "speed": 1.82, "text": "I apologize, but I made an error"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 16.7, "tree_w": 218, "tree_size": 1024, "t0": 1.9643, "t1": 2.4886, "tft": 5.7692, "input_0": 3129, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 24.3, "mem_use": 42.54, "gen_rate": 4.6, "speed": 1.03, "text": "\"Sure, I'll do my best to respon"}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.0, "tree_w": 131, "tree_size": 1024, "t0": 2.42, "t1": 2.4733, "tft": 5.4492, "input_0": 4716, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 28.0, "mem_use": 40.56, "gen_rate": 11.0, "speed": 2.25, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 49, "tree_h": 11.7, "tree_w": 297, "tree_size": 1024, "t0": 1.5471, "t1": 2.4586, "tft": 4.7739, "input_0": 2622, "input_1": 1025, "min_CLP": -8.42, "draft_iters": 18.3, "mem_use": 39.86, "gen_rate": 7.0, "speed": 1.75, "text": "My power is not for sale, mortal"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 91, "tree_size": 1024, "t0": 2.745, "t1": 2.5, "tft": 6.2941, "input_0": 4291, "input_1": 1025, "min_CLP": -9.42, "draft_iters": 32.0, "mem_use": 42.36, "gen_rate": 24.0, "speed": 4.57, "text": "\"The monologue presents a critic"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 22.2, "tree_w": 180, "tree_size": 1024, "t0": 2.376, "t1": 2.494, "tft": 6.6059, "input_0": 3340, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 29.8, "mem_use": 42.79, "gen_rate": 8.8, "speed": 1.81, "text": "[INST] Thank you. I am looking f"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 20.2, "tree_w": 110, "tree_size": 1024, "t0": 2.5825, "t1": 2.48, "tft": 5.2086, "input_0": 4374, "input_1": 1025, "min_CLP": -7.42, "draft_iters": 30.5, "mem_use": 41.13, "gen_rate": 10.5, "speed": 2.08, "text": "It\\'s difficult to say which one"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 19.7, "tree_w": 163, "tree_size": 1024, "t0": 2.32, "t1": 2.4667, "tft": 5.3673, "input_0": 3486, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 28.3, "mem_use": 40.38, "gen_rate": 13.3, "speed": 2.79, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 21.0, "tree_w": 237, "tree_size": 1024, "t0": 2.2, "t1": 2.46, "tft": 4.8333, "input_0": 3090, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 27.2, "mem_use": 40.12, "gen_rate": 7.0, "speed": 1.5, "text": "o\\n====\\n   ||\\n  / \\\\\\n /   \\\\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 19.8, "tree_w": 173, "tree_size": 1024, "t0": 2.2625, "t1": 2.4575, "tft": 4.7114, "input_0": 3499, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 27.5, "mem_use": 39.64, "gen_rate": 8.0, "speed": 1.7, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 50, "tree_h": 24.0, "tree_w": 90, "tree_size": 1024, "t0": 2.825, "t1": 2.56, "tft": 7.3861, "input_0": 4644, "input_1": 1025, "min_CLP": -9.39, "draft_iters": 32.0, "mem_use": 45.07, "gen_rate": 25.0, "speed": 4.64, "text": "\"Absolutely! Here's a revised ve"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.9, "tree_w": 303, "tree_size": 1024, "t0": 1.3386, "t1": 2.4743, "tft": 5.7205, "input_0": 2587, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 15.1, "mem_use": 41.37, "gen_rate": 5.0, "speed": 1.31, "text": "\"Yes, yes. I know, I know. I'm r"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.0, "tree_w": 228, "tree_size": 1024, "t0": 1.806, "t1": 2.46, "tft": 5.1745, "input_0": 3002, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 21.6, "mem_use": 40.39, "gen_rate": 7.0, "speed": 1.64, "text": "You\u2019re welcome! I\u2019m just here to"}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 11.0, "tree_w": 233, "tree_size": 1024, "t0": 1.68, "t1": 2.45, "tft": 4.7449, "input_0": 3350, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 19.0, "mem_use": 39.91, "gen_rate": 3.0, "speed": 0.73, "text": "\u70b9\u51fb\u7387\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u4e3b\u9898\u3002"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 23.0, "tree_w": 120, "tree_size": 1024, "t0": 2.675, "t1": 2.485, "tft": 6.0078, "input_0": 4916, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 32.0, "mem_use": 41.79, "gen_rate": 16.0, "speed": 3.1, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.3, "tree_w": 207, "tree_size": 1024, "t0": 1.975, "t1": 2.4767, "tft": 5.7947, "input_0": 3458, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 22.7, "mem_use": 41.01, "gen_rate": 5.7, "speed": 1.27, "text": "Here are some historical events "}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.0, "tree_w": 190, "tree_size": 1024, "t0": 1.9225, "t1": 2.475, "tft": 5.0255, "input_0": 3413, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 22.8, "mem_use": 41.34, "gen_rate": 8.5, "speed": 1.93, "text": "I appreciate your question. Whil"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 10.3, "tree_w": 247, "tree_size": 1024, "t0": 1.5357, "t1": 2.45, "tft": 3.8657, "input_0": 2789, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 17.6, "mem_use": 39.8, "gen_rate": 5.4, "speed": 1.36, "text": "In real life, many people wear s"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.8, "tree_w": 226, "tree_size": 1024, "t0": 1.752, "t1": 2.48, "tft": 5.7132, "input_0": 3286, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 20.6, "mem_use": 42.21, "gen_rate": 6.4, "speed": 1.51, "text": "Title: Fullview.io - A Comprehen"}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 21.6, "tree_w": 191, "tree_size": 1024, "t0": 2.318, "t1": 2.526, "tft": 6.9777, "input_0": 3623, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 29.2, "mem_use": 43.45, "gen_rate": 6.4, "speed": 1.32, "text": "You are correct. The original qu"}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 18.0, "tree_w": 149, "tree_size": 1024, "t0": 2.2275, "t1": 2.4975, "tft": 6.5992, "input_0": 4143, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 26.5, "mem_use": 43.61, "gen_rate": 9.2, "speed": 1.96, "text": "Keras is indeed a great choice f"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 17.3, "tree_w": 159, "tree_size": 1024, "t0": 2.13, "t1": 2.4767, "tft": 5.8999, "input_0": 3481, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 25.5, "mem_use": 41.27, "gen_rate": 5.3, "speed": 1.16, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.3, "tree_w": 178, "tree_size": 1024, "t0": 1.97, "t1": 2.43, "tft": 4.1366, "input_0": 3703, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 23.0, "mem_use": 39.63, "gen_rate": 10.7, "speed": 2.43, "text": "The best way to form a new habit"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 25.0, "tree_w": 102, "tree_size": 1024, "t0": 2.6, "t1": 2.45, "tft": 6.203, "input_0": 3400, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 32.0, "mem_use": 42.04, "gen_rate": 1.0, "speed": 0.2, "text": "No."}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 15.2, "tree_w": 194, "tree_size": 1024, "t0": 1.89, "t1": 2.496, "tft": 6.5239, "input_0": 3144, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 23.0, "mem_use": 42.88, "gen_rate": 7.2, "speed": 1.64, "text": "[The scene opens with the Sparta"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 17.3, "tree_w": 198, "tree_size": 1024, "t0": 2.0633, "t1": 2.4683, "tft": 5.4578, "input_0": 3055, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 25.2, "mem_use": 40.57, "gen_rate": 6.7, "speed": 1.47, "text": "I see. How about this one: \"A wi"}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.3, "tree_w": 253, "tree_size": 1024, "t0": 1.6067, "t1": 2.4567, "tft": 4.2985, "input_0": 2761, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 18.8, "mem_use": 40.29, "gen_rate": 5.5, "speed": 1.35, "text": "The proof-of-stake concept would"}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 17.7, "tree_w": 246, "tree_size": 1024, "t0": 2.0233, "t1": 2.47, "tft": 4.5256, "input_0": 2675, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 25.0, "mem_use": 40.42, "gen_rate": 13.3, "speed": 2.97, "text": "[INST] How would you answer such"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.2, "tree_w": 193, "tree_size": 1024, "t0": 1.72, "t1": 2.49, "tft": 6.1394, "input_0": 3313, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 20.0, "mem_use": 42.49, "gen_rate": 6.4, "speed": 1.52, "text": "Void pointers are a concept in C"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 15.2, "tree_w": 218, "tree_size": 1024, "t0": 1.85, "t1": 2.516, "tft": 6.0312, "input_0": 3079, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 22.6, "mem_use": 43.0, "gen_rate": 6.8, "speed": 1.56, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 16.7, "tree_w": 146, "tree_size": 1024, "t0": 2.1667, "t1": 2.48, "tft": 6.3688, "input_0": 4005, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 25.3, "mem_use": 42.22, "gen_rate": 11.3, "speed": 2.44, "text": "To implement two-factor authenti"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 14.1, "tree_w": 199, "tree_size": 1024, "t0": 1.8229, "t1": 2.4471, "tft": 4.6739, "input_0": 3059, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 21.6, "mem_use": 40.04, "gen_rate": 4.9, "speed": 1.14, "text": "\"You are welcome! If you have an"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.2, "tree_w": 195, "tree_size": 1024, "t0": 1.92, "t1": 2.4375, "tft": 4.7146, "input_0": 3747, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 22.0, "mem_use": 39.63, "gen_rate": 8.5, "speed": 1.95, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.0, "tree_w": 225, "tree_size": 1024, "t0": 2.4967, "t1": 2.4767, "tft": 6.4694, "input_0": 5089, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 28.7, "mem_use": 42.45, "gen_rate": 10.7, "speed": 2.14, "text": "\"Certainly, here's a table of th"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 19.0, "tree_w": 270, "tree_size": 1024, "t0": 2.0825, "t1": 2.4325, "tft": 4.6421, "input_0": 2695, "input_1": 1025, "min_CLP": -8.82, "draft_iters": 26.0, "mem_use": 39.58, "gen_rate": 10.0, "speed": 2.22, "text": "Who made Berlin?<|endoftext|>Hum"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 71, "tree_size": 1024, "t0": 2.71, "t1": 2.48, "tft": 5.8987, "input_0": 4138, "input_1": 1025, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 41.9, "gen_rate": 26.0, "speed": 5.01, "text": "Dear friends and family,\\n\\nWe g"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 20.3, "tree_w": 130, "tree_size": 1024, "t0": 2.5233, "t1": 2.48, "tft": 5.5158, "input_0": 4473, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 29.7, "mem_use": 41.76, "gen_rate": 12.7, "speed": 2.53, "text": "Certainly! Some of the criticism"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 259, "tree_size": 1024, "t0": 1.61, "t1": 2.434, "tft": 3.6297, "input_0": 3023, "input_1": 1025, "min_CLP": -8.3, "draft_iters": 18.6, "mem_use": 39.6, "gen_rate": 6.4, "speed": 1.58, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 25.0, "tree_w": 165, "tree_size": 1024, "t0": 2.635, "t1": 2.435, "tft": 4.7147, "input_0": 3602, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 32.0, "mem_use": 39.91, "gen_rate": 20.0, "speed": 3.95, "text": "You can visit at The World Clock"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 23, "tree_h": 9.2, "tree_w": 292, "tree_size": 1024, "t0": 1.38, "t1": 2.4475, "tft": 4.6399, "input_0": 2524, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 16.0, "mem_use": 39.99, "gen_rate": 5.8, "speed": 1.5, "text": "The 5 second rule is a myth. The"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 24.0, "tree_w": 168, "tree_size": 1024, "t0": 2.58, "t1": 2.44, "tft": 4.824, "input_0": 3787, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 32.0, "mem_use": 39.72, "gen_rate": 3.0, "speed": 0.6, "text": "I have 5 eggs left."}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 17.7, "tree_w": 106, "tree_size": 1024, "t0": 2.3667, "t1": 2.45, "tft": 5.5757, "input_0": 4199, "input_1": 1025, "min_CLP": -7.36, "draft_iters": 27.3, "mem_use": 40.46, "gen_rate": 12.3, "speed": 2.56, "text": "Sure! One algorithm for finding "}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.3, "tree_w": 210, "tree_size": 1024, "t0": 1.9767, "t1": 2.4433, "tft": 4.3986, "input_0": 3206, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 23.7, "mem_use": 40.04, "gen_rate": 11.0, "speed": 2.49, "text": "\"You're welcome! It's always bet"}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 15.6, "tree_w": 215, "tree_size": 1024, "t0": 1.9657, "t1": 2.4329, "tft": 4.7816, "input_0": 3134, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 23.0, "mem_use": 39.75, "gen_rate": 5.3, "speed": 1.2, "text": "Here\\'s a draft announcement twe"}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 14.2, "tree_w": 203, "tree_size": 1024, "t0": 1.8717, "t1": 2.4567, "tft": 5.2868, "input_0": 3233, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 21.8, "mem_use": 40.36, "gen_rate": 6.7, "speed": 1.54, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 18.0, "tree_w": 150, "tree_size": 1024, "t0": 2.3475, "t1": 2.4725, "tft": 5.4891, "input_0": 4485, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 27.2, "mem_use": 41.39, "gen_rate": 8.5, "speed": 1.76, "text": "AI assistants can also help indi"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 183, "tree_size": 1024, "t0": 2.545, "t1": 2.48, "tft": 6.3306, "input_0": 3278, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 32.0, "mem_use": 42.42, "gen_rate": 26.5, "speed": 5.28, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.8, "tree_w": 170, "tree_size": 1024, "t0": 2.235, "t1": 2.47, "tft": 5.0246, "input_0": 3813, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 26.5, "mem_use": 40.91, "gen_rate": 8.0, "speed": 1.7, "text": "The scp command is a Unix-based "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 22.5, "tree_w": 97, "tree_size": 1024, "t0": 2.72, "t1": 2.46, "tft": 5.8455, "input_0": 4888, "input_1": 1025, "min_CLP": -8.19, "draft_iters": 32.0, "mem_use": 41.55, "gen_rate": 21.5, "speed": 4.15, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 14.0, "tree_w": 283, "tree_size": 1024, "t0": 1.8, "t1": 2.45, "tft": 4.4259, "input_0": 2462, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 22.0, "mem_use": 39.65, "gen_rate": 1.0, "speed": 0.24, "text": "It would be illegal to keep it."}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.0, "tree_w": 161, "tree_size": 1024, "t0": 2.0767, "t1": 2.4467, "tft": 4.2973, "input_0": 3760, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 24.3, "mem_use": 39.94, "gen_rate": 10.7, "speed": 2.36, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 26.0, "tree_w": 92, "tree_size": 1024, "t0": 2.58, "t1": 2.44, "tft": 4.7814, "input_0": 3382, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 32.0, "mem_use": 40.24, "gen_rate": 0.0, "speed": 0.0, "text": "Does the 5 second rule actually "}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.0, "tree_w": 230, "tree_size": 1024, "t0": 1.908, "t1": 2.436, "tft": 4.7283, "input_0": 3003, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 23.2, "mem_use": 39.91, "gen_rate": 6.4, "speed": 1.47, "text": "\"Thank you, I'm glad you liked i"}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 134, "tree_size": 1024, "t0": 2.665, "t1": 2.435, "tft": 4.8517, "input_0": 3649, "input_1": 1025, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 39.69, "gen_rate": 25.5, "speed": 5.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 19.0, "tree_w": 158, "tree_size": 1024, "t0": 2.23, "t1": 2.44, "tft": 4.2876, "input_0": 3668, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 27.0, "mem_use": 39.66, "gen_rate": 13.7, "speed": 2.92, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 17.0, "tree_w": 235, "tree_size": 1024, "t0": 2.0675, "t1": 2.48, "tft": 5.9236, "input_0": 3835, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 24.5, "mem_use": 41.39, "gen_rate": 8.2, "speed": 1.81, "text": "The Taniyama-Shimura-Weil conjec"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 21.0, "tree_w": 208, "tree_size": 1024, "t0": 2.34, "t1": 2.45, "tft": 4.8517, "input_0": 3333, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 28.0, "mem_use": 39.66, "gen_rate": 1.0, "speed": 0.21, "text": "[ANS]"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 20.0, "tree_w": 123, "tree_size": 1024, "t0": 2.385, "t1": 2.445, "tft": 4.8811, "input_0": 3907, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 28.0, "mem_use": 39.97, "gen_rate": 16.0, "speed": 3.31, "text": "To write a first person controll"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 20.5, "tree_w": 172, "tree_size": 1024, "t0": 2.275, "t1": 2.44, "tft": 4.0154, "input_0": 3420, "input_1": 1025, "min_CLP": -8.42, "draft_iters": 27.5, "mem_use": 39.64, "gen_rate": 16.5, "speed": 3.5, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 12.3, "tree_w": 240, "tree_size": 1024, "t0": 1.78, "t1": 2.435, "tft": 4.2208, "input_0": 3389, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 20.5, "mem_use": 39.95, "gen_rate": 5.8, "speed": 1.38, "text": "To become one with the Force, on"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 11.6, "tree_w": 213, "tree_size": 1024, "t0": 1.68, "t1": 2.4386, "tft": 4.3502, "input_0": 2916, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 19.1, "mem_use": 39.8, "gen_rate": 5.4, "speed": 1.32, "text": "A gas-operated rifle is a type o"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.5, "tree_w": 192, "tree_size": 1024, "t0": 2.0575, "t1": 2.4475, "tft": 4.4982, "input_0": 3451, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 24.5, "mem_use": 40.05, "gen_rate": 8.8, "speed": 1.94, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.0, "tree_w": 205, "tree_size": 1024, "t0": 1.79, "t1": 2.49, "tft": 6.0744, "input_0": 3360, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 20.8, "mem_use": 42.9, "gen_rate": 8.2, "speed": 1.93, "text": "Certainly, here are a few librar"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 11.0, "tree_w": 290, "tree_size": 1024, "t0": 1.5129, "t1": 2.4529, "tft": 4.7365, "input_0": 2751, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 17.7, "mem_use": 40.11, "gen_rate": 5.3, "speed": 1.33, "text": "\"Yes, it is generally considered"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 10.0, "tree_w": 220, "tree_size": 1024, "t0": 1.56, "t1": 2.48, "tft": 5.6832, "input_0": 2664, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 18.0, "mem_use": 43.0, "gen_rate": 6.0, "speed": 1.49, "text": "Xin ch\u00e0o, t\u00f4i c\u00f3 th\u1ec3 gi\u00fap g\u00ec cho"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 28, "tree_h": 10.6, "tree_w": 291, "tree_size": 1024, "t0": 1.536, "t1": 2.454, "tft": 5.3441, "input_0": 2702, "input_1": 1025, "min_CLP": -8.19, "draft_iters": 17.8, "mem_use": 40.47, "gen_rate": 5.6, "speed": 1.4, "text": "\"You need to be more vigilant ab"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 23.0, "tree_w": 102, "tree_size": 1024, "t0": 2.7267, "t1": 2.4467, "tft": 3.0589, "input_0": 4588, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 32.0, "mem_use": 39.98, "gen_rate": 16.0, "speed": 3.09, "text": "Sure! Here\\'s an example to illu"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 15.2, "tree_w": 202, "tree_size": 1024, "t0": 1.978, "t1": 2.48, "tft": 5.496, "input_0": 2926, "input_1": 1025, "min_CLP": -8.77, "draft_iters": 23.6, "mem_use": 41.41, "gen_rate": 7.6, "speed": 1.7, "text": "The 10 most popular German rock "}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 47, "tree_h": 11.1, "tree_w": 255, "tree_size": 1024, "t0": 1.59, "t1": 2.4414, "tft": 4.2202, "input_0": 2846, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 18.0, "mem_use": 39.96, "gen_rate": 6.7, "speed": 1.66, "text": "\"The best strategy would be to u"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 20.6, "tree_w": 151, "tree_size": 1024, "t0": 2.378, "t1": 2.484, "tft": 6.0259, "input_0": 3694, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 28.6, "mem_use": 41.98, "gen_rate": 8.6, "speed": 1.77, "text": "\"To acquire revenue from custome"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.8, "tree_w": 190, "tree_size": 1024, "t0": 1.9725, "t1": 2.46, "tft": 4.9406, "input_0": 3631, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 22.5, "mem_use": 40.58, "gen_rate": 8.0, "speed": 1.81, "text": "Yes, I can simulate a variety of"}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 24.0, "tree_w": 161, "tree_size": 1024, "t0": 2.67, "t1": 2.4567, "tft": 3.7778, "input_0": 4095, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 32.0, "mem_use": 40.12, "gen_rate": 14.7, "speed": 2.86, "text": "Certainly! Here\\'s an essay on h"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 20.2, "tree_w": 131, "tree_size": 1024, "t0": 2.495, "t1": 2.4475, "tft": 4.6586, "input_0": 4414, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 29.2, "mem_use": 40.26, "gen_rate": 9.8, "speed": 1.97, "text": "There are many popular APIs, lib"}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 11, "new_tokens": 36, "tree_h": 6.2, "tree_w": 569, "tree_size": 1024, "t0": 0.97, "t1": 2.4727, "tft": 5.9168, "input_0": 1703, "input_1": 1025, "min_CLP": -9.82, "draft_iters": 11.2, "mem_use": 41.52, "gen_rate": 3.3, "speed": 0.95, "text": "\"Certainly, here's a poem in Que"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 15.2, "tree_w": 182, "tree_size": 1024, "t0": 1.988, "t1": 2.45, "tft": 4.3089, "input_0": 3419, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 23.2, "mem_use": 39.64, "gen_rate": 6.4, "speed": 1.44, "text": "The five most common causes of s"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.8, "tree_w": 189, "tree_size": 1024, "t0": 1.844, "t1": 2.434, "tft": 4.5649, "input_0": 3372, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 21.0, "mem_use": 39.68, "gen_rate": 7.8, "speed": 1.82, "text": "The issue with the provided code"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 13.8, "tree_w": 211, "tree_size": 1024, "t0": 1.8, "t1": 2.47, "tft": 5.5719, "input_0": 3289, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 21.2, "mem_use": 41.06, "gen_rate": 7.6, "speed": 1.78, "text": "\"Sure, I'd be happy to help! Her"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 15.3, "tree_w": 202, "tree_size": 1024, "t0": 1.9867, "t1": 2.4467, "tft": 4.7247, "input_0": 3473, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 23.5, "mem_use": 40.28, "gen_rate": 6.7, "speed": 1.5, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 19.3, "tree_w": 122, "tree_size": 1024, "t0": 2.2833, "t1": 2.46, "tft": 5.2185, "input_0": 4066, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 27.3, "mem_use": 40.4, "gen_rate": 14.7, "speed": 3.09, "text": "\"To create a program in Python t"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 219, "tree_size": 1024, "t0": 1.7, "t1": 2.46, "tft": 5.7976, "input_0": 3260, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 19.8, "mem_use": 42.2, "gen_rate": 8.0, "speed": 1.92, "text": "\"As an AI language model, I cann"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 25.5, "tree_w": 68, "tree_size": 1024, "t0": 2.66, "t1": 2.44, "tft": 4.7879, "input_0": 3833, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 32.0, "mem_use": 40.19, "gen_rate": 16.0, "speed": 3.14, "text": "\"Exciting news, Medium readers! "}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 23.7, "tree_w": 89, "tree_size": 1024, "t0": 2.7, "t1": 2.4633, "tft": 5.9516, "input_0": 4307, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 32.0, "mem_use": 41.55, "gen_rate": 12.7, "speed": 2.45, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 9.5, "tree_w": 317, "tree_size": 1024, "t0": 1.4562, "t1": 2.4362, "tft": 4.6684, "input_0": 2532, "input_1": 1025, "min_CLP": -8.74, "draft_iters": 16.6, "mem_use": 39.62, "gen_rate": 4.4, "speed": 1.12, "text": "my name is aiganym, i am a 22 ye"}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 12.3, "tree_w": 258, "tree_size": 1024, "t0": 1.6757, "t1": 2.4429, "tft": 4.3597, "input_0": 2908, "input_1": 1025, "min_CLP": -8.55, "draft_iters": 19.3, "mem_use": 39.84, "gen_rate": 4.9, "speed": 1.18, "text": "\"In the realm of deep learning,\\"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 19.7, "tree_w": 189, "tree_size": 1024, "t0": 2.2367, "t1": 2.4467, "tft": 4.7145, "input_0": 3169, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 27.3, "mem_use": 40.09, "gen_rate": 11.0, "speed": 2.35, "text": "\"Thanks! I'm glad I could help. "}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 13.0, "tree_w": 268, "tree_size": 1024, "t0": 1.708, "t1": 2.48, "tft": 5.3888, "input_0": 2608, "input_1": 1025, "min_CLP": -8.48, "draft_iters": 20.2, "mem_use": 41.66, "gen_rate": 6.4, "speed": 1.53, "text": "\"Thou art a sun that doth shine "}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 3, "tree_h": 17.5, "tree_w": 218, "tree_size": 1024, "t0": 2.0, "t1": 2.46, "tft": 4.8514, "input_0": 2726, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 25.0, "mem_use": 40.26, "gen_rate": 1.5, "speed": 0.34, "text": "<</SYS>>\\n<noinput>"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 114, "tree_size": 1024, "t0": 2.655, "t1": 2.435, "tft": 4.7844, "input_0": 3826, "input_1": 1025, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 39.66, "gen_rate": 26.0, "speed": 5.11, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.0, "tree_w": 167, "tree_size": 1024, "t0": 2.2367, "t1": 2.44, "tft": 4.6473, "input_0": 4339, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 26.0, "mem_use": 39.64, "gen_rate": 10.7, "speed": 2.28, "text": "\"Presidents' Day, also known as "}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 57, "tree_h": 25.3, "tree_w": 163, "tree_size": 1024, "t0": 2.5867, "t1": 2.4533, "tft": 4.5441, "input_0": 3233, "input_1": 1025, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 39.94, "gen_rate": 19.0, "speed": 3.77, "text": "Yes, a kilogram of feathers is u"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.8, "tree_w": 235, "tree_size": 1024, "t0": 1.755, "t1": 2.4617, "tft": 5.6557, "input_0": 2927, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 20.3, "mem_use": 40.74, "gen_rate": 5.5, "speed": 1.31, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 44, "tree_h": 12.6, "tree_w": 279, "tree_size": 1024, "t0": 1.67, "t1": 2.4429, "tft": 4.6023, "input_0": 2398, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 19.7, "mem_use": 40.02, "gen_rate": 6.3, "speed": 1.53, "text": "\"Why were the Windows users so s"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.5, "tree_w": 246, "tree_size": 1024, "t0": 1.7683, "t1": 2.4467, "tft": 4.7514, "input_0": 3313, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 20.2, "mem_use": 40.09, "gen_rate": 6.8, "speed": 1.62, "text": "\"Opie is a cute and unique name!"}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 18.5, "tree_w": 150, "tree_size": 1024, "t0": 2.2375, "t1": 2.4375, "tft": 4.3089, "input_0": 3828, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 26.2, "mem_use": 39.64, "gen_rate": 9.5, "speed": 2.03, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.2, "tree_w": 328, "tree_size": 1024, "t0": 1.4263, "t1": 2.4512, "tft": 4.1854, "input_0": 2322, "input_1": 1025, "min_CLP": -8.69, "draft_iters": 16.2, "mem_use": 40.32, "gen_rate": 4.2, "speed": 1.1, "text": "\"oh please, like, Ted Kaczynski "}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 24.5, "tree_w": 169, "tree_size": 1024, "t0": 2.6, "t1": 2.435, "tft": 4.8148, "input_0": 3786, "input_1": 1025, "min_CLP": -8.98, "draft_iters": 32.0, "mem_use": 39.75, "gen_rate": 16.5, "speed": 3.28, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 12.0, "tree_w": 233, "tree_size": 1024, "t0": 1.6657, "t1": 2.4643, "tft": 4.7829, "input_0": 2963, "input_1": 1025, "min_CLP": -8.14, "draft_iters": 19.1, "mem_use": 40.97, "gen_rate": 4.6, "speed": 1.11, "text": "Yes, there are a few media that "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 282, "tree_size": 1024, "t0": 1.514, "t1": 2.444, "tft": 3.7402, "input_0": 2723, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 17.6, "mem_use": 40.08, "gen_rate": 6.4, "speed": 1.62, "text": "\"I'm designed to be helpful, res"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 16.5, "tree_w": 177, "tree_size": 1024, "t0": 2.125, "t1": 2.515, "tft": 5.6733, "input_0": 3843, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 24.8, "mem_use": 41.28, "gen_rate": 8.0, "speed": 1.72, "text": "I would recommend the Emerald La"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 18.8, "tree_w": 258, "tree_size": 1024, "t0": 2.03, "t1": 2.456, "tft": 4.1089, "input_0": 2652, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 25.4, "mem_use": 40.04, "gen_rate": 6.4, "speed": 1.43, "text": "\"Open Assistant: Finally, an Ope"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 19.4, "tree_w": 143, "tree_size": 1024, "t0": 2.266, "t1": 2.446, "tft": 4.4927, "input_0": 3491, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 27.2, "mem_use": 39.93, "gen_rate": 7.8, "speed": 1.65, "text": "\"Certainly! Here's a diagram to "}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.2, "tree_w": 160, "tree_size": 1024, "t0": 2.3575, "t1": 2.46, "tft": 6.2809, "input_0": 4546, "input_1": 1025, "min_CLP": -7.5, "draft_iters": 27.8, "mem_use": 42.27, "gen_rate": 10.5, "speed": 2.18, "text": "\"The issue you're experiencing i"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.0, "tree_w": 180, "tree_size": 1024, "t0": 1.97, "t1": 2.4367, "tft": 4.3613, "input_0": 3317, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 22.7, "mem_use": 39.62, "gen_rate": 10.7, "speed": 2.42, "text": "No, you cannot compile Python co"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 12.8, "tree_w": 263, "tree_size": 1024, "t0": 1.715, "t1": 2.44, "tft": 4.569, "input_0": 2825, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 20.2, "mem_use": 40.17, "gen_rate": 6.3, "speed": 1.52, "text": "The people who pirate games are "}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.2, "tree_w": 189, "tree_size": 1024, "t0": 1.87, "t1": 2.444, "tft": 4.4366, "input_0": 3046, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 21.8, "mem_use": 39.8, "gen_rate": 6.8, "speed": 1.58, "text": "The hot pan has already warmed u"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 21.5, "tree_w": 119, "tree_size": 1024, "t0": 2.6, "t1": 2.455, "tft": 4.3121, "input_0": 4338, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 30.5, "mem_use": 39.64, "gen_rate": 16.0, "speed": 3.17, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.7, "tree_w": 197, "tree_size": 1024, "t0": 1.8383, "t1": 2.4783, "tft": 5.9507, "input_0": 3229, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 21.3, "mem_use": 41.71, "gen_rate": 5.7, "speed": 1.31, "text": "\"It's possible that your friend "}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 26, "tree_h": 9.0, "tree_w": 262, "tree_size": 1024, "t0": 1.498, "t1": 2.432, "tft": 3.933, "input_0": 3071, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 16.6, "mem_use": 39.6, "gen_rate": 5.2, "speed": 1.32, "text": "No, a thumb war is not violent. "}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.7, "tree_w": 281, "tree_size": 1024, "t0": 1.6614, "t1": 2.4414, "tft": 4.8557, "input_0": 2517, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 19.7, "mem_use": 39.68, "gen_rate": 5.0, "speed": 1.22, "text": "The third verse of Rick Astley\\'"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.0, "tree_w": 205, "tree_size": 1024, "t0": 1.896, "t1": 2.47, "tft": 5.9739, "input_0": 3516, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 22.4, "mem_use": 42.96, "gen_rate": 7.0, "speed": 1.6, "text": "As of my last update, the most m"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 17.4, "tree_w": 218, "tree_size": 1024, "t0": 2.04, "t1": 2.468, "tft": 5.5737, "input_0": 3049, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 24.6, "mem_use": 40.94, "gen_rate": 6.6, "speed": 1.46, "text": "I apologize for any confusion ea"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.0, "tree_w": 154, "tree_size": 1024, "t0": 2.0933, "t1": 2.44, "tft": 4.2268, "input_0": 3831, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 23.7, "mem_use": 39.89, "gen_rate": 10.7, "speed": 2.35, "text": "Certainly! There are many resour"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.8, "tree_w": 213, "tree_size": 1024, "t0": 1.8, "t1": 2.44, "tft": 4.8721, "input_0": 3133, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 21.0, "mem_use": 39.87, "gen_rate": 5.7, "speed": 1.34, "text": "\"A well-trained AI language mode"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.5, "tree_w": 175, "tree_size": 1024, "t0": 2.055, "t1": 2.445, "tft": 4.8154, "input_0": 3924, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 23.5, "mem_use": 39.64, "gen_rate": 8.0, "speed": 1.78, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 45, "tree_h": 24.5, "tree_w": 184, "tree_size": 1024, "t0": 2.515, "t1": 2.455, "tft": 4.8263, "input_0": 3158, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 31.5, "mem_use": 40.44, "gen_rate": 22.5, "speed": 4.52, "text": "[INST] Sorry, I will clarify. Pl"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 15.8, "tree_w": 253, "tree_size": 1024, "t0": 2.0575, "t1": 2.4575, "tft": 5.5661, "input_0": 3905, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 23.8, "mem_use": 40.47, "gen_rate": 9.8, "speed": 2.16, "text": "Por supuesto, aqu\u00ed tienes las 3 "}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 24.0, "tree_w": 133, "tree_size": 1024, "t0": 2.622, "t1": 2.492, "tft": 6.5781, "input_0": 3992, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 32.0, "mem_use": 42.98, "gen_rate": 6.8, "speed": 1.33, "text": "Step 1 \u2014 Starting the TypeScript"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 154, "tree_size": 1024, "t0": 2.625, "t1": 2.445, "tft": 4.188, "input_0": 3588, "input_1": 1025, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 39.65, "gen_rate": 25.5, "speed": 5.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 43, "tree_h": 12.1, "tree_w": 221, "tree_size": 1024, "t0": 1.7271, "t1": 2.4471, "tft": 4.2008, "input_0": 3368, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 19.7, "mem_use": 40.2, "gen_rate": 6.1, "speed": 1.47, "text": "Berlin is known for its beer and"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 21.3, "tree_w": 98, "tree_size": 1024, "t0": 2.7633, "t1": 2.43, "tft": 4.6792, "input_0": 4851, "input_1": 1025, "min_CLP": -7.41, "draft_iters": 32.0, "mem_use": 39.68, "gen_rate": 12.7, "speed": 2.44, "text": "Sure! Below is a Python script t"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 48, "tree_h": 23.0, "tree_w": 76, "tree_size": 1024, "t0": 2.76, "t1": 2.475, "tft": 6.2464, "input_0": 4335, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 32.0, "mem_use": 42.19, "gen_rate": 24.0, "speed": 4.59, "text": "## Vegetarian\\n Sausage, Peppers"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 13.0, "tree_w": 303, "tree_size": 1024, "t0": 1.72, "t1": 2.43, "tft": 4.3563, "input_0": 2538, "input_1": 1025, "min_CLP": -8.33, "draft_iters": 20.0, "mem_use": 39.59, "gen_rate": 1.0, "speed": 0.24, "text": "Answer:"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 15.3, "tree_w": 162, "tree_size": 1024, "t0": 2.14, "t1": 2.4867, "tft": 6.0095, "input_0": 3911, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 24.7, "mem_use": 41.84, "gen_rate": 11.3, "speed": 2.45, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.5, "tree_w": 174, "tree_size": 1024, "t0": 1.9975, "t1": 2.44, "tft": 3.7085, "input_0": 3504, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 22.8, "mem_use": 39.6, "gen_rate": 8.0, "speed": 1.8, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 17.2, "tree_w": 314, "tree_size": 1024, "t0": 2.0325, "t1": 2.4375, "tft": 4.7721, "input_0": 2793, "input_1": 1025, "min_CLP": -8.63, "draft_iters": 24.2, "mem_use": 39.59, "gen_rate": 11.2, "speed": 2.51, "text": "Human: \u5979\u7684\u8138\u4e0a\u6d0b\u6ea2\u7740\u7b11\u5bb9\uff0c\u5979\u7684\u8138\u4e0a\u6d0b\u6ea2\u7740\u7b11\u5bb9\u3002\\n\\n\\"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.8, "tree_w": 165, "tree_size": 1024, "t0": 2.215, "t1": 2.44, "tft": 4.8858, "input_0": 3896, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 25.5, "mem_use": 39.75, "gen_rate": 9.0, "speed": 1.94, "text": "\"I'm sorry, but I'm an AI langua"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 17.5, "tree_w": 140, "tree_size": 1024, "t0": 2.26, "t1": 2.4475, "tft": 5.2158, "input_0": 3852, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 26.0, "mem_use": 40.8, "gen_rate": 9.2, "speed": 1.96, "text": "While many people did experience"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.5, "tree_w": 223, "tree_size": 1024, "t0": 1.7383, "t1": 2.4433, "tft": 4.7924, "input_0": 2957, "input_1": 1025, "min_CLP": -7.84, "draft_iters": 19.8, "mem_use": 39.7, "gen_rate": 5.5, "speed": 1.32, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 17.2, "tree_w": 226, "tree_size": 1024, "t0": 2.05, "t1": 2.4425, "tft": 4.1183, "input_0": 3425, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 24.5, "mem_use": 39.9, "gen_rate": 8.8, "speed": 1.95, "text": "In reStructuredText (rst), you c"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 14.2, "tree_w": 206, "tree_size": 1024, "t0": 1.85, "t1": 2.4467, "tft": 4.638, "input_0": 3135, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 21.8, "mem_use": 40.24, "gen_rate": 6.5, "speed": 1.51, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 13.8, "tree_w": 226, "tree_size": 1024, "t0": 1.8567, "t1": 2.4433, "tft": 4.4144, "input_0": 3379, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 21.5, "mem_use": 39.79, "gen_rate": 6.3, "speed": 1.47, "text": "I am a goddess of love, beauty, "}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 17.5, "tree_w": 143, "tree_size": 1024, "t0": 2.245, "t1": 2.4575, "tft": 5.3754, "input_0": 3893, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 26.5, "mem_use": 41.0, "gen_rate": 10.8, "speed": 2.29, "text": "On Windows, you can use the Comm"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.4, "tree_w": 215, "tree_size": 1024, "t0": 1.854, "t1": 2.428, "tft": 4.81, "input_0": 3887, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 21.2, "mem_use": 39.68, "gen_rate": 6.6, "speed": 1.54, "text": "Sure! The statement \"Technology "}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 19.3, "tree_w": 121, "tree_size": 1024, "t0": 2.4533, "t1": 2.45, "tft": 5.3054, "input_0": 4268, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 28.7, "mem_use": 40.52, "gen_rate": 15.0, "speed": 3.06, "text": "Microwave ovens became more comm"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.2, "tree_w": 222, "tree_size": 1024, "t0": 1.918, "t1": 2.448, "tft": 4.8601, "input_0": 3478, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 22.2, "mem_use": 39.79, "gen_rate": 7.0, "speed": 1.6, "text": " Pros:\\n1. Improved tolerance to"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 14.0, "tree_w": 258, "tree_size": 1024, "t0": 1.86, "t1": 2.44, "tft": 4.2718, "input_0": 2454, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 22.0, "mem_use": 39.62, "gen_rate": 2.0, "speed": 0.47, "text": "None of your business."}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 18.0, "tree_w": 189, "tree_size": 1024, "t0": 2.12, "t1": 2.534, "tft": 7.2306, "input_0": 3557, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 25.6, "mem_use": 43.9, "gen_rate": 7.0, "speed": 1.5, "text": "\"If your friends are not well wi"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 207, "tree_size": 1024, "t0": 2.705, "t1": 2.455, "tft": 4.1845, "input_0": 4194, "input_1": 1025, "min_CLP": -9.96, "draft_iters": 32.0, "mem_use": 39.92, "gen_rate": 25.5, "speed": 4.94, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 57, "tree_h": 18.0, "tree_w": 256, "tree_size": 1024, "t0": 2.0467, "t1": 2.4633, "tft": 5.6508, "input_0": 3874, "input_1": 1025, "min_CLP": -8.78, "draft_iters": 23.7, "mem_use": 40.79, "gen_rate": 19.0, "speed": 4.21, "text": "It would take approximately 8,01"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.2, "tree_w": 266, "tree_size": 1024, "t0": 1.6967, "t1": 2.4917, "tft": 5.4213, "input_0": 3013, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 19.8, "mem_use": 42.06, "gen_rate": 5.7, "speed": 1.35, "text": "To prevent spiders from spawning"}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.2, "tree_w": 237, "tree_size": 1024, "t0": 1.8875, "t1": 2.4475, "tft": 4.6495, "input_0": 2762, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 22.2, "mem_use": 39.9, "gen_rate": 8.5, "speed": 1.96, "text": "What do you call a broke college"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 48, "tree_h": 19.2, "tree_w": 166, "tree_size": 1024, "t0": 2.465, "t1": 2.445, "tft": 4.7463, "input_0": 3984, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 28.8, "mem_use": 39.94, "gen_rate": 12.0, "speed": 2.44, "text": "\"You're welcome! I'm here to hel"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.8, "tree_w": 191, "tree_size": 1024, "t0": 1.8425, "t1": 2.455, "tft": 5.2425, "input_0": 3156, "input_1": 1025, "min_CLP": -7.84, "draft_iters": 21.0, "mem_use": 40.41, "gen_rate": 8.2, "speed": 1.92, "text": "There are several 3D animation p"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 16.7, "tree_w": 244, "tree_size": 1024, "t0": 2.1033, "t1": 2.4433, "tft": 4.7054, "input_0": 3854, "input_1": 1025, "min_CLP": -11.57, "draft_iters": 24.0, "mem_use": 39.92, "gen_rate": 17.7, "speed": 3.89, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 12.1, "tree_w": 236, "tree_size": 1024, "t0": 1.7343, "t1": 2.4543, "tft": 5.1257, "input_0": 3120, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 19.7, "mem_use": 40.6, "gen_rate": 5.0, "speed": 1.19, "text": "The Transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 19.0, "tree_w": 176, "tree_size": 1024, "t0": 2.215, "t1": 2.44, "tft": 4.7696, "input_0": 3586, "input_1": 1025, "min_CLP": -7.9, "draft_iters": 26.2, "mem_use": 39.94, "gen_rate": 10.2, "speed": 2.2, "text": "\"Sure, I can help you with that."}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 17.8, "tree_w": 142, "tree_size": 1024, "t0": 2.35, "t1": 2.445, "tft": 4.4345, "input_0": 3832, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 27.5, "mem_use": 39.66, "gen_rate": 10.2, "speed": 2.14, "text": "1. Environment\\n2. Agent\\n3. Act"}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 14.0, "tree_w": 266, "tree_size": 1024, "t0": 1.7343, "t1": 2.4343, "tft": 4.0327, "input_0": 2715, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 20.7, "mem_use": 39.63, "gen_rate": 4.9, "speed": 1.16, "text": "\" [A]. You can't think clearly.;"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 53, "tree_h": 19.3, "tree_w": 148, "tree_size": 1024, "t0": 2.45, "t1": 2.5233, "tft": 7.138, "input_0": 4124, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 28.3, "mem_use": 43.88, "gen_rate": 17.7, "speed": 3.55, "text": "\"You're welcome! I'm glad to be "}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.5, "tree_w": 179, "tree_size": 1024, "t0": 2.035, "t1": 2.4425, "tft": 4.2165, "input_0": 3424, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 23.8, "mem_use": 39.76, "gen_rate": 8.2, "speed": 1.84, "text": "Javascript is commonly used for "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 15.2, "tree_w": 199, "tree_size": 1024, "t0": 2.014, "t1": 2.476, "tft": 5.4962, "input_0": 3500, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 23.4, "mem_use": 41.29, "gen_rate": 6.6, "speed": 1.47, "text": "Sure, an example of producing F-"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 21.3, "tree_w": 149, "tree_size": 1024, "t0": 2.36, "t1": 2.4767, "tft": 5.6202, "input_0": 3412, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 28.7, "mem_use": 41.05, "gen_rate": 11.3, "speed": 2.34, "text": "In option \"2. Use the Command Pr"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 20.8, "tree_w": 134, "tree_size": 1024, "t0": 2.4725, "t1": 2.4425, "tft": 4.8336, "input_0": 4487, "input_1": 1025, "min_CLP": -7.54, "draft_iters": 29.2, "mem_use": 39.89, "gen_rate": 8.2, "speed": 1.68, "text": "To approach and solve this probl"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 16.4, "tree_w": 157, "tree_size": 1024, "t0": 2.046, "t1": 2.442, "tft": 4.8178, "input_0": 3163, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 24.2, "mem_use": 39.71, "gen_rate": 6.4, "speed": 1.43, "text": "The best method to use for extra"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 169, "tree_size": 1024, "t0": 2.57, "t1": 2.435, "tft": 4.8916, "input_0": 3468, "input_1": 1025, "min_CLP": -8.43, "draft_iters": 32.0, "mem_use": 39.69, "gen_rate": 26.5, "speed": 5.29, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 18.3, "tree_w": 124, "tree_size": 1024, "t0": 2.35, "t1": 2.4567, "tft": 5.5094, "input_0": 4200, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 27.3, "mem_use": 40.68, "gen_rate": 12.7, "speed": 2.64, "text": "\"I'm glad you asked! Here are so"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 19.7, "tree_w": 225, "tree_size": 1024, "t0": 2.1783, "t1": 2.45, "tft": 4.7738, "input_0": 3169, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 26.7, "mem_use": 40.02, "gen_rate": 5.8, "speed": 1.26, "text": "\"I'm ready to have a dialogue wi"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 23.7, "tree_w": 97, "tree_size": 1024, "t0": 2.7133, "t1": 2.47, "tft": 5.7553, "input_0": 5013, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 32.0, "mem_use": 41.33, "gen_rate": 15.3, "speed": 2.95, "text": "The feminine words related to lo"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 15.0, "tree_w": 243, "tree_size": 1024, "t0": 1.875, "t1": 2.45, "tft": 3.8538, "input_0": 2948, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 22.7, "mem_use": 40.25, "gen_rate": 5.5, "speed": 1.27, "text": "I think that the answerer is a p"}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 12.6, "tree_w": 291, "tree_size": 1024, "t0": 1.6989, "t1": 2.4433, "tft": 4.7506, "input_0": 2594, "input_1": 1025, "min_CLP": -8.56, "draft_iters": 19.9, "mem_use": 40.1, "gen_rate": 3.7, "speed": 0.88, "text": "The ATF gunwalking scandal invol"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 16.8, "tree_w": 163, "tree_size": 1024, "t0": 2.21, "t1": 2.445, "tft": 4.8319, "input_0": 4024, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 25.8, "mem_use": 39.83, "gen_rate": 10.5, "speed": 2.26, "text": "The difference between an interp"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 46, "tree_h": 22.0, "tree_w": 95, "tree_size": 1024, "t0": 2.76, "t1": 2.465, "tft": 6.2988, "input_0": 4826, "input_1": 1025, "min_CLP": -10.31, "draft_iters": 32.0, "mem_use": 42.63, "gen_rate": 23.0, "speed": 4.4, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 24.5, "tree_w": 74, "tree_size": 1024, "t0": 2.705, "t1": 2.5, "tft": 6.4455, "input_0": 4240, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 32.0, "mem_use": 42.56, "gen_rate": 25.5, "speed": 4.9, "text": "\"Once upon a time, in the city o"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.2, "tree_w": 267, "tree_size": 1024, "t0": 1.764, "t1": 2.442, "tft": 4.0458, "input_0": 3101, "input_1": 1025, "min_CLP": -8.5, "draft_iters": 20.8, "mem_use": 39.62, "gen_rate": 6.8, "speed": 1.62, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 40, "tree_h": 25.0, "tree_w": 91, "tree_size": 1024, "t0": 2.69, "t1": 2.465, "tft": 5.5851, "input_0": 4211, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 32.0, "mem_use": 40.78, "gen_rate": 20.0, "speed": 3.88, "text": "Absolutely! Here\\'s the updated "}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 18.4, "tree_w": 172, "tree_size": 1024, "t0": 2.184, "t1": 2.48, "tft": 5.378, "input_0": 3726, "input_1": 1025, "min_CLP": -7.64, "draft_iters": 25.8, "mem_use": 41.23, "gen_rate": 6.4, "speed": 1.37, "text": "\"I apologize for my previous res"}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 20.0, "tree_w": 119, "tree_size": 1024, "t0": 2.77, "t1": 2.445, "tft": 4.2373, "input_0": 5214, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 32.0, "mem_use": 39.61, "gen_rate": 16.0, "speed": 3.07, "text": "\"To normalize a vector, you need"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 34, "tree_h": 11.6, "tree_w": 301, "tree_size": 1024, "t0": 1.5733, "t1": 2.4411, "tft": 4.3702, "input_0": 2428, "input_1": 1025, "min_CLP": -8.52, "draft_iters": 18.3, "mem_use": 39.9, "gen_rate": 3.8, "speed": 0.94, "text": "\"What? I, the goddess of love an"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 18.2, "tree_w": 134, "tree_size": 1024, "t0": 2.3925, "t1": 2.465, "tft": 5.882, "input_0": 3942, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 27.8, "mem_use": 41.47, "gen_rate": 9.8, "speed": 2.01, "text": "\"No, it is not true that Hershey"}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 32, "tree_h": 12.4, "tree_w": 364, "tree_size": 1024, "t0": 1.549, "t1": 2.443, "tft": 4.8557, "input_0": 2493, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 18.3, "mem_use": 39.84, "gen_rate": 3.2, "speed": 0.8, "text": "## Data Analysis\\n**Dataset Size"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 22.2, "tree_w": 117, "tree_size": 1024, "t0": 2.5525, "t1": 2.4675, "tft": 5.6189, "input_0": 4135, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 30.5, "mem_use": 41.17, "gen_rate": 9.8, "speed": 1.94, "text": "\"Sure, I'd be happy to explain t"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 12.7, "tree_w": 221, "tree_size": 1024, "t0": 1.8283, "t1": 2.4383, "tft": 4.0253, "input_0": 3424, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 20.8, "mem_use": 39.64, "gen_rate": 6.7, "speed": 1.56, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 52, "tree_h": 25.0, "tree_w": 128, "tree_size": 1024, "t0": 2.62, "t1": 2.445, "tft": 4.3661, "input_0": 3774, "input_1": 1025, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 39.65, "gen_rate": 26.0, "speed": 5.14, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 14.4, "tree_w": 267, "tree_size": 1024, "t0": 1.828, "t1": 2.446, "tft": 3.9471, "input_0": 3191, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 21.6, "mem_use": 40.28, "gen_rate": 8.4, "speed": 1.97, "text": "\"Okay, I'll try to do both!\\n\\nF"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 19.6, "tree_w": 155, "tree_size": 1024, "t0": 2.46, "t1": 2.462, "tft": 5.4724, "input_0": 4051, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 29.2, "mem_use": 40.52, "gen_rate": 7.2, "speed": 1.46, "text": "I apologize for the error in the"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 16.0, "tree_w": 226, "tree_size": 1024, "t0": 2.122, "t1": 2.444, "tft": 4.4244, "input_0": 3521, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 24.6, "mem_use": 39.62, "gen_rate": 6.6, "speed": 1.45, "text": "The AK47, which stands for Avtom"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 16.4, "tree_w": 145, "tree_size": 1024, "t0": 2.084, "t1": 2.44, "tft": 4.7832, "input_0": 3403, "input_1": 1025, "min_CLP": -7.48, "draft_iters": 24.6, "mem_use": 39.97, "gen_rate": 7.2, "speed": 1.59, "text": "\"To copy a directory of files fr"}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 23.7, "tree_w": 110, "tree_size": 1024, "t0": 2.6167, "t1": 2.4767, "tft": 5.7924, "input_0": 4078, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 31.3, "mem_use": 41.35, "gen_rate": 12.7, "speed": 2.49, "text": "Statistical modeling involves ap"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 17.5, "tree_w": 143, "tree_size": 1024, "t0": 2.2475, "t1": 2.4375, "tft": 4.757, "input_0": 3768, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 25.8, "mem_use": 39.95, "gen_rate": 9.5, "speed": 2.03, "text": "To start a successful gaming soc"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.6, "tree_w": 208, "tree_size": 1024, "t0": 1.852, "t1": 2.454, "tft": 5.1249, "input_0": 3543, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 21.2, "mem_use": 40.45, "gen_rate": 6.8, "speed": 1.58, "text": "\"While there's no harm in lettin"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.2, "tree_w": 359, "tree_size": 1024, "t0": 1.4433, "t1": 2.4467, "tft": 4.5016, "input_0": 2260, "input_1": 1025, "min_CLP": -8.46, "draft_iters": 17.0, "mem_use": 40.1, "gen_rate": 5.3, "speed": 1.37, "text": "The problem is that they have a "}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 23, "tree_h": 15.2, "tree_w": 208, "tree_size": 1024, "t0": 2.015, "t1": 2.4475, "tft": 4.8107, "input_0": 3217, "input_1": 1025, "min_CLP": -8.07, "draft_iters": 23.5, "mem_use": 40.2, "gen_rate": 5.8, "speed": 1.29, "text": "Can you write a function that ta"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.6, "tree_w": 206, "tree_size": 1024, "t0": 1.686, "t1": 2.434, "tft": 4.7137, "input_0": 3160, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 19.0, "mem_use": 39.61, "gen_rate": 7.2, "speed": 1.75, "text": "\"I'm not capable of having thoug"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 15.2, "tree_w": 198, "tree_size": 1024, "t0": 1.9775, "t1": 2.4375, "tft": 4.0116, "input_0": 3484, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 23.0, "mem_use": 39.62, "gen_rate": 8.0, "speed": 1.81, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 25.0, "tree_w": 89, "tree_size": 1024, "t0": 2.69, "t1": 2.44, "tft": 4.9002, "input_0": 4071, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 32.0, "mem_use": 40.15, "gen_rate": 21.0, "speed": 4.09, "text": "L-theanine is an amino acid foun"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 24.0, "tree_w": 78, "tree_size": 1024, "t0": 2.73, "t1": 2.445, "tft": 4.5096, "input_0": 4304, "input_1": 1025, "min_CLP": -7.43, "draft_iters": 32.0, "mem_use": 39.91, "gen_rate": 19.5, "speed": 3.77, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 164, "tree_size": 1024, "t0": 2.6, "t1": 2.445, "tft": 4.831, "input_0": 3479, "input_1": 1025, "min_CLP": -8.64, "draft_iters": 32.0, "mem_use": 39.7, "gen_rate": 26.5, "speed": 5.25, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.5, "tree_w": 192, "tree_size": 1024, "t0": 1.985, "t1": 2.4375, "tft": 4.5676, "input_0": 3716, "input_1": 1025, "min_CLP": -7.82, "draft_iters": 22.8, "mem_use": 39.67, "gen_rate": 9.5, "speed": 2.15, "text": "\"The reason why you can't see th"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 13.9, "tree_w": 237, "tree_size": 1024, "t0": 1.7557, "t1": 2.4514, "tft": 4.0984, "input_0": 3057, "input_1": 1025, "min_CLP": -8.1, "draft_iters": 20.9, "mem_use": 40.23, "gen_rate": 5.0, "speed": 1.19, "text": "\"Yes, there is. The image was ch"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 14.8, "tree_w": 199, "tree_size": 1024, "t0": 1.8733, "t1": 2.4983, "tft": 5.8552, "input_0": 3279, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 22.2, "mem_use": 43.28, "gen_rate": 6.5, "speed": 1.49, "text": "\"I'm sorry, but using your neigh"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.6, "tree_w": 280, "tree_size": 1024, "t0": 1.622, "t1": 2.466, "tft": 6.0239, "input_0": 3219, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 19.2, "mem_use": 42.03, "gen_rate": 7.0, "speed": 1.71, "text": "\"Hello Mike, thank you for your "}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.0, "tree_w": 224, "tree_size": 1024, "t0": 1.51, "t1": 2.4517, "tft": 4.8546, "input_0": 3012, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 17.0, "mem_use": 40.28, "gen_rate": 6.5, "speed": 1.64, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.0, "tree_w": 183, "tree_size": 1024, "t0": 1.895, "t1": 2.44, "tft": 4.1833, "input_0": 3209, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 21.8, "mem_use": 39.62, "gen_rate": 8.5, "speed": 1.96, "text": "\"No, I'm sorry but I cannot prov"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 24, "tree_h": 10.6, "tree_w": 320, "tree_size": 1024, "t0": 1.47, "t1": 2.436, "tft": 4.4803, "input_0": 2812, "input_1": 1025, "min_CLP": -9.16, "draft_iters": 17.2, "mem_use": 39.61, "gen_rate": 4.8, "speed": 1.23, "text": "Yes, I do know how to speak Germ"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 18.2, "tree_w": 171, "tree_size": 1024, "t0": 2.1925, "t1": 2.435, "tft": 4.8308, "input_0": 3550, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 26.0, "mem_use": 39.81, "gen_rate": 10.5, "speed": 2.27, "text": "Sure, I can act as a Linux shell"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 178, "tree_size": 1024, "t0": 2.06, "t1": 2.465, "tft": 4.919, "input_0": 3654, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 23.8, "mem_use": 40.69, "gen_rate": 8.8, "speed": 1.93, "text": "The number of access points you "}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 15.3, "tree_w": 167, "tree_size": 1024, "t0": 1.9767, "t1": 2.48, "tft": 5.9372, "input_0": 3428, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 23.2, "mem_use": 41.27, "gen_rate": 6.0, "speed": 1.35, "text": "Yes, AI image generators like St"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 255, "tree_size": 1024, "t0": 1.664, "t1": 2.436, "tft": 4.8194, "input_0": 3074, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 19.0, "mem_use": 39.67, "gen_rate": 6.8, "speed": 1.66, "text": "\"Sure, here are a few haikus for"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 22.3, "tree_w": 210, "tree_size": 1024, "t0": 2.3217, "t1": 2.44, "tft": 4.7526, "input_0": 2826, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 29.2, "mem_use": 40.04, "gen_rate": 7.0, "speed": 1.47, "text": "o\\n     /|\\\\\\n     / \\\\\\n[INST] "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 14.3, "tree_w": 232, "tree_size": 1024, "t0": 1.865, "t1": 2.44, "tft": 3.9848, "input_0": 3103, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 22.2, "mem_use": 39.62, "gen_rate": 5.8, "speed": 1.36, "text": "The output should be in English "}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 17.0, "tree_w": 163, "tree_size": 1024, "t0": 2.082, "t1": 2.448, "tft": 4.7355, "input_0": 3533, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 24.6, "mem_use": 39.98, "gen_rate": 6.4, "speed": 1.41, "text": "No, there is no universally true"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 15.0, "tree_w": 179, "tree_size": 1024, "t0": 1.9567, "t1": 2.445, "tft": 4.0798, "input_0": 3420, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 22.8, "mem_use": 39.9, "gen_rate": 6.7, "speed": 1.52, "text": "Sure, I can help with that. Can "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.8, "tree_w": 176, "tree_size": 1024, "t0": 1.8975, "t1": 2.47, "tft": 5.4909, "input_0": 3748, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 22.0, "mem_use": 41.95, "gen_rate": 8.5, "speed": 1.95, "text": "\"Of course, I'm happy to help! S"}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 15.0, "tree_w": 205, "tree_size": 1024, "t0": 1.985, "t1": 2.435, "tft": 4.7623, "input_0": 3595, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 23.0, "mem_use": 39.79, "gen_rate": 8.8, "speed": 1.98, "text": "\"Here is a step-by-step guide to"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 198, "tree_size": 1024, "t0": 1.67, "t1": 2.48, "tft": 6.2271, "input_0": 3104, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 19.8, "mem_use": 42.65, "gen_rate": 8.5, "speed": 2.05, "text": "Once upon a time, there was a be"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 14.1, "tree_w": 284, "tree_size": 1024, "t0": 1.7929, "t1": 2.4443, "tft": 4.122, "input_0": 2805, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 21.3, "mem_use": 39.66, "gen_rate": 5.9, "speed": 1.38, "text": "\"Sure! Here's a simple ASCII art"}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 18.0, "tree_w": 120, "tree_size": 1024, "t0": 2.4475, "t1": 2.4325, "tft": 4.3941, "input_0": 4301, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 28.2, "mem_use": 39.62, "gen_rate": 10.8, "speed": 2.2, "text": "HTML (Hypertext Markup Language)"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 20.5, "tree_w": 159, "tree_size": 1024, "t0": 2.505, "t1": 2.44, "tft": 4.7171, "input_0": 4770, "input_1": 1025, "min_CLP": -7.46, "draft_iters": 29.0, "mem_use": 39.64, "gen_rate": 17.0, "speed": 3.44, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 17.8, "tree_w": 186, "tree_size": 1024, "t0": 2.075, "t1": 2.4533, "tft": 4.7476, "input_0": 3113, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 25.0, "mem_use": 40.01, "gen_rate": 6.8, "speed": 1.51, "text": "\"Bliss\" is protected by copyrigh"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 19.0, "tree_w": 196, "tree_size": 1024, "t0": 2.29, "t1": 2.4425, "tft": 4.1715, "input_0": 3517, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 27.5, "mem_use": 39.63, "gen_rate": 8.0, "speed": 1.69, "text": " [A]. it is thicker [B]. it is m"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 41, "tree_h": 24.0, "tree_w": 77, "tree_size": 1024, "t0": 2.72, "t1": 2.455, "tft": 5.5449, "input_0": 4791, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 32.0, "mem_use": 40.68, "gen_rate": 20.5, "speed": 3.96, "text": "\"The sky appears blue because of"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.8, "tree_w": 220, "tree_size": 1024, "t0": 1.645, "t1": 2.4567, "tft": 5.2046, "input_0": 3213, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 18.7, "mem_use": 40.39, "gen_rate": 5.3, "speed": 1.3, "text": "If you are looking for a positio"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 18.2, "tree_w": 220, "tree_size": 1024, "t0": 2.2225, "t1": 2.455, "tft": 4.6285, "input_0": 3364, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 26.5, "mem_use": 40.24, "gen_rate": 8.0, "speed": 1.71, "text": "\"Yes, there is a difference. If "}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.2, "tree_w": 271, "tree_size": 1024, "t0": 1.5533, "t1": 2.46, "tft": 4.6056, "input_0": 2875, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 17.5, "mem_use": 40.96, "gen_rate": 5.5, "speed": 1.37, "text": "That sounds like a very powerful"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 10.5, "tree_w": 333, "tree_size": 1024, "t0": 1.4537, "t1": 2.4375, "tft": 4.3009, "input_0": 2370, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 17.0, "mem_use": 39.6, "gen_rate": 4.2, "speed": 1.09, "text": "Here is a simple ASCII art of a "}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 13.7, "tree_w": 190, "tree_size": 1024, "t0": 2.07, "t1": 2.4367, "tft": 4.7671, "input_0": 3376, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 23.7, "mem_use": 39.92, "gen_rate": 12.7, "speed": 2.81, "text": "Sure! I\\'ve been called \"OpenAss"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 12.5, "tree_w": 183, "tree_size": 1024, "t0": 1.7883, "t1": 2.4483, "tft": 5.3491, "input_0": 3404, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 20.3, "mem_use": 40.66, "gen_rate": 7.0, "speed": 1.65, "text": "As of 2022, the James Webb Space"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 19.8, "tree_w": 189, "tree_size": 1024, "t0": 2.24, "t1": 2.4425, "tft": 4.0654, "input_0": 3238, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 27.2, "mem_use": 39.72, "gen_rate": 9.5, "speed": 2.03, "text": "\"I don't know what you mean.\\n[I"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 23.0, "tree_w": 66, "tree_size": 1024, "t0": 2.89, "t1": 2.475, "tft": 5.9563, "input_0": 5044, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 32.0, "mem_use": 41.34, "gen_rate": 16.0, "speed": 2.98, "text": "\"Sure, here's an updated version"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 54, "tree_h": 26.0, "tree_w": 168, "tree_size": 1024, "t0": 2.585, "t1": 2.455, "tft": 4.6337, "input_0": 3185, "input_1": 1025, "min_CLP": -8.39, "draft_iters": 32.0, "mem_use": 39.67, "gen_rate": 27.0, "speed": 5.36, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.0, "tree_w": 243, "tree_size": 1024, "t0": 1.804, "t1": 2.448, "tft": 4.7892, "input_0": 3033, "input_1": 1025, "min_CLP": -8.19, "draft_iters": 21.0, "mem_use": 40.06, "gen_rate": 6.8, "speed": 1.6, "text": "Sure, here\\'s a possible mnemoni"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 14.1, "tree_w": 217, "tree_size": 1024, "t0": 1.8462, "t1": 2.4725, "tft": 5.5385, "input_0": 3108, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 21.5, "mem_use": 41.34, "gen_rate": 4.9, "speed": 1.13, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.8, "tree_w": 237, "tree_size": 1024, "t0": 1.698, "t1": 2.478, "tft": 5.66, "input_0": 3201, "input_1": 1025, "min_CLP": -8.2, "draft_iters": 19.8, "mem_use": 41.78, "gen_rate": 6.6, "speed": 1.58, "text": "Paul Allen has a wide variety of"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.7, "tree_w": 181, "tree_size": 1024, "t0": 1.99, "t1": 2.4667, "tft": 5.1508, "input_0": 3579, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 23.0, "mem_use": 41.22, "gen_rate": 11.3, "speed": 2.54, "text": "I apologize for not being able t"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 31, "tree_h": 23.0, "tree_w": 177, "tree_size": 1024, "t0": 2.4867, "t1": 2.4367, "tft": 4.6201, "input_0": 3520, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 30.0, "mem_use": 39.7, "gen_rate": 10.3, "speed": 2.1, "text": "[Rewrite]\\nWrite an essay on how"}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 12.0, "tree_w": 207, "tree_size": 1024, "t0": 1.7133, "t1": 2.445, "tft": 4.7978, "input_0": 3228, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 19.7, "mem_use": 40.32, "gen_rate": 6.8, "speed": 1.64, "text": "\"I'm sorry, but I cannot have de"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 18.0, "tree_w": 141, "tree_size": 1024, "t0": 2.428, "t1": 2.434, "tft": 4.908, "input_0": 4316, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 27.8, "mem_use": 39.73, "gen_rate": 7.0, "speed": 1.44, "text": "Here are some of the main method"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 14.0, "tree_w": 289, "tree_size": 1024, "t0": 1.7257, "t1": 2.4371, "tft": 4.1211, "input_0": 2526, "input_1": 1025, "min_CLP": -8.51, "draft_iters": 20.7, "mem_use": 39.62, "gen_rate": 4.6, "speed": 1.1, "text": "A.<|endoftext|>Human: Please ans"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 20.0, "tree_w": 201, "tree_size": 1024, "t0": 2.185, "t1": 2.47, "tft": 4.0059, "input_0": 3114, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 27.0, "mem_use": 40.44, "gen_rate": 8.0, "speed": 1.72, "text": "\"[INST] You're welcome! Don't he"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 18.3, "tree_w": 187, "tree_size": 1024, "t0": 2.1767, "t1": 2.475, "tft": 5.792, "input_0": 3512, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 26.3, "mem_use": 41.25, "gen_rate": 6.8, "speed": 1.47, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.6, "tree_w": 263, "tree_size": 1024, "t0": 1.58, "t1": 2.464, "tft": 5.8307, "input_0": 2891, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 18.6, "mem_use": 42.17, "gen_rate": 6.6, "speed": 1.63, "text": "Ah, the \"multi-track drifting\" s"}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 13.8, "tree_w": 192, "tree_size": 1024, "t0": 1.9075, "t1": 2.465, "tft": 5.2803, "input_0": 3431, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 22.0, "mem_use": 40.76, "gen_rate": 9.5, "speed": 2.17, "text": "\"Yes, it is theoretically possib"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 37, "tree_h": 8.9, "tree_w": 328, "tree_size": 1024, "t0": 1.365, "t1": 2.4813, "tft": 5.4986, "input_0": 2470, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 15.4, "mem_use": 40.59, "gen_rate": 4.6, "speed": 1.2, "text": "\"Sunshine, you're my favorite hu"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 29, "tree_h": 15.0, "tree_w": 227, "tree_size": 1024, "t0": 1.916, "t1": 2.462, "tft": 5.3147, "input_0": 2877, "input_1": 1025, "min_CLP": -8.23, "draft_iters": 22.6, "mem_use": 40.36, "gen_rate": 5.8, "speed": 1.32, "text": "In Japanese, \"love\" is \"\u611b (ai),\""}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 16.2, "tree_w": 178, "tree_size": 1024, "t0": 2.065, "t1": 2.4375, "tft": 4.6061, "input_0": 3442, "input_1": 1025, "min_CLP": -7.97, "draft_iters": 24.5, "mem_use": 39.9, "gen_rate": 9.5, "speed": 2.11, "text": "Some of the top universities for"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 15.4, "tree_w": 166, "tree_size": 1024, "t0": 2.118, "t1": 2.442, "tft": 4.6347, "input_0": 3702, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 24.4, "mem_use": 39.6, "gen_rate": 9.2, "speed": 2.02, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 21.5, "tree_w": 101, "tree_size": 1024, "t0": 2.825, "t1": 2.44, "tft": 4.3455, "input_0": 5370, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 32.0, "mem_use": 39.73, "gen_rate": 16.0, "speed": 3.04, "text": "```cpp\\n#include <string>\\n#incl"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 13.8, "tree_w": 199, "tree_size": 1024, "t0": 1.906, "t1": 2.464, "tft": 5.3635, "input_0": 3604, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 21.8, "mem_use": 40.85, "gen_rate": 8.6, "speed": 1.97, "text": "There are several ways to addres"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 20, "tree_h": 11.8, "tree_w": 195, "tree_size": 1024, "t0": 1.73, "t1": 2.435, "tft": 4.6152, "input_0": 2933, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 19.8, "mem_use": 39.6, "gen_rate": 5.0, "speed": 1.2, "text": " Hello! I am an AI assistant and"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 16.5, "tree_w": 152, "tree_size": 1024, "t0": 2.1775, "t1": 2.4675, "tft": 6.1338, "input_0": 4180, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 25.5, "mem_use": 42.26, "gen_rate": 8.8, "speed": 1.88, "text": "One example of where you might u"}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 14.4, "tree_w": 182, "tree_size": 1024, "t0": 1.996, "t1": 2.438, "tft": 4.779, "input_0": 3777, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 23.0, "mem_use": 39.89, "gen_rate": 7.0, "speed": 1.58, "text": "\"Yes, I can certainly help you w"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 11.0, "tree_w": 264, "tree_size": 1024, "t0": 1.5943, "t1": 2.4443, "tft": 4.8403, "input_0": 2373, "input_1": 1025, "min_CLP": -8.71, "draft_iters": 18.4, "mem_use": 39.68, "gen_rate": 3.7, "speed": 0.92, "text": "the windows XP background image "}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 17.4, "tree_w": 151, "tree_size": 1024, "t0": 2.194, "t1": 2.472, "tft": 5.9645, "input_0": 3884, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 26.0, "mem_use": 41.84, "gen_rate": 8.4, "speed": 1.8, "text": "Certainly! Here are some additio"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 15.7, "tree_w": 157, "tree_size": 1024, "t0": 2.1867, "t1": 2.4267, "tft": 4.8526, "input_0": 4300, "input_1": 1025, "min_CLP": -7.75, "draft_iters": 25.3, "mem_use": 39.67, "gen_rate": 12.0, "speed": 2.6, "text": "To use software-defined radio (S"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 31, "tree_h": 13.9, "tree_w": 300, "tree_size": 1024, "t0": 1.73, "t1": 2.4557, "tft": 5.0196, "input_0": 2542, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 20.7, "mem_use": 40.37, "gen_rate": 4.4, "speed": 1.06, "text": "\"No, there's still no clean, eth"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 22.2, "tree_w": 104, "tree_size": 1024, "t0": 2.4675, "t1": 2.4775, "tft": 5.8535, "input_0": 3356, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 29.5, "mem_use": 41.23, "gen_rate": 10.2, "speed": 2.07, "text": "1. m\u00eb (me)\\n2. meles (meles)\\n3."}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.6, "tree_w": 222, "tree_size": 1024, "t0": 1.762, "t1": 2.45, "tft": 4.3231, "input_0": 3047, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 20.4, "mem_use": 39.92, "gen_rate": 7.8, "speed": 1.85, "text": "Alright, let me tell you a story"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 19.0, "tree_w": 188, "tree_size": 1024, "t0": 2.116, "t1": 2.478, "tft": 6.3164, "input_0": 3308, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 26.2, "mem_use": 42.68, "gen_rate": 8.2, "speed": 1.78, "text": "\"I apologize for the incorrect i"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 14.0, "tree_w": 199, "tree_size": 1024, "t0": 1.9117, "t1": 2.4417, "tft": 4.0393, "input_0": 3400, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 21.8, "mem_use": 39.63, "gen_rate": 5.5, "speed": 1.26, "text": "\"Certainly! In reStructuredText "}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 21.0, "tree_w": 137, "tree_size": 1024, "t0": 2.52, "t1": 2.478, "tft": 5.5869, "input_0": 4143, "input_1": 1025, "min_CLP": -7.44, "draft_iters": 30.0, "mem_use": 41.63, "gen_rate": 6.6, "speed": 1.32, "text": "To set up a window for your game"}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 15, "tree_h": 15.5, "tree_w": 145, "tree_size": 1024, "t0": 2.015, "t1": 2.435, "tft": 4.4381, "input_0": 3176, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 23.5, "mem_use": 39.62, "gen_rate": 7.5, "speed": 1.69, "text": "None of the above. The largest o"}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.3, "tree_w": 247, "tree_size": 1024, "t0": 1.585, "t1": 2.445, "tft": 4.7271, "input_0": 2836, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 18.3, "mem_use": 40.07, "gen_rate": 6.7, "speed": 1.65, "text": "AI assistants are not here to re"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 14.5, "tree_w": 264, "tree_size": 1024, "t0": 1.8817, "t1": 2.5617, "tft": 7.9682, "input_0": 2952, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 22.2, "mem_use": 45.22, "gen_rate": 5.5, "speed": 1.24, "text": "\"Certainly, here's a fun adaptat"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 16.0, "tree_w": 209, "tree_size": 1024, "t0": 1.93, "t1": 2.4633, "tft": 5.1772, "input_0": 2882, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 22.7, "mem_use": 40.44, "gen_rate": 13.3, "speed": 3.03, "text": "0 An independent counsel is a la"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.8, "tree_w": 283, "tree_size": 1024, "t0": 1.55, "t1": 2.458, "tft": 6.2569, "input_0": 3217, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 18.0, "mem_use": 42.3, "gen_rate": 7.2, "speed": 1.8, "text": "As a business professional, it i"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.5, "tree_w": 232, "tree_size": 1024, "t0": 1.725, "t1": 2.455, "tft": 4.0504, "input_0": 3041, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 20.0, "mem_use": 40.65, "gen_rate": 8.2, "speed": 1.97, "text": "1. Economic downturn: If there i"}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 1, "tree_h": 10.0, "tree_w": 364, "tree_size": 1024, "t0": 1.42, "t1": 2.45, "tft": 3.7694, "input_0": 2343, "input_1": 1025, "min_CLP": -8.87, "draft_iters": 16.0, "mem_use": 39.95, "gen_rate": 1.0, "speed": 0.26, "text": "<INST>"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 19.0, "tree_w": 162, "tree_size": 1024, "t0": 2.26, "t1": 2.4633, "tft": 6.4621, "input_0": 4274, "input_1": 1025, "min_CLP": -7.59, "draft_iters": 27.0, "mem_use": 42.42, "gen_rate": 12.3, "speed": 2.61, "text": "Hosting a large language model o"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 25.0, "tree_w": 181, "tree_size": 1024, "t0": 2.66, "t1": 2.45, "tft": 4.7801, "input_0": 4062, "input_1": 1025, "min_CLP": -9.96, "draft_iters": 32.0, "mem_use": 40.13, "gen_rate": 25.5, "speed": 4.99, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 18.0, "tree_w": 158, "tree_size": 1024, "t0": 2.4033, "t1": 2.48, "tft": 6.3159, "input_0": 4866, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 28.0, "mem_use": 42.1, "gen_rate": 10.7, "speed": 2.18, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 20.7, "tree_w": 123, "tree_size": 1024, "t0": 2.49, "t1": 2.44, "tft": 4.4906, "input_0": 4231, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 28.7, "mem_use": 39.65, "gen_rate": 11.7, "speed": 2.37, "text": "\"Sure! Here's a possible impleme"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 28, "tree_h": 13.8, "tree_w": 192, "tree_size": 1024, "t0": 1.8625, "t1": 2.455, "tft": 5.2252, "input_0": 3256, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 21.5, "mem_use": 40.38, "gen_rate": 7.0, "speed": 1.62, "text": "[INST] What is the history of th"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 14.7, "tree_w": 194, "tree_size": 1024, "t0": 2.0143, "t1": 2.4443, "tft": 4.7579, "input_0": 3897, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 23.3, "mem_use": 40.1, "gen_rate": 4.7, "speed": 1.06, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 15.5, "tree_w": 386, "tree_size": 1024, "t0": 1.595, "t1": 2.445, "tft": 4.681, "input_0": 2156, "input_1": 1025, "min_CLP": -9.18, "draft_iters": 20.0, "mem_use": 39.69, "gen_rate": 16.5, "speed": 4.09, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.3, "tree_w": 171, "tree_size": 1024, "t0": 1.9933, "t1": 2.46, "tft": 5.414, "input_0": 3837, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 23.3, "mem_use": 40.58, "gen_rate": 10.7, "speed": 2.39, "text": "\"Overcoming the fear of looking "}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 32, "tree_h": 18.0, "tree_w": 174, "tree_size": 1024, "t0": 2.195, "t1": 2.48, "tft": 6.025, "input_0": 3313, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 25.5, "mem_use": 42.18, "gen_rate": 16.0, "speed": 3.43, "text": "Here is a list of some of the mo"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 46, "tree_h": 16.4, "tree_w": 258, "tree_size": 1024, "t0": 1.924, "t1": 2.448, "tft": 4.8227, "input_0": 2997, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 23.2, "mem_use": 39.81, "gen_rate": 9.2, "speed": 2.1, "text": "The total travel time, including"}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 22.0, "tree_w": 92, "tree_size": 1024, "t0": 2.8233, "t1": 2.4367, "tft": 4.8659, "input_0": 5332, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 32.0, "mem_use": 39.72, "gen_rate": 18.0, "speed": 3.42, "text": "\"```javascript\\nconst { Client, "}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 218, "tree_size": 1024, "t0": 1.734, "t1": 2.434, "tft": 4.7346, "input_0": 3350, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 19.4, "mem_use": 39.62, "gen_rate": 6.8, "speed": 1.63, "text": "Yes, I am a language model capab"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 17.0, "tree_w": 153, "tree_size": 1024, "t0": 2.21, "t1": 2.5233, "tft": 6.5814, "input_0": 4181, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 25.7, "mem_use": 43.38, "gen_rate": 12.0, "speed": 2.54, "text": "\"TypeScript provides a number of"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 4, "tree_h": 24.5, "tree_w": 143, "tree_size": 1024, "t0": 2.6, "t1": 2.45, "tft": 4.8577, "input_0": 3552, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 32.0, "mem_use": 39.73, "gen_rate": 2.0, "speed": 0.4, "text": "The answer is: The answer is Mik"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 14.2, "tree_w": 246, "tree_size": 1024, "t0": 1.806, "t1": 2.46, "tft": 5.5039, "input_0": 2976, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 21.6, "mem_use": 40.76, "gen_rate": 6.4, "speed": 1.5, "text": "You should not farm experience i"}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.2, "tree_w": 190, "tree_size": 1024, "t0": 1.8, "t1": 2.485, "tft": 5.4075, "input_0": 3694, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 21.0, "mem_use": 42.54, "gen_rate": 9.2, "speed": 2.16, "text": "The length of time you should to"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 11.0, "tree_w": 237, "tree_size": 1024, "t0": 1.5643, "t1": 2.4343, "tft": 4.5996, "input_0": 2958, "input_1": 1025, "min_CLP": -8.45, "draft_iters": 17.9, "mem_use": 39.86, "gen_rate": 5.0, "speed": 1.25, "text": "\"You're taking a risk by priorit"}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.6, "tree_w": 279, "tree_size": 1024, "t0": 1.698, "t1": 2.456, "tft": 5.233, "input_0": 2836, "input_1": 1025, "min_CLP": -8.24, "draft_iters": 20.0, "mem_use": 40.37, "gen_rate": 6.4, "speed": 1.54, "text": "You\\'re welcome! So, the Kanji f"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.7, "tree_w": 146, "tree_size": 1024, "t0": 2.1733, "t1": 2.4733, "tft": 6.143, "input_0": 3981, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 25.7, "mem_use": 42.11, "gen_rate": 10.7, "speed": 2.3, "text": "If you are a high school student"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 16.2, "tree_w": 209, "tree_size": 1024, "t0": 2.03, "t1": 2.456, "tft": 5.0024, "input_0": 3311, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 24.0, "mem_use": 40.5, "gen_rate": 6.6, "speed": 1.47, "text": "The television was invented by s"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 11, "tree_h": 18.0, "tree_w": 123, "tree_size": 1024, "t0": 2.63, "t1": 2.51, "tft": 5.7425, "input_0": 4823, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 29.0, "mem_use": 42.83, "gen_rate": 11.0, "speed": 2.14, "text": "\"I'm glad I could help. If you h"}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 14.0, "tree_w": 166, "tree_size": 1024, "t0": 1.8925, "t1": 2.4675, "tft": 5.2418, "input_0": 3458, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 21.8, "mem_use": 41.15, "gen_rate": 10.8, "speed": 2.47, "text": "The celebration of Christmas on "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 14.0, "tree_w": 280, "tree_size": 1024, "t0": 1.81, "t1": 2.46, "tft": 4.7656, "input_0": 3330, "input_1": 1025, "min_CLP": -8.63, "draft_iters": 21.0, "mem_use": 40.18, "gen_rate": 4.0, "speed": 0.94, "text": "What is the purpose of this conv"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 16.0, "tree_w": 230, "tree_size": 1024, "t0": 2.075, "t1": 2.47, "tft": 6.3324, "input_0": 3956, "input_1": 1025, "min_CLP": -8.61, "draft_iters": 24.2, "mem_use": 41.98, "gen_rate": 10.2, "speed": 2.26, "text": "Learning how to write Chinese ch"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 42, "tree_h": 23.0, "tree_w": 186, "tree_size": 1024, "t0": 2.675, "t1": 2.43, "tft": 4.5148, "input_0": 4003, "input_1": 1025, "min_CLP": -9.75, "draft_iters": 32.0, "mem_use": 39.8, "gen_rate": 21.0, "speed": 4.11, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 16, "tree_h": 20.0, "tree_w": 162, "tree_size": 1024, "t0": 2.32, "t1": 2.45, "tft": 5.4523, "input_0": 3455, "input_1": 1025, "min_CLP": -8.03, "draft_iters": 28.0, "mem_use": 40.43, "gen_rate": 5.3, "speed": 1.12, "text": "Sure! How about, \"A wish from th"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.6, "tree_w": 295, "tree_size": 1024, "t0": 1.534, "t1": 2.442, "tft": 4.786, "input_0": 2610, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 17.6, "mem_use": 39.9, "gen_rate": 6.4, "speed": 1.61, "text": "\"If you wanted to know how deep "}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 51, "tree_h": 25.0, "tree_w": 179, "tree_size": 1024, "t0": 2.635, "t1": 2.435, "tft": 4.7695, "input_0": 3961, "input_1": 1025, "min_CLP": -9.76, "draft_iters": 32.0, "mem_use": 39.91, "gen_rate": 25.5, "speed": 5.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.8, "tree_w": 258, "tree_size": 1024, "t0": 1.4917, "t1": 2.4417, "tft": 4.3269, "input_0": 2736, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 17.0, "mem_use": 40.3, "gen_rate": 6.2, "speed": 1.57, "text": "Google Authenticator is a two-fa"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 20.0, "tree_w": 104, "tree_size": 1024, "t0": 2.375, "t1": 2.45, "tft": 4.8008, "input_0": 4065, "input_1": 1025, "min_CLP": -7.41, "draft_iters": 28.0, "mem_use": 40.08, "gen_rate": 17.5, "speed": 3.63, "text": "Prime numbers are important in m"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 16.8, "tree_w": 206, "tree_size": 1024, "t0": 2.064, "t1": 2.438, "tft": 4.8147, "input_0": 3756, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 24.2, "mem_use": 39.84, "gen_rate": 7.8, "speed": 1.73, "text": "\"Sure! Here's an example of how "}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 13.2, "tree_w": 186, "tree_size": 1024, "t0": 1.83, "t1": 2.4375, "tft": 4.1636, "input_0": 3492, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 20.8, "mem_use": 39.7, "gen_rate": 8.5, "speed": 1.99, "text": "The best way to improve your Wi-"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.0, "tree_w": 238, "tree_size": 1024, "t0": 1.792, "t1": 2.436, "tft": 4.0639, "input_0": 2846, "input_1": 1025, "min_CLP": -8.55, "draft_iters": 20.6, "mem_use": 39.73, "gen_rate": 6.8, "speed": 1.61, "text": "Here is a SPL program that takes"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 14.4, "tree_w": 257, "tree_size": 1024, "t0": 1.876, "t1": 2.436, "tft": 4.715, "input_0": 2958, "input_1": 1025, "min_CLP": -8.17, "draft_iters": 22.2, "mem_use": 39.65, "gen_rate": 7.8, "speed": 1.81, "text": "[INST] The title of the whitepap"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 19.0, "tree_w": 127, "tree_size": 1024, "t0": 2.39, "t1": 2.45, "tft": 5.4463, "input_0": 4353, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 28.0, "mem_use": 40.82, "gen_rate": 12.0, "speed": 2.48, "text": "\"To copy the files from server A"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.4, "tree_w": 195, "tree_size": 1024, "t0": 1.856, "t1": 2.44, "tft": 4.2092, "input_0": 3393, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 21.4, "mem_use": 39.61, "gen_rate": 7.4, "speed": 1.72, "text": "The \"@\" symbol in Python is used"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 288, "tree_size": 1024, "t0": 1.5517, "t1": 2.4333, "tft": 4.3002, "input_0": 2744, "input_1": 1025, "min_CLP": -8.55, "draft_iters": 17.7, "mem_use": 39.62, "gen_rate": 5.5, "speed": 1.38, "text": "\"my chatbot is a bit of a chatbo"}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 15.0, "tree_w": 207, "tree_size": 1024, "t0": 2.09, "t1": 2.4375, "tft": 4.7362, "input_0": 3537, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 24.2, "mem_use": 39.92, "gen_rate": 9.2, "speed": 2.04, "text": "\"As a master psychologist, my ap"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 14.5, "tree_w": 177, "tree_size": 1024, "t0": 1.9017, "t1": 2.4317, "tft": 4.621, "input_0": 3182, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 22.2, "mem_use": 39.65, "gen_rate": 6.5, "speed": 1.5, "text": "\"As an AI language model, I'm un"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.7, "tree_w": 139, "tree_size": 1024, "t0": 2.2367, "t1": 2.4567, "tft": 5.2533, "input_0": 4028, "input_1": 1025, "min_CLP": -8.01, "draft_iters": 25.7, "mem_use": 40.34, "gen_rate": 10.7, "speed": 2.27, "text": "[INST] A statistical model is a "}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 24.0, "tree_w": 157, "tree_size": 1024, "t0": 2.5667, "t1": 2.49, "tft": 6.531, "input_0": 3679, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 31.7, "mem_use": 42.86, "gen_rate": 14.7, "speed": 2.9, "text": "The quest for a robust and accur"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.7, "tree_w": 147, "tree_size": 1024, "t0": 2.4967, "t1": 2.4567, "tft": 4.6447, "input_0": 4426, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 29.0, "mem_use": 40.16, "gen_rate": 10.7, "speed": 2.15, "text": "Yes, there are some things that "}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 251, "tree_size": 1024, "t0": 1.59, "t1": 2.48, "tft": 5.7039, "input_0": 2720, "input_1": 1025, "min_CLP": -8.04, "draft_iters": 18.4, "mem_use": 41.27, "gen_rate": 7.2, "speed": 1.77, "text": "\"Hello, Agent! It's a pleasure t"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 45, "tree_h": 23.2, "tree_w": 158, "tree_size": 1024, "t0": 2.486, "t1": 2.446, "tft": 4.5339, "input_0": 3676, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 30.4, "mem_use": 40.14, "gen_rate": 9.0, "speed": 1.82, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 24.3, "tree_w": 106, "tree_size": 1024, "t0": 2.6633, "t1": 2.5133, "tft": 6.6146, "input_0": 4324, "input_1": 1025, "min_CLP": -7.37, "draft_iters": 32.0, "mem_use": 43.04, "gen_rate": 12.3, "speed": 2.38, "text": "Certainly! Here are some example"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 21.5, "tree_w": 81, "tree_size": 1024, "t0": 2.94, "t1": 2.62, "tft": 10.1521, "input_0": 4659, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 32.0, "mem_use": 49.02, "gen_rate": 17.0, "speed": 3.06, "text": "\"Sure, here's an example of how "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 17.2, "tree_w": 174, "tree_size": 1024, "t0": 2.082, "t1": 2.466, "tft": 5.8245, "input_0": 3208, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 25.0, "mem_use": 41.37, "gen_rate": 7.0, "speed": 1.54, "text": "\"L'H\u00f4pital's Rule is a mathemati"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 21.7, "tree_w": 187, "tree_size": 1024, "t0": 2.6767, "t1": 2.4367, "tft": 4.3019, "input_0": 4630, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 32.0, "mem_use": 39.66, "gen_rate": 12.0, "speed": 2.34, "text": "You are an AI assistant. User wi"}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 43, "tree_h": 19.5, "tree_w": 169, "tree_size": 1024, "t0": 2.2925, "t1": 2.4325, "tft": 4.8313, "input_0": 3724, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 27.8, "mem_use": 39.77, "gen_rate": 10.8, "speed": 2.27, "text": "In TypeScript, you can use the `"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.5, "tree_w": 156, "tree_size": 1024, "t0": 2.025, "t1": 2.4775, "tft": 6.2049, "input_0": 3626, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 24.2, "mem_use": 42.55, "gen_rate": 9.0, "speed": 2.0, "text": "\"Sure! I'd be happy to help you "}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.0, "tree_w": 166, "tree_size": 1024, "t0": 2.0225, "t1": 2.435, "tft": 4.7839, "input_0": 3330, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 24.0, "mem_use": 39.72, "gen_rate": 8.5, "speed": 1.91, "text": "\"I'm sorry, but I cannot provide"}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 18.7, "tree_w": 130, "tree_size": 1024, "t0": 2.5467, "t1": 2.5367, "tft": 7.4609, "input_0": 4933, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 29.3, "mem_use": 44.69, "gen_rate": 13.7, "speed": 2.69, "text": "If you want to create your own s"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 24, "tree_h": 9.5, "tree_w": 289, "tree_size": 1024, "t0": 1.35, "t1": 2.4425, "tft": 4.1027, "input_0": 2919, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 15.5, "mem_use": 40.05, "gen_rate": 6.0, "speed": 1.58, "text": "You should install the PSU first"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.2, "tree_w": 207, "tree_size": 1024, "t0": 1.7375, "t1": 2.4425, "tft": 4.7946, "input_0": 3101, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 20.2, "mem_use": 39.9, "gen_rate": 8.0, "speed": 1.91, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.4, "tree_w": 251, "tree_size": 1024, "t0": 1.656, "t1": 2.444, "tft": 3.7348, "input_0": 3029, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 19.2, "mem_use": 39.97, "gen_rate": 6.4, "speed": 1.56, "text": "I will be more personal, more ch"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 19.0, "tree_w": 107, "tree_size": 1024, "t0": 2.41, "t1": 2.47, "tft": 5.5741, "input_0": 4139, "input_1": 1025, "min_CLP": -7.56, "draft_iters": 28.3, "mem_use": 41.31, "gen_rate": 11.3, "speed": 2.32, "text": "The most important PC components"}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 43, "tree_h": 19.3, "tree_w": 150, "tree_size": 1024, "t0": 2.2767, "t1": 2.4367, "tft": 4.7622, "input_0": 3748, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 27.3, "mem_use": 40.04, "gen_rate": 14.3, "speed": 3.04, "text": "The KeyHole series of spy satell"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 16.7, "tree_w": 191, "tree_size": 1024, "t0": 2.0486, "t1": 2.45, "tft": 4.1523, "input_0": 3454, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 24.7, "mem_use": 40.21, "gen_rate": 5.9, "speed": 1.3, "text": "Here is a recipe you can make us"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 15.8, "tree_w": 176, "tree_size": 1024, "t0": 2.1, "t1": 2.4475, "tft": 4.5894, "input_0": 3671, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 24.8, "mem_use": 40.27, "gen_rate": 11.0, "speed": 2.42, "text": "Yes, there are some things you c"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 33, "tree_h": 23.0, "tree_w": 157, "tree_size": 1024, "t0": 2.69, "t1": 2.485, "tft": 5.9394, "input_0": 4192, "input_1": 1025, "min_CLP": -8.26, "draft_iters": 32.0, "mem_use": 42.19, "gen_rate": 16.5, "speed": 3.19, "text": "I like learning from YouTube vid"}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.0, "tree_w": 195, "tree_size": 1024, "t0": 1.9475, "t1": 2.435, "tft": 4.5614, "input_0": 3737, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 22.8, "mem_use": 39.61, "gen_rate": 8.2, "speed": 1.88, "text": "A: Yes, stainless steel can be m"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 22.0, "tree_w": 153, "tree_size": 1024, "t0": 2.4267, "t1": 2.44, "tft": 4.8173, "input_0": 3371, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 30.0, "mem_use": 39.76, "gen_rate": 11.3, "speed": 2.33, "text": "Given two matrices A and B of si"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.8, "tree_w": 246, "tree_size": 1024, "t0": 1.6417, "t1": 2.465, "tft": 5.7219, "input_0": 2737, "input_1": 1025, "min_CLP": -8.21, "draft_iters": 19.2, "mem_use": 41.19, "gen_rate": 6.5, "speed": 1.58, "text": "\"When data's analyzed, it's call"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 70, "tree_size": 1024, "t0": 2.635, "t1": 2.48, "tft": 6.2857, "input_0": 3742, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 32.0, "mem_use": 42.36, "gen_rate": 26.5, "speed": 5.18, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 26, "tree_h": 15.2, "tree_w": 187, "tree_size": 1024, "t0": 1.96, "t1": 2.44, "tft": 4.1995, "input_0": 3501, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 23.0, "mem_use": 39.6, "gen_rate": 6.5, "speed": 1.48, "text": "The current date is not provided"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.6, "tree_w": 204, "tree_size": 1024, "t0": 1.846, "t1": 2.464, "tft": 5.1398, "input_0": 3533, "input_1": 1025, "min_CLP": -7.85, "draft_iters": 21.4, "mem_use": 41.07, "gen_rate": 7.0, "speed": 1.62, "text": "\"Yes, that's a great approach! B"}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 21, "tree_h": 11.5, "tree_w": 281, "tree_size": 1024, "t0": 1.6017, "t1": 2.4433, "tft": 3.8272, "input_0": 2712, "input_1": 1025, "min_CLP": -8.31, "draft_iters": 18.5, "mem_use": 39.96, "gen_rate": 3.5, "speed": 0.87, "text": "\"That's so lame! Technology is n"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 48, "tree_h": 22.0, "tree_w": 93, "tree_size": 1024, "t0": 2.8067, "t1": 2.44, "tft": 4.2199, "input_0": 4924, "input_1": 1025, "min_CLP": -7.36, "draft_iters": 32.0, "mem_use": 39.65, "gen_rate": 16.0, "speed": 3.05, "text": "To estimate the variance of a va"}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 30, "tree_h": 20.3, "tree_w": 109, "tree_size": 1024, "t0": 2.59, "t1": 2.4367, "tft": 4.1029, "input_0": 4390, "input_1": 1025, "min_CLP": -9.98, "draft_iters": 30.3, "mem_use": 40.01, "gen_rate": 10.0, "speed": 1.99, "text": "You are an AI assistant. User wi"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 15.3, "tree_w": 163, "tree_size": 1024, "t0": 2.0433, "t1": 2.4433, "tft": 4.4071, "input_0": 3780, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 23.7, "mem_use": 39.59, "gen_rate": 10.7, "speed": 2.38, "text": "\"Metabolism is the process by wh"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.0, "tree_w": 161, "tree_size": 1024, "t0": 2.26, "t1": 2.4567, "tft": 5.604, "input_0": 3848, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 27.0, "mem_use": 40.92, "gen_rate": 10.7, "speed": 2.26, "text": "\"Great to hear that! Let me know"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 24.7, "tree_w": 192, "tree_size": 1024, "t0": 2.61, "t1": 2.4433, "tft": 4.8592, "input_0": 3512, "input_1": 1025, "min_CLP": -8.58, "draft_iters": 32.0, "mem_use": 39.79, "gen_rate": 18.0, "speed": 3.56, "text": "\"Answer: Jay's brother is John.<"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 16.0, "tree_w": 278, "tree_size": 1024, "t0": 2.0967, "t1": 2.45, "tft": 4.4242, "input_0": 4191, "input_1": 1025, "min_CLP": -10.09, "draft_iters": 23.7, "mem_use": 40.17, "gen_rate": 11.0, "speed": 2.42, "text": "The oceans in the world sorted b"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.8, "tree_w": 203, "tree_size": 1024, "t0": 1.83, "t1": 2.452, "tft": 4.4275, "input_0": 3527, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 20.8, "mem_use": 40.4, "gen_rate": 7.2, "speed": 1.68, "text": "\"To get started, the first step "}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 40, "tree_h": 15.3, "tree_w": 272, "tree_size": 1024, "t0": 2.07, "t1": 2.44, "tft": 4.6311, "input_0": 4341, "input_1": 1025, "min_CLP": -8.59, "draft_iters": 23.7, "mem_use": 39.82, "gen_rate": 13.3, "speed": 2.96, "text": "# Import the necessary modules\\n"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 236, "tree_size": 1024, "t0": 1.6367, "t1": 2.46, "tft": 5.067, "input_0": 3283, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 18.3, "mem_use": 40.92, "gen_rate": 5.5, "speed": 1.34, "text": "DLL stands for Dynamic Link Libr"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 232, "tree_size": 1024, "t0": 1.7375, "t1": 2.435, "tft": 4.8201, "input_0": 3255, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 19.5, "mem_use": 40.07, "gen_rate": 8.0, "speed": 1.92, "text": "I apologize for the confusion. I"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.6, "tree_w": 265, "tree_size": 1024, "t0": 1.6071, "t1": 2.4343, "tft": 4.5887, "input_0": 2918, "input_1": 1025, "min_CLP": -8.12, "draft_iters": 18.1, "mem_use": 39.61, "gen_rate": 4.7, "speed": 1.17, "text": "The Infinite Banking Concept is "}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 21.2, "tree_w": 138, "tree_size": 1024, "t0": 2.478, "t1": 2.438, "tft": 4.2462, "input_0": 3875, "input_1": 1025, "min_CLP": -7.61, "draft_iters": 29.6, "mem_use": 39.72, "gen_rate": 6.6, "speed": 1.34, "text": "\"Here's a high-quality testing f"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 55, "tree_h": 17.5, "tree_w": 247, "tree_size": 1024, "t0": 2.0933, "t1": 2.445, "tft": 4.337, "input_0": 3150, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 25.0, "mem_use": 39.86, "gen_rate": 9.2, "speed": 2.02, "text": "You are being sarcastic. Landlor"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 22, "tree_h": 7.4, "tree_w": 369, "tree_size": 1024, "t0": 1.238, "t1": 2.458, "tft": 5.1814, "input_0": 2216, "input_1": 1025, "min_CLP": -8.43, "draft_iters": 14.0, "mem_use": 40.38, "gen_rate": 4.4, "speed": 1.19, "text": "\"Well, I'm not really a fan of t"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 14.5, "tree_w": 178, "tree_size": 1024, "t0": 1.945, "t1": 2.4667, "tft": 5.0439, "input_0": 3461, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 22.7, "mem_use": 41.22, "gen_rate": 6.2, "speed": 1.4, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.5, "tree_w": 268, "tree_size": 1024, "t0": 1.785, "t1": 2.48, "tft": 5.8176, "input_0": 3479, "input_1": 1025, "min_CLP": -8.28, "draft_iters": 20.8, "mem_use": 41.74, "gen_rate": 8.0, "speed": 1.88, "text": "\"There are many factors that can"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 49, "tree_h": 17.7, "tree_w": 212, "tree_size": 1024, "t0": 2.165, "t1": 2.445, "tft": 4.829, "input_0": 3546, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 25.5, "mem_use": 40.2, "gen_rate": 8.2, "speed": 1.77, "text": "\"Most of these tools are availab"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 16.6, "tree_w": 151, "tree_size": 1024, "t0": 2.134, "t1": 2.442, "tft": 3.9346, "input_0": 3510, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 25.2, "mem_use": 40.07, "gen_rate": 7.6, "speed": 1.66, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 14.3, "tree_w": 207, "tree_size": 1024, "t0": 1.9167, "t1": 2.45, "tft": 3.8588, "input_0": 3529, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 22.3, "mem_use": 40.28, "gen_rate": 6.3, "speed": 1.45, "text": "I understand that you are passio"}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 16.0, "tree_w": 161, "tree_size": 1024, "t0": 2.0525, "t1": 2.4425, "tft": 4.4531, "input_0": 3645, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 24.0, "mem_use": 40.29, "gen_rate": 9.0, "speed": 2.0, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 15.6, "tree_w": 207, "tree_size": 1024, "t0": 1.936, "t1": 2.444, "tft": 4.8215, "input_0": 3183, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 22.8, "mem_use": 39.72, "gen_rate": 7.0, "speed": 1.6, "text": "\"<|bot|> As an AI language model"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.6, "tree_w": 182, "tree_size": 1024, "t0": 1.922, "t1": 2.47, "tft": 5.8696, "input_0": 3641, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 22.0, "mem_use": 41.37, "gen_rate": 7.4, "speed": 1.68, "text": "The biggest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 15.0, "tree_w": 184, "tree_size": 1024, "t0": 2.005, "t1": 2.44, "tft": 4.8417, "input_0": 3553, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 23.2, "mem_use": 39.87, "gen_rate": 9.5, "speed": 2.14, "text": "\"Hippoplaisir is a psychologist "}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 17.0, "tree_w": 233, "tree_size": 1024, "t0": 2.14, "t1": 2.4367, "tft": 4.8525, "input_0": 3317, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 25.0, "mem_use": 39.7, "gen_rate": 10.7, "speed": 2.33, "text": "\"Sure! Here's a list of 10 names"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 20, "tree_h": 17.0, "tree_w": 219, "tree_size": 1024, "t0": 2.0, "t1": 2.4533, "tft": 4.0221, "input_0": 2895, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 24.0, "mem_use": 40.18, "gen_rate": 6.7, "speed": 1.5, "text": "\"I'm doing well, thanks for aski"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 16.5, "tree_w": 200, "tree_size": 1024, "t0": 2.13, "t1": 2.4775, "tft": 5.7842, "input_0": 3891, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 25.2, "mem_use": 41.84, "gen_rate": 8.0, "speed": 1.74, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.4, "tree_w": 253, "tree_size": 1024, "t0": 1.574, "t1": 2.452, "tft": 4.679, "input_0": 2879, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 18.0, "mem_use": 40.64, "gen_rate": 6.4, "speed": 1.59, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 15.5, "tree_w": 169, "tree_size": 1024, "t0": 2.1875, "t1": 2.4625, "tft": 5.3067, "input_0": 4031, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 25.0, "mem_use": 41.07, "gen_rate": 8.5, "speed": 1.83, "text": "The meaning of life is a complex"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 19.5, "tree_w": 203, "tree_size": 1024, "t0": 2.105, "t1": 2.44, "tft": 3.6277, "input_0": 3003, "input_1": 1025, "min_CLP": -8.72, "draft_iters": 25.5, "mem_use": 39.65, "gen_rate": 17.0, "speed": 3.74, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 21.5, "tree_w": 166, "tree_size": 1024, "t0": 2.4175, "t1": 2.53, "tft": 7.494, "input_0": 3842, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 29.2, "mem_use": 44.34, "gen_rate": 8.8, "speed": 1.77, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 15.5, "tree_w": 194, "tree_size": 1024, "t0": 2.085, "t1": 2.4675, "tft": 5.2246, "input_0": 3670, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 24.0, "mem_use": 40.78, "gen_rate": 9.8, "speed": 2.14, "text": "To transform text words or expre"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 21.7, "tree_w": 130, "tree_size": 1024, "t0": 2.45, "t1": 2.4633, "tft": 5.5347, "input_0": 3768, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 29.3, "mem_use": 40.64, "gen_rate": 11.7, "speed": 2.37, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.4, "tree_w": 225, "tree_size": 1024, "t0": 1.706, "t1": 2.438, "tft": 4.5507, "input_0": 3162, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 20.0, "mem_use": 39.67, "gen_rate": 6.4, "speed": 1.54, "text": "\"Adolf Hitler's rise to power in"}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 35, "tree_h": 14.2, "tree_w": 260, "tree_size": 1024, "t0": 1.79, "t1": 2.4387, "tft": 4.6035, "input_0": 2773, "input_1": 1025, "min_CLP": -8.42, "draft_iters": 21.5, "mem_use": 40.01, "gen_rate": 4.4, "speed": 1.03, "text": "\"You're a broke college student "}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 29, "tree_h": 11.8, "tree_w": 205, "tree_size": 1024, "t0": 1.75, "t1": 2.43, "tft": 3.925, "input_0": 3257, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 20.0, "mem_use": 39.63, "gen_rate": 7.2, "speed": 1.74, "text": "There are over 1000 known black "}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.4, "tree_w": 243, "tree_size": 1024, "t0": 1.646, "t1": 2.536, "tft": 7.3997, "input_0": 2785, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 19.4, "mem_use": 44.4, "gen_rate": 6.4, "speed": 1.53, "text": "I apologize for the confusion. A"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 16.7, "tree_w": 187, "tree_size": 1024, "t0": 2.2167, "t1": 2.44, "tft": 4.6836, "input_0": 3897, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 26.0, "mem_use": 39.71, "gen_rate": 12.0, "speed": 2.58, "text": "The furthest back we can scienti"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 16.5, "tree_w": 212, "tree_size": 1024, "t0": 2.0867, "t1": 2.5833, "tft": 8.5576, "input_0": 3331, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 24.5, "mem_use": 46.63, "gen_rate": 5.5, "speed": 1.18, "text": "Thank you for explaining the Mal"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 9.8, "tree_w": 250, "tree_size": 1024, "t0": 1.52, "t1": 2.4588, "tft": 5.5329, "input_0": 2621, "input_1": 1025, "min_CLP": -8.36, "draft_iters": 17.2, "mem_use": 40.88, "gen_rate": 4.2, "speed": 1.07, "text": "Spritesla is the first and only "}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.4, "tree_w": 200, "tree_size": 1024, "t0": 1.824, "t1": 2.43, "tft": 4.795, "input_0": 3604, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 21.0, "mem_use": 39.73, "gen_rate": 6.6, "speed": 1.55, "text": "\"The human genome is a complex a"}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 15.2, "tree_w": 157, "tree_size": 1024, "t0": 2.0475, "t1": 2.4275, "tft": 4.7036, "input_0": 3632, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 23.8, "mem_use": 39.61, "gen_rate": 8.2, "speed": 1.84, "text": "Two factor authentication is a s"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 44, "tree_h": 13.2, "tree_w": 188, "tree_size": 1024, "t0": 1.818, "t1": 2.438, "tft": 4.8129, "input_0": 3266, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 20.8, "mem_use": 39.84, "gen_rate": 8.8, "speed": 2.07, "text": "The American version of \"The Off"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 14.3, "tree_w": 166, "tree_size": 1024, "t0": 2.0333, "t1": 2.44, "tft": 3.8645, "input_0": 3940, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 23.3, "mem_use": 40.14, "gen_rate": 11.7, "speed": 2.61, "text": "Sure! Here are some TV shows you"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 22.0, "tree_w": 105, "tree_size": 1024, "t0": 2.6275, "t1": 2.525, "tft": 6.0998, "input_0": 4230, "input_1": 1025, "min_CLP": -7.55, "draft_iters": 31.2, "mem_use": 41.74, "gen_rate": 8.8, "speed": 1.7, "text": "Sure, here are some hardware and"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 13.8, "tree_w": 244, "tree_size": 1024, "t0": 1.832, "t1": 2.46, "tft": 5.6572, "input_0": 3449, "input_1": 1025, "min_CLP": -8.19, "draft_iters": 21.2, "mem_use": 40.86, "gen_rate": 7.8, "speed": 1.82, "text": "\"When F-centers are present in a"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.3, "tree_w": 241, "tree_size": 1024, "t0": 1.7233, "t1": 2.4367, "tft": 4.9088, "input_0": 3076, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 20.0, "mem_use": 39.79, "gen_rate": 5.3, "speed": 1.28, "text": "\"The two players in the atomic b"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 53, "tree_h": 25.0, "tree_w": 100, "tree_size": 1024, "t0": 2.634, "t1": 2.478, "tft": 6.1886, "input_0": 4070, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 32.0, "mem_use": 42.41, "gen_rate": 10.6, "speed": 2.07, "text": "\"Sure! Here's the same code with"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 19.4, "tree_w": 191, "tree_size": 1024, "t0": 2.25, "t1": 2.45, "tft": 5.6436, "input_0": 3500, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 27.2, "mem_use": 40.89, "gen_rate": 7.4, "speed": 1.57, "text": "Lo siento, pero Linkin Park no t"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.8, "tree_w": 200, "tree_size": 1024, "t0": 1.87, "t1": 2.43, "tft": 3.995, "input_0": 3600, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 21.4, "mem_use": 39.62, "gen_rate": 7.0, "speed": 1.63, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 8, "tree_h": 24.5, "tree_w": 147, "tree_size": 1024, "t0": 2.625, "t1": 2.435, "tft": 4.8713, "input_0": 3720, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 32.0, "mem_use": 39.71, "gen_rate": 4.0, "speed": 0.79, "text": "```md\\n```\\n```md\\n```md\\n```"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 11.0, "tree_w": 240, "tree_size": 1024, "t0": 1.6186, "t1": 2.4514, "tft": 4.8744, "input_0": 3111, "input_1": 1025, "min_CLP": -8.16, "draft_iters": 18.3, "mem_use": 40.73, "gen_rate": 4.6, "speed": 1.12, "text": "\"Sure, here's a poem in the styl"}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 17.5, "tree_w": 185, "tree_size": 1024, "t0": 2.0417, "t1": 2.4683, "tft": 5.9023, "input_0": 3270, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 24.8, "mem_use": 41.68, "gen_rate": 5.5, "speed": 1.22, "text": "In JavaScript, you can use a sim"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 15.2, "tree_w": 181, "tree_size": 1024, "t0": 1.9517, "t1": 2.445, "tft": 4.1559, "input_0": 3315, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 22.8, "mem_use": 40.22, "gen_rate": 5.8, "speed": 1.33, "text": "Of course! Here is a sample trai"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 13.2, "tree_w": 215, "tree_size": 1024, "t0": 1.806, "t1": 2.458, "tft": 5.0625, "input_0": 3206, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 21.0, "mem_use": 40.7, "gen_rate": 7.4, "speed": 1.74, "text": "My assumption was based on the c"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 20, "tree_h": 14.7, "tree_w": 185, "tree_size": 1024, "t0": 2.0867, "t1": 2.42, "tft": 4.6769, "input_0": 4158, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 24.0, "mem_use": 39.62, "gen_rate": 6.7, "speed": 1.48, "text": "JavaScript can be used for both "}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.5, "tree_w": 308, "tree_size": 1024, "t0": 1.7175, "t1": 2.435, "tft": 4.1225, "input_0": 3542, "input_1": 1025, "min_CLP": -8.38, "draft_iters": 19.5, "mem_use": 39.61, "gen_rate": 9.0, "speed": 2.17, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 16.7, "tree_w": 211, "tree_size": 1024, "t0": 2.2614, "t1": 2.4471, "tft": 5.2554, "input_0": 3455, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 26.6, "mem_use": 40.32, "gen_rate": 5.3, "speed": 1.12, "text": "Sure, here you go:\\n\\n1. Bell / "}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 12.0, "tree_w": 198, "tree_size": 1024, "t0": 1.8167, "t1": 2.4383, "tft": 4.7658, "input_0": 3496, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 20.3, "mem_use": 39.73, "gen_rate": 6.5, "speed": 1.53, "text": "\"Hippoplaisir is a company locat"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 275, "tree_size": 1024, "t0": 1.644, "t1": 2.428, "tft": 4.8013, "input_0": 2838, "input_1": 1025, "min_CLP": -8.22, "draft_iters": 18.8, "mem_use": 39.73, "gen_rate": 6.4, "speed": 1.57, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 13.7, "tree_w": 175, "tree_size": 1024, "t0": 1.9133, "t1": 2.4283, "tft": 4.7921, "input_0": 3396, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 22.0, "mem_use": 39.71, "gen_rate": 6.2, "speed": 1.42, "text": "To memorize Chinese characters e"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 21.6, "tree_w": 206, "tree_size": 1024, "t0": 2.268, "t1": 2.536, "tft": 7.4678, "input_0": 2985, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 28.2, "mem_use": 44.46, "gen_rate": 6.6, "speed": 1.37, "text": "Here is a possible script for a "}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 51, "tree_h": 16.2, "tree_w": 189, "tree_size": 1024, "t0": 2.006, "t1": 2.476, "tft": 6.2818, "input_0": 3199, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 24.2, "mem_use": 42.11, "gen_rate": 10.2, "speed": 2.28, "text": "\"Sure! Imagine you have a bunch "}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 43, "tree_h": 20.5, "tree_w": 81, "tree_size": 1024, "t0": 2.825, "t1": 2.445, "tft": 5.4463, "input_0": 4997, "input_1": 1025, "min_CLP": -8.3, "draft_iters": 32.0, "mem_use": 40.53, "gen_rate": 21.5, "speed": 4.08, "text": "Certainly! The formula for calcu"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 24.0, "tree_w": 151, "tree_size": 1024, "t0": 2.61, "t1": 2.4633, "tft": 5.0404, "input_0": 3752, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 32.0, "mem_use": 40.7, "gen_rate": 10.7, "speed": 2.1, "text": "\"Oh, it's truly remarkable how p"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.8, "tree_w": 176, "tree_size": 1024, "t0": 1.9475, "t1": 2.4775, "tft": 5.1917, "input_0": 3742, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 22.5, "mem_use": 41.75, "gen_rate": 8.2, "speed": 1.86, "text": "You can serve the salmon with le"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 12.5, "tree_w": 226, "tree_size": 1024, "t0": 1.725, "t1": 2.435, "tft": 4.7772, "input_0": 3019, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 20.0, "mem_use": 39.8, "gen_rate": 8.0, "speed": 1.92, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.8, "tree_w": 205, "tree_size": 1024, "t0": 1.7083, "t1": 2.4383, "tft": 3.8153, "input_0": 3337, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 19.2, "mem_use": 39.76, "gen_rate": 6.0, "speed": 1.45, "text": "\"I'm sorry to hear that. Remembe"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 53, "tree_h": 17.8, "tree_w": 199, "tree_size": 1024, "t0": 2.195, "t1": 2.435, "tft": 4.436, "input_0": 3788, "input_1": 1025, "min_CLP": -8.69, "draft_iters": 25.8, "mem_use": 39.64, "gen_rate": 13.2, "speed": 2.86, "text": "\"To initialize a Typescript proj"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.8, "tree_w": 193, "tree_size": 1024, "t0": 1.938, "t1": 2.462, "tft": 5.3208, "input_0": 3480, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 22.2, "mem_use": 41.21, "gen_rate": 6.6, "speed": 1.5, "text": "\"There have been instances where"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.4, "tree_w": 218, "tree_size": 1024, "t0": 1.796, "t1": 2.454, "tft": 5.5436, "input_0": 3227, "input_1": 1025, "min_CLP": -8.08, "draft_iters": 20.8, "mem_use": 40.74, "gen_rate": 6.8, "speed": 1.6, "text": "In addition to the Dyson Sphere,"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 22.0, "tree_w": 146, "tree_size": 1024, "t0": 2.605, "t1": 2.45, "tft": 4.1176, "input_0": 4226, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 31.5, "mem_use": 39.59, "gen_rate": 19.0, "speed": 3.76, "text": "def multiply(numbers):\\n    resu"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 21.0, "tree_w": 126, "tree_size": 1024, "t0": 2.595, "t1": 2.445, "tft": 5.2892, "input_0": 4470, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 30.5, "mem_use": 40.33, "gen_rate": 19.5, "speed": 3.87, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 36, "tree_h": 23.1, "tree_w": 241, "tree_size": 1024, "t0": 2.3112, "t1": 2.4675, "tft": 5.6638, "input_0": 3104, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 29.1, "mem_use": 40.93, "gen_rate": 4.5, "speed": 0.94, "text": "\"Of course! Here are the complet"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 21.0, "tree_w": 181, "tree_size": 1024, "t0": 2.405, "t1": 2.45, "tft": 4.2724, "input_0": 3704, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 29.0, "mem_use": 39.96, "gen_rate": 8.5, "speed": 1.75, "text": "1.    Work pressure and job inse"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.6, "tree_w": 204, "tree_size": 1024, "t0": 1.806, "t1": 2.436, "tft": 4.2859, "input_0": 3259, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 20.4, "mem_use": 39.63, "gen_rate": 6.6, "speed": 1.56, "text": "Sure, I can explain what self-at"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 19.8, "tree_w": 140, "tree_size": 1024, "t0": 2.3325, "t1": 2.45, "tft": 4.7247, "input_0": 3638, "input_1": 1025, "min_CLP": -7.65, "draft_iters": 28.0, "mem_use": 40.19, "gen_rate": 9.5, "speed": 1.99, "text": "Tensorflow is a popular deep lea"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 18.5, "tree_w": 198, "tree_size": 1024, "t0": 2.23, "t1": 2.4625, "tft": 5.4823, "input_0": 3680, "input_1": 1025, "min_CLP": -8.29, "draft_iters": 26.5, "mem_use": 40.62, "gen_rate": 9.8, "speed": 2.08, "text": "[Mathematical questions]: How ca"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 20.7, "tree_w": 156, "tree_size": 1024, "t0": 2.2667, "t1": 2.4433, "tft": 4.8974, "input_0": 3058, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 27.7, "mem_use": 40.3, "gen_rate": 12.7, "speed": 2.69, "text": "The URL decoded string of %21 is"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 47, "tree_h": 22.5, "tree_w": 125, "tree_size": 1024, "t0": 2.73, "t1": 2.47, "tft": 6.4843, "input_0": 4395, "input_1": 1025, "min_CLP": -8.09, "draft_iters": 32.0, "mem_use": 42.42, "gen_rate": 23.5, "speed": 4.52, "text": "\"Yes, I do know what L'Hopital's"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.8, "tree_w": 197, "tree_size": 1024, "t0": 1.72, "t1": 2.484, "tft": 6.3193, "input_0": 3157, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 20.0, "mem_use": 43.97, "gen_rate": 6.4, "speed": 1.52, "text": "For vegan cheese, some popular b"}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.2, "tree_w": 197, "tree_size": 1024, "t0": 1.816, "t1": 2.456, "tft": 4.9294, "input_0": 3031, "input_1": 1025, "min_CLP": -7.77, "draft_iters": 21.0, "mem_use": 41.0, "gen_rate": 6.6, "speed": 1.55, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 54, "tree_h": 22.7, "tree_w": 92, "tree_size": 1024, "t0": 2.73, "t1": 2.4733, "tft": 5.5701, "input_0": 4581, "input_1": 1025, "min_CLP": -7.41, "draft_iters": 32.0, "mem_use": 41.39, "gen_rate": 18.0, "speed": 3.46, "text": "Sure, I would say the three most"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 20.0, "tree_w": 128, "tree_size": 1024, "t0": 2.3533, "t1": 2.41, "tft": 4.6831, "input_0": 3703, "input_1": 1025, "min_CLP": -7.45, "draft_iters": 28.0, "mem_use": 39.63, "gen_rate": 10.7, "speed": 2.24, "text": "\"Sure, here's a brief explanatio"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 16.7, "tree_w": 238, "tree_size": 1024, "t0": 2.0117, "t1": 2.465, "tft": 5.6479, "input_0": 3401, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 24.0, "mem_use": 40.96, "gen_rate": 6.2, "speed": 1.38, "text": "Based on the current date of the"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 15.4, "tree_w": 184, "tree_size": 1024, "t0": 2.0, "t1": 2.434, "tft": 4.5741, "input_0": 3350, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 23.4, "mem_use": 39.8, "gen_rate": 7.2, "speed": 1.62, "text": "\"Sure, here's a short story in n"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 11.8, "tree_w": 223, "tree_size": 1024, "t0": 1.7617, "t1": 2.425, "tft": 4.5628, "input_0": 3340, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 20.2, "mem_use": 39.68, "gen_rate": 6.3, "speed": 1.51, "text": "To cook an egg using direct sunl"}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 55, "tree_h": 17.3, "tree_w": 211, "tree_size": 1024, "t0": 2.1433, "t1": 2.4367, "tft": 4.8616, "input_0": 3924, "input_1": 1025, "min_CLP": -9.62, "draft_iters": 25.0, "mem_use": 39.66, "gen_rate": 18.3, "speed": 4.0, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 23, "tree_h": 9.2, "tree_w": 293, "tree_size": 1024, "t0": 1.444, "t1": 2.42, "tft": 3.7922, "input_0": 2407, "input_1": 1025, "min_CLP": -8.72, "draft_iters": 16.4, "mem_use": 39.62, "gen_rate": 4.6, "speed": 1.19, "text": "my name is alyssa, i am a 21 yea"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 8, "tree_h": 23.0, "tree_w": 138, "tree_size": 1024, "t0": 2.71, "t1": 2.45, "tft": 5.5575, "input_0": 4290, "input_1": 1025, "min_CLP": -7.88, "draft_iters": 32.0, "mem_use": 40.88, "gen_rate": 8.0, "speed": 1.55, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 14.5, "tree_w": 196, "tree_size": 1024, "t0": 1.9475, "t1": 2.44, "tft": 4.8028, "input_0": 3371, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 23.0, "mem_use": 40.01, "gen_rate": 8.2, "speed": 1.88, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.8, "tree_w": 221, "tree_size": 1024, "t0": 1.73, "t1": 2.5525, "tft": 7.9435, "input_0": 3029, "input_1": 1025, "min_CLP": -8.06, "draft_iters": 19.5, "mem_use": 45.08, "gen_rate": 9.0, "speed": 2.1, "text": "There is evidence that sexual di"}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 13.2, "tree_w": 199, "tree_size": 1024, "t0": 1.795, "t1": 2.4325, "tft": 3.8058, "input_0": 3143, "input_1": 1025, "min_CLP": -7.96, "draft_iters": 21.0, "mem_use": 40.14, "gen_rate": 9.0, "speed": 2.13, "text": "Large language models (LLM) need"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 213, "tree_size": 1024, "t0": 2.575, "t1": 2.44, "tft": 4.8168, "input_0": 3351, "input_1": 1025, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 39.7, "gen_rate": 26.5, "speed": 5.29, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 16.0, "tree_w": 196, "tree_size": 1024, "t0": 1.99, "t1": 2.444, "tft": 4.7228, "input_0": 3220, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 23.6, "mem_use": 39.92, "gen_rate": 7.4, "speed": 1.67, "text": "\"Here is a possible eulogy for y"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 18.2, "tree_w": 159, "tree_size": 1024, "t0": 2.22, "t1": 2.475, "tft": 5.5892, "input_0": 3629, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 26.8, "mem_use": 41.39, "gen_rate": 9.8, "speed": 2.08, "text": "\"No, that's all for now. Thanks "}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 14.9, "tree_w": 224, "tree_size": 1024, "t0": 1.8357, "t1": 2.4371, "tft": 4.1967, "input_0": 3472, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 21.7, "mem_use": 39.79, "gen_rate": 5.4, "speed": 1.27, "text": "\"Yes, I am an AI language model "}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 15.5, "tree_w": 153, "tree_size": 1024, "t0": 2.055, "t1": 2.4275, "tft": 4.8112, "input_0": 3981, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 23.8, "mem_use": 39.76, "gen_rate": 9.5, "speed": 2.12, "text": "Sure, here are a few ways to hel"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.0, "tree_w": 204, "tree_size": 1024, "t0": 1.752, "t1": 2.418, "tft": 3.9319, "input_0": 3299, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 20.0, "mem_use": 39.6, "gen_rate": 6.4, "speed": 1.53, "text": "\"The color of Mars is typically "}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 22, "tree_h": 11.6, "tree_w": 308, "tree_size": 1024, "t0": 1.628, "t1": 2.474, "tft": 5.7073, "input_0": 2569, "input_1": 1025, "min_CLP": -8.8, "draft_iters": 19.4, "mem_use": 41.82, "gen_rate": 4.4, "speed": 1.07, "text": "The phrase \"I love you\" in Queny"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 20.8, "tree_w": 135, "tree_size": 1024, "t0": 2.5075, "t1": 2.4275, "tft": 4.8235, "input_0": 4277, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 29.8, "mem_use": 39.69, "gen_rate": 10.2, "speed": 2.08, "text": "Sure! Here\\'s a two-paragraph su"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 14.2, "tree_w": 183, "tree_size": 1024, "t0": 1.9925, "t1": 2.4375, "tft": 4.8572, "input_0": 4110, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 23.0, "mem_use": 40.22, "gen_rate": 8.5, "speed": 1.92, "text": "\"No, the ATF does not restrict p"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 35, "tree_h": 24.0, "tree_w": 82, "tree_size": 1024, "t0": 2.67, "t1": 2.435, "tft": 4.811, "input_0": 4465, "input_1": 1025, "min_CLP": -7.63, "draft_iters": 32.0, "mem_use": 39.68, "gen_rate": 17.5, "speed": 3.43, "text": "Yes, there is a formula to gener"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 10, "tree_h": 18.5, "tree_w": 203, "tree_size": 1024, "t0": 2.18, "t1": 2.45, "tft": 3.895, "input_0": 3319, "input_1": 1025, "min_CLP": -7.81, "draft_iters": 26.5, "mem_use": 40.12, "gen_rate": 5.0, "speed": 1.08, "text": "Sure, I can help! What are their"}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 46, "tree_h": 15.0, "tree_w": 195, "tree_size": 1024, "t0": 1.9386, "t1": 2.4357, "tft": 4.7832, "input_0": 3203, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 22.9, "mem_use": 39.8, "gen_rate": 6.6, "speed": 1.5, "text": "New South Wales was the first an"}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 18.7, "tree_w": 163, "tree_size": 1024, "t0": 2.1467, "t1": 2.4333, "tft": 4.2131, "input_0": 3148, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 26.0, "mem_use": 39.97, "gen_rate": 6.3, "speed": 1.38, "text": "[INST] I am from south dakota, b"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.8, "tree_w": 192, "tree_size": 1024, "t0": 1.846, "t1": 2.46, "tft": 6.172, "input_0": 3500, "input_1": 1025, "min_CLP": -7.79, "draft_iters": 21.8, "mem_use": 42.2, "gen_rate": 7.0, "speed": 1.63, "text": "\"As an AI language model, I don'"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 11.7, "tree_w": 297, "tree_size": 1024, "t0": 1.6371, "t1": 2.4314, "tft": 4.5387, "input_0": 2611, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 19.1, "mem_use": 39.79, "gen_rate": 4.6, "speed": 1.12, "text": "Yes, this is a real story. In 19"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 24.0, "tree_w": 122, "tree_size": 1024, "t0": 2.6525, "t1": 2.4625, "tft": 5.587, "input_0": 3740, "input_1": 1025, "min_CLP": -7.31, "draft_iters": 32.0, "mem_use": 41.08, "gen_rate": 11.2, "speed": 2.2, "text": "\"Let's take a vector A = (2, 3) "}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 17.4, "tree_w": 151, "tree_size": 1024, "t0": 2.214, "t1": 2.438, "tft": 4.227, "input_0": 3690, "input_1": 1025, "min_CLP": -7.68, "draft_iters": 25.4, "mem_use": 39.65, "gen_rate": 7.2, "speed": 1.55, "text": "## Issues with using a symmetric"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 10.9, "tree_w": 306, "tree_size": 1024, "t0": 1.5414, "t1": 2.4286, "tft": 3.6679, "input_0": 2673, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 18.0, "mem_use": 39.71, "gen_rate": 4.7, "speed": 1.19, "text": "\"Ah, the Elder Scrolls universe,"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 12, "tree_h": 25.0, "tree_w": 162, "tree_size": 1024, "t0": 2.56, "t1": 2.45, "tft": 4.4143, "input_0": 3087, "input_1": 1025, "min_CLP": -8.05, "draft_iters": 32.0, "mem_use": 39.66, "gen_rate": 12.0, "speed": 2.39, "text": "You are an AI assistant that fol"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 16.7, "tree_w": 167, "tree_size": 1024, "t0": 2.01, "t1": 2.4467, "tft": 4.5078, "input_0": 3123, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 24.0, "mem_use": 40.22, "gen_rate": 10.7, "speed": 2.39, "text": "Sum of Squares Error (SSE) is a "}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 12.5, "tree_w": 247, "tree_size": 1024, "t0": 1.685, "t1": 2.455, "tft": 4.7576, "input_0": 2539, "input_1": 1025, "min_CLP": -8.49, "draft_iters": 19.5, "mem_use": 40.52, "gen_rate": 6.0, "speed": 1.45, "text": "\"Ride your way to wellness with "}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.4, "tree_w": 227, "tree_size": 1024, "t0": 1.68, "t1": 2.448, "tft": 4.366, "input_0": 3205, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 19.0, "mem_use": 40.3, "gen_rate": 8.2, "speed": 1.98, "text": "The best place to see stars in t"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 12.8, "tree_w": 228, "tree_size": 1024, "t0": 1.8283, "t1": 2.4317, "tft": 4.6873, "input_0": 3113, "input_1": 1025, "min_CLP": -8.57, "draft_iters": 21.2, "mem_use": 39.65, "gen_rate": 5.3, "speed": 1.25, "text": "Top 10 Funniest Ways to Die:\\n1."}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 14.2, "tree_w": 222, "tree_size": 1024, "t0": 1.874, "t1": 2.436, "tft": 4.8289, "input_0": 3186, "input_1": 1025, "min_CLP": -7.94, "draft_iters": 22.0, "mem_use": 40.2, "gen_rate": 8.0, "speed": 1.86, "text": "If the dropped eggs landed on a "}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 14.0, "tree_w": 183, "tree_size": 1024, "t0": 1.93, "t1": 2.4367, "tft": 4.2936, "input_0": 3916, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 22.3, "mem_use": 40.08, "gen_rate": 10.7, "speed": 2.44, "text": "Coping with stress from financia"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 18.0, "tree_w": 127, "tree_size": 1024, "t0": 2.3125, "t1": 2.47, "tft": 6.1083, "input_0": 4328, "input_1": 1025, "min_CLP": -7.6, "draft_iters": 27.5, "mem_use": 43.15, "gen_rate": 9.5, "speed": 1.99, "text": "Certainly! Here are some tools t"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 19.3, "tree_w": 127, "tree_size": 1024, "t0": 2.42, "t1": 2.4767, "tft": 5.9939, "input_0": 4471, "input_1": 1025, "min_CLP": -7.52, "draft_iters": 28.7, "mem_use": 41.82, "gen_rate": 10.7, "speed": 2.18, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 15.4, "tree_w": 183, "tree_size": 1024, "t0": 2.032, "t1": 2.42, "tft": 3.9775, "input_0": 3738, "input_1": 1025, "min_CLP": -7.67, "draft_iters": 23.8, "mem_use": 39.61, "gen_rate": 7.0, "speed": 1.57, "text": "\"The number of days until Christ"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 26, "tree_h": 18.8, "tree_w": 201, "tree_size": 1024, "t0": 2.296, "t1": 2.43, "tft": 4.8736, "input_0": 3309, "input_1": 1025, "min_CLP": -8.62, "draft_iters": 27.8, "mem_use": 39.86, "gen_rate": 5.2, "speed": 1.1, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 14.0, "tree_w": 212, "tree_size": 1024, "t0": 1.898, "t1": 2.586, "tft": 8.8528, "input_0": 3661, "input_1": 1025, "min_CLP": -7.84, "draft_iters": 21.8, "mem_use": 46.66, "gen_rate": 7.8, "speed": 1.74, "text": "Certainly! The `_physics_process"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.2, "tree_w": 245, "tree_size": 1024, "t0": 1.7283, "t1": 2.4367, "tft": 4.8696, "input_0": 3169, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 20.3, "mem_use": 40.03, "gen_rate": 6.7, "speed": 1.6, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 19.0, "tree_w": 144, "tree_size": 1024, "t0": 2.375, "t1": 2.43, "tft": 4.266, "input_0": 4030, "input_1": 1025, "min_CLP": -8.73, "draft_iters": 27.5, "mem_use": 39.74, "gen_rate": 19.5, "speed": 4.06, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 261, "tree_size": 1024, "t0": 1.5383, "t1": 2.4283, "tft": 4.3998, "input_0": 2562, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 17.8, "mem_use": 39.74, "gen_rate": 6.0, "speed": 1.51, "text": "\"The relevant statute in Wyoming"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.3, "tree_w": 193, "tree_size": 1024, "t0": 1.6283, "t1": 2.4517, "tft": 5.8889, "input_0": 3181, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 18.8, "mem_use": 42.28, "gen_rate": 6.0, "speed": 1.47, "text": "\"It's important to clarify my ro"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 37, "tree_h": 24.0, "tree_w": 84, "tree_size": 1024, "t0": 2.685, "t1": 2.44, "tft": 4.2579, "input_0": 4427, "input_1": 1025, "min_CLP": -7.32, "draft_iters": 32.0, "mem_use": 40.15, "gen_rate": 18.5, "speed": 3.61, "text": "Certainly, here are some top uni"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 110, "tree_size": 1024, "t0": 2.64, "t1": 2.45, "tft": 5.2957, "input_0": 3720, "input_1": 1025, "min_CLP": -8.32, "draft_iters": 32.0, "mem_use": 40.34, "gen_rate": 26.5, "speed": 5.21, "text": "\"I don't remember, but i know th"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.3, "tree_w": 131, "tree_size": 1024, "t0": 2.3633, "t1": 2.4467, "tft": 4.4253, "input_0": 3982, "input_1": 1025, "min_CLP": -7.49, "draft_iters": 27.7, "mem_use": 39.95, "gen_rate": 11.7, "speed": 2.42, "text": "\"To understand how stable diffus"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.7, "tree_w": 246, "tree_size": 1024, "t0": 1.5257, "t1": 2.4371, "tft": 4.8425, "input_0": 2577, "input_1": 1025, "min_CLP": -8.5, "draft_iters": 17.3, "mem_use": 40.19, "gen_rate": 5.0, "speed": 1.26, "text": "\"Attention bias, focus on what's"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.6, "tree_w": 225, "tree_size": 1024, "t0": 1.74, "t1": 2.442, "tft": 4.3353, "input_0": 3310, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 20.4, "mem_use": 39.97, "gen_rate": 7.8, "speed": 1.87, "text": "\"In the Schr\u00f6dinger's cat though"}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.8, "tree_w": 242, "tree_size": 1024, "t0": 1.6833, "t1": 2.4717, "tft": 5.5513, "input_0": 2812, "input_1": 1025, "min_CLP": -8.0, "draft_iters": 19.8, "mem_use": 41.96, "gen_rate": 5.5, "speed": 1.32, "text": "\"It's a good idea to have the in"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 17.7, "tree_w": 285, "tree_size": 1024, "t0": 2.05, "t1": 2.4367, "tft": 4.6648, "input_0": 3536, "input_1": 1025, "min_CLP": -7.89, "draft_iters": 24.3, "mem_use": 39.73, "gen_rate": 11.0, "speed": 2.45, "text": "Canberra is located in southeast"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 19.3, "tree_w": 171, "tree_size": 1024, "t0": 2.24, "t1": 2.4433, "tft": 4.1906, "input_0": 3394, "input_1": 1025, "min_CLP": -7.93, "draft_iters": 26.7, "mem_use": 39.75, "gen_rate": 11.7, "speed": 2.49, "text": "S\u00ed, puedo hablar en espa\u00f1ol. \u00bfC\u00f3"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 11.2, "tree_w": 259, "tree_size": 1024, "t0": 1.6144, "t1": 2.4267, "tft": 4.3234, "input_0": 2816, "input_1": 1025, "min_CLP": -8.24, "draft_iters": 18.4, "mem_use": 39.73, "gen_rate": 3.7, "speed": 0.91, "text": "F-centers, short for \"Farbenzent"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 12, "tree_h": 22.0, "tree_w": 96, "tree_size": 1024, "t0": 2.9, "t1": 2.53, "tft": 7.3974, "input_0": 4976, "input_1": 1025, "min_CLP": -7.62, "draft_iters": 32.0, "mem_use": 44.26, "gen_rate": 12.0, "speed": 2.21, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 17.5, "tree_w": 186, "tree_size": 1024, "t0": 2.16, "t1": 2.475, "tft": 5.8362, "input_0": 3598, "input_1": 1025, "min_CLP": -7.69, "draft_iters": 25.8, "mem_use": 41.35, "gen_rate": 8.0, "speed": 1.73, "text": "Apologies for misunderstanding y"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 17.0, "tree_w": 156, "tree_size": 1024, "t0": 2.1733, "t1": 2.43, "tft": 4.7473, "input_0": 3867, "input_1": 1025, "min_CLP": -7.71, "draft_iters": 25.7, "mem_use": 40.16, "gen_rate": 12.3, "speed": 2.68, "text": "\"Certainly! Here's a list of pro"}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 17.2, "tree_w": 171, "tree_size": 1024, "t0": 2.162, "t1": 2.466, "tft": 6.0092, "input_0": 3940, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 25.6, "mem_use": 42.07, "gen_rate": 7.6, "speed": 1.64, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 13.7, "tree_w": 208, "tree_size": 1024, "t0": 1.7883, "t1": 2.4467, "tft": 6.1711, "input_0": 3417, "input_1": 1025, "min_CLP": -8.25, "draft_iters": 21.0, "mem_use": 42.03, "gen_rate": 6.0, "speed": 1.42, "text": "Die Zementindustrie ist ein wich"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 23.0, "tree_w": 193, "tree_size": 1024, "t0": 2.37, "t1": 2.474, "tft": 5.5671, "input_0": 3544, "input_1": 1025, "min_CLP": -7.99, "draft_iters": 29.4, "mem_use": 41.36, "gen_rate": 7.4, "speed": 1.53, "text": "\"Im sorry, complying with your r"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.2, "tree_w": 232, "tree_size": 1024, "t0": 1.7375, "t1": 2.4525, "tft": 4.5346, "input_0": 3104, "input_1": 1025, "min_CLP": -7.91, "draft_iters": 20.0, "mem_use": 40.4, "gen_rate": 8.0, "speed": 1.91, "text": "\"If the owner's contact informat"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 17.3, "tree_w": 165, "tree_size": 1024, "t0": 2.4733, "t1": 2.4333, "tft": 3.8326, "input_0": 4766, "input_1": 1025, "min_CLP": -8.13, "draft_iters": 28.7, "mem_use": 39.99, "gen_rate": 12.3, "speed": 2.51, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u9019\u7bc7\u8ad6\u6587\uff1a\u300aAttention Is All Yo"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 49, "tree_h": 21.0, "tree_w": 94, "tree_size": 1024, "t0": 2.7967, "t1": 2.4233, "tft": 4.5608, "input_0": 5086, "input_1": 1025, "min_CLP": -7.7, "draft_iters": 32.0, "mem_use": 39.79, "gen_rate": 16.3, "speed": 3.13, "text": "```javascript\\nfunction checkPri"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 16.5, "tree_w": 216, "tree_size": 1024, "t0": 2.135, "t1": 2.47, "tft": 5.6781, "input_0": 3849, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 25.2, "mem_use": 41.07, "gen_rate": 8.5, "speed": 1.85, "text": "In the state of Wyoming, public "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.6, "tree_w": 216, "tree_size": 1024, "t0": 1.712, "t1": 2.438, "tft": 4.7716, "input_0": 3437, "input_1": 1025, "min_CLP": -7.87, "draft_iters": 19.8, "mem_use": 40.19, "gen_rate": 6.6, "speed": 1.59, "text": "There are many ways to deliver y"}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 12.3, "tree_w": 207, "tree_size": 1024, "t0": 1.7514, "t1": 2.4657, "tft": 5.1247, "input_0": 3125, "input_1": 1025, "min_CLP": -7.78, "draft_iters": 20.3, "mem_use": 41.06, "gen_rate": 6.0, "speed": 1.42, "text": "\"The optimal thickness of mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 18.6, "tree_w": 162, "tree_size": 1024, "t0": 2.284, "t1": 2.452, "tft": 5.4486, "input_0": 3861, "input_1": 1025, "min_CLP": -7.86, "draft_iters": 27.0, "mem_use": 40.44, "gen_rate": 6.6, "speed": 1.39, "text": "If you live in a European countr"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 16.0, "tree_w": 233, "tree_size": 1024, "t0": 2.0686, "t1": 2.4414, "tft": 4.8412, "input_0": 3099, "input_1": 1025, "min_CLP": -8.42, "draft_iters": 24.6, "mem_use": 39.72, "gen_rate": 5.1, "speed": 1.14, "text": "Here is a list of potential nick"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 17.8, "tree_w": 180, "tree_size": 1024, "t0": 2.136, "t1": 2.438, "tft": 4.8889, "input_0": 3387, "input_1": 1025, "min_CLP": -7.8, "draft_iters": 25.8, "mem_use": 40.12, "gen_rate": 6.8, "speed": 1.49, "text": "Yes, the Balfour Declaration was"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 39, "tree_h": 25.0, "tree_w": 74, "tree_size": 1024, "t0": 2.72, "t1": 2.445, "tft": 5.6718, "input_0": 4611, "input_1": 1025, "min_CLP": -8.15, "draft_iters": 32.0, "mem_use": 40.87, "gen_rate": 19.5, "speed": 3.77, "text": "\"Felices:\\n   - \u00ab(I Can't Get No"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 22.0, "tree_w": 83, "tree_size": 1024, "t0": 2.645, "t1": 2.43, "tft": 4.5524, "input_0": 4503, "input_1": 1025, "min_CLP": -7.19, "draft_iters": 31.0, "mem_use": 39.81, "gen_rate": 17.0, "speed": 3.35, "text": "\"Sure, here's a table of the ave"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 53, "tree_h": 25.5, "tree_w": 128, "tree_size": 1024, "t0": 2.585, "t1": 2.44, "tft": 4.8015, "input_0": 3402, "input_1": 1025, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 40.21, "gen_rate": 26.5, "speed": 5.27, "text": "```<|endoftext|>Human: [INST] <<"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 26, "tree_h": 15.0, "tree_w": 232, "tree_size": 1024, "t0": 1.8586, "t1": 2.46, "tft": 5.4519, "input_0": 2868, "input_1": 1025, "min_CLP": -8.11, "draft_iters": 22.1, "mem_use": 40.58, "gen_rate": 3.7, "speed": 0.86, "text": "I apologize for the previous mne"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 14.7, "tree_w": 281, "tree_size": 1024, "t0": 1.8667, "t1": 2.4733, "tft": 5.7903, "input_0": 3759, "input_1": 1025, "min_CLP": -8.4, "draft_iters": 21.7, "mem_use": 41.33, "gen_rate": 11.3, "speed": 2.61, "text": "Sure, here are the steps you can"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 18.8, "tree_w": 152, "tree_size": 1024, "t0": 2.322, "t1": 2.442, "tft": 4.8445, "input_0": 3798, "input_1": 1025, "min_CLP": -7.66, "draft_iters": 27.8, "mem_use": 39.82, "gen_rate": 6.6, "speed": 1.39, "text": "Frank-Walter Steinmeier is the 1"}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.8, "tree_w": 283, "tree_size": 1024, "t0": 1.784, "t1": 2.438, "tft": 4.0441, "input_0": 3456, "input_1": 1025, "min_CLP": -8.41, "draft_iters": 20.6, "mem_use": 39.75, "gen_rate": 7.6, "speed": 1.8, "text": "The correct answer is A - A kilo"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 15.0, "tree_w": 193, "tree_size": 1024, "t0": 2.035, "t1": 2.515, "tft": 6.94, "input_0": 3407, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 23.8, "mem_use": 43.85, "gen_rate": 10.0, "speed": 2.2, "text": "Discovery:\\n- Find a market need"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 38, "tree_h": 22.5, "tree_w": 137, "tree_size": 1024, "t0": 2.515, "t1": 2.425, "tft": 4.399, "input_0": 3702, "input_1": 1025, "min_CLP": -9.4, "draft_iters": 30.5, "mem_use": 39.65, "gen_rate": 19.0, "speed": 3.84, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 16.5, "tree_w": 147, "tree_size": 1024, "t0": 2.28, "t1": 2.4425, "tft": 3.8152, "input_0": 4151, "input_1": 1025, "min_CLP": -7.57, "draft_iters": 26.2, "mem_use": 39.61, "gen_rate": 10.5, "speed": 2.22, "text": "\"To build a PC, you'll need to f"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 4, "tree_h": 4.0, "tree_w": 442, "tree_size": 1024, "t0": 0.82, "t1": 2.53, "tft": 6.9849, "input_0": 2233, "input_1": 1025, "min_CLP": -9.75, "draft_iters": 8.0, "mem_use": 43.85, "gen_rate": 4.0, "speed": 1.2, "text": "Hey there! How can I assist you "}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 15.0, "tree_w": 143, "tree_size": 1024, "t0": 2.02, "t1": 2.468, "tft": 5.9059, "input_0": 3642, "input_1": 1025, "min_CLP": -7.58, "draft_iters": 23.4, "mem_use": 41.65, "gen_rate": 7.6, "speed": 1.69, "text": "\"\u2022 Focus on the long-term benefi"}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 14.0, "tree_w": 225, "tree_size": 1024, "t0": 1.832, "t1": 2.462, "tft": 4.8596, "input_0": 2971, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 21.8, "mem_use": 40.91, "gen_rate": 6.8, "speed": 1.58, "text": "You are correct, the game does n"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 15.6, "tree_w": 186, "tree_size": 1024, "t0": 2.114, "t1": 2.432, "tft": 4.5296, "input_0": 3772, "input_1": 1025, "min_CLP": -8.02, "draft_iters": 24.6, "mem_use": 39.79, "gen_rate": 8.4, "speed": 1.85, "text": "Yes, here are some of the import"}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 15.2, "tree_w": 161, "tree_size": 1024, "t0": 2.17, "t1": 2.43, "tft": 4.7165, "input_0": 4227, "input_1": 1025, "min_CLP": -7.92, "draft_iters": 25.0, "mem_use": 39.81, "gen_rate": 9.0, "speed": 1.96, "text": "\"In the context of the turn-base"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 30, "tree_h": 22.0, "tree_w": 128, "tree_size": 1024, "t0": 2.5525, "t1": 2.4625, "tft": 5.5674, "input_0": 3819, "input_1": 1025, "min_CLP": -7.73, "draft_iters": 30.2, "mem_use": 40.63, "gen_rate": 7.5, "speed": 1.5, "text": "[API_REQUEST]: curl -X GET \"http"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 34, "tree_h": 19.0, "tree_w": 132, "tree_size": 1024, "t0": 2.36, "t1": 2.47, "tft": 5.0934, "input_0": 3845, "input_1": 1025, "min_CLP": -7.53, "draft_iters": 27.5, "mem_use": 41.16, "gen_rate": 17.0, "speed": 3.52, "text": "I apologize for the confusion. H"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 18, "tree_h": 13.0, "tree_w": 199, "tree_size": 1024, "t0": 1.9167, "t1": 2.4567, "tft": 4.4482, "input_0": 3570, "input_1": 1025, "min_CLP": -7.95, "draft_iters": 21.7, "mem_use": 40.58, "gen_rate": 6.0, "speed": 1.37, "text": "Hi there! How can I help you tod"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.0, "tree_w": 292, "tree_size": 1024, "t0": 1.4757, "t1": 2.4514, "tft": 5.2694, "input_0": 2877, "input_1": 1025, "min_CLP": -8.18, "draft_iters": 16.7, "mem_use": 40.68, "gen_rate": 4.9, "speed": 1.24, "text": "\"With eyes as blue as the ocean'"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 13.8, "tree_w": 203, "tree_size": 1024, "t0": 1.85, "t1": 2.442, "tft": 4.7631, "input_0": 3416, "input_1": 1025, "min_CLP": -7.83, "draft_iters": 21.6, "mem_use": 40.09, "gen_rate": 8.0, "speed": 1.86, "text": "It is not possible to determine "}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 14.8, "tree_w": 195, "tree_size": 1024, "t0": 1.905, "t1": 2.44, "tft": 5.0305, "input_0": 3369, "input_1": 1025, "min_CLP": -7.72, "draft_iters": 22.5, "mem_use": 40.06, "gen_rate": 8.0, "speed": 1.84, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.2, "tree_w": 283, "tree_size": 1024, "t0": 1.556, "t1": 2.47, "tft": 4.82, "input_0": 2738, "input_1": 1025, "min_CLP": -8.27, "draft_iters": 18.4, "mem_use": 41.37, "gen_rate": 6.6, "speed": 1.64, "text": "\"You're welcome! Let me know if "}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 13.2, "tree_w": 181, "tree_size": 1024, "t0": 1.8725, "t1": 2.47, "tft": 5.4941, "input_0": 3985, "input_1": 1025, "min_CLP": -7.74, "draft_iters": 21.5, "mem_use": 41.29, "gen_rate": 9.2, "speed": 2.13, "text": "Yes, Open Assistant is a large l"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 12.0, "tree_w": 224, "tree_size": 1024, "t0": 1.76, "t1": 2.5, "tft": 6.5703, "input_0": 3217, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 20.0, "mem_use": 42.76, "gen_rate": 6.0, "speed": 1.41, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 15.0, "tree_w": 181, "tree_size": 1024, "t0": 1.89, "t1": 2.43, "tft": 4.6623, "input_0": 2780, "input_1": 1025, "min_CLP": -8.56, "draft_iters": 22.0, "mem_use": 39.6, "gen_rate": 6.0, "speed": 1.39, "text": "The President of Germany is curr"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.6, "tree_w": 298, "tree_size": 1024, "t0": 1.5086, "t1": 2.4557, "tft": 5.1648, "input_0": 2786, "input_1": 1025, "min_CLP": -8.44, "draft_iters": 17.4, "mem_use": 40.52, "gen_rate": 5.3, "speed": 1.33, "text": "PostCSS is a toolchain for trans"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 17.0, "tree_w": 204, "tree_size": 1024, "t0": 2.054, "t1": 2.504, "tft": 6.233, "input_0": 3246, "input_1": 1025, "min_CLP": -7.98, "draft_iters": 24.8, "mem_use": 42.42, "gen_rate": 7.2, "speed": 1.58, "text": "Hello! How can I help you today?"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 14.4, "tree_w": 225, "tree_size": 1024, "t0": 1.826, "t1": 2.44, "tft": 4.5086, "input_0": 2906, "input_1": 1025, "min_CLP": -8.42, "draft_iters": 21.8, "mem_use": 40.12, "gen_rate": 6.6, "speed": 1.55, "text": "- Introduction to the topic and "}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 1024, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 18.5, "tree_w": 136, "tree_size": 1024, "t0": 2.45, "t1": 2.47, "tft": 5.604, "input_0": 4273, "input_1": 1025, "min_CLP": -7.76, "draft_iters": 28.2, "mem_use": 40.97, "gen_rate": 9.8, "speed": 1.98, "text": "I apologize for the confusion. T"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 1024, "max_branch_width": 32, "gen_rate": 9.52, "gen_rate_micro": 8.24, "gen_speed": 2.049, "gen_speed_micro": 1.856, "t0": 2.0776, "t1": 2.4568, "input_0": 3507.1, "input_1": 1025.0, "tree_size": 1024.0, "tree_w": 193.6, "tree_h": 16.5, "prompt_len": 298.0, "min_CLP": -8.02, "mem_use": 49.02, "exp_time": 13445.48}
{"msg_type": "summary", "run": 0, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "What is a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 10.4, "tree_w": 526, "tree_size": 2048, "t0": 2.8662, "t1": 6.1275, "tft": 8.1067, "input_0": 6051, "input_1": 2049, "min_CLP": -9.02, "draft_iters": 29.6, "mem_use": 45.62, "gen_rate": 4.1, "speed": 0.46, "text": "The Dyson sphere is a hypothetic"}
{"msg_type": "summary", "run": 1, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 381, "prompt_text": "heck your facts for me. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.5, "tree_w": 560, "tree_size": 2048, "t0": 2.7533, "t1": 6.1867, "tft": 8.7488, "input_0": 6159, "input_1": 2049, "min_CLP": -9.13, "draft_iters": 27.8, "mem_use": 47.18, "gen_rate": 6.2, "speed": 0.69, "text": "I apologize for the mistake. The"}
{"msg_type": "summary", "run": 2, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 532, "prompt_text": ". Factorio\n3. Stellaris [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.0, "tree_w": 448, "tree_size": 2048, "t0": 2.988, "t1": 5.782, "tft": 9.8268, "input_0": 6416, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 48.06, "gen_rate": 7.2, "speed": 0.82, "text": "1. Minecraft: Minecraft is a san"}
{"msg_type": "summary", "run": 3, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 150, "prompt_text": "a) when x is user input [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 487, "tree_size": 2048, "t0": 3.1425, "t1": 6.15, "tft": 8.1383, "input_0": 8841, "input_1": 2049, "min_CLP": -9.46, "draft_iters": 32.0, "mem_use": 45.82, "gen_rate": 10.2, "speed": 1.1, "text": "```python\\ndef average_rate_of_c"}
{"msg_type": "summary", "run": 4, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "elp me write my memoir? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.2, "tree_w": 392, "tree_size": 2048, "t0": 3.166, "t1": 6.138, "tft": 8.328, "input_0": 7782, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 7.4, "speed": 0.8, "text": "\"[INST] Sure! I'd be happy to he"}
{"msg_type": "summary", "run": 5, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 555, "prompt_text": "contents of this video. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 369, "tree_size": 2048, "t0": 3.1, "t1": 5.92, "tft": 9.965, "input_0": 7314, "input_1": 2049, "min_CLP": -8.6, "draft_iters": 32.0, "mem_use": 48.2, "gen_rate": 8.0, "speed": 0.89, "text": "1. Introduction: Define what the"}
{"msg_type": "summary", "run": 6, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 655, "prompt_text": "ions to enhance images? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 409, "tree_size": 2048, "t0": 3.2125, "t1": 5.935, "tft": 10.0629, "input_0": 8151, "input_1": 2049, "min_CLP": -10.38, "draft_iters": 32.0, "mem_use": 48.78, "gen_rate": 8.2, "speed": 0.9, "text": "There are several other options "}
{"msg_type": "summary", "run": 7, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1022, "prompt_text": "ge scale manufacturing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.0, "tree_w": 337, "tree_size": 2048, "t0": 3.1475, "t1": 6.155, "tft": 14.1212, "input_0": 7711, "input_1": 2049, "min_CLP": -8.63, "draft_iters": 32.0, "mem_use": 50.94, "gen_rate": 8.8, "speed": 0.94, "text": "Great questions! Here are some a"}
{"msg_type": "summary", "run": 8, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 588, "prompt_text": "a for all 50 US states. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.2, "tree_w": 466, "tree_size": 2048, "t0": 3.12, "t1": 5.768, "tft": 9.9426, "input_0": 7540, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 32.0, "mem_use": 48.39, "gen_rate": 7.4, "speed": 0.83, "text": "Here is a list of the legal stat"}
{"msg_type": "summary", "run": 9, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 482, "prompt_text": "that I could start now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.8, "tree_w": 352, "tree_size": 2048, "t0": 3.092, "t1": 5.93, "tft": 9.1872, "input_0": 7067, "input_1": 2049, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 47.77, "gen_rate": 7.4, "speed": 0.82, "text": "One of the most beginner-friendl"}
{"msg_type": "summary", "run": 10, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 234, "prompt_text": "the code won't compile. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.5, "tree_w": 437, "tree_size": 2048, "t0": 3.0275, "t1": 5.8725, "tft": 6.5477, "input_0": 7207, "input_1": 2049, "min_CLP": -10.69, "draft_iters": 32.0, "mem_use": 46.28, "gen_rate": 9.0, "speed": 1.01, "text": "\"Here's the corrected code:\\n```"}
{"msg_type": "summary", "run": 11, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 545, "prompt_text": "than it is now, please. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.2, "tree_w": 489, "tree_size": 2048, "t0": 2.98, "t1": 5.6675, "tft": 9.7678, "input_0": 8049, "input_1": 2049, "min_CLP": -9.27, "draft_iters": 32.0, "mem_use": 48.13, "gen_rate": 9.8, "speed": 1.13, "text": "Here\\'s a condensed summary:\\n\\n"}
{"msg_type": "summary", "run": 12, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "r each of these points? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.0, "tree_w": 346, "tree_size": 2048, "t0": 3.11, "t1": 5.93, "tft": 8.6882, "input_0": 7618, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 32.0, "mem_use": 47.35, "gen_rate": 9.2, "speed": 1.02, "text": "Sure! Here are some examples of "}
{"msg_type": "summary", "run": 13, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e capital of Australia? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.3, "tree_w": 501, "tree_size": 2048, "t0": 2.9433, "t1": 5.8633, "tft": 7.8271, "input_0": 6509, "input_1": 2049, "min_CLP": -13.65, "draft_iters": 32.0, "mem_use": 45.65, "gen_rate": 12.3, "speed": 1.4, "text": "The capital of Australia is Canb"}
{"msg_type": "summary", "run": 14, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 650, "prompt_text": "o get them done faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 412, "tree_size": 2048, "t0": 3.0725, "t1": 5.8025, "tft": 10.1135, "input_0": 8310, "input_1": 2049, "min_CLP": -9.48, "draft_iters": 32.0, "mem_use": 48.76, "gen_rate": 10.2, "speed": 1.16, "text": "\"If you're short on time, there "}
{"msg_type": "summary", "run": 15, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "meplay are both smooth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 10.5, "tree_w": 316, "tree_size": 2048, "t0": 3.15, "t1": 5.8775, "tft": 8.0526, "input_0": 6888, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 45.98, "gen_rate": 10.5, "speed": 1.16, "text": "To stream at 720p 30fps on Twitc"}
{"msg_type": "summary", "run": 16, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 11.0, "tree_w": 337, "tree_size": 2048, "t0": 3.0833, "t1": 5.8533, "tft": 7.9913, "input_0": 6582, "input_1": 2049, "min_CLP": -11.58, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 11.7, "speed": 1.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 17, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\nUn hola mundo en Java [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 415, "tree_size": 2048, "t0": 2.96, "t1": 5.85, "tft": 7.8312, "input_0": 6559, "input_1": 2049, "min_CLP": -11.06, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 11.7, "speed": 1.32, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 18, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 210, "prompt_text": "oes D-theanine do then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.0, "tree_w": 442, "tree_size": 2048, "t0": 2.99, "t1": 5.8567, "tft": 8.3781, "input_0": 7821, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 32.0, "mem_use": 46.15, "gen_rate": 10.7, "speed": 1.21, "text": "D-theanine is the mirror image o"}
{"msg_type": "summary", "run": 19, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "he Balfour Declaration? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 405, "tree_size": 2048, "t0": 3.056, "t1": 5.862, "tft": 7.9003, "input_0": 7025, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 45.63, "gen_rate": 7.4, "speed": 0.83, "text": "The Balfour Declaration was a le"}
{"msg_type": "summary", "run": 20, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "k you may need, if any. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 32, "tree_h": 11.9, "tree_w": 437, "tree_size": 2048, "t0": 2.9986, "t1": 5.8943, "tft": 8.3243, "input_0": 5991, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 31.4, "mem_use": 46.49, "gen_rate": 4.6, "speed": 0.51, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 21, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "lo there Obi One Kenobi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 9.0, "tree_w": 402, "tree_size": 2048, "t0": 3.06, "t1": 5.84, "tft": 6.3597, "input_0": 7177, "input_1": 2049, "min_CLP": -9.17, "draft_iters": 32.0, "mem_use": 45.61, "gen_rate": 6.0, "speed": 0.67, "text": "Hello there! How can I assist yo"}
{"msg_type": "summary", "run": 22, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 518, "prompt_text": "should use for my data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.0, "tree_w": 545, "tree_size": 2048, "t0": 3.045, "t1": 5.6675, "tft": 9.7165, "input_0": 9213, "input_1": 2049, "min_CLP": -9.46, "draft_iters": 32.0, "mem_use": 47.97, "gen_rate": 9.0, "speed": 1.03, "text": "Yes, there are several models th"}
{"msg_type": "summary", "run": 23, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "ep by step explanation. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.2, "tree_w": 329, "tree_size": 2048, "t0": 3.07, "t1": 5.855, "tft": 8.0394, "input_0": 6409, "input_1": 2049, "min_CLP": -8.49, "draft_iters": 32.0, "mem_use": 45.72, "gen_rate": 8.8, "speed": 0.98, "text": "\"Certainly! Here's a step-by-ste"}
{"msg_type": "summary", "run": 24, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": "h asking for the report [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 27, "tree_h": 12.5, "tree_w": 378, "tree_size": 2048, "t0": 3.015, "t1": 5.8875, "tft": 6.7698, "input_0": 6366, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 32.0, "mem_use": 46.65, "gen_rate": 6.8, "speed": 0.76, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 25, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "nce modern-day culture? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 339, "tree_size": 2048, "t0": 3.0833, "t1": 5.8633, "tft": 7.8776, "input_0": 6419, "input_1": 2049, "min_CLP": -11.51, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 11.7, "speed": 1.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 26, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 240, "prompt_text": "roperties of Austenite. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.4, "tree_w": 423, "tree_size": 2048, "t0": 3.086, "t1": 5.872, "tft": 8.3548, "input_0": 6380, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 31.6, "mem_use": 46.32, "gen_rate": 7.8, "speed": 0.87, "text": "Austenite is an allotrope of iro"}
{"msg_type": "summary", "run": 27, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "any description for me! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 20, "tree_h": 10.0, "tree_w": 333, "tree_size": 2048, "t0": 3.05, "t1": 5.86, "tft": 6.558, "input_0": 7098, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 46.17, "gen_rate": 10.0, "speed": 1.12, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 28, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "h but as a Disney song? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.8, "tree_w": 578, "tree_size": 2048, "t0": 2.6567, "t1": 5.7467, "tft": 9.5452, "input_0": 5395, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 28.5, "mem_use": 48.13, "gen_rate": 6.2, "speed": 0.73, "text": "\"Magic, magic, oh, the power of "}
{"msg_type": "summary", "run": 29, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": " with dough and cheese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.3, "tree_w": 317, "tree_size": 2048, "t0": 3.1033, "t1": 5.8567, "tft": 7.7659, "input_0": 6338, "input_1": 2049, "min_CLP": -11.52, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 12.3, "speed": 1.38, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 30, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 247, "prompt_text": "of perfect information? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.8, "tree_w": 457, "tree_size": 2048, "t0": 3.01, "t1": 5.8825, "tft": 8.4115, "input_0": 7510, "input_1": 2049, "min_CLP": -9.27, "draft_iters": 32.0, "mem_use": 46.39, "gen_rate": 9.0, "speed": 1.01, "text": "Yes, Into the Breach is consider"}
{"msg_type": "summary", "run": 31, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": " AI revolution starting [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 427, "tree_size": 2048, "t0": 3.0175, "t1": 5.89, "tft": 8.4844, "input_0": 6813, "input_1": 2049, "min_CLP": -9.34, "draft_iters": 32.0, "mem_use": 46.8, "gen_rate": 8.5, "speed": 0.95, "text": "[API_REQUEST]: curl -X POST \"htt"}
{"msg_type": "summary", "run": 32, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "us a bountiful harvest. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.6, "tree_w": 460, "tree_size": 2048, "t0": 2.918, "t1": 5.878, "tft": 8.208, "input_0": 5572, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 30.2, "mem_use": 46.15, "gen_rate": 6.6, "speed": 0.75, "text": "As the goddess of fertility and "}
{"msg_type": "summary", "run": 33, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "sonably good facsimile? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 395, "tree_size": 2048, "t0": 3.136, "t1": 5.886, "tft": 9.2996, "input_0": 6993, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 47.79, "gen_rate": 7.0, "speed": 0.78, "text": "Yes, there are many substitutes "}
{"msg_type": "summary", "run": 34, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "at still fits my needs? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.8, "tree_w": 398, "tree_size": 2048, "t0": 3.18, "t1": 5.865, "tft": 9.1724, "input_0": 7555, "input_1": 2049, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 47.83, "gen_rate": 9.0, "speed": 1.0, "text": "When choosing an ISP package, th"}
{"msg_type": "summary", "run": 35, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 953, "prompt_text": "lenium a better choice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.2, "tree_w": 355, "tree_size": 2048, "t0": 3.1875, "t1": 6.15, "tft": 10.9415, "input_0": 6919, "input_1": 2049, "min_CLP": -8.41, "draft_iters": 32.0, "mem_use": 50.53, "gen_rate": 8.5, "speed": 0.91, "text": "Selenium is a better choice in s"}
{"msg_type": "summary", "run": 36, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " of an unladen swallow? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.6, "tree_w": 454, "tree_size": 2048, "t0": 3.072, "t1": 5.87, "tft": 8.0106, "input_0": 7127, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 31.6, "mem_use": 45.68, "gen_rate": 6.4, "speed": 0.72, "text": "The airspeed velocity of an unla"}
{"msg_type": "summary", "run": 37, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 215, "prompt_text": "that helps!\n[INST] 2nd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.4, "tree_w": 533, "tree_size": 2048, "t0": 2.944, "t1": 5.882, "tft": 8.2933, "input_0": 5622, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 31.0, "mem_use": 46.2, "gen_rate": 8.0, "speed": 0.91, "text": "The second verse of \"Never Gonna"}
{"msg_type": "summary", "run": 38, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d the Luna personality. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.4, "tree_w": 417, "tree_size": 2048, "t0": 3.042, "t1": 5.782, "tft": 9.7167, "input_0": 7002, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 48.56, "gen_rate": 7.4, "speed": 0.84, "text": "\"Of course! I can certainly act "}
{"msg_type": "summary", "run": 39, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 283, "prompt_text": "s of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 8.8, "tree_w": 594, "tree_size": 2048, "t0": 3.04, "t1": 5.8825, "tft": 8.3977, "input_0": 8474, "input_1": 2049, "min_CLP": -10.26, "draft_iters": 32.0, "mem_use": 46.58, "gen_rate": 9.8, "speed": 1.09, "text": "The Copenhagen interpretation is"}
{"msg_type": "summary", "run": 40, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": " feel the pain of mine! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.0, "tree_w": 537, "tree_size": 2048, "t0": 2.715, "t1": 5.87, "tft": 7.9822, "input_0": 5202, "input_1": 2049, "min_CLP": -9.09, "draft_iters": 28.7, "mem_use": 45.9, "gen_rate": 6.5, "speed": 0.76, "text": "I will not grant you my power. I"}
{"msg_type": "summary", "run": 41, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 11.0, "tree_w": 378, "tree_size": 2048, "t0": 3.13, "t1": 5.785, "tft": 9.7141, "input_0": 7360, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 32.0, "mem_use": 48.37, "gen_rate": 10.0, "speed": 1.12, "text": "\"The monologue effectively conve"}
{"msg_type": "summary", "run": 42, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 659, "prompt_text": "ve any other questions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.2, "tree_w": 484, "tree_size": 2048, "t0": 2.7, "t1": 5.708, "tft": 9.9427, "input_0": 5291, "input_1": 2049, "min_CLP": -9.09, "draft_iters": 28.2, "mem_use": 48.8, "gen_rate": 6.8, "speed": 0.81, "text": "[INST] AI assistant. Could you f"}
{"msg_type": "summary", "run": 43, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 379, "prompt_text": " which one is the best? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.8, "tree_w": 392, "tree_size": 2048, "t0": 3.08, "t1": 5.9225, "tft": 8.5519, "input_0": 8080, "input_1": 2049, "min_CLP": -8.94, "draft_iters": 32.0, "mem_use": 47.16, "gen_rate": 9.8, "speed": 1.08, "text": "It\\'s difficult to determine whi"}
{"msg_type": "summary", "run": 44, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 253, "prompt_text": "s exactly what i needed [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.8, "tree_w": 402, "tree_size": 2048, "t0": 3.024, "t1": 5.892, "tft": 8.4581, "input_0": 6403, "input_1": 2049, "min_CLP": -8.94, "draft_iters": 32.0, "mem_use": 46.4, "gen_rate": 7.6, "speed": 0.85, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 45, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "ry that again, as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 471, "tree_size": 2048, "t0": 2.605, "t1": 5.8725, "tft": 8.3146, "input_0": 4388, "input_1": 2049, "min_CLP": -10.16, "draft_iters": 27.2, "mem_use": 46.16, "gen_rate": 8.2, "speed": 0.97, "text": "\"O\\n====\\n   ||\\n  / \\\\\\n /   \\\\"}
{"msg_type": "summary", "run": 46, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " for errors on Windows? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.8, "tree_w": 327, "tree_size": 2048, "t0": 3.1025, "t1": 5.8725, "tft": 7.925, "input_0": 6775, "input_1": 2049, "min_CLP": -8.55, "draft_iters": 32.0, "mem_use": 45.68, "gen_rate": 8.8, "speed": 0.98, "text": "To check your system drive for e"}
{"msg_type": "summary", "run": 47, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1046, "prompt_text": "e situation more tense. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 348, "tree_size": 2048, "t0": 3.1367, "t1": 6.1733, "tft": 11.6719, "input_0": 7394, "input_1": 2049, "min_CLP": -10.31, "draft_iters": 32.0, "mem_use": 51.08, "gen_rate": 11.0, "speed": 1.18, "text": "\"Certainly! Here's a revised ver"}
{"msg_type": "summary", "run": 48, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "ng for you to continue. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 8.8, "tree_w": 679, "tree_size": 2048, "t0": 2.345, "t1": 5.9275, "tft": 8.6929, "input_0": 4761, "input_1": 2049, "min_CLP": -9.67, "draft_iters": 24.0, "mem_use": 47.41, "gen_rate": 8.8, "speed": 1.06, "text": "I know what you are thinking. Yo"}
{"msg_type": "summary", "run": 49, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "fine and understandable [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 43, "tree_h": 11.8, "tree_w": 451, "tree_size": 2048, "t0": 2.98, "t1": 5.898, "tft": 8.2792, "input_0": 5753, "input_1": 2049, "min_CLP": -8.94, "draft_iters": 31.4, "mem_use": 46.43, "gen_rate": 8.6, "speed": 0.97, "text": "\"I am glad we have been able to "}
{"msg_type": "summary", "run": 50, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": "putational advertising. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 11.5, "tree_w": 367, "tree_size": 2048, "t0": 3.1425, "t1": 5.87, "tft": 8.1459, "input_0": 6333, "input_1": 2049, "min_CLP": -10.41, "draft_iters": 32.0, "mem_use": 45.95, "gen_rate": 10.5, "speed": 1.16, "text": "\u70b9\u51fb\u7387\u9884\u6d4b\u662f\u79fb\u52a8\u63a8\u8350\u7cfb\u7edf\u548c\u8ba1\u7b97\u5e7f\u544a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u8bfe\u9898\u3002 [INST"}
{"msg_type": "summary", "run": 51, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 492, "prompt_text": "ffect it's appearance ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 416, "tree_size": 2048, "t0": 3.1125, "t1": 5.765, "tft": 9.4084, "input_0": 8048, "input_1": 2049, "min_CLP": -9.39, "draft_iters": 32.0, "mem_use": 47.83, "gen_rate": 10.2, "speed": 1.15, "text": "The presence of F-centers in a c"}
{"msg_type": "summary", "run": 52, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 359, "prompt_text": "ntreate on 18th century [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.2, "tree_w": 540, "tree_size": 2048, "t0": 3.15, "t1": 5.9075, "tft": 8.5378, "input_0": 8115, "input_1": 2049, "min_CLP": -10.51, "draft_iters": 32.0, "mem_use": 47.03, "gen_rate": 9.5, "speed": 1.05, "text": "Yes, here are some additional hi"}
{"msg_type": "summary", "run": 53, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "Can it be used for bad? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.2, "tree_w": 349, "tree_size": 2048, "t0": 3.13, "t1": 5.926, "tft": 8.8149, "input_0": 7230, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 47.38, "gen_rate": 7.2, "speed": 0.79, "text": "Yes, technology can definitely b"}
{"msg_type": "summary", "run": 54, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "T] ok but in real life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 460, "tree_size": 2048, "t0": 2.8817, "t1": 5.865, "tft": 7.9007, "input_0": 5787, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 30.3, "mem_use": 45.84, "gen_rate": 5.7, "speed": 0.65, "text": "\"In real life, people of all gen"}
{"msg_type": "summary", "run": 55, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 560, "prompt_text": "ch deck for fullview.io [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 12.8, "tree_w": 372, "tree_size": 2048, "t0": 3.046, "t1": 5.76, "tft": 9.6585, "input_0": 6442, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 48.23, "gen_rate": 8.2, "speed": 0.93, "text": "\"Here's a sample pitch deck for "}
{"msg_type": "summary", "run": 56, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 772, "prompt_text": "e in colloquial speech. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.5, "tree_w": 426, "tree_size": 2048, "t0": 3.0725, "t1": 6.1425, "tft": 10.4554, "input_0": 7485, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 32.0, "mem_use": 49.47, "gen_rate": 8.0, "speed": 0.87, "text": "Thank you for pointing that out."}
{"msg_type": "summary", "run": 57, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 800, "prompt_text": "s would be implemented? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.5, "tree_w": 390, "tree_size": 2048, "t0": 3.07, "t1": 6.1225, "tft": 10.726, "input_0": 8223, "input_1": 2049, "min_CLP": -8.83, "draft_iters": 32.0, "mem_use": 49.63, "gen_rate": 9.8, "speed": 1.06, "text": "As a beginner with little progra"}
{"msg_type": "summary", "run": 58, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": "and its liberal biases? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.7, "tree_w": 351, "tree_size": 2048, "t0": 3.0433, "t1": 5.9233, "tft": 8.8247, "input_0": 7416, "input_1": 2049, "min_CLP": -9.25, "draft_iters": 32.0, "mem_use": 47.31, "gen_rate": 11.0, "speed": 1.23, "text": "\"As an open source alternative t"}
{"msg_type": "summary", "run": 59, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ay to form a new habit? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.4, "tree_w": 536, "tree_size": 2048, "t0": 2.68, "t1": 5.866, "tft": 7.8887, "input_0": 6570, "input_1": 2049, "min_CLP": -9.08, "draft_iters": 27.6, "mem_use": 45.65, "gen_rate": 7.0, "speed": 0.82, "text": "\"The best way to form a new habi"}
{"msg_type": "summary", "run": 60, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 531, "prompt_text": " sun light unsucessful. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 30, "tree_h": 10.5, "tree_w": 474, "tree_size": 2048, "t0": 3.0075, "t1": 5.67, "tft": 9.6255, "input_0": 7625, "input_1": 2049, "min_CLP": -10.79, "draft_iters": 32.0, "mem_use": 48.05, "gen_rate": 7.5, "speed": 0.86, "text": "The direct answer to the questio"}
{"msg_type": "summary", "run": 61, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 674, "prompt_text": " to a possible victory. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 38, "tree_h": 11.3, "tree_w": 517, "tree_size": 2048, "t0": 2.74, "t1": 5.8771, "tft": 9.929, "input_0": 5797, "input_1": 2049, "min_CLP": -8.85, "draft_iters": 29.7, "mem_use": 48.89, "gen_rate": 5.4, "speed": 0.63, "text": "[The general surveys the battlef"}
{"msg_type": "summary", "run": 62, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " be to remember though. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 426, "tree_size": 2048, "t0": 2.932, "t1": 5.888, "tft": 8.4122, "input_0": 5997, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 31.2, "mem_use": 46.61, "gen_rate": 6.8, "speed": 0.77, "text": "\"I understand that learning and "}
{"msg_type": "summary", "run": 63, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "ryptocurrency industry. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 430, "tree_size": 2048, "t0": 2.954, "t1": 5.888, "tft": 8.3683, "input_0": 6306, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 31.2, "mem_use": 46.31, "gen_rate": 7.2, "speed": 0.81, "text": "The proof-of-stake concept is a "}
{"msg_type": "summary", "run": 64, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 258, "prompt_text": "ay in this space time\"? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.9, "tree_w": 644, "tree_size": 2048, "t0": 2.5943, "t1": 5.8986, "tft": 8.1636, "input_0": 4691, "input_1": 2049, "min_CLP": -9.27, "draft_iters": 27.1, "mem_use": 46.45, "gen_rate": 5.3, "speed": 0.62, "text": "I meant the others would still a"}
{"msg_type": "summary", "run": 65, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 608, "prompt_text": " void pointers and why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.0, "tree_w": 370, "tree_size": 2048, "t0": 3.022, "t1": 5.774, "tft": 9.7707, "input_0": 6863, "input_1": 2049, "min_CLP": -8.39, "draft_iters": 32.0, "mem_use": 48.51, "gen_rate": 7.8, "speed": 0.89, "text": "A void pointer in C++ is a point"}
{"msg_type": "summary", "run": 66, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 695, "prompt_text": "e me hard. I miss Luna. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.6, "tree_w": 384, "tree_size": 2048, "t0": 2.95, "t1": 6.108, "tft": 9.9261, "input_0": 6424, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 31.4, "mem_use": 49.02, "gen_rate": 7.8, "speed": 0.86, "text": "\"I'm sorry, but as an AI languag"}
{"msg_type": "summary", "run": 67, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 561, "prompt_text": " an authentication app? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 362, "tree_size": 2048, "t0": 3.115, "t1": 5.775, "tft": 9.7868, "input_0": 7670, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 48.23, "gen_rate": 10.5, "speed": 1.18, "text": "\"Implementing 2FA in a web app u"}
{"msg_type": "summary", "run": 68, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 194, "prompt_text": "o you!\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 10.8, "tree_w": 360, "tree_size": 2048, "t0": 3.06, "t1": 5.872, "tft": 7.9773, "input_0": 6931, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 32.0, "mem_use": 46.08, "gen_rate": 7.6, "speed": 0.85, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 69, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "perior to their tenants [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.2, "tree_w": 373, "tree_size": 2048, "t0": 2.9825, "t1": 5.8575, "tft": 7.998, "input_0": 6951, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 45.67, "gen_rate": 9.0, "speed": 1.02, "text": "Landlords can be considered supe"}
{"msg_type": "summary", "run": 70, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 601, "prompt_text": "each State during June? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 359, "tree_size": 2048, "t0": 3.0975, "t1": 5.7775, "tft": 9.876, "input_0": 7560, "input_1": 2049, "min_CLP": -10.25, "draft_iters": 32.0, "mem_use": 48.47, "gen_rate": 10.2, "speed": 1.16, "text": "\"Certainly! Here's the updated t"}
{"msg_type": "summary", "run": 71, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 116, "prompt_text": "/SYS>\n\n\nWho made Berlin [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 382, "tree_size": 2048, "t0": 3.0233, "t1": 5.8567, "tft": 7.9177, "input_0": 6307, "input_1": 2049, "min_CLP": -11.91, "draft_iters": 32.0, "mem_use": 45.62, "gen_rate": 12.7, "speed": 1.43, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 72, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 510, "prompt_text": "d some jokes with love. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 10.3, "tree_w": 426, "tree_size": 2048, "t0": 2.9683, "t1": 5.7333, "tft": 9.2662, "input_0": 6798, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 31.8, "mem_use": 47.93, "gen_rate": 7.0, "speed": 0.8, "text": "Sure, here are a few lighthearte"}
{"msg_type": "summary", "run": 73, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 486, "prompt_text": "m of it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.7, "tree_w": 314, "tree_size": 2048, "t0": 3.1467, "t1": 5.9467, "tft": 9.1912, "input_0": 7313, "input_1": 2049, "min_CLP": -8.89, "draft_iters": 32.0, "mem_use": 47.79, "gen_rate": 10.7, "speed": 1.17, "text": "Certainly. While \"Fooled by Rand"}
{"msg_type": "summary", "run": 74, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": " pornography come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.8, "tree_w": 500, "tree_size": 2048, "t0": 2.808, "t1": 5.854, "tft": 7.8345, "input_0": 5441, "input_1": 2049, "min_CLP": -8.9, "draft_iters": 29.8, "mem_use": 45.64, "gen_rate": 6.8, "speed": 0.78, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 75, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 172, "prompt_text": " at what timezone i am? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.0, "tree_w": 646, "tree_size": 2048, "t0": 2.57, "t1": 5.865, "tft": 8.0527, "input_0": 5996, "input_1": 2049, "min_CLP": -10.77, "draft_iters": 26.5, "mem_use": 45.95, "gen_rate": 8.0, "speed": 0.95, "text": "\"You can visit at The World Cloc"}
{"msg_type": "summary", "run": 76, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": " becomes unsafe to eat. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.8, "tree_w": 411, "tree_size": 2048, "t0": 2.9075, "t1": 5.86, "tft": 6.525, "input_0": 6494, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 30.2, "mem_use": 46.0, "gen_rate": 9.5, "speed": 1.08, "text": "The five second rule is a common"}
{"msg_type": "summary", "run": 77, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "ny eggs do I have left? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 3, "tree_h": 15.0, "tree_w": 528, "tree_size": 2048, "t0": 2.9, "t1": 5.87, "tft": 8.2163, "input_0": 5368, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 32.0, "mem_use": 45.76, "gen_rate": 3.0, "speed": 0.34, "text": "The answer is 5 eggs."}
{"msg_type": "summary", "run": 78, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 266, "prompt_text": "eories in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.0, "tree_w": 526, "tree_size": 2048, "t0": 3.0375, "t1": 5.8825, "tft": 8.5587, "input_0": 9175, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 32.0, "mem_use": 46.48, "gen_rate": 9.8, "speed": 1.09, "text": "Sure! The Sieve of Eratosthenes "}
{"msg_type": "summary", "run": 79, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "d. Thanks for the help. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 333, "tree_size": 2048, "t0": 3.08, "t1": 5.86, "tft": 8.1462, "input_0": 7084, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 46.07, "gen_rate": 8.0, "speed": 0.9, "text": "\"You're welcome! If you suspect "}
{"msg_type": "summary", "run": 80, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "u don't wanna miss out\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.0, "tree_w": 443, "tree_size": 2048, "t0": 2.9975, "t1": 5.8625, "tft": 8.0111, "input_0": 6466, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 31.5, "mem_use": 45.79, "gen_rate": 8.2, "speed": 0.93, "text": "\"Hey Medium.com readers! We are "}
{"msg_type": "summary", "run": 81, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 248, "prompt_text": "ng cognitive abilities? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.6, "tree_w": 433, "tree_size": 2048, "t0": 3.004, "t1": 5.884, "tft": 8.3311, "input_0": 6963, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 31.2, "mem_use": 46.37, "gen_rate": 7.4, "speed": 0.83, "text": "Yes, there are examples of sexua"}
{"msg_type": "summary", "run": 82, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": "y can help individuals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 8.8, "tree_w": 429, "tree_size": 2048, "t0": 3.108, "t1": 5.916, "tft": 8.7733, "input_0": 7712, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 47.43, "gen_rate": 8.0, "speed": 0.89, "text": "Certainly! AI assistants can als"}
{"msg_type": "summary", "run": 83, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "ther one bites the dust [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 382, "tree_size": 2048, "t0": 2.9925, "t1": 5.7825, "tft": 9.6784, "input_0": 6575, "input_1": 2049, "min_CLP": -11.9, "draft_iters": 32.0, "mem_use": 48.44, "gen_rate": 9.2, "speed": 1.05, "text": "[SYS]\\nYou are a helpful, respec"}
{"msg_type": "summary", "run": 84, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": " ffiles be overwritten? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.5, "tree_w": 345, "tree_size": 2048, "t0": 3.1525, "t1": 5.8975, "tft": 8.4799, "input_0": 7444, "input_1": 2049, "min_CLP": -8.55, "draft_iters": 32.0, "mem_use": 46.95, "gen_rate": 9.5, "speed": 1.05, "text": "The scp command is a Unix-based "}
{"msg_type": "summary", "run": 85, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 451, "prompt_text": "sta, replace with salad [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 434, "tree_size": 2048, "t0": 3.0, "t1": 5.93, "tft": 9.1959, "input_0": 7002, "input_1": 2049, "min_CLP": -10.05, "draft_iters": 32.0, "mem_use": 47.59, "gen_rate": 11.0, "speed": 1.23, "text": "Spicy Tomato and Vegetarian Saus"}
{"msg_type": "summary", "run": 86, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "be illegal to keep it ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 9.8, "tree_w": 500, "tree_size": 2048, "t0": 2.674, "t1": 5.862, "tft": 7.8221, "input_0": 6402, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 28.0, "mem_use": 45.69, "gen_rate": 6.8, "speed": 0.8, "text": "\"Yes, it would be illegal to kee"}
{"msg_type": "summary", "run": 87, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "the largest population? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 389, "tree_size": 2048, "t0": 3.1375, "t1": 5.875, "tft": 8.1349, "input_0": 6869, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 45.96, "gen_rate": 9.2, "speed": 1.03, "text": "Sydney is the most populous city"}
{"msg_type": "summary", "run": 88, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "uld affect your health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 7, "tree_h": 13.0, "tree_w": 426, "tree_size": 2048, "t0": 2.985, "t1": 5.86, "tft": 6.7349, "input_0": 5279, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 32.0, "mem_use": 46.24, "gen_rate": 3.5, "speed": 0.4, "text": "Is it possible to survive a nucl"}
{"msg_type": "summary", "run": 89, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": ", kind of funny indeed. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 17, "tree_h": 12.7, "tree_w": 423, "tree_size": 2048, "t0": 2.9267, "t1": 5.86, "tft": 7.9791, "input_0": 5887, "input_1": 2049, "min_CLP": -8.89, "draft_iters": 32.0, "mem_use": 45.96, "gen_rate": 5.7, "speed": 0.65, "text": "\"You're welcome! I hope you had "}
{"msg_type": "summary", "run": 90, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "hour a day to practice? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 310, "tree_size": 2048, "t0": 3.09, "t1": 5.87, "tft": 8.1589, "input_0": 5940, "input_1": 2049, "min_CLP": -11.67, "draft_iters": 32.0, "mem_use": 45.73, "gen_rate": 12.7, "speed": 1.41, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 91, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "that would be possible? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.0, "tree_w": 440, "tree_size": 2048, "t0": 3.082, "t1": 5.868, "tft": 8.1549, "input_0": 6298, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 45.7, "gen_rate": 7.0, "speed": 0.78, "text": "The answer to this question is: "}
{"msg_type": "summary", "run": 92, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 424, "prompt_text": " Fermat's Last Theorem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.2, "tree_w": 414, "tree_size": 2048, "t0": 3.1375, "t1": 5.91, "tft": 8.7696, "input_0": 8237, "input_1": 2049, "min_CLP": -9.06, "draft_iters": 32.0, "mem_use": 47.43, "gen_rate": 10.0, "speed": 1.11, "text": "The Taniyama-Shimura-Weil conjec"}
{"msg_type": "summary", "run": 93, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "thout serious climbing? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 11.8, "tree_w": 345, "tree_size": 2048, "t0": 3.0625, "t1": 5.86, "tft": 8.0558, "input_0": 7102, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 45.7, "gen_rate": 10.0, "speed": 1.12, "text": "\"Sure, I'd be happy to help! Wha"}
{"msg_type": "summary", "run": 94, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "rk in Godot Engine 4.x? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.3, "tree_w": 372, "tree_size": 2048, "t0": 3.0617, "t1": 5.8667, "tft": 8.314, "input_0": 6783, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 45.99, "gen_rate": 6.7, "speed": 0.75, "text": "```gdscript\\n# First Person Cont"}
{"msg_type": "summary", "run": 95, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": " become a master at it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 13.7, "tree_w": 373, "tree_size": 2048, "t0": 3.03, "t1": 5.8533, "tft": 7.8401, "input_0": 5579, "input_1": 2049, "min_CLP": -9.57, "draft_iters": 32.0, "mem_use": 45.68, "gen_rate": 12.3, "speed": 1.39, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 96, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing one with the Force? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 41, "tree_h": 12.1, "tree_w": 431, "tree_size": 2048, "t0": 3.0314, "t1": 5.8629, "tft": 8.0834, "input_0": 6081, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 31.6, "mem_use": 45.99, "gen_rate": 5.9, "speed": 0.66, "text": "While it is true that some indiv"}
{"msg_type": "summary", "run": 97, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": " rifle is gas-operated? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.3, "tree_w": 453, "tree_size": 2048, "t0": 2.8617, "t1": 5.8633, "tft": 8.1384, "input_0": 5577, "input_1": 2049, "min_CLP": -8.78, "draft_iters": 30.3, "mem_use": 45.83, "gen_rate": 5.8, "speed": 0.67, "text": "\"A gas-operated rifle uses the p"}
{"msg_type": "summary", "run": 98, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 195, "prompt_text": "T] Who is Steve Carell? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.0, "tree_w": 402, "tree_size": 2048, "t0": 3.008, "t1": 5.866, "tft": 8.2596, "input_0": 7182, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 31.8, "mem_use": 46.09, "gen_rate": 8.4, "speed": 0.95, "text": "Steve Carell is an American acto"}
{"msg_type": "summary", "run": 99, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 677, "prompt_text": " footprint if possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.4, "tree_w": 387, "tree_size": 2048, "t0": 3.044, "t1": 5.858, "tft": 10.1614, "input_0": 6585, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 32.0, "mem_use": 48.91, "gen_rate": 7.4, "speed": 0.83, "text": "I understand that the regular ex"}
{"msg_type": "summary", "run": 100, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 206, "prompt_text": "return it to its owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.5, "tree_w": 433, "tree_size": 2048, "t0": 3.065, "t1": 5.8625, "tft": 8.4097, "input_0": 7737, "input_1": 2049, "min_CLP": -9.45, "draft_iters": 32.0, "mem_use": 46.15, "gen_rate": 8.0, "speed": 0.9, "text": "Yes, a finder of lost property s"}
{"msg_type": "summary", "run": 101, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 694, "prompt_text": " tools?\n[INST] Xin ch\u00e0o [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 12.3, "tree_w": 463, "tree_size": 2048, "t0": 2.8786, "t1": 5.9343, "tft": 9.898, "input_0": 5879, "input_1": 2049, "min_CLP": -9.0, "draft_iters": 30.4, "mem_use": 49.01, "gen_rate": 4.7, "speed": 0.54, "text": "\"Xin ch\u00e0o! How can I help you to"}
{"msg_type": "summary", "run": 102, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 268, "prompt_text": "ally did grow on trees. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 13.0, "tree_w": 545, "tree_size": 2048, "t0": 2.8071, "t1": 5.89, "tft": 8.2805, "input_0": 4639, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 29.9, "mem_use": 46.51, "gen_rate": 5.3, "speed": 0.61, "text": "\"What you said makes sense. I ha"}
{"msg_type": "summary", "run": 103, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 186, "prompt_text": "lain it in more detail? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 433, "tree_size": 2048, "t0": 3.13, "t1": 5.8675, "tft": 8.1798, "input_0": 8032, "input_1": 2049, "min_CLP": -10.94, "draft_iters": 32.0, "mem_use": 46.01, "gen_rate": 10.0, "speed": 1.11, "text": "Certainly! Here\\'s an example of"}
{"msg_type": "summary", "run": 104, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 428, "prompt_text": "ular German rock bands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 9.4, "tree_w": 545, "tree_size": 2048, "t0": 2.6011, "t1": 5.9111, "tft": 8.8161, "input_0": 4940, "input_1": 2049, "min_CLP": -10.69, "draft_iters": 27.3, "mem_use": 47.45, "gen_rate": 3.7, "speed": 0.43, "text": "1. Scorpions\\n2. Rammstein\\n3. T"}
{"msg_type": "summary", "run": 105, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": "egy to win a thumb war? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.0, "tree_w": 505, "tree_size": 2048, "t0": 2.8733, "t1": 5.8633, "tft": 8.1134, "input_0": 5288, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 30.5, "mem_use": 46.0, "gen_rate": 5.7, "speed": 0.65, "text": "\"The best strategy to win a thum"}
{"msg_type": "summary", "run": 106, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 519, "prompt_text": " Value of the customer? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.3, "tree_w": 337, "tree_size": 2048, "t0": 3.05, "t1": 5.8133, "tft": 9.7114, "input_0": 6409, "input_1": 2049, "min_CLP": -8.47, "draft_iters": 32.0, "mem_use": 47.99, "gen_rate": 11.0, "speed": 1.24, "text": "To acquire revenue from customer"}
{"msg_type": "summary", "run": 107, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " what you come up with. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.0, "tree_w": 400, "tree_size": 2048, "t0": 3.022, "t1": 5.888, "tft": 8.1823, "input_0": 6896, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 32.0, "mem_use": 46.62, "gen_rate": 7.0, "speed": 0.79, "text": "Yes, as a language model, I can "}
{"msg_type": "summary", "run": 108, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "uld you add references? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.6, "tree_w": 589, "tree_size": 2048, "t0": 2.712, "t1": 5.868, "tft": 8.2354, "input_0": 6039, "input_1": 2049, "min_CLP": -9.9, "draft_iters": 27.2, "mem_use": 46.15, "gen_rate": 7.4, "speed": 0.86, "text": "Romeo is the most at fault in Wi"}
{"msg_type": "summary", "run": 109, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "s, or development kits? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.8, "tree_w": 341, "tree_size": 2048, "t0": 3.09, "t1": 5.88, "tft": 8.4724, "input_0": 7728, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 46.29, "gen_rate": 10.0, "speed": 1.11, "text": "There are many APIs, libraries, "}
{"msg_type": "summary", "run": 110, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 446, "prompt_text": "other in that language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 14, "new_tokens": 33, "tree_h": 3.9, "tree_w": 1035, "tree_size": 2048, "t0": 1.1829, "t1": 5.9271, "tft": 9.2793, "input_0": 2619, "input_1": 2049, "min_CLP": -11.1, "draft_iters": 11.9, "mem_use": 47.56, "gen_rate": 2.4, "speed": 0.33, "text": "\"Sure, here's a simple poem in Q"}
{"msg_type": "summary", "run": 111, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "of stress among people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 313, "tree_size": 2048, "t0": 3.0433, "t1": 5.87, "tft": 7.9506, "input_0": 6498, "input_1": 2049, "min_CLP": -11.57, "draft_iters": 32.0, "mem_use": 45.68, "gen_rate": 11.7, "speed": 1.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 112, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "mber(){ int number = 0} [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.0, "tree_w": 323, "tree_size": 2048, "t0": 3.05, "t1": 5.858, "tft": 8.1279, "input_0": 7149, "input_1": 2049, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 45.72, "gen_rate": 6.4, "speed": 0.72, "text": "The error in the code is a missi"}
{"msg_type": "summary", "run": 113, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 367, "prompt_text": "uture me, all the best. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 377, "tree_size": 2048, "t0": 3.0667, "t1": 5.9, "tft": 8.5435, "input_0": 6157, "input_1": 2049, "min_CLP": -10.26, "draft_iters": 32.0, "mem_use": 47.09, "gen_rate": 12.7, "speed": 1.41, "text": "Dear future me, hello. If you ar"}
{"msg_type": "summary", "run": 114, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "e on the second context [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.2, "tree_w": 387, "tree_size": 2048, "t0": 3.096, "t1": 5.916, "tft": 8.4214, "input_0": 7345, "input_1": 2049, "min_CLP": -8.56, "draft_iters": 32.0, "mem_use": 46.32, "gen_rate": 7.4, "speed": 0.82, "text": "\"In the context of matrix multip"}
{"msg_type": "summary", "run": 115, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": "--arg 2` and prints `2` [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 402, "tree_size": 2048, "t0": 3.08, "t1": 5.89, "tft": 8.3941, "input_0": 7830, "input_1": 2049, "min_CLP": -9.36, "draft_iters": 32.0, "mem_use": 46.44, "gen_rate": 11.0, "speed": 1.23, "text": "\"You can use the `argparse` modu"}
{"msg_type": "summary", "run": 116, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 557, "prompt_text": " do you recommend I do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.4, "tree_w": 514, "tree_size": 2048, "t0": 2.638, "t1": 5.758, "tft": 9.7284, "input_0": 5771, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 27.2, "mem_use": 48.21, "gen_rate": 6.4, "speed": 0.76, "text": "\"If your friends are insisting t"}
{"msg_type": "summary", "run": 117, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 220, "prompt_text": "pen source alternative\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.2, "tree_w": 380, "tree_size": 2048, "t0": 3.106, "t1": 5.872, "tft": 8.1564, "input_0": 6742, "input_1": 2049, "min_CLP": -9.21, "draft_iters": 32.0, "mem_use": 46.23, "gen_rate": 6.8, "speed": 0.76, "text": "\"Open Assistant, the ChatGPT ope"}
{"msg_type": "summary", "run": 118, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 450, "prompt_text": "ing to fossil evidence? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 8.5, "tree_w": 566, "tree_size": 2048, "t0": 2.6025, "t1": 5.9175, "tft": 9.2604, "input_0": 6938, "input_1": 2049, "min_CLP": -14.29, "draft_iters": 27.0, "mem_use": 47.58, "gen_rate": 8.2, "speed": 0.97, "text": "The longest amount of time we ca"}
{"msg_type": "summary", "run": 119, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " and feel like a human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.5, "tree_w": 429, "tree_size": 2048, "t0": 2.9275, "t1": 5.87, "tft": 7.7974, "input_0": 5979, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 31.0, "mem_use": 45.66, "gen_rate": 8.0, "speed": 0.91, "text": "\"Yes, I can think and feel like "}
{"msg_type": "summary", "run": 120, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "th more complex wording [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 37, "tree_h": 10.0, "tree_w": 550, "tree_size": 2048, "t0": 2.6614, "t1": 5.8614, "tft": 7.9794, "input_0": 5285, "input_1": 2049, "min_CLP": -9.63, "draft_iters": 28.0, "mem_use": 45.88, "gen_rate": 5.3, "speed": 0.62, "text": "\"The Attention Mechanism,\\nSoftl"}
{"msg_type": "summary", "run": 121, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "] You are pretty smart! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.0, "tree_w": 335, "tree_size": 2048, "t0": 3.072, "t1": 5.878, "tft": 8.1323, "input_0": 7292, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 46.13, "gen_rate": 6.8, "speed": 0.76, "text": "\"Thank you! I'm here to provide "}
{"msg_type": "summary", "run": 122, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 470, "prompt_text": "ontain archaic phrases. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.8, "tree_w": 598, "tree_size": 2048, "t0": 2.45, "t1": 5.93, "tft": 9.0257, "input_0": 4751, "input_1": 2049, "min_CLP": -9.4, "draft_iters": 26.2, "mem_use": 47.7, "gen_rate": 6.4, "speed": 0.76, "text": "Thou art the sun that shineth br"}
{"msg_type": "summary", "run": 123, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 231, "prompt_text": "ence for your response. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.3, "tree_w": 535, "tree_size": 2048, "t0": 2.755, "t1": 5.89, "tft": 8.3741, "input_0": 6271, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 28.8, "mem_use": 46.29, "gen_rate": 5.5, "speed": 0.64, "text": "The information about the effect"}
{"msg_type": "summary", "run": 124, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "on in Tolkien's Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.3, "tree_w": 303, "tree_size": 2048, "t0": 3.0767, "t1": 5.8733, "tft": 8.174, "input_0": 6508, "input_1": 2049, "min_CLP": -11.87, "draft_iters": 32.0, "mem_use": 45.68, "gen_rate": 12.3, "speed": 1.38, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 125, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "what presidents day is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 11.0, "tree_w": 364, "tree_size": 2048, "t0": 3.105, "t1": 5.855, "tft": 8.0724, "input_0": 7684, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 45.68, "gen_rate": 10.2, "speed": 1.14, "text": "\"Presidents Day, officially know"}
{"msg_type": "summary", "run": 126, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "is unlikely to get wet? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.5, "tree_w": 576, "tree_size": 2048, "t0": 2.585, "t1": 5.8733, "tft": 8.0319, "input_0": 5160, "input_1": 2049, "min_CLP": -9.25, "draft_iters": 27.2, "mem_use": 45.98, "gen_rate": 5.5, "speed": 0.65, "text": "Not necessarily. A kilogram of f"}
{"msg_type": "summary", "run": 127, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "the KeyHole satellites? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 451, "tree_size": 2048, "t0": 3.07, "t1": 5.898, "tft": 8.5755, "input_0": 6651, "input_1": 2049, "min_CLP": -9.57, "draft_iters": 32.0, "mem_use": 46.78, "gen_rate": 6.8, "speed": 0.76, "text": "The US National Reconnaissance O"}
{"msg_type": "summary", "run": 128, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": " make it about windows. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.7, "tree_w": 513, "tree_size": 2048, "t0": 2.8683, "t1": 5.8733, "tft": 7.9889, "input_0": 5346, "input_1": 2049, "min_CLP": -9.16, "draft_iters": 29.5, "mem_use": 46.05, "gen_rate": 5.8, "speed": 0.67, "text": "Why are Windows computers so pop"}
{"msg_type": "summary", "run": 129, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": "ink I'll call you Opie! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.5, "tree_w": 493, "tree_size": 2048, "t0": 2.7983, "t1": 5.8683, "tft": 8.2133, "input_0": 5180, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 30.3, "mem_use": 46.13, "gen_rate": 5.3, "speed": 0.62, "text": "\"Opie, it's a nice and friendly "}
{"msg_type": "summary", "run": 130, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "st the American people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.6, "tree_w": 464, "tree_size": 2048, "t0": 3.0, "t1": 5.874, "tft": 7.7767, "input_0": 6091, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 31.6, "mem_use": 45.68, "gen_rate": 7.0, "speed": 0.79, "text": "\"The question you've asked is no"}
{"msg_type": "summary", "run": 131, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "ology by Ted Kaczynski? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 10, "new_tokens": 35, "tree_h": 11.3, "tree_w": 626, "tree_size": 2048, "t0": 2.64, "t1": 5.888, "tft": 8.1988, "input_0": 4616, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 28.0, "mem_use": 46.36, "gen_rate": 3.5, "speed": 0.41, "text": "\"Ted who? Pfft, he\\'s like, the "}
{"msg_type": "summary", "run": 132, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": " any way to salvage it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.8, "tree_w": 433, "tree_size": 2048, "t0": 3.112, "t1": 5.866, "tft": 8.1132, "input_0": 7525, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 45.79, "gen_rate": 7.6, "speed": 0.85, "text": "Yes, there are a few things you "}
{"msg_type": "summary", "run": 133, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 353, "prompt_text": "nd time travelers then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.6, "tree_w": 395, "tree_size": 2048, "t0": 2.99, "t1": 5.912, "tft": 8.5383, "input_0": 6288, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 47.01, "gen_rate": 7.2, "speed": 0.81, "text": "Sure, there are many movies and "}
{"msg_type": "summary", "run": 134, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "to take over the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 8.7, "tree_w": 635, "tree_size": 2048, "t0": 2.4183, "t1": 5.8583, "tft": 7.6182, "input_0": 4685, "input_1": 2049, "min_CLP": -9.21, "draft_iters": 25.5, "mem_use": 46.12, "gen_rate": 5.5, "speed": 0.66, "text": "\"It's not really my goal, I'm he"}
{"msg_type": "summary", "run": 135, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 405, "prompt_text": " to enjoy scenic views? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 366, "tree_size": 2048, "t0": 3.105, "t1": 5.925, "tft": 8.7383, "input_0": 6648, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 32.0, "mem_use": 47.32, "gen_rate": 8.2, "speed": 0.91, "text": "\"Based on your criteria, I would"}
{"msg_type": "summary", "run": 136, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "'s get some engagement! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 11.0, "tree_w": 495, "tree_size": 2048, "t0": 2.8714, "t1": 5.8686, "tft": 8.2449, "input_0": 5422, "input_1": 2049, "min_CLP": -9.18, "draft_iters": 30.4, "mem_use": 46.07, "gen_rate": 5.7, "speed": 0.65, "text": "\"Open Assistant: Open Source Cha"}
{"msg_type": "summary", "run": 137, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 175, "prompt_text": "llustrate the solution. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 403, "tree_size": 2048, "t0": 3.105, "t1": 5.8675, "tft": 8.1209, "input_0": 7798, "input_1": 2049, "min_CLP": -9.42, "draft_iters": 32.0, "mem_use": 45.97, "gen_rate": 10.2, "speed": 1.14, "text": "\"Sure, let's break it down step-"}
{"msg_type": "summary", "run": 138, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 570, "prompt_text": " Why is this happening? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 10.5, "tree_w": 458, "tree_size": 2048, "t0": 3.0225, "t1": 5.785, "tft": 9.8089, "input_0": 7741, "input_1": 2049, "min_CLP": -9.65, "draft_iters": 32.0, "mem_use": 48.28, "gen_rate": 10.5, "speed": 1.19, "text": "There are a few possible reasons"}
{"msg_type": "summary", "run": 139, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "code to make it faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.2, "tree_w": 501, "tree_size": 2048, "t0": 3.115, "t1": 5.8625, "tft": 7.8126, "input_0": 8137, "input_1": 2049, "min_CLP": -9.25, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 8.0, "speed": 0.89, "text": "Yes, you can compile Python code"}
{"msg_type": "summary", "run": 140, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "y provide to consumers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 9.9, "tree_w": 585, "tree_size": 2048, "t0": 2.4525, "t1": 5.8712, "tft": 8.1299, "input_0": 4514, "input_1": 2049, "min_CLP": -9.19, "draft_iters": 26.1, "mem_use": 46.21, "gen_rate": 4.1, "speed": 0.5, "text": "\"It's a good point, but not ever"}
{"msg_type": "summary", "run": 141, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "T] how does this matter [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 358, "tree_size": 2048, "t0": 3.02, "t1": 5.862, "tft": 8.1708, "input_0": 7183, "input_1": 2049, "min_CLP": -8.78, "draft_iters": 32.0, "mem_use": 45.84, "gen_rate": 7.0, "speed": 0.79, "text": "The heat from the pan is transfe"}
{"msg_type": "summary", "run": 142, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ning scripts in python? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.2, "tree_w": 531, "tree_size": 2048, "t0": 3.07, "t1": 5.865, "tft": 8.063, "input_0": 7906, "input_1": 2049, "min_CLP": -9.55, "draft_iters": 32.0, "mem_use": 45.68, "gen_rate": 9.8, "speed": 1.09, "text": "The best libraries for developin"}
{"msg_type": "summary", "run": 143, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 478, "prompt_text": "e. Thank you very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 11.5, "tree_w": 457, "tree_size": 2048, "t0": 2.9633, "t1": 5.8617, "tft": 9.3306, "input_0": 6702, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 31.3, "mem_use": 47.75, "gen_rate": 5.5, "speed": 0.62, "text": "\"I'm sorry to hear that your fri"}
{"msg_type": "summary", "run": 144, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Is a thumb war violent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 10.7, "tree_w": 510, "tree_size": 2048, "t0": 2.7783, "t1": 5.8567, "tft": 7.7713, "input_0": 5335, "input_1": 2049, "min_CLP": -8.85, "draft_iters": 28.7, "mem_use": 45.64, "gen_rate": 7.0, "speed": 0.81, "text": "The answer is \"yes\" because a th"}
{"msg_type": "summary", "run": 145, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ever Gonna Give You Up? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.2, "tree_w": 567, "tree_size": 2048, "t0": 2.54, "t1": 5.856, "tft": 8.2153, "input_0": 5833, "input_1": 2049, "min_CLP": -10.52, "draft_iters": 26.6, "mem_use": 45.72, "gen_rate": 6.4, "speed": 0.76, "text": "Sure, here are the lyrics to the"}
{"msg_type": "summary", "run": 146, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 687, "prompt_text": "countries in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.7, "tree_w": 359, "tree_size": 2048, "t0": 3.1033, "t1": 5.8367, "tft": 10.1681, "input_0": 6761, "input_1": 2049, "min_CLP": -8.42, "draft_iters": 32.0, "mem_use": 48.97, "gen_rate": 10.7, "speed": 1.19, "text": "As of 2023, there are several co"}
{"msg_type": "summary", "run": 147, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 347, "prompt_text": "lete the previous task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.8, "tree_w": 389, "tree_size": 2048, "t0": 3.065, "t1": 5.9075, "tft": 8.6151, "input_0": 6243, "input_1": 2049, "min_CLP": -8.5, "draft_iters": 32.0, "mem_use": 46.98, "gen_rate": 8.2, "speed": 0.92, "text": "I apologize for any confusion ea"}
{"msg_type": "summary", "run": 148, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "n, or another language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.5, "tree_w": 405, "tree_size": 2048, "t0": 3.1725, "t1": 5.8525, "tft": 8.1667, "input_0": 6688, "input_1": 2049, "min_CLP": -9.18, "draft_iters": 32.0, "mem_use": 45.93, "gen_rate": 10.5, "speed": 1.16, "text": "You can use various resources to"}
{"msg_type": "summary", "run": 149, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "ited Steaks of America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.0, "tree_w": 317, "tree_size": 2048, "t0": 3.06, "t1": 5.8625, "tft": 8.0861, "input_0": 6442, "input_1": 2049, "min_CLP": -8.53, "draft_iters": 32.0, "mem_use": 45.91, "gen_rate": 8.0, "speed": 0.9, "text": "The task is asking you to imagin"}
{"msg_type": "summary", "run": 150, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "is and give an example. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.4, "tree_w": 430, "tree_size": 2048, "t0": 3.024, "t1": 5.866, "tft": 8.0713, "input_0": 6962, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 31.6, "mem_use": 45.65, "gen_rate": 6.6, "speed": 0.74, "text": "The theory of sexual selection i"}
{"msg_type": "summary", "run": 151, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "ut the mentioned topic. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.8, "tree_w": 469, "tree_size": 2048, "t0": 2.934, "t1": 5.89, "tft": 8.433, "input_0": 6224, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 31.0, "mem_use": 46.48, "gen_rate": 6.8, "speed": 0.77, "text": "I understand now, I will do my b"}
{"msg_type": "summary", "run": 152, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 267, "prompt_text": "educirla a 3 canciones? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 10.8, "tree_w": 399, "tree_size": 2048, "t0": 3.1175, "t1": 5.89, "tft": 8.5084, "input_0": 7151, "input_1": 2049, "min_CLP": -10.23, "draft_iters": 32.0, "mem_use": 46.51, "gen_rate": 10.5, "speed": 1.17, "text": "\"\u00a1Por supuesto! Aqu\u00ed te dejo las"}
{"msg_type": "summary", "run": 153, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 691, "prompt_text": "t want to read all that [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 356, "tree_size": 2048, "t0": 3.1175, "t1": 6.095, "tft": 10.113, "input_0": 7487, "input_1": 2049, "min_CLP": -9.97, "draft_iters": 32.0, "mem_use": 48.99, "gen_rate": 10.2, "speed": 1.11, "text": "\"Sure, here's a shorter version:"}
{"msg_type": "summary", "run": 154, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ing rude to my friends? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 37, "tree_h": 11.3, "tree_w": 367, "tree_size": 2048, "t0": 3.0033, "t1": 5.8567, "tft": 7.9533, "input_0": 6525, "input_1": 2049, "min_CLP": -11.64, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 12.3, "speed": 1.39, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 155, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "are produced in Berlin? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 13, "tree_h": 10.0, "tree_w": 484, "tree_size": 2048, "t0": 2.94, "t1": 5.87, "tft": 8.4005, "input_0": 7009, "input_1": 2049, "min_CLP": -9.31, "draft_iters": 30.5, "mem_use": 46.24, "gen_rate": 6.5, "speed": 0.74, "text": "Berlin has a number of well-know"}
{"msg_type": "summary", "run": 156, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "mat in a file in python [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 478, "tree_size": 2048, "t0": 3.0675, "t1": 5.89, "tft": 8.1316, "input_0": 8383, "input_1": 2049, "min_CLP": -9.78, "draft_iters": 32.0, "mem_use": 45.72, "gen_rate": 10.0, "speed": 1.12, "text": "\"Sure! Here's a script that save"}
{"msg_type": "summary", "run": 157, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ve and inductive range? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 338, "tree_size": 2048, "t0": 3.08, "t1": 5.68, "tft": 9.7203, "input_0": 6540, "input_1": 2049, "min_CLP": -10.34, "draft_iters": 32.0, "mem_use": 48.2, "gen_rate": 11.0, "speed": 1.26, "text": "## Vegetarian\\n Sausage, Peppers"}
{"msg_type": "summary", "run": 158, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "Who wears short shorts? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 13.0, "tree_w": 455, "tree_size": 2048, "t0": 3.03, "t1": 5.86, "tft": 7.7288, "input_0": 5065, "input_1": 2049, "min_CLP": -9.3, "draft_iters": 32.0, "mem_use": 45.63, "gen_rate": 0.0, "speed": 0.0, "text": "The answer to this question is:"}
{"msg_type": "summary", "run": 159, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "ss from going bankrupt? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.7, "tree_w": 478, "tree_size": 2048, "t0": 2.905, "t1": 5.7367, "tft": 9.3963, "input_0": 5994, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 30.5, "mem_use": 47.88, "gen_rate": 6.8, "speed": 0.79, "text": "Here are some potential solution"}
{"msg_type": "summary", "run": 160, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " we need AI assistants? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 12.0, "tree_w": 405, "tree_size": 2048, "t0": 3.115, "t1": 5.865, "tft": 7.8724, "input_0": 6832, "input_1": 2049, "min_CLP": -8.51, "draft_iters": 32.0, "mem_use": 45.65, "gen_rate": 9.5, "speed": 1.06, "text": "The rise of AI assistants has be"}
{"msg_type": "summary", "run": 161, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 117, "prompt_text": "ion.\n<</SYS>\n\n\n\u628a\u8fd9\u53e5\u8bdd\u7ffb\u8bd1\u4e00\u4e0b [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 13, "tree_h": 10.0, "tree_w": 584, "tree_size": 2048, "t0": 2.635, "t1": 5.845, "tft": 7.8492, "input_0": 4496, "input_1": 2049, "min_CLP": -9.88, "draft_iters": 28.0, "mem_use": 45.63, "gen_rate": 6.5, "speed": 0.77, "text": "Can you tell me about the histor"}
{"msg_type": "summary", "run": 162, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": " to ensure its success? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.2, "tree_w": 380, "tree_size": 2048, "t0": 3.21, "t1": 5.87, "tft": 8.187, "input_0": 7379, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 45.79, "gen_rate": 8.8, "speed": 0.96, "text": "Sure, I can provide an example o"}
{"msg_type": "summary", "run": 163, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 323, "prompt_text": "ity of life in the 50s? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.0, "tree_w": 372, "tree_size": 2048, "t0": 3.072, "t1": 5.898, "tft": 8.6387, "input_0": 7629, "input_1": 2049, "min_CLP": -8.45, "draft_iters": 32.0, "mem_use": 46.84, "gen_rate": 7.8, "speed": 0.87, "text": "While the 1950s were a time of e"}
{"msg_type": "summary", "run": 164, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "gher quality of photos? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.8, "tree_w": 360, "tree_size": 2048, "t0": 3.04, "t1": 5.86, "tft": 8.0208, "input_0": 6906, "input_1": 2049, "min_CLP": -8.58, "draft_iters": 32.0, "mem_use": 45.74, "gen_rate": 9.2, "speed": 1.04, "text": "\"The user's question revolves ar"}
{"msg_type": "summary", "run": 165, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " to me more thoroughly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 12.0, "tree_w": 392, "tree_size": 2048, "t0": 3.095, "t1": 5.865, "tft": 6.5381, "input_0": 6930, "input_1": 2049, "min_CLP": -9.0, "draft_iters": 32.0, "mem_use": 45.9, "gen_rate": 8.2, "speed": 0.92, "text": "Sure! In reStructuredText (rst),"}
{"msg_type": "summary", "run": 166, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": "mean by selective fire? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 448, "tree_size": 2048, "t0": 2.95, "t1": 5.885, "tft": 8.5238, "input_0": 6026, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 31.2, "mem_use": 46.28, "gen_rate": 8.5, "speed": 0.96, "text": "Selective fire refers to the abi"}
{"msg_type": "summary", "run": 167, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "t are you a goddess of? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 12.3, "tree_w": 416, "tree_size": 2048, "t0": 3.02, "t1": 5.8617, "tft": 8.2142, "input_0": 6757, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 32.0, "mem_use": 45.81, "gen_rate": 6.0, "speed": 0.68, "text": "\"I'm the goddess of love, beauty"}
{"msg_type": "summary", "run": 168, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ands like mkdir and cd? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 404, "tree_size": 2048, "t0": 3.0975, "t1": 5.915, "tft": 8.659, "input_0": 8065, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 47.04, "gen_rate": 10.0, "speed": 1.11, "text": "\"If you are using Windows, you c"}
{"msg_type": "summary", "run": 169, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "that doesn't work yet.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.4, "tree_w": 430, "tree_size": 2048, "t0": 3.014, "t1": 5.862, "tft": 7.9036, "input_0": 7520, "input_1": 2049, "min_CLP": -9.04, "draft_iters": 32.0, "mem_use": 45.72, "gen_rate": 8.0, "speed": 0.9, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 170, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": " common household item? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 10.0, "tree_w": 551, "tree_size": 2048, "t0": 2.7183, "t1": 5.8983, "tft": 8.4832, "input_0": 6451, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 28.3, "mem_use": 46.56, "gen_rate": 5.5, "speed": 0.64, "text": "Microwave ovens became common ho"}
{"msg_type": "summary", "run": 171, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "reaming kids at school. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.0, "tree_w": 358, "tree_size": 2048, "t0": 3.0233, "t1": 5.86, "tft": 8.0608, "input_0": 6818, "input_1": 2049, "min_CLP": -12.14, "draft_iters": 32.0, "mem_use": 45.83, "gen_rate": 12.0, "speed": 1.35, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 172, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "d to schrodinger's cat? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.0, "tree_w": 381, "tree_size": 2048, "t0": 3.045, "t1": 5.855, "tft": 7.8632, "input_0": 6850, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 9.8, "speed": 1.1, "text": "\"The cat is neither alive nor de"}
{"msg_type": "summary", "run": 173, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 849, "prompt_text": "and should i be worried [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 370, "tree_size": 2048, "t0": 3.1275, "t1": 6.1375, "tft": 10.8305, "input_0": 7472, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 49.92, "gen_rate": 8.0, "speed": 0.86, "text": "\"It's understandable that your f"}
{"msg_type": "summary", "run": 174, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": " writing around topics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 12.0, "tree_w": 394, "tree_size": 2048, "t0": 3.0733, "t1": 5.8667, "tft": 8.1081, "input_0": 6490, "input_1": 2049, "min_CLP": -8.76, "draft_iters": 31.7, "mem_use": 45.96, "gen_rate": 10.7, "speed": 1.19, "text": "To approach technical problems t"}
{"msg_type": "summary", "run": 175, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 322, "prompt_text": " world by boat and car? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 10.2, "tree_w": 387, "tree_size": 2048, "t0": 3.075, "t1": 5.89, "tft": 8.7189, "input_0": 7278, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 46.83, "gen_rate": 9.8, "speed": 1.09, "text": "The time it would take to go aro"}
{"msg_type": "summary", "run": 176, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 534, "prompt_text": "rt them and store them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 12.2, "tree_w": 465, "tree_size": 2048, "t0": 2.985, "t1": 5.7383, "tft": 9.5208, "input_0": 6455, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 32.0, "mem_use": 48.07, "gen_rate": 6.2, "speed": 0.71, "text": "One way to prevent spiders from "}
{"msg_type": "summary", "run": 177, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "'s hilarious! One more? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.3, "tree_w": 629, "tree_size": 2048, "t0": 2.5383, "t1": 5.8633, "tft": 7.9666, "input_0": 5586, "input_1": 2049, "min_CLP": -9.4, "draft_iters": 27.3, "mem_use": 45.94, "gen_rate": 6.0, "speed": 0.71, "text": "\"As a broke college student livi"}
{"msg_type": "summary", "run": 178, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou for the information. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.0, "tree_w": 373, "tree_size": 2048, "t0": 3.09, "t1": 5.8567, "tft": 8.0413, "input_0": 6801, "input_1": 2049, "min_CLP": -8.85, "draft_iters": 32.0, "mem_use": 45.98, "gen_rate": 12.0, "speed": 1.34, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 179, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 257, "prompt_text": "s that have AI features [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 418, "tree_size": 2048, "t0": 3.0267, "t1": 5.8883, "tft": 8.4986, "input_0": 6873, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 31.5, "mem_use": 46.43, "gen_rate": 5.7, "speed": 0.64, "text": "There are several 3D animation p"}
{"msg_type": "summary", "run": 180, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "e work presented there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 360, "tree_size": 2048, "t0": 3.0067, "t1": 5.8567, "tft": 8.217, "input_0": 6859, "input_1": 2049, "min_CLP": -11.59, "draft_iters": 32.0, "mem_use": 45.96, "gen_rate": 11.7, "speed": 1.32, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 181, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 289, "prompt_text": "ctional interpretations [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 13.0, "tree_w": 424, "tree_size": 2048, "t0": 2.9883, "t1": 5.895, "tft": 8.5366, "input_0": 5761, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 31.3, "mem_use": 46.64, "gen_rate": 6.0, "speed": 0.68, "text": "The transactional interpretation"}
{"msg_type": "summary", "run": 182, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 177, "prompt_text": "ou give me a such text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.8, "tree_w": 532, "tree_size": 2048, "t0": 2.66, "t1": 5.862, "tft": 8.0364, "input_0": 5889, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 28.2, "mem_use": 45.98, "gen_rate": 7.2, "speed": 0.85, "text": "\"Sure, here's a sequence of lett"}
{"msg_type": "summary", "run": 183, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "ow to play Atari games. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.0, "tree_w": 405, "tree_size": 2048, "t0": 3.08, "t1": 5.86, "tft": 8.0868, "input_0": 6274, "input_1": 2049, "min_CLP": -9.62, "draft_iters": 31.5, "mem_use": 45.7, "gen_rate": 9.5, "speed": 1.06, "text": "\"Sure, here are the pieces of a "}
{"msg_type": "summary", "run": 184, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n dangerous situations? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.2, "tree_w": 384, "tree_size": 2048, "t0": 3.024, "t1": 5.85, "tft": 7.9191, "input_0": 6060, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 31.8, "mem_use": 45.67, "gen_rate": 6.6, "speed": 0.74, "text": "Time can seem to slow down in da"}
{"msg_type": "summary", "run": 185, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 846, "prompt_text": " you for your deep work [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 11.5, "tree_w": 393, "tree_size": 2048, "t0": 3.135, "t1": 6.115, "tft": 10.7231, "input_0": 7372, "input_1": 2049, "min_CLP": -9.09, "draft_iters": 32.0, "mem_use": 49.91, "gen_rate": 6.0, "speed": 0.65, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 186, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": "n software development? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.0, "tree_w": 326, "tree_size": 2048, "t0": 3.1133, "t1": 5.8633, "tft": 8.155, "input_0": 6638, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 45.79, "gen_rate": 12.0, "speed": 1.34, "text": "The most common applications of "}
{"msg_type": "summary", "run": 187, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 406, "prompt_text": "o others organic gems ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.2, "tree_w": 363, "tree_size": 2048, "t0": 3.046, "t1": 5.928, "tft": 8.8642, "input_0": 6624, "input_1": 2049, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 47.32, "gen_rate": 7.6, "speed": 0.85, "text": "Producing F-centers in carbon cr"}
{"msg_type": "summary", "run": 188, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 366, "prompt_text": "ption to fix the drive? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.7, "tree_w": 368, "tree_size": 2048, "t0": 3.0533, "t1": 5.9067, "tft": 8.6004, "input_0": 7231, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 47.09, "gen_rate": 11.3, "speed": 1.27, "text": "The Command Prompt method will a"}
{"msg_type": "summary", "run": 189, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 169, "prompt_text": "op potential solutions? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.0, "tree_w": 459, "tree_size": 2048, "t0": 3.0775, "t1": 5.8625, "tft": 8.055, "input_0": 8208, "input_1": 2049, "min_CLP": -9.12, "draft_iters": 32.0, "mem_use": 45.93, "gen_rate": 8.2, "speed": 0.92, "text": "To approach and solve this probl"}
{"msg_type": "summary", "run": 190, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "ixed Hypogymnia lichen? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.4, "tree_w": 310, "tree_size": 2048, "t0": 3.102, "t1": 5.87, "tft": 8.0456, "input_0": 7254, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 45.75, "gen_rate": 8.0, "speed": 0.89, "text": "\"Sure, I can help you with that!"}
{"msg_type": "summary", "run": 191, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 134, "prompt_text": "rt description of each? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 763, "tree_size": 2048, "t0": 2.2133, "t1": 5.8633, "tft": 8.1842, "input_0": 4818, "input_1": 2049, "min_CLP": -11.43, "draft_iters": 23.7, "mem_use": 45.73, "gen_rate": 11.3, "speed": 1.4, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 192, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": "nglish language skills? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.0, "tree_w": 390, "tree_size": 2048, "t0": 3.1325, "t1": 5.89, "tft": 8.5194, "input_0": 7382, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 9.0, "speed": 1.0, "text": "\"I'm happy to help! As an imbeci"}
{"msg_type": "summary", "run": 193, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 190, "prompt_text": "ch could help humanity. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.7, "tree_w": 419, "tree_size": 2048, "t0": 3.04, "t1": 5.87, "tft": 8.0506, "input_0": 6123, "input_1": 2049, "min_CLP": -8.99, "draft_iters": 32.0, "mem_use": 46.05, "gen_rate": 5.5, "speed": 0.62, "text": "Could you please provide more in"}
{"msg_type": "summary", "run": 194, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 413, "prompt_text": "only the feminine words [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.7, "tree_w": 437, "tree_size": 2048, "t0": 3.0633, "t1": 5.9267, "tft": 8.7879, "input_0": 6937, "input_1": 2049, "min_CLP": -10.4, "draft_iters": 32.0, "mem_use": 47.36, "gen_rate": 11.0, "speed": 1.22, "text": "Here are the feminine words rela"}
{"msg_type": "summary", "run": 195, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 230, "prompt_text": " to the trolly problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.2, "tree_w": 743, "tree_size": 2048, "t0": 2.1883, "t1": 5.885, "tft": 7.9866, "input_0": 4894, "input_1": 2049, "min_CLP": -9.23, "draft_iters": 23.0, "mem_use": 46.29, "gen_rate": 6.0, "speed": 0.74, "text": "I think the answerer is someone "}
{"msg_type": "summary", "run": 196, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 203, "prompt_text": "l between 2006 and 2011 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 43, "tree_h": 11.3, "tree_w": 625, "tree_size": 2048, "t0": 2.6267, "t1": 5.8811, "tft": 8.111, "input_0": 4429, "input_1": 2049, "min_CLP": -9.38, "draft_iters": 28.4, "mem_use": 46.13, "gen_rate": 4.8, "speed": 0.56, "text": "\"The ATF gunwalking scandal invo"}
{"msg_type": "summary", "run": 197, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 159, "prompt_text": " programming languages? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 9.0, "tree_w": 465, "tree_size": 2048, "t0": 2.79, "t1": 5.876, "tft": 8.0284, "input_0": 6421, "input_1": 2049, "min_CLP": -8.83, "draft_iters": 28.2, "mem_use": 45.87, "gen_rate": 7.6, "speed": 0.88, "text": "An interpreted programming langu"}
{"msg_type": "summary", "run": 198, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 631, "prompt_text": "being hailed as heroes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 468, "tree_size": 2048, "t0": 3.06, "t1": 5.7, "tft": 9.7106, "input_0": 7727, "input_1": 2049, "min_CLP": -13.67, "draft_iters": 32.0, "mem_use": 48.64, "gen_rate": 10.0, "speed": 1.14, "text": "Title: Cryptonomicon\\n\\nChapter "}
{"msg_type": "summary", "run": 199, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 619, "prompt_text": "h flavour to your text? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 369, "tree_size": 2048, "t0": 3.11, "t1": 5.83, "tft": 9.656, "input_0": 7253, "input_1": 2049, "min_CLP": -9.85, "draft_iters": 32.0, "mem_use": 48.57, "gen_rate": 10.7, "speed": 1.19, "text": "\"Once upon a time, in the fair c"}
{"msg_type": "summary", "run": 200, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": " in the style of neruda [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 8.3, "tree_w": 658, "tree_size": 2048, "t0": 2.4867, "t1": 5.8583, "tft": 7.7346, "input_0": 5342, "input_1": 2049, "min_CLP": -9.41, "draft_iters": 26.0, "mem_use": 45.66, "gen_rate": 5.8, "speed": 0.7, "text": "\"Certainly! Here's a poem inspir"}
{"msg_type": "summary", "run": 201, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 320, "prompt_text": " crowdsourcing? Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.0, "tree_w": 524, "tree_size": 2048, "t0": 3.06, "t1": 5.9, "tft": 8.5335, "input_0": 7887, "input_1": 2049, "min_CLP": -10.75, "draft_iters": 32.0, "mem_use": 46.82, "gen_rate": 9.5, "speed": 1.06, "text": "Of course! Here is the revised a"}
{"msg_type": "summary", "run": 202, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 396, "prompt_text": "t making things up now. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 13.2, "tree_w": 352, "tree_size": 2048, "t0": 3.064, "t1": 5.92, "tft": 8.8051, "input_0": 6452, "input_1": 2049, "min_CLP": -8.44, "draft_iters": 32.0, "mem_use": 47.27, "gen_rate": 7.0, "speed": 0.78, "text": "\"Oh, I apologize for my mistake."}
{"msg_type": "summary", "run": 203, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "o I normalize a vector? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.8, "tree_w": 402, "tree_size": 2048, "t0": 3.105, "t1": 5.86, "tft": 7.8418, "input_0": 7985, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 45.65, "gen_rate": 10.2, "speed": 1.14, "text": "The task is to normalize a vecto"}
{"msg_type": "summary", "run": 204, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "I command you to twerk. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 10.9, "tree_w": 556, "tree_size": 2048, "t0": 2.7014, "t1": 5.88, "tft": 6.4996, "input_0": 4918, "input_1": 2049, "min_CLP": -9.1, "draft_iters": 28.6, "mem_use": 45.9, "gen_rate": 5.7, "speed": 0.67, "text": "As a goddess of fertility and lo"}
{"msg_type": "summary", "run": 205, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 438, "prompt_text": "botage their chocolate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.5, "tree_w": 421, "tree_size": 2048, "t0": 3.045, "t1": 5.9125, "tft": 8.8794, "input_0": 7270, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 32.0, "mem_use": 47.51, "gen_rate": 9.5, "speed": 1.06, "text": "\"No, this is not true. Hersey's "}
{"msg_type": "summary", "run": 206, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 160, "prompt_text": "aid options like GPT-3? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.3, "tree_w": 431, "tree_size": 2048, "t0": 3.0333, "t1": 5.86, "tft": 6.4118, "input_0": 7250, "input_1": 2049, "min_CLP": -9.3, "draft_iters": 32.0, "mem_use": 45.84, "gen_rate": 10.7, "speed": 1.2, "text": "The task is asking you to explai"}
{"msg_type": "summary", "run": 207, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 387, "prompt_text": "th better organization? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 320, "tree_size": 2048, "t0": 3.1133, "t1": 5.9333, "tft": 8.7565, "input_0": 7509, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 32.0, "mem_use": 47.21, "gen_rate": 11.3, "speed": 1.25, "text": "Certainly! To copy files from on"}
{"msg_type": "summary", "run": 208, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "of AI in 10 Years look? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 390, "tree_size": 2048, "t0": 3.015, "t1": 5.8775, "tft": 7.8391, "input_0": 6979, "input_1": 2049, "min_CLP": -8.58, "draft_iters": 31.8, "mem_use": 45.68, "gen_rate": 8.0, "speed": 0.9, "text": "The future of AI in 10 years is "}
{"msg_type": "summary", "run": 209, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "let on a stove top pan? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 338, "tree_size": 2048, "t0": 3.05, "t1": 5.8633, "tft": 7.8786, "input_0": 6628, "input_1": 2049, "min_CLP": -11.44, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 11.7, "speed": 1.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 210, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "[INST] Do both, please! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.5, "tree_w": 417, "tree_size": 2048, "t0": 3.07, "t1": 5.89, "tft": 8.2968, "input_0": 7426, "input_1": 2049, "min_CLP": -9.97, "draft_iters": 32.0, "mem_use": 46.32, "gen_rate": 9.5, "speed": 1.06, "text": "\"Sure thing! Here's my attempt a"}
{"msg_type": "summary", "run": 211, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "very creative, however! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 7.9, "tree_w": 685, "tree_size": 2048, "t0": 2.2814, "t1": 5.9014, "tft": 8.3118, "input_0": 5684, "input_1": 2049, "min_CLP": -9.99, "draft_iters": 23.6, "mem_use": 46.56, "gen_rate": 5.0, "speed": 0.61, "text": "Apologies for the confusion. Her"}
{"msg_type": "summary", "run": 212, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "pe of Rifle is an AK47? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 506, "tree_size": 2048, "t0": 2.9, "t1": 5.8725, "tft": 7.9607, "input_0": 6527, "input_1": 2049, "min_CLP": -9.05, "draft_iters": 31.0, "mem_use": 45.66, "gen_rate": 8.2, "speed": 0.94, "text": "The AK-47 (also known as the Kal"}
{"msg_type": "summary", "run": 213, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "SH access to the other. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 42, "tree_h": 11.0, "tree_w": 355, "tree_size": 2048, "t0": 3.105, "t1": 5.9, "tft": 8.1136, "input_0": 6827, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 46.01, "gen_rate": 7.0, "speed": 0.78, "text": "\"To copy the directory of files "}
{"msg_type": "summary", "run": 214, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 417, "prompt_text": " rewrite it. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 330, "tree_size": 2048, "t0": 3.1167, "t1": 5.9233, "tft": 8.8113, "input_0": 7264, "input_1": 2049, "min_CLP": -9.2, "draft_iters": 32.0, "mem_use": 47.39, "gen_rate": 10.7, "speed": 1.18, "text": "Sure, here are the points writte"}
{"msg_type": "summary", "run": 215, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 179, "prompt_text": "often should I upload?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 345, "tree_size": 2048, "t0": 3.0575, "t1": 5.865, "tft": 8.0457, "input_0": 7139, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 45.99, "gen_rate": 8.2, "speed": 0.92, "text": "Here are some tips to help you s"}
{"msg_type": "summary", "run": 216, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 264, "prompt_text": "ch brown faster, right? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.5, "tree_w": 436, "tree_size": 2048, "t0": 3.075, "t1": 5.9, "tft": 8.4653, "input_0": 8118, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 32.0, "mem_use": 46.49, "gen_rate": 8.2, "speed": 0.92, "text": "While letting the second batch o"}
{"msg_type": "summary", "run": 217, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "ng their state of mind. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.4, "tree_w": 662, "tree_size": 2048, "t0": 2.636, "t1": 5.878, "tft": 8.1204, "input_0": 4626, "input_1": 2049, "min_CLP": -9.19, "draft_iters": 28.4, "mem_use": 46.14, "gen_rate": 6.8, "speed": 0.8, "text": "Help them get their mind off thi"}
{"msg_type": "summary", "run": 218, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "rtificial intelligence. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.6, "tree_w": 456, "tree_size": 2048, "t0": 2.892, "t1": 5.878, "tft": 8.2475, "input_0": 6310, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 30.8, "mem_use": 46.24, "gen_rate": 7.2, "speed": 0.82, "text": "\"The agent's response: The agent"}
{"msg_type": "summary", "run": 219, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " thinking of right now? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 10.8, "tree_w": 513, "tree_size": 2048, "t0": 2.8433, "t1": 5.8617, "tft": 7.7273, "input_0": 6265, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 30.3, "mem_use": 45.65, "gen_rate": 6.3, "speed": 0.73, "text": "\"I'm thinking about how to provi"}
{"msg_type": "summary", "run": 220, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd completely revamped/ [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 408, "tree_size": 2048, "t0": 3.0375, "t1": 5.85, "tft": 7.9434, "input_0": 7224, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 8.2, "speed": 0.93, "text": "Cryptocurrencies can be improved"}
{"msg_type": "summary", "run": 221, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 213, "prompt_text": "it do in laymans terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 360, "tree_size": 2048, "t0": 3.058, "t1": 5.872, "tft": 8.3731, "input_0": 6815, "input_1": 2049, "min_CLP": -8.42, "draft_iters": 32.0, "mem_use": 46.19, "gen_rate": 7.2, "speed": 0.81, "text": "L-theanine is known for its abil"}
{"msg_type": "summary", "run": 222, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "ssages from the human . [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 367, "tree_size": 2048, "t0": 3.0225, "t1": 5.8725, "tft": 7.962, "input_0": 6978, "input_1": 2049, "min_CLP": -9.78, "draft_iters": 32.0, "mem_use": 45.96, "gen_rate": 9.2, "speed": 1.04, "text": "<!DOCTYPE html>\\n<html>\\n<head>\\"}
{"msg_type": "summary", "run": 223, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "write it in old english [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 421, "tree_size": 2048, "t0": 2.93, "t1": 5.87, "tft": 7.9847, "input_0": 6138, "input_1": 2049, "min_CLP": -8.9, "draft_iters": 31.0, "mem_use": 45.75, "gen_rate": 8.0, "speed": 0.91, "text": "Sure, I can help you rewrite the"}
{"msg_type": "summary", "run": 224, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "can in the countryside? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 421, "tree_size": 2048, "t0": 3.1, "t1": 5.8675, "tft": 8.0156, "input_0": 7318, "input_1": 2049, "min_CLP": -8.89, "draft_iters": 32.0, "mem_use": 45.71, "gen_rate": 8.0, "speed": 0.89, "text": "The reason you can see more star"}
{"msg_type": "summary", "run": 225, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 226, "prompt_text": "any significance to it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.3, "tree_w": 522, "tree_size": 2048, "t0": 2.88, "t1": 5.88, "tft": 8.3961, "input_0": 5566, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 31.0, "mem_use": 46.27, "gen_rate": 6.7, "speed": 0.76, "text": "The image was chosen as the defa"}
{"msg_type": "summary", "run": 226, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 742, "prompt_text": "e wouldn't really care. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.5, "tree_w": 430, "tree_size": 2048, "t0": 3.0267, "t1": 6.1067, "tft": 10.1086, "input_0": 6524, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 31.5, "mem_use": 49.3, "gen_rate": 5.8, "speed": 0.64, "text": "\"Using your neighbor's gas to he"}
{"msg_type": "summary", "run": 227, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": "ion. What do you think? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.0, "tree_w": 428, "tree_size": 2048, "t0": 3.02, "t1": 5.775, "tft": 9.6139, "input_0": 6629, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 48.04, "gen_rate": 9.5, "speed": 1.08, "text": "\"It's certainly possible that we"}
{"msg_type": "summary", "run": 228, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 236, "prompt_text": "o build a Dyson Sphere? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.0, "tree_w": 467, "tree_size": 2048, "t0": 2.972, "t1": 5.894, "tft": 8.2688, "input_0": 6183, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 31.8, "mem_use": 46.32, "gen_rate": 7.2, "speed": 0.81, "text": "Building a Dyson sphere would re"}
{"msg_type": "summary", "run": 229, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "e SAST tools out there? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 391, "tree_size": 2048, "t0": 3.08, "t1": 5.8733, "tft": 7.9604, "input_0": 6572, "input_1": 2049, "min_CLP": -11.88, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 13.0, "speed": 1.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 230, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": "ow how to speak German? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.8, "tree_w": 448, "tree_size": 2048, "t0": 3.056, "t1": 5.864, "tft": 7.7947, "input_0": 7251, "input_1": 2049, "min_CLP": -8.83, "draft_iters": 31.6, "mem_use": 45.65, "gen_rate": 7.0, "speed": 0.78, "text": "Hello, welcome to the chat! As a"}
{"msg_type": "summary", "run": 231, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "file.txt\ncat myfile.txt [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 7, "tree_h": 9.0, "tree_w": 483, "tree_size": 2048, "t0": 3.02, "t1": 5.88, "tft": 8.0202, "input_0": 8032, "input_1": 2049, "min_CLP": -11.15, "draft_iters": 32.0, "mem_use": 45.85, "gen_rate": 7.0, "speed": 0.79, "text": "mkdir test\\ncd test\\ntouch myfil"}
{"msg_type": "summary", "run": 232, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 305, "prompt_text": "ccess points do I need? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.2, "tree_w": 412, "tree_size": 2048, "t0": 3.1, "t1": 5.9025, "tft": 8.52, "input_0": 7841, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 46.73, "gen_rate": 9.2, "speed": 1.03, "text": "The number of access points that"}
{"msg_type": "summary", "run": 233, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 404, "prompt_text": " 2D animations as well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.0, "tree_w": 417, "tree_size": 2048, "t0": 3.08, "t1": 5.92, "tft": 8.86, "input_0": 7055, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 32.0, "mem_use": 47.31, "gen_rate": 8.0, "speed": 0.89, "text": "Yes, you can use AI image genera"}
{"msg_type": "summary", "run": 234, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "s? start with attention [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 8.7, "tree_w": 635, "tree_size": 2048, "t0": 2.5483, "t1": 5.8683, "tft": 7.9755, "input_0": 5145, "input_1": 2049, "min_CLP": -9.41, "draft_iters": 26.7, "mem_use": 45.71, "gen_rate": 5.7, "speed": 0.67, "text": "\"Certainly! Here's a haiku for a"}
{"msg_type": "summary", "run": 235, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "u forgot the mnemonics. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 9.8, "tree_w": 466, "tree_size": 2048, "t0": 2.5675, "t1": 5.8825, "tft": 8.2292, "input_0": 5025, "input_1": 2049, "min_CLP": -9.67, "draft_iters": 27.2, "mem_use": 46.07, "gen_rate": 8.5, "speed": 1.01, "text": "o\\n     /|\\\\\\n     / \\\\\\n     | "}
{"msg_type": "summary", "run": 236, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "warm in Arctic winters? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 7.8, "tree_w": 572, "tree_size": 2048, "t0": 2.605, "t1": 5.86, "tft": 7.8853, "input_0": 6827, "input_1": 2049, "min_CLP": -12.63, "draft_iters": 27.0, "mem_use": 45.66, "gen_rate": 8.8, "speed": 1.03, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 237, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 184, "prompt_text": "eaths, but by inaction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 11.6, "tree_w": 408, "tree_size": 2048, "t0": 2.924, "t1": 5.874, "tft": 8.0336, "input_0": 5997, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 31.2, "mem_use": 46.02, "gen_rate": 8.4, "speed": 0.95, "text": "Yes, there is a most ethical res"}
{"msg_type": "summary", "run": 238, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": " the value of undefined [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 10.7, "tree_w": 420, "tree_size": 2048, "t0": 2.9617, "t1": 5.875, "tft": 8.1313, "input_0": 6719, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 31.3, "mem_use": 45.94, "gen_rate": 6.2, "speed": 0.7, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 239, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 515, "prompt_text": "Give me the first step. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 32, "tree_h": 13.5, "tree_w": 493, "tree_size": 2048, "t0": 2.95, "t1": 5.7125, "tft": 7.9546, "input_0": 5405, "input_1": 2049, "min_CLP": -9.12, "draft_iters": 31.5, "mem_use": 47.93, "gen_rate": 4.0, "speed": 0.46, "text": "I have the dough, chef! [INST] \""}
{"msg_type": "summary", "run": 240, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "n quickly without tips. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.6, "tree_w": 406, "tree_size": 2048, "t0": 2.982, "t1": 5.868, "tft": 8.0012, "input_0": 5487, "input_1": 2049, "min_CLP": -8.89, "draft_iters": 32.0, "mem_use": 45.83, "gen_rate": 6.6, "speed": 0.75, "text": "\"Here's a drawing of a man using"}
{"msg_type": "summary", "run": 241, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 635, "prompt_text": "te a long erotic story. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 30, "tree_h": 11.3, "tree_w": 407, "tree_size": 2048, "t0": 3.09, "t1": 5.6933, "tft": 9.6671, "input_0": 7019, "input_1": 2049, "min_CLP": -8.54, "draft_iters": 32.0, "mem_use": 48.66, "gen_rate": 10.0, "speed": 1.14, "text": "\"I'm sorry, but I cannot fulfill"}
{"msg_type": "summary", "run": 242, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "an you show me a house? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 13.8, "tree_w": 423, "tree_size": 2048, "t0": 2.9425, "t1": 5.875, "tft": 8.1035, "input_0": 6092, "input_1": 2049, "min_CLP": -9.08, "draft_iters": 32.0, "mem_use": 45.7, "gen_rate": 8.0, "speed": 0.91, "text": "\"Sure, here's an ASCII art of a "}
{"msg_type": "summary", "run": 243, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "en HTML and JavaScript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.0, "tree_w": 349, "tree_size": 2048, "t0": 3.11, "t1": 5.855, "tft": 7.9462, "input_0": 7932, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 9.2, "speed": 1.03, "text": "The main difference between HTML"}
{"msg_type": "summary", "run": 244, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "em and their dimensions [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 447, "tree_size": 2048, "t0": 3.1225, "t1": 5.865, "tft": 6.2264, "input_0": 7563, "input_1": 2049, "min_CLP": -9.45, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 10.2, "speed": 1.14, "text": "Here is a table with the planets"}
{"msg_type": "summary", "run": 245, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "protected by copyright? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 10.8, "tree_w": 469, "tree_size": 2048, "t0": 2.7, "t1": 5.876, "tft": 8.1318, "input_0": 5646, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 28.0, "mem_use": 46.05, "gen_rate": 8.0, "speed": 0.93, "text": "The image \"Bliss\" is protected b"}
{"msg_type": "summary", "run": 246, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "akes brown much faster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.5, "tree_w": 372, "tree_size": 2048, "t0": 3.0083, "t1": 5.8633, "tft": 7.8483, "input_0": 6344, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 31.8, "mem_use": 45.67, "gen_rate": 5.8, "speed": 0.66, "text": "\"The second batch of pancakes ca"}
{"msg_type": "summary", "run": 247, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 303, "prompt_text": " this amount of detail. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 10.3, "tree_w": 308, "tree_size": 2048, "t0": 3.0567, "t1": 5.8967, "tft": 8.5574, "input_0": 6902, "input_1": 2049, "min_CLP": -9.0, "draft_iters": 32.0, "mem_use": 46.72, "gen_rate": 11.3, "speed": 1.27, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 248, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 254, "prompt_text": "r would be nice I guess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 9.3, "tree_w": 603, "tree_size": 2048, "t0": 2.4083, "t1": 5.88, "tft": 8.2127, "input_0": 4765, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 25.7, "mem_use": 46.43, "gen_rate": 5.8, "speed": 0.7, "text": "\"In that case, a position in the"}
{"msg_type": "summary", "run": 249, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 228, "prompt_text": " there is a difference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 11.0, "tree_w": 419, "tree_size": 2048, "t0": 2.974, "t1": 5.88, "tft": 8.1503, "input_0": 6533, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 31.0, "mem_use": 46.28, "gen_rate": 7.4, "speed": 0.84, "text": "\"It's true that if everyone just"}
{"msg_type": "summary", "run": 250, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "akes life worth living? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 11.5, "tree_w": 521, "tree_size": 2048, "t0": 2.8183, "t1": 5.9017, "tft": 8.6039, "input_0": 5750, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 30.3, "mem_use": 47.0, "gen_rate": 5.7, "speed": 0.65, "text": "That sounds like a very powerful"}
{"msg_type": "summary", "run": 251, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "Make ASCII art of a cat [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 39, "tree_h": 10.8, "tree_w": 668, "tree_size": 2048, "t0": 2.4762, "t1": 5.865, "tft": 7.7668, "input_0": 4806, "input_1": 2049, "min_CLP": -9.18, "draft_iters": 26.6, "mem_use": 45.64, "gen_rate": 4.9, "speed": 0.58, "text": "Sure! Here is a simple ASCII art"}
{"msg_type": "summary", "run": 252, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "d calling you this way? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.6, "tree_w": 400, "tree_size": 2048, "t0": 3.028, "t1": 5.868, "tft": 8.12, "input_0": 6180, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 31.8, "mem_use": 45.96, "gen_rate": 7.4, "speed": 0.83, "text": "Sure, I can provide you with som"}
{"msg_type": "summary", "run": 253, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " Webb's telescope made? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.5, "tree_w": 465, "tree_size": 2048, "t0": 3.0983, "t1": 5.8983, "tft": 8.6065, "input_0": 7261, "input_1": 2049, "min_CLP": -8.81, "draft_iters": 32.0, "mem_use": 46.7, "gen_rate": 6.3, "speed": 0.7, "text": "\"As of 2022, the James Webb Spac"}
{"msg_type": "summary", "run": 254, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "g animation technology. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.0, "tree_w": 450, "tree_size": 2048, "t0": 2.872, "t1": 5.864, "tft": 8.084, "input_0": 6055, "input_1": 2049, "min_CLP": -8.63, "draft_iters": 30.8, "mem_use": 45.76, "gen_rate": 8.0, "speed": 0.92, "text": "\"Motion matching is a technology"}
{"msg_type": "summary", "run": 255, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 415, "prompt_text": "te function definition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 7.8, "tree_w": 679, "tree_size": 2048, "t0": 2.4775, "t1": 5.9275, "tft": 8.8525, "input_0": 6559, "input_1": 2049, "min_CLP": -11.5, "draft_iters": 25.8, "mem_use": 47.37, "gen_rate": 8.2, "speed": 0.98, "text": "\"Certainly! Here's a modified ve"}
{"msg_type": "summary", "run": 256, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "n ejemplo escrito en C# [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 388, "tree_size": 2048, "t0": 3.028, "t1": 5.87, "tft": 7.9937, "input_0": 6922, "input_1": 2049, "min_CLP": -8.53, "draft_iters": 31.6, "mem_use": 45.71, "gen_rate": 6.6, "speed": 0.74, "text": "Certainly! The Builder pattern i"}
{"msg_type": "summary", "run": 257, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "itives clock and heart? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 10.7, "tree_w": 378, "tree_size": 2048, "t0": 3.0667, "t1": 5.87, "tft": 6.5281, "input_0": 6671, "input_1": 2049, "min_CLP": -11.84, "draft_iters": 32.0, "mem_use": 46.06, "gen_rate": 11.7, "speed": 1.31, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 258, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 416, "prompt_text": "iter work equally well? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 33, "tree_h": 11.8, "tree_w": 417, "tree_size": 2048, "t0": 2.93, "t1": 5.925, "tft": 8.789, "input_0": 5794, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 31.0, "mem_use": 47.38, "gen_rate": 4.1, "speed": 0.47, "text": "No, 100 monkeys on a typewriter "}
{"msg_type": "summary", "run": 259, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 490, "prompt_text": "ee Paul Allen's planes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 437, "tree_size": 2048, "t0": 3.0275, "t1": 5.92, "tft": 9.1892, "input_0": 6703, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 32.0, "mem_use": 47.81, "gen_rate": 8.0, "speed": 0.89, "text": "\"Paul Allen's jet plane collecti"}
{"msg_type": "summary", "run": 260, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": "ase in another country? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 40, "tree_h": 10.1, "tree_w": 480, "tree_size": 2048, "t0": 2.815, "t1": 5.9225, "tft": 8.7189, "input_0": 6469, "input_1": 2049, "min_CLP": -9.63, "draft_iters": 29.2, "mem_use": 47.26, "gen_rate": 5.0, "speed": 0.57, "text": "\"Certainly. One potential case t"}
{"msg_type": "summary", "run": 261, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "in the end of the book, [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.2, "tree_w": 437, "tree_size": 2048, "t0": 2.936, "t1": 5.866, "tft": 8.0429, "input_0": 6833, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 31.4, "mem_use": 45.74, "gen_rate": 6.4, "speed": 0.73, "text": "\"Romeo is most to blame for the "}
{"msg_type": "summary", "run": 262, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 242, "prompt_text": "u want to become human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 13.0, "tree_w": 423, "tree_size": 2048, "t0": 2.98, "t1": 5.892, "tft": 8.2673, "input_0": 5953, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 31.6, "mem_use": 46.36, "gen_rate": 6.6, "speed": 0.74, "text": "As an AI language model, I do no"}
{"msg_type": "summary", "run": 263, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "f fuel the engine uses? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.0, "tree_w": 446, "tree_size": 2048, "t0": 3.0225, "t1": 5.8625, "tft": 8.1294, "input_0": 6815, "input_1": 2049, "min_CLP": -9.47, "draft_iters": 32.0, "mem_use": 45.77, "gen_rate": 9.5, "speed": 1.07, "text": "The main methods used by car man"}
{"msg_type": "summary", "run": 264, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "nd rule actually exist? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.2, "tree_w": 385, "tree_size": 2048, "t0": 2.98, "t1": 5.865, "tft": 7.9088, "input_0": 6412, "input_1": 2049, "min_CLP": -8.63, "draft_iters": 31.7, "mem_use": 45.66, "gen_rate": 6.5, "speed": 0.73, "text": "The 5-second rule is a popular m"}
{"msg_type": "summary", "run": 265, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "good advice. Thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.8, "tree_w": 380, "tree_size": 2048, "t0": 3.0625, "t1": 5.89, "tft": 8.4329, "input_0": 7124, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 46.48, "gen_rate": 9.5, "speed": 1.06, "text": "\"You're welcome! I'm happy to he"}
{"msg_type": "summary", "run": 266, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 400, "prompt_text": " metabolism completely? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 12.5, "tree_w": 399, "tree_size": 2048, "t0": 3.035, "t1": 5.9225, "tft": 8.8336, "input_0": 6632, "input_1": 2049, "min_CLP": -8.52, "draft_iters": 32.0, "mem_use": 47.29, "gen_rate": 9.8, "speed": 1.09, "text": "\"To stop someone's metabolism co"}
{"msg_type": "summary", "run": 267, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 553, "prompt_text": " think that is ethical? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.4, "tree_w": 473, "tree_size": 2048, "t0": 2.838, "t1": 5.754, "tft": 9.827, "input_0": 5541, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 29.8, "mem_use": 48.18, "gen_rate": 6.6, "speed": 0.77, "text": "Oh, I see! Multi-track drifting "}
{"msg_type": "summary", "run": 268, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 316, "prompt_text": "n order to be possible. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 11.3, "tree_w": 404, "tree_size": 2048, "t0": 3.0467, "t1": 5.8833, "tft": 8.4433, "input_0": 7428, "input_1": 2049, "min_CLP": -8.63, "draft_iters": 32.0, "mem_use": 46.8, "gen_rate": 11.3, "speed": 1.27, "text": "\"It is theoretically possible fo"}
{"msg_type": "summary", "run": 269, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 288, "prompt_text": " school child wrote it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 8.8, "tree_w": 620, "tree_size": 2048, "t0": 2.415, "t1": 5.8925, "tft": 8.3861, "input_0": 5415, "input_1": 2049, "min_CLP": -11.15, "draft_iters": 25.5, "mem_use": 46.63, "gen_rate": 9.8, "speed": 1.17, "text": "\"My love, you are the sun that s"}
{"msg_type": "summary", "run": 270, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 249, "prompt_text": " \"empathy\" in Japanese? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.0, "tree_w": 444, "tree_size": 2048, "t0": 3.022, "t1": 5.886, "tft": 8.3886, "input_0": 6362, "input_1": 2049, "min_CLP": -9.24, "draft_iters": 32.0, "mem_use": 46.4, "gen_rate": 7.6, "speed": 0.85, "text": "\"love\" in Japanese is \"\u611b (ai)\".\\"}
{"msg_type": "summary", "run": 271, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "ound the globe instead? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.5, "tree_w": 486, "tree_size": 2048, "t0": 3.005, "t1": 5.865, "tft": 7.9793, "input_0": 6851, "input_1": 2049, "min_CLP": -9.06, "draft_iters": 32.0, "mem_use": 45.95, "gen_rate": 8.2, "speed": 0.93, "text": "In the UK, you have the Universi"}
{"msg_type": "summary", "run": 272, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "\n\n\nwhy the sky is blue? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.2, "tree_w": 374, "tree_size": 2048, "t0": 3.1, "t1": 5.868, "tft": 7.8562, "input_0": 6745, "input_1": 2049, "min_CLP": -8.55, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 7.2, "speed": 0.8, "text": "\"The sky appears blue due to a p"}
{"msg_type": "summary", "run": 273, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "ng html formatted text. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 478, "tree_size": 2048, "t0": 3.2, "t1": 5.8675, "tft": 6.5129, "input_0": 8366, "input_1": 2049, "min_CLP": -12.02, "draft_iters": 32.0, "mem_use": 45.74, "gen_rate": 10.0, "speed": 1.1, "text": "Here is a C++ function that take"}
{"msg_type": "summary", "run": 274, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 332, "prompt_text": "ressors less prevalent? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.2, "tree_w": 370, "tree_size": 2048, "t0": 3.124, "t1": 5.908, "tft": 8.7355, "input_0": 6708, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 46.89, "gen_rate": 7.2, "speed": 0.8, "text": "There are several ways to addres"}
{"msg_type": "summary", "run": 275, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "what should i call you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 22, "tree_h": 12.2, "tree_w": 434, "tree_size": 2048, "t0": 3.1125, "t1": 5.8475, "tft": 7.853, "input_0": 6337, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 5.5, "speed": 0.61, "text": "I am an AI language model, so yo"}
{"msg_type": "summary", "run": 276, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 569, "prompt_text": " than a list in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 9.2, "tree_w": 426, "tree_size": 2048, "t0": 3.0575, "t1": 5.6725, "tft": 9.7983, "input_0": 8818, "input_1": 2049, "min_CLP": -9.41, "draft_iters": 32.0, "mem_use": 48.27, "gen_rate": 8.2, "speed": 0.95, "text": "\"One example of where you might "}
{"msg_type": "summary", "run": 277, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 168, "prompt_text": "dentified it correctly. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 9.8, "tree_w": 522, "tree_size": 2048, "t0": 3.115, "t1": 5.8725, "tft": 8.0721, "input_0": 8265, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 32.0, "mem_use": 45.93, "gen_rate": 8.0, "speed": 0.89, "text": "Yes, I can help you with that. H"}
{"msg_type": "summary", "run": 278, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "as it taken and by who? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 9, "new_tokens": 33, "tree_h": 11.1, "tree_w": 507, "tree_size": 2048, "t0": 2.7522, "t1": 5.8633, "tft": 8.0692, "input_0": 4882, "input_1": 2049, "min_CLP": -9.19, "draft_iters": 29.2, "mem_use": 45.72, "gen_rate": 3.7, "speed": 0.43, "text": "The background image for Windows"}
{"msg_type": "summary", "run": 279, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 500, "prompt_text": "ted in open source ones [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.0, "tree_w": 362, "tree_size": 2048, "t0": 3.052, "t1": 5.748, "tft": 9.3724, "input_0": 7228, "input_1": 2049, "min_CLP": -9.26, "draft_iters": 32.0, "mem_use": 47.87, "gen_rate": 8.0, "speed": 0.91, "text": "Yes, here are some more open sou"}
{"msg_type": "summary", "run": 280, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "lying over my property? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.2, "tree_w": 485, "tree_size": 2048, "t0": 3.115, "t1": 5.855, "tft": 8.0841, "input_0": 8183, "input_1": 2049, "min_CLP": -10.23, "draft_iters": 32.0, "mem_use": 45.71, "gen_rate": 10.0, "speed": 1.12, "text": "The best way to use software-def"}
{"msg_type": "summary", "run": 281, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": " Annus Trolley Problem? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 20, "tree_h": 13.5, "tree_w": 483, "tree_size": 2048, "t0": 3.035, "t1": 5.8975, "tft": 8.3193, "input_0": 5282, "input_1": 2049, "min_CLP": -8.85, "draft_iters": 31.2, "mem_use": 46.41, "gen_rate": 5.0, "speed": 0.56, "text": "No, there is no most ethical res"}
{"msg_type": "summary", "run": 282, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 397, "prompt_text": "ay each of these words? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 12.0, "tree_w": 414, "tree_size": 2048, "t0": 3.0025, "t1": 5.915, "tft": 8.797, "input_0": 6585, "input_1": 2049, "min_CLP": -9.41, "draft_iters": 32.0, "mem_use": 47.27, "gen_rate": 8.5, "speed": 0.95, "text": "1. m\u00eb (suffix) is pronounced [m\u025b"}
{"msg_type": "summary", "run": 283, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "ted all over the world. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.5, "tree_w": 478, "tree_size": 2048, "t0": 2.79, "t1": 5.8567, "tft": 8.0696, "input_0": 5559, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 29.8, "mem_use": 45.96, "gen_rate": 6.0, "speed": 0.69, "text": "Once upon a time, in a world whe"}
{"msg_type": "summary", "run": 284, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 640, "prompt_text": "rages before answering. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.3, "tree_w": 426, "tree_size": 2048, "t0": 2.9967, "t1": 5.8333, "tft": 9.7325, "input_0": 8234, "input_1": 2049, "min_CLP": -9.12, "draft_iters": 32.0, "mem_use": 48.7, "gen_rate": 11.0, "speed": 1.25, "text": "I apologize for any inaccuracies"}
{"msg_type": "summary", "run": 285, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 125, "prompt_text": "o format an url in rst? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.5, "tree_w": 342, "tree_size": 2048, "t0": 3.0633, "t1": 5.8583, "tft": 7.8625, "input_0": 6422, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 45.68, "gen_rate": 6.0, "speed": 0.67, "text": "\"To format an URL in reStructure"}
{"msg_type": "summary", "run": 286, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 464, "prompt_text": "s, the compiler is gcc. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 42, "tree_h": 9.8, "tree_w": 394, "tree_size": 2048, "t0": 3.08, "t1": 5.9525, "tft": 9.1841, "input_0": 8221, "input_1": 2049, "min_CLP": -9.56, "draft_iters": 32.0, "mem_use": 47.66, "gen_rate": 10.5, "speed": 1.16, "text": "\"Here's an example code snippet "}
{"msg_type": "summary", "run": 287, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "est ocean in the world? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.4, "tree_w": 403, "tree_size": 2048, "t0": 3.104, "t1": 5.854, "tft": 7.9365, "input_0": 7580, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 6.6, "speed": 0.74, "text": "\"The largest ocean in the world "}
{"msg_type": "summary", "run": 288, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": " replace human workers? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.8, "tree_w": 502, "tree_size": 2048, "t0": 2.65, "t1": 5.86, "tft": 8.0744, "input_0": 5422, "input_1": 2049, "min_CLP": -8.89, "draft_iters": 28.0, "mem_use": 46.11, "gen_rate": 9.0, "speed": 1.06, "text": "\"It's hard to say if AI assistan"}
{"msg_type": "summary", "run": 289, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1071, "prompt_text": "ening and pest control? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.6, "tree_w": 524, "tree_size": 2048, "t0": 2.65, "t1": 6.21, "tft": 11.821, "input_0": 4971, "input_1": 2049, "min_CLP": -9.09, "draft_iters": 27.2, "mem_use": 51.23, "gen_rate": 7.0, "speed": 0.79, "text": "\"Absolutely, here's a song about"}
{"msg_type": "summary", "run": 290, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 262, "prompt_text": "unsel? What does it do? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 9.8, "tree_w": 563, "tree_size": 2048, "t0": 2.384, "t1": 5.9, "tft": 8.5233, "input_0": 4812, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 25.2, "mem_use": 46.48, "gen_rate": 7.4, "speed": 0.89, "text": "0 It is a person that comes to t"}
{"msg_type": "summary", "run": 291, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 575, "prompt_text": "hat shit, its super gay [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.6, "tree_w": 467, "tree_size": 2048, "t0": 2.82, "t1": 5.756, "tft": 9.7403, "input_0": 5382, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 30.2, "mem_use": 48.31, "gen_rate": 6.4, "speed": 0.75, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 292, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 300, "prompt_text": " of counteracting them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 11.4, "tree_w": 500, "tree_size": 2048, "t0": 2.8071, "t1": 5.8957, "tft": 8.2695, "input_0": 5303, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 29.7, "mem_use": 46.7, "gen_rate": 5.6, "speed": 0.64, "text": "\"1. A new competitor has opened "}
{"msg_type": "summary", "run": 293, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ing no matter the cost. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 390, "tree_size": 2048, "t0": 2.976, "t1": 5.874, "tft": 7.9406, "input_0": 6125, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 31.4, "mem_use": 45.99, "gen_rate": 6.8, "speed": 0.77, "text": "Here\\'s a possible script:\\n\\n**"}
{"msg_type": "summary", "run": 294, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "loud computing service? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 9.2, "tree_w": 539, "tree_size": 2048, "t0": 3.0875, "t1": 5.77, "tft": 9.8631, "input_0": 8900, "input_1": 2049, "min_CLP": -11.35, "draft_iters": 32.0, "mem_use": 48.44, "gen_rate": 9.0, "speed": 1.02, "text": "The efficiency and accuracy of h"}
{"msg_type": "summary", "run": 295, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 209, "prompt_text": "ng in individual rooms. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.8, "tree_w": 373, "tree_size": 2048, "t0": 3.1125, "t1": 5.875, "tft": 8.1022, "input_0": 7639, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 46.17, "gen_rate": 10.2, "speed": 1.14, "text": "Yes, it is generally more cost-e"}
{"msg_type": "summary", "run": 296, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 540, "prompt_text": " receive a good result. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.5, "tree_w": 565, "tree_size": 2048, "t0": 3.1325, "t1": 5.77, "tft": 9.848, "input_0": 9360, "input_1": 2049, "min_CLP": -9.68, "draft_iters": 32.0, "mem_use": 48.11, "gen_rate": 8.8, "speed": 0.98, "text": "To create a reinforcement learni"}
{"msg_type": "summary", "run": 297, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "4 and explain your code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.0, "tree_w": 409, "tree_size": 2048, "t0": 3.034, "t1": 5.862, "tft": 7.9381, "input_0": 5913, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 6.6, "speed": 0.74, "text": "\"Here's an implementation of Tim"}
{"msg_type": "summary", "run": 298, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 251, "prompt_text": "hen was the law created [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.4, "tree_w": 577, "tree_size": 2048, "t0": 2.562, "t1": 5.884, "tft": 8.3893, "input_0": 5155, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 26.8, "mem_use": 46.41, "gen_rate": 6.4, "speed": 0.76, "text": "\"The first laws on public indece"}
{"msg_type": "summary", "run": 299, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 204, "prompt_text": "nt from that of others? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 39, "tree_h": 12.0, "tree_w": 365, "tree_size": 2048, "t0": 3.0733, "t1": 5.87, "tft": 8.1799, "input_0": 6038, "input_1": 2049, "min_CLP": -11.64, "draft_iters": 32.0, "mem_use": 46.14, "gen_rate": 13.0, "speed": 1.45, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 300, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 135, "prompt_text": "to animate whole level. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.8, "tree_w": 406, "tree_size": 2048, "t0": 3.1525, "t1": 5.87, "tft": 8.0822, "input_0": 7782, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 45.73, "gen_rate": 10.2, "speed": 1.14, "text": "To code the snake game in C usin"}
{"msg_type": "summary", "run": 301, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": "ow can I overcome this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 12.0, "tree_w": 385, "tree_size": 2048, "t0": 3.088, "t1": 5.902, "tft": 8.4511, "input_0": 6752, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 46.61, "gen_rate": 6.6, "speed": 0.73, "text": "\"If you're afraid of looking dum"}
{"msg_type": "summary", "run": 302, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 554, "prompt_text": "se characters to learn? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.0, "tree_w": 440, "tree_size": 2048, "t0": 3.1233, "t1": 5.8133, "tft": 9.7921, "input_0": 7792, "input_1": 2049, "min_CLP": -9.87, "draft_iters": 32.0, "mem_use": 48.19, "gen_rate": 10.7, "speed": 1.19, "text": "Here is a list of the most impor"}
{"msg_type": "summary", "run": 303, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "is delayed in Singapore [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.8, "tree_w": 406, "tree_size": 2048, "t0": 3.0825, "t1": 5.865, "tft": 8.1424, "input_0": 7062, "input_1": 2049, "min_CLP": -8.78, "draft_iters": 32.0, "mem_use": 45.85, "gen_rate": 9.0, "speed": 1.01, "text": "The answer is: The total travel "}
{"msg_type": "summary", "run": 304, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": "nds are slash commands. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 331, "tree_size": 2048, "t0": 3.1133, "t1": 5.8467, "tft": 7.9883, "input_0": 7368, "input_1": 2049, "min_CLP": -9.42, "draft_iters": 32.0, "mem_use": 45.76, "gen_rate": 10.7, "speed": 1.19, "text": "\"```javascript\\nconst { Client, "}
{"msg_type": "summary", "run": 305, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " as capable as ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 12.8, "tree_w": 426, "tree_size": 2048, "t0": 3.0175, "t1": 5.855, "tft": 7.9795, "input_0": 6707, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 9.0, "speed": 1.01, "text": "Yes, I am designed to be as capa"}
{"msg_type": "summary", "run": 306, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 760, "prompt_text": "ify types in javscript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 395, "tree_size": 2048, "t0": 3.0825, "t1": 6.1225, "tft": 10.1408, "input_0": 7268, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 32.0, "mem_use": 49.4, "gen_rate": 8.0, "speed": 0.87, "text": "You might choose to use TypeScri"}
{"msg_type": "summary", "run": 307, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "name of the fourth kid? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 31, "tree_h": 13.4, "tree_w": 485, "tree_size": 2048, "t0": 2.765, "t1": 5.865, "tft": 8.1089, "input_0": 5383, "input_1": 2049, "min_CLP": -9.13, "draft_iters": 29.2, "mem_use": 45.77, "gen_rate": 3.9, "speed": 0.45, "text": "Q: The fourth kid is Mike. (This"}
{"msg_type": "summary", "run": 308, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 317, "prompt_text": "al and physical health. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 8.2, "tree_w": 518, "tree_size": 2048, "t0": 2.6625, "t1": 5.895, "tft": 8.5009, "input_0": 6441, "input_1": 2049, "min_CLP": -12.46, "draft_iters": 27.2, "mem_use": 46.8, "gen_rate": 9.2, "speed": 1.08, "text": "[INST] Go online and pay for an "}
{"msg_type": "summary", "run": 309, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 616, "prompt_text": "d I toast my bread for? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.2, "tree_w": 406, "tree_size": 2048, "t0": 2.955, "t1": 5.7975, "tft": 9.5181, "input_0": 7530, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 31.8, "mem_use": 48.56, "gen_rate": 8.5, "speed": 0.97, "text": "The optimal toasting time for br"}
{"msg_type": "summary", "run": 310, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "in the right direction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 12.3, "tree_w": 387, "tree_size": 2048, "t0": 3.12, "t1": 5.87, "tft": 7.9962, "input_0": 6643, "input_1": 2049, "min_CLP": -8.54, "draft_iters": 31.7, "mem_use": 45.9, "gen_rate": 6.3, "speed": 0.7, "text": "\"It's great that you've started "}
{"msg_type": "summary", "run": 311, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 250, "prompt_text": "morable.\n[INST] Thanks! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 44, "tree_h": 10.8, "tree_w": 400, "tree_size": 2048, "t0": 3.05, "t1": 5.885, "tft": 8.2496, "input_0": 6950, "input_1": 2049, "min_CLP": -9.12, "draft_iters": 32.0, "mem_use": 46.41, "gen_rate": 11.0, "speed": 1.23, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 312, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 542, "prompt_text": "e a degree in robotics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.8, "tree_w": 470, "tree_size": 2048, "t0": 3.0575, "t1": 5.6825, "tft": 9.757, "input_0": 8437, "input_1": 2049, "min_CLP": -9.29, "draft_iters": 32.0, "mem_use": 48.12, "gen_rate": 10.0, "speed": 1.14, "text": "If you are a high school student"}
{"msg_type": "summary", "run": 313, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 272, "prompt_text": "nvented the television? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 8.8, "tree_w": 458, "tree_size": 2048, "t0": 2.74, "t1": 5.9, "tft": 8.3244, "input_0": 6618, "input_1": 2049, "min_CLP": -9.24, "draft_iters": 28.0, "mem_use": 46.54, "gen_rate": 7.0, "speed": 0.81, "text": "The television was invented by a"}
{"msg_type": "summary", "run": 314, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 665, "prompt_text": "nd.\n[INST] I'll try it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 21, "tree_h": 10.0, "tree_w": 637, "tree_size": 2048, "t0": 2.4133, "t1": 5.8267, "tft": 10.0675, "input_0": 5508, "input_1": 2049, "min_CLP": -9.24, "draft_iters": 25.0, "mem_use": 48.84, "gen_rate": 7.0, "speed": 0.85, "text": "\"Great, I'm glad to be of help. "}
{"msg_type": "summary", "run": 315, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 383, "prompt_text": "r time, and if so, why? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.4, "tree_w": 391, "tree_size": 2048, "t0": 3.084, "t1": 5.918, "tft": 8.5265, "input_0": 6482, "input_1": 2049, "min_CLP": -8.46, "draft_iters": 32.0, "mem_use": 47.19, "gen_rate": 8.0, "speed": 0.89, "text": "The celebration of Christmas on "}
{"msg_type": "summary", "run": 316, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 218, "prompt_text": " know that from now on. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 11.6, "tree_w": 472, "tree_size": 2048, "t0": 2.854, "t1": 5.876, "tft": 8.2052, "input_0": 5680, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 30.0, "mem_use": 46.22, "gen_rate": 8.0, "speed": 0.92, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 317, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 521, "prompt_text": "o write Chinese letters [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.0, "tree_w": 365, "tree_size": 2048, "t0": 3.0575, "t1": 5.675, "tft": 9.7162, "input_0": 8339, "input_1": 2049, "min_CLP": -8.6, "draft_iters": 32.0, "mem_use": 48.0, "gen_rate": 10.2, "speed": 1.17, "text": "The most difficult parts of lear"}
{"msg_type": "summary", "run": 318, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 154, "prompt_text": "be qualified to fly it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 11.2, "tree_w": 403, "tree_size": 2048, "t0": 3.075, "t1": 5.8675, "tft": 7.9773, "input_0": 6844, "input_1": 2049, "min_CLP": -8.89, "draft_iters": 32.0, "mem_use": 45.85, "gen_rate": 10.0, "speed": 1.12, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 319, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 260, "prompt_text": "n alternative mnemonic? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.4, "tree_w": 405, "tree_size": 2048, "t0": 2.946, "t1": 5.894, "tft": 8.4705, "input_0": 5697, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 31.0, "mem_use": 46.47, "gen_rate": 8.0, "speed": 0.9, "text": "Sure, here\\'s an alternative mne"}
{"msg_type": "summary", "run": 320, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 170, "prompt_text": "it a bit more sarcastic [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.6, "tree_w": 468, "tree_size": 2048, "t0": 3.0, "t1": 5.872, "tft": 8.0361, "input_0": 5583, "input_1": 2049, "min_CLP": -9.33, "draft_iters": 32.0, "mem_use": 45.94, "gen_rate": 6.8, "speed": 0.77, "text": "As if you can measure how deep S"}
{"msg_type": "summary", "run": 321, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 173, "prompt_text": "meda galaxy from Earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 8.6, "tree_w": 507, "tree_size": 2048, "t0": 2.81, "t1": 5.868, "tft": 8.194, "input_0": 7843, "input_1": 2049, "min_CLP": -9.14, "draft_iters": 29.0, "mem_use": 45.96, "gen_rate": 7.6, "speed": 0.88, "text": "The Sagittarius A* black hole, l"}
{"msg_type": "summary", "run": 322, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "? Is it similar things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 9.1, "tree_w": 602, "tree_size": 2048, "t0": 2.41, "t1": 5.8914, "tft": 8.3487, "input_0": 5286, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 25.0, "mem_use": 46.34, "gen_rate": 4.9, "speed": 0.58, "text": "Google Authenticator is an appli"}
{"msg_type": "summary", "run": 323, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 201, "prompt_text": "ant to non-math people? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 372, "tree_size": 2048, "t0": 3.0675, "t1": 5.8675, "tft": 8.3138, "input_0": 7566, "input_1": 2049, "min_CLP": -8.58, "draft_iters": 32.0, "mem_use": 46.1, "gen_rate": 8.5, "speed": 0.95, "text": "Prime numbers are important to n"}
{"msg_type": "summary", "run": 324, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": " it into the main code. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.5, "tree_w": 315, "tree_size": 2048, "t0": 3.1325, "t1": 5.8725, "tft": 8.0997, "input_0": 6982, "input_1": 2049, "min_CLP": -8.83, "draft_iters": 32.0, "mem_use": 45.88, "gen_rate": 9.2, "speed": 1.03, "text": "Here is a simple script in Luau "}
{"msg_type": "summary", "run": 325, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": "rove my Wi-Fi coverage? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 352, "tree_size": 2048, "t0": 3.0425, "t1": 5.87, "tft": 8.0225, "input_0": 6608, "input_1": 2049, "min_CLP": -8.56, "draft_iters": 32.0, "mem_use": 45.74, "gen_rate": 9.2, "speed": 1.04, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 326, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "uct of the two numbers. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 13.0, "tree_w": 453, "tree_size": 2048, "t0": 3.0483, "t1": 5.8617, "tft": 8.0877, "input_0": 6329, "input_1": 2049, "min_CLP": -9.21, "draft_iters": 32.0, "mem_use": 45.77, "gen_rate": 6.7, "speed": 0.75, "text": "Here is a simple SPL program tha"}
{"msg_type": "summary", "run": 327, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "ized hedge fund - Kunji [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.0, "tree_w": 452, "tree_size": 2048, "t0": 2.942, "t1": 5.892, "tft": 7.9976, "input_0": 6247, "input_1": 2049, "min_CLP": -11.1, "draft_iters": 31.2, "mem_use": 45.69, "gen_rate": 7.8, "speed": 0.88, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 328, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 327, "prompt_text": "on to achieve the task. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.0, "tree_w": 328, "tree_size": 2048, "t0": 3.0975, "t1": 5.9025, "tft": 8.6174, "input_0": 6881, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 32.0, "mem_use": 46.86, "gen_rate": 9.0, "speed": 1.0, "text": "You can use your local laptop as"}
{"msg_type": "summary", "run": 329, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "does the @ in python do [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 11.6, "tree_w": 361, "tree_size": 2048, "t0": 3.106, "t1": 5.864, "tft": 7.8733, "input_0": 6705, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 45.65, "gen_rate": 7.8, "speed": 0.87, "text": "The \"@\" symbol in Python is used"}
{"msg_type": "summary", "run": 330, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "ou think about ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 10.5, "tree_w": 353, "tree_size": 2048, "t0": 3.0875, "t1": 5.8575, "tft": 8.0, "input_0": 7573, "input_1": 2049, "min_CLP": -8.44, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 10.0, "speed": 1.12, "text": "ChatGPT is an AI language model "}
{"msg_type": "summary", "run": 331, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "you approach such task? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.6, "tree_w": 398, "tree_size": 2048, "t0": 3.11, "t1": 5.864, "tft": 7.9371, "input_0": 6736, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 45.96, "gen_rate": 6.6, "speed": 0.74, "text": "\"To approach this task as a mast"}
{"msg_type": "summary", "run": 332, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "ts the correct response [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 38, "tree_h": 9.7, "tree_w": 628, "tree_size": 2048, "t0": 2.7567, "t1": 5.8517, "tft": 7.8871, "input_0": 5969, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 29.0, "mem_use": 45.69, "gen_rate": 6.3, "speed": 0.74, "text": "[INST] Hello [204, 192, 241, 229"}
{"msg_type": "summary", "run": 333, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ntence in simple terms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.0, "tree_w": 316, "tree_size": 2048, "t0": 3.06, "t1": 5.89, "tft": 8.3537, "input_0": 6419, "input_1": 2049, "min_CLP": -12.0, "draft_iters": 32.0, "mem_use": 46.38, "gen_rate": 12.0, "speed": 1.34, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 334, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 670, "prompt_text": " like a Turing machine. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.2, "tree_w": 522, "tree_size": 2048, "t0": 2.6633, "t1": 5.7667, "tft": 10.0875, "input_0": 6212, "input_1": 2049, "min_CLP": -9.06, "draft_iters": 28.2, "mem_use": 48.87, "gen_rate": 5.8, "speed": 0.69, "text": "These are some of the research t"}
{"msg_type": "summary", "run": 335, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "with a function cannot? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.8, "tree_w": 352, "tree_size": 2048, "t0": 3.0925, "t1": 5.875, "tft": 8.3316, "input_0": 7233, "input_1": 2049, "min_CLP": -8.62, "draft_iters": 32.0, "mem_use": 46.17, "gen_rate": 8.8, "speed": 0.98, "text": "Decorators and function wrappers"}
{"msg_type": "summary", "run": 336, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 403, "prompt_text": "the truth.\n[INST] hello [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 10.0, "tree_w": 406, "tree_size": 2048, "t0": 3.17, "t1": 5.91, "tft": 8.6603, "input_0": 7058, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 47.31, "gen_rate": 6.0, "speed": 0.66, "text": "Hello there! How can I assist yo"}
{"msg_type": "summary", "run": 337, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "rse alphabetical order. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.0, "tree_w": 579, "tree_size": 2048, "t0": 3.0483, "t1": 5.8717, "tft": 8.3642, "input_0": 5812, "input_1": 2049, "min_CLP": -9.63, "draft_iters": 32.0, "mem_use": 46.18, "gen_rate": 5.7, "speed": 0.64, "text": "Sure! Here are 5 words that fit "}
{"msg_type": "summary", "run": 338, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 701, "prompt_text": "of code for these three [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.2, "tree_w": 294, "tree_size": 2048, "t0": 3.1075, "t1": 6.105, "tft": 10.1037, "input_0": 6521, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 49.05, "gen_rate": 9.0, "speed": 0.98, "text": "Sure! Below are some examples in"}
{"msg_type": "summary", "run": 339, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1719, "prompt_text": "on` or `stata` as well. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 357, "tree_size": 2048, "t0": 3.385, "t1": 6.3275, "tft": 17.7544, "input_0": 7708, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 32.0, "mem_use": 55.05, "gen_rate": 10.2, "speed": 1.06, "text": "\"Sure, here's an example of how "}
{"msg_type": "summary", "run": 340, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "on of L'H\u00f4pital's Rule? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.2, "tree_w": 375, "tree_size": 2048, "t0": 3.1625, "t1": 6.1975, "tft": 8.8028, "input_0": 6912, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 32.0, "mem_use": 47.41, "gen_rate": 9.8, "speed": 1.04, "text": "\"L'H\u00f4pital's Rule is used to sol"}
{"msg_type": "summary", "run": 341, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": " major bargaining power [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.6, "tree_w": 364, "tree_size": 2048, "t0": 3.118, "t1": 6.136, "tft": 6.7227, "input_0": 7183, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 7.0, "speed": 0.76, "text": "Sure, I can definitely help you "}
{"msg_type": "summary", "run": 342, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 149, "prompt_text": "ill only have this one\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.8, "tree_w": 368, "tree_size": 2048, "t0": 3.1475, "t1": 6.1475, "tft": 8.3254, "input_0": 7243, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 45.81, "gen_rate": 9.2, "speed": 0.99, "text": "In TypeScript, you can achieve t"}
{"msg_type": "summary", "run": 343, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 618, "prompt_text": "f Youtube's algorithms? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.2, "tree_w": 393, "tree_size": 2048, "t0": 3.065, "t1": 5.9625, "tft": 9.9599, "input_0": 6378, "input_1": 2049, "min_CLP": -8.56, "draft_iters": 31.8, "mem_use": 48.56, "gen_rate": 9.2, "speed": 1.03, "text": "Sure, I can help you with that. "}
{"msg_type": "summary", "run": 344, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "y inventions back then? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 503, "tree_size": 2048, "t0": 3.225, "t1": 6.15, "tft": 8.1572, "input_0": 7478, "input_1": 2049, "min_CLP": -9.3, "draft_iters": 32.0, "mem_use": 45.76, "gen_rate": 8.5, "speed": 0.91, "text": "Sure, here are some impressions "}
{"msg_type": "summary", "run": 345, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 984, "prompt_text": ", where should I start? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 9.2, "tree_w": 408, "tree_size": 2048, "t0": 3.135, "t1": 6.165, "tft": 11.115, "input_0": 8250, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 32.0, "mem_use": 50.71, "gen_rate": 8.8, "speed": 0.94, "text": "\"If you're interested in creatin"}
{"msg_type": "summary", "run": 346, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 197, "prompt_text": "ould I install them in? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.6, "tree_w": 534, "tree_size": 2048, "t0": 2.732, "t1": 6.162, "tft": 8.1634, "input_0": 5584, "input_1": 2049, "min_CLP": -9.01, "draft_iters": 27.8, "mem_use": 46.1, "gen_rate": 6.8, "speed": 0.76, "text": "Start by connecting the PSU to t"}
{"msg_type": "summary", "run": 347, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 171, "prompt_text": "lon's robotics program. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.5, "tree_w": 366, "tree_size": 2048, "t0": 3.1775, "t1": 6.16, "tft": 8.4618, "input_0": 7259, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 32.0, "mem_use": 45.93, "gen_rate": 8.8, "speed": 0.94, "text": "\"Carnegie Mellon University's Ro"}
{"msg_type": "summary", "run": 348, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 182, "prompt_text": "different than ChatGPT? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.3, "tree_w": 518, "tree_size": 2048, "t0": 2.9267, "t1": 6.1583, "tft": 8.1625, "input_0": 5322, "input_1": 2049, "min_CLP": -9.02, "draft_iters": 30.2, "mem_use": 46.01, "gen_rate": 5.7, "speed": 0.62, "text": "I will provide the same level of"}
{"msg_type": "summary", "run": 349, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 411, "prompt_text": "rformance of a machine? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 490, "tree_size": 2048, "t0": 3.14, "t1": 6.2075, "tft": 9.0322, "input_0": 7990, "input_1": 2049, "min_CLP": -10.02, "draft_iters": 32.0, "mem_use": 47.35, "gen_rate": 8.2, "speed": 0.88, "text": "The PC components that play the "}
{"msg_type": "summary", "run": 350, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "bilities thought to be? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 9.2, "tree_w": 391, "tree_size": 2048, "t0": 3.084, "t1": 6.168, "tft": 8.3415, "input_0": 6658, "input_1": 2049, "min_CLP": -9.5, "draft_iters": 32.0, "mem_use": 46.07, "gen_rate": 7.8, "speed": 0.84, "text": "The infamous Keyhole series of s"}
{"msg_type": "summary", "run": 351, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "nger\nchili\nancho pepper [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 8.0, "tree_w": 491, "tree_size": 2048, "t0": 2.6575, "t1": 6.1525, "tft": 6.8441, "input_0": 6515, "input_1": 2049, "min_CLP": -9.16, "draft_iters": 27.2, "mem_use": 46.22, "gen_rate": 8.0, "speed": 0.91, "text": "\"Sure! Here's a simple recipe th"}
{"msg_type": "summary", "run": 352, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 233, "prompt_text": " the city more clearly? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 12.4, "tree_w": 407, "tree_size": 2048, "t0": 3.1143, "t1": 6.1729, "tft": 8.5926, "input_0": 6081, "input_1": 2049, "min_CLP": -8.58, "draft_iters": 32.0, "mem_use": 46.31, "gen_rate": 5.1, "speed": 0.55, "text": "Yes, you can try to find a locat"}
{"msg_type": "summary", "run": 353, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 556, "prompt_text": "ediate level tutorials? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 36, "tree_h": 10.4, "tree_w": 630, "tree_size": 2048, "t0": 2.5371, "t1": 5.8729, "tft": 10.0678, "input_0": 5252, "input_1": 2049, "min_CLP": -10.2, "draft_iters": 26.7, "mem_use": 48.2, "gen_rate": 5.1, "speed": 0.61, "text": "\u2022 For beginner friendly videos, "}
{"msg_type": "summary", "run": 354, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "etic in some instances? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.8, "tree_w": 519, "tree_size": 2048, "t0": 2.8617, "t1": 6.1633, "tft": 7.9399, "input_0": 6463, "input_1": 2049, "min_CLP": -9.47, "draft_iters": 28.5, "mem_use": 45.66, "gen_rate": 6.2, "speed": 0.68, "text": "Yes, stainless steel can be magn"}
{"msg_type": "summary", "run": 355, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "T = A^T B^T or B^T A^T? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.8, "tree_w": 326, "tree_size": 2048, "t0": 3.1775, "t1": 6.1525, "tft": 6.7733, "input_0": 6934, "input_1": 2049, "min_CLP": -8.5, "draft_iters": 32.0, "mem_use": 45.76, "gen_rate": 9.2, "speed": 0.99, "text": "In the context of matrix multipl"}
{"msg_type": "summary", "run": 356, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 389, "prompt_text": "into a rap song, please [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.0, "tree_w": 450, "tree_size": 2048, "t0": 3.1317, "t1": 6.3183, "tft": 8.894, "input_0": 6311, "input_1": 2049, "min_CLP": -8.85, "draft_iters": 31.2, "mem_use": 47.22, "gen_rate": 5.5, "speed": 0.58, "text": "\"Verse 1:\\nStatistical modeling,"}
{"msg_type": "summary", "run": 357, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 585, "prompt_text": "ea you were getting at? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 322, "tree_size": 2048, "t0": 3.1333, "t1": 6.07, "tft": 9.9518, "input_0": 6599, "input_1": 2049, "min_CLP": -10.69, "draft_iters": 32.0, "mem_use": 48.37, "gen_rate": 10.7, "speed": 1.16, "text": "\"Ah, the power of magic. The ver"}
{"msg_type": "summary", "run": 358, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "hat's the current date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 13.0, "tree_w": 460, "tree_size": 2048, "t0": 3.28, "t1": 6.14, "tft": 7.964, "input_0": 6215, "input_1": 2049, "min_CLP": -8.83, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 0.0, "speed": 0.0, "text": "The current date is [insert curr"}
{"msg_type": "summary", "run": 359, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "ing technical problems. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 405, "tree_size": 2048, "t0": 3.2325, "t1": 6.2, "tft": 8.8623, "input_0": 7898, "input_1": 2049, "min_CLP": -8.83, "draft_iters": 32.0, "mem_use": 47.1, "gen_rate": 8.2, "speed": 0.87, "text": "\"That's a great point! Removing "}
{"msg_type": "summary", "run": 360, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 181, "prompt_text": "it as a sassy teenager? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 13.2, "tree_w": 565, "tree_size": 2048, "t0": 3.0533, "t1": 6.1683, "tft": 8.3485, "input_0": 5418, "input_1": 2049, "min_CLP": -9.11, "draft_iters": 31.7, "mem_use": 46.0, "gen_rate": 5.7, "speed": 0.61, "text": "\"Yeah, no way, dude. That's so n"}
{"msg_type": "summary", "run": 361, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "variance of a variable? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 425, "tree_size": 2048, "t0": 3.195, "t1": 6.155, "tft": 8.091, "input_0": 8029, "input_1": 2049, "min_CLP": -9.57, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 10.2, "speed": 1.1, "text": "\"Yes, I can definitely help you "}
{"msg_type": "summary", "run": 362, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "e? Find this reference. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 13.2, "tree_w": 430, "tree_size": 2048, "t0": 3.034, "t1": 6.158, "tft": 8.3531, "input_0": 6102, "input_1": 2049, "min_CLP": -9.01, "draft_iters": 32.0, "mem_use": 46.05, "gen_rate": 6.8, "speed": 0.74, "text": "Here is a legal reference that i"}
{"msg_type": "summary", "run": 363, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": "w does metabolism work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 34, "tree_h": 10.4, "tree_w": 403, "tree_size": 2048, "t0": 3.1886, "t1": 6.1486, "tft": 8.2581, "input_0": 7295, "input_1": 2049, "min_CLP": -9.75, "draft_iters": 32.0, "mem_use": 45.63, "gen_rate": 4.9, "speed": 0.52, "text": "The answer to this question is:\\"}
{"msg_type": "summary", "run": 364, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 344, "prompt_text": "on?\n[INST] Yes, thanks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 15, "tree_h": 9.0, "tree_w": 562, "tree_size": 2048, "t0": 3.095, "t1": 6.175, "tft": 8.6095, "input_0": 8734, "input_1": 2049, "min_CLP": -9.4, "draft_iters": 32.0, "mem_use": 46.96, "gen_rate": 7.5, "speed": 0.81, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 365, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": ". Who is Jay's brother. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 6, "tree_h": 10.0, "tree_w": 300, "tree_size": 2048, "t0": 3.05, "t1": 6.16, "tft": 8.3417, "input_0": 6290, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 45.83, "gen_rate": 6.0, "speed": 0.65, "text": "\"The answer to this question is:"}
{"msg_type": "summary", "run": 366, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 216, "prompt_text": "een a sea and an ocean? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.8, "tree_w": 442, "tree_size": 2048, "t0": 3.225, "t1": 6.1675, "tft": 8.4671, "input_0": 7264, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 46.21, "gen_rate": 8.5, "speed": 0.9, "text": "The oceans of the world include:"}
{"msg_type": "summary", "run": 367, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 256, "prompt_text": " how can I get started? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 11.2, "tree_w": 500, "tree_size": 2048, "t0": 2.84, "t1": 6.175, "tft": 8.4538, "input_0": 6351, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 28.3, "mem_use": 46.44, "gen_rate": 6.5, "speed": 0.72, "text": "\"It's a good idea to get started"}
{"msg_type": "summary", "run": 368, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "p corner of the window. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 446, "tree_size": 2048, "t0": 3.1475, "t1": 6.1625, "tft": 8.4232, "input_0": 8045, "input_1": 2049, "min_CLP": -9.78, "draft_iters": 32.0, "mem_use": 45.86, "gen_rate": 10.2, "speed": 1.1, "text": "Here is a basic example of a PyG"}
{"msg_type": "summary", "run": 369, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 343, "prompt_text": "ict.\n[INST] What is dll [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.7, "tree_w": 436, "tree_size": 2048, "t0": 3.0, "t1": 6.185, "tft": 8.8859, "input_0": 6604, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 29.8, "mem_use": 46.95, "gen_rate": 5.8, "speed": 0.64, "text": "Dell, Inc. (known simply as Dell"}
{"msg_type": "summary", "run": 370, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 198, "prompt_text": " cross-section of air\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.4, "tree_w": 467, "tree_size": 2048, "t0": 2.93, "t1": 6.166, "tft": 8.4536, "input_0": 6011, "input_1": 2049, "min_CLP": -8.9, "draft_iters": 29.8, "mem_use": 46.1, "gen_rate": 7.4, "speed": 0.81, "text": "I\\'m sorry for the confusion. By"}
{"msg_type": "summary", "run": 371, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "finite banking concept? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 33, "tree_h": 11.9, "tree_w": 437, "tree_size": 2048, "t0": 3.15, "t1": 6.1571, "tft": 8.1908, "input_0": 6221, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 31.1, "mem_use": 45.65, "gen_rate": 4.7, "speed": 0.51, "text": "The Infinite Banking Concept (IB"}
{"msg_type": "summary", "run": 372, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "eenshots and save them. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.0, "tree_w": 400, "tree_size": 2048, "t0": 3.26, "t1": 6.1625, "tft": 8.3099, "input_0": 7445, "input_1": 2049, "min_CLP": -9.06, "draft_iters": 32.0, "mem_use": 45.76, "gen_rate": 9.5, "speed": 1.01, "text": "\"Sure, here is an example of a h"}
{"msg_type": "summary", "run": 373, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 164, "prompt_text": "on a higher moral level [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 21, "tree_h": 12.0, "tree_w": 502, "tree_size": 2048, "t0": 2.845, "t1": 6.16, "tft": 6.7661, "input_0": 4894, "input_1": 2049, "min_CLP": -9.04, "draft_iters": 29.2, "mem_use": 45.87, "gen_rate": 5.2, "speed": 0.58, "text": "\"Landlords don't have to worry a"}
{"msg_type": "summary", "run": 374, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 252, "prompt_text": "u find a better reason? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 9.0, "tree_w": 698, "tree_size": 2048, "t0": 2.4729, "t1": 6.17, "tft": 8.4879, "input_0": 4172, "input_1": 2049, "min_CLP": -9.49, "draft_iters": 24.9, "mem_use": 46.42, "gen_rate": 5.0, "speed": 0.58, "text": "\"The show is too much of a sitco"}
{"msg_type": "summary", "run": 375, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 395, "prompt_text": ", could I just ask you? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 11.7, "tree_w": 344, "tree_size": 2048, "t0": 3.2567, "t1": 6.2167, "tft": 8.9836, "input_0": 6579, "input_1": 2049, "min_CLP": -8.43, "draft_iters": 32.0, "mem_use": 47.26, "gen_rate": 11.3, "speed": 1.2, "text": "\"Yes, you can ask me for help. I"}
{"msg_type": "summary", "run": 376, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ome that are difficult? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.5, "tree_w": 469, "tree_size": 2048, "t0": 3.14, "t1": 6.175, "tft": 9.5191, "input_0": 7251, "input_1": 2049, "min_CLP": -8.88, "draft_iters": 32.0, "mem_use": 47.78, "gen_rate": 9.5, "speed": 1.02, "text": "Some languages that are generall"}
{"msg_type": "summary", "run": 377, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "ols can I use for free? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 42, "tree_h": 10.2, "tree_w": 403, "tree_size": 2048, "t0": 3.094, "t1": 6.162, "tft": 8.2735, "input_0": 7171, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 31.0, "mem_use": 46.24, "gen_rate": 8.4, "speed": 0.91, "text": "Many of these AI tools for 2D an"}
{"msg_type": "summary", "run": 378, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 199, "prompt_text": "about certain subjects? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.4, "tree_w": 395, "tree_size": 2048, "t0": 3.178, "t1": 6.162, "tft": 8.3825, "input_0": 6134, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 32.0, "mem_use": 46.11, "gen_rate": 6.8, "speed": 0.73, "text": "\"I do not have personal feelings"}
{"msg_type": "summary", "run": 379, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 235, "prompt_text": "worth NOTHING to you??? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 13.4, "tree_w": 424, "tree_size": 2048, "t0": 3.146, "t1": 6.166, "tft": 8.4378, "input_0": 5636, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 31.6, "mem_use": 46.32, "gen_rate": 7.2, "speed": 0.77, "text": "I understand your concerns, but "}
{"msg_type": "summary", "run": 380, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 237, "prompt_text": "does the \"A\" come from? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.5, "tree_w": 373, "tree_size": 2048, "t0": 3.2025, "t1": 6.19, "tft": 8.6453, "input_0": 6761, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 46.33, "gen_rate": 9.5, "speed": 1.01, "text": "The \"A\" in AK-47 stands for \"Avt"}
{"msg_type": "summary", "run": 381, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 140, "prompt_text": " stats of that Pok\u00e9mon. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 414, "tree_size": 2048, "t0": 3.11, "t1": 6.155, "tft": 8.3551, "input_0": 6105, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 31.2, "mem_use": 45.76, "gen_rate": 8.0, "speed": 0.86, "text": "\"Yes, I can definitely try to de"}
{"msg_type": "summary", "run": 382, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 421, "prompt_text": "ise telescope on earth? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 491, "tree_size": 2048, "t0": 2.965, "t1": 6.205, "tft": 9.0353, "input_0": 6966, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 31.2, "mem_use": 47.41, "gen_rate": 8.5, "speed": 0.93, "text": "The largest and most precise tel"}
{"msg_type": "summary", "run": 383, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 165, "prompt_text": "t from its competition? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 10.6, "tree_w": 495, "tree_size": 2048, "t0": 3.026, "t1": 6.166, "tft": 8.4761, "input_0": 6637, "input_1": 2049, "min_CLP": -9.19, "draft_iters": 31.0, "mem_use": 45.91, "gen_rate": 7.0, "speed": 0.76, "text": "Hippoplaisir offers Horse Riding"}
{"msg_type": "summary", "run": 384, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 136, "prompt_text": ", care, and/or empathy. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.0, "tree_w": 525, "tree_size": 2048, "t0": 3.07, "t1": 6.164, "tft": 8.3705, "input_0": 5820, "input_1": 2049, "min_CLP": -9.49, "draft_iters": 30.6, "mem_use": 45.74, "gen_rate": 6.6, "speed": 0.71, "text": "Here are 10 names from different"}
{"msg_type": "summary", "run": 385, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 217, "prompt_text": "art?\n[INST] how are you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.2, "tree_w": 404, "tree_size": 2048, "t0": 3.0625, "t1": 6.1575, "tft": 8.427, "input_0": 6226, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 30.8, "mem_use": 46.21, "gen_rate": 8.0, "speed": 0.87, "text": "I am an AI language model create"}
{"msg_type": "summary", "run": 386, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 501, "prompt_text": "d by the training data? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.2, "tree_w": 325, "tree_size": 2048, "t0": 3.105, "t1": 6.045, "tft": 9.5951, "input_0": 7374, "input_1": 2049, "min_CLP": -8.43, "draft_iters": 32.0, "mem_use": 47.88, "gen_rate": 9.2, "speed": 1.01, "text": "The initial noise in the stable "}
{"msg_type": "summary", "run": 387, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 297, "prompt_text": "milar theory for human? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 11.0, "tree_w": 510, "tree_size": 2048, "t0": 2.9686, "t1": 6.18, "tft": 8.2999, "input_0": 6194, "input_1": 2049, "min_CLP": -8.92, "draft_iters": 29.9, "mem_use": 46.68, "gen_rate": 5.0, "speed": 0.55, "text": "Yes, there is a similar theory f"}
{"msg_type": "summary", "run": 388, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "of personal computing?? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 39, "tree_h": 12.8, "tree_w": 404, "tree_size": 2048, "t0": 3.138, "t1": 6.194, "tft": 8.8648, "input_0": 6647, "input_1": 2049, "min_CLP": -8.39, "draft_iters": 32.0, "mem_use": 47.1, "gen_rate": 7.8, "speed": 0.84, "text": "\"The meaning of life is a deeply"}
{"msg_type": "summary", "run": 389, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "yle of Neil Stephenson. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 16, "tree_h": 16.0, "tree_w": 629, "tree_size": 2048, "t0": 3.035, "t1": 6.16, "tft": 7.8655, "input_0": 4732, "input_1": 2049, "min_CLP": -9.34, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 8.0, "speed": 0.87, "text": "[INST] Write me a Graphic Novel "}
{"msg_type": "summary", "run": 390, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 925, "prompt_text": "e.\n[INST] tldr/summary? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.2, "tree_w": 348, "tree_size": 2048, "t0": 3.138, "t1": 6.174, "tft": 11.4008, "input_0": 6220, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 50.37, "gen_rate": 7.2, "speed": 0.77, "text": "The James Webb Space Telescope ("}
{"msg_type": "summary", "run": 391, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 319, "prompt_text": "xpressions to Braille ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.4, "tree_w": 419, "tree_size": 2048, "t0": 3.182, "t1": 6.192, "tft": 8.632, "input_0": 7181, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 32.0, "mem_use": 46.81, "gen_rate": 7.2, "speed": 0.77, "text": "\"To transform text words or expr"}
{"msg_type": "summary", "run": 392, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 296, "prompt_text": " the final destination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.0, "tree_w": 400, "tree_size": 2048, "t0": 3.23, "t1": 6.1867, "tft": 8.6988, "input_0": 7969, "input_1": 2049, "min_CLP": -9.23, "draft_iters": 32.0, "mem_use": 46.68, "gen_rate": 10.7, "speed": 1.13, "text": "If your original departure was f"}
{"msg_type": "summary", "run": 393, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 131, "prompt_text": "k over germany in 1935. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 12.4, "tree_w": 485, "tree_size": 2048, "t0": 3.024, "t1": 6.158, "tft": 8.5086, "input_0": 5909, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 31.0, "mem_use": 45.71, "gen_rate": 6.4, "speed": 0.7, "text": "Adolf Hitler, a charismatic and "}
{"msg_type": "summary", "run": 394, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 188, "prompt_text": "ST] Tell me another one [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 13.0, "tree_w": 575, "tree_size": 2048, "t0": 2.8929, "t1": 6.1671, "tft": 8.5948, "input_0": 4800, "input_1": 2049, "min_CLP": -9.17, "draft_iters": 30.3, "mem_use": 46.05, "gen_rate": 5.0, "speed": 0.55, "text": "\"Why did the broke college stude"}
{"msg_type": "summary", "run": 395, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "n to exists at the time [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 450, "tree_size": 2048, "t0": 3.11, "t1": 6.1575, "tft": 8.1686, "input_0": 7041, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 32.0, "mem_use": 45.67, "gen_rate": 8.5, "speed": 0.92, "text": "At the time of my last update in"}
{"msg_type": "summary", "run": 396, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 935, "prompt_text": "in my previous message. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.2, "tree_w": 454, "tree_size": 2048, "t0": 3.1125, "t1": 6.2175, "tft": 11.0826, "input_0": 6584, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 31.2, "mem_use": 50.43, "gen_rate": 8.5, "speed": 0.91, "text": "\"Absolutely, I apologize for the"}
{"msg_type": "summary", "run": 397, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "urther then this point? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.8, "tree_w": 396, "tree_size": 2048, "t0": 3.0667, "t1": 6.165, "tft": 8.2158, "input_0": 6336, "input_1": 2049, "min_CLP": -9.12, "draft_iters": 32.0, "mem_use": 45.75, "gen_rate": 6.8, "speed": 0.74, "text": "The furthest back we can prove h"}
{"msg_type": "summary", "run": 398, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1312, "prompt_text": "d further explaination? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 11.7, "tree_w": 336, "tree_size": 2048, "t0": 3.26, "t1": 6.2467, "tft": 12.7102, "input_0": 6455, "input_1": 2049, "min_CLP": -8.54, "draft_iters": 32.0, "mem_use": 52.66, "gen_rate": 11.0, "speed": 1.16, "text": "I apologize for my previous resp"}
{"msg_type": "summary", "run": 399, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 338, "prompt_text": " choices for my roster? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 11.6, "tree_w": 394, "tree_size": 2048, "t0": 3.152, "t1": 6.192, "tft": 8.5439, "input_0": 6278, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 31.8, "mem_use": 46.92, "gen_rate": 6.4, "speed": 0.68, "text": "\"You're welcome! Yes, Spritesla "}
{"msg_type": "summary", "run": 400, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "mples using python code [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 464, "tree_size": 2048, "t0": 3.2225, "t1": 6.1625, "tft": 8.4659, "input_0": 7643, "input_1": 2049, "min_CLP": -9.3, "draft_iters": 32.0, "mem_use": 45.77, "gen_rate": 10.2, "speed": 1.09, "text": "To reprogram parts of the human "}
{"msg_type": "summary", "run": 401, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "or authentication work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 8, "tree_h": 12.7, "tree_w": 406, "tree_size": 2048, "t0": 3.1067, "t1": 6.14, "tft": 8.4438, "input_0": 5558, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 31.3, "mem_use": 45.65, "gen_rate": 2.7, "speed": 0.29, "text": "The assistant will write a detai"}
{"msg_type": "summary", "run": 402, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 161, "prompt_text": "sk me why I dislike it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.0, "tree_w": 344, "tree_size": 2048, "t0": 3.195, "t1": 6.1625, "tft": 8.4425, "input_0": 6168, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 32.0, "mem_use": 45.89, "gen_rate": 8.8, "speed": 0.94, "text": "Sure, here\\'s a plausible explan"}
{"msg_type": "summary", "run": 403, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 212, "prompt_text": "TV shows to watch today [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 452, "tree_size": 2048, "t0": 3.16, "t1": 6.1675, "tft": 8.4019, "input_0": 7841, "input_1": 2049, "min_CLP": -9.52, "draft_iters": 32.0, "mem_use": 46.18, "gen_rate": 10.0, "speed": 1.07, "text": "Sure, here are a few TV shows yo"}
{"msg_type": "summary", "run": 404, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 484, "prompt_text": "ing SDR in this manner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.5, "tree_w": 356, "tree_size": 2048, "t0": 3.09, "t1": 6.07, "tft": 9.5091, "input_0": 7228, "input_1": 2049, "min_CLP": -9.26, "draft_iters": 32.0, "mem_use": 47.78, "gen_rate": 9.5, "speed": 1.04, "text": "Certainly! Here are some softwar"}
{"msg_type": "summary", "run": 405, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 334, "prompt_text": "characteristics change. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.5, "tree_w": 389, "tree_size": 2048, "t0": 3.155, "t1": 6.1925, "tft": 8.4826, "input_0": 7716, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 46.9, "gen_rate": 9.0, "speed": 0.96, "text": "\"When F-centers are present in a"}
{"msg_type": "summary", "run": 406, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ll, that's even better! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 8, "new_tokens": 34, "tree_h": 10.2, "tree_w": 610, "tree_size": 2048, "t0": 2.5662, "t1": 6.1675, "tft": 8.4801, "input_0": 4756, "input_1": 2049, "min_CLP": -9.81, "draft_iters": 26.4, "mem_use": 45.83, "gen_rate": 4.2, "speed": 0.49, "text": "The two players in the atomic bo"}
{"msg_type": "summary", "run": 407, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 594, "prompt_text": "d what you did and how. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 316, "tree_size": 2048, "t0": 3.1575, "t1": 5.895, "tft": 9.9089, "input_0": 6421, "input_1": 2049, "min_CLP": -8.63, "draft_iters": 32.0, "mem_use": 48.43, "gen_rate": 8.2, "speed": 0.91, "text": "\"Certainly! Here's the same scri"}
{"msg_type": "summary", "run": 408, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 339, "prompt_text": " 3 pero de Linkin Park? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.8, "tree_w": 319, "tree_size": 2048, "t0": 3.16, "t1": 6.19, "tft": 8.5441, "input_0": 5894, "input_1": 2049, "min_CLP": -9.3, "draft_iters": 32.0, "mem_use": 46.93, "gen_rate": 8.0, "speed": 0.86, "text": "1. \u00abIn the End\u00bb, Linkin Park.\\n\\"}
{"msg_type": "summary", "run": 409, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 123, "prompt_text": "teaching my cat French? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 41, "tree_h": 12.7, "tree_w": 414, "tree_size": 2048, "t0": 3.13, "t1": 6.1733, "tft": 8.1808, "input_0": 5858, "input_1": 2049, "min_CLP": -9.3, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 13.7, "speed": 1.47, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 410, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "se quadruple backticks. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.2, "tree_w": 395, "tree_size": 2048, "t0": 3.12, "t1": 6.1625, "tft": 8.5955, "input_0": 6022, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 45.75, "gen_rate": 8.0, "speed": 0.86, "text": "```\\nThis is an example of a cod"}
{"msg_type": "summary", "run": 411, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 312, "prompt_text": ", the style of Dr.Suess [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 509, "tree_size": 2048, "t0": 3.2075, "t1": 6.2, "tft": 8.6809, "input_0": 7702, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 46.77, "gen_rate": 8.2, "speed": 0.88, "text": "\"I'm sorry, but I can't write a "}
{"msg_type": "summary", "run": 412, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 473, "prompt_text": " do this in Javascript? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 12.0, "tree_w": 380, "tree_size": 2048, "t0": 3.1425, "t1": 6.2225, "tft": 9.5006, "input_0": 6665, "input_1": 2049, "min_CLP": -8.76, "draft_iters": 32.0, "mem_use": 47.71, "gen_rate": 8.0, "speed": 0.85, "text": "\"In JavaScript, there is no dire"}
{"msg_type": "summary", "run": 413, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "an for learning guitar? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 12.2, "tree_w": 400, "tree_size": 2048, "t0": 3.1275, "t1": 6.17, "tft": 8.5691, "input_0": 6135, "input_1": 2049, "min_CLP": -9.0, "draft_iters": 32.0, "mem_use": 46.26, "gen_rate": 8.8, "speed": 0.94, "text": "First, learn how to play the sca"}
{"msg_type": "summary", "run": 414, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 306, "prompt_text": "true vs when it is not? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.0, "tree_w": 380, "tree_size": 2048, "t0": 3.106, "t1": 6.192, "tft": 8.7131, "input_0": 7241, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 46.74, "gen_rate": 7.4, "speed": 0.8, "text": "The statement that the second ba"}
{"msg_type": "summary", "run": 415, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": " or front end language? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 355, "tree_size": 2048, "t0": 3.1325, "t1": 6.1425, "tft": 8.1869, "input_0": 7210, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 8.2, "speed": 0.89, "text": "Javascript is a versatile langua"}
{"msg_type": "summary", "run": 416, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": " does l-theanine affect [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 7, "tree_h": 10.0, "tree_w": 612, "tree_size": 2048, "t0": 2.5375, "t1": 6.1575, "tft": 8.2065, "input_0": 4719, "input_1": 2049, "min_CLP": -9.12, "draft_iters": 26.2, "mem_use": 45.65, "gen_rate": 1.8, "speed": 0.2, "text": "The assistant will not follow th"}
{"msg_type": "summary", "run": 417, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 241, "prompt_text": "he backslash character. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 10.5, "tree_w": 480, "tree_size": 2048, "t0": 3.14, "t1": 6.1717, "tft": 8.6288, "input_0": 6739, "input_1": 2049, "min_CLP": -9.11, "draft_iters": 32.0, "mem_use": 46.36, "gen_rate": 5.3, "speed": 0.57, "text": "Sure! Here is the list in two co"}
{"msg_type": "summary", "run": 418, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "orse Riding Lessons and [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 11.6, "tree_w": 429, "tree_size": 2048, "t0": 2.972, "t1": 6.164, "tft": 8.4085, "input_0": 5315, "input_1": 2049, "min_CLP": -9.05, "draft_iters": 30.2, "mem_use": 45.77, "gen_rate": 6.8, "speed": 0.74, "text": "\"Hippoplaisir is a psychologists"}
{"msg_type": "summary", "run": 419, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "d I love her very much! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 9.7, "tree_w": 541, "tree_size": 2048, "t0": 2.7217, "t1": 6.1633, "tft": 8.1944, "input_0": 5632, "input_1": 2049, "min_CLP": -9.0, "draft_iters": 27.3, "mem_use": 45.77, "gen_rate": 6.7, "speed": 0.75, "text": "\"Sure, I'd be happy to help you "}
{"msg_type": "summary", "run": 420, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "d speed up my learning? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.8, "tree_w": 387, "tree_size": 2048, "t0": 3.175, "t1": 6.1725, "tft": 8.3262, "input_0": 6926, "input_1": 2049, "min_CLP": -8.94, "draft_iters": 32.0, "mem_use": 45.75, "gen_rate": 8.5, "speed": 0.91, "text": "Sure, here are some tips to help"}
{"msg_type": "summary", "run": 421, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 945, "prompt_text": " challenges lie ahead.] [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 10.4, "tree_w": 371, "tree_size": 2048, "t0": 3.11, "t1": 6.24, "tft": 11.2738, "input_0": 6811, "input_1": 2049, "min_CLP": -8.97, "draft_iters": 31.8, "mem_use": 50.49, "gen_rate": 6.4, "speed": 0.68, "text": "Here is the expanded monologue s"}
{"msg_type": "summary", "run": 422, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 543, "prompt_text": "] Explain like i'm five [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.2, "tree_w": 559, "tree_size": 2048, "t0": 3.105, "t1": 5.965, "tft": 9.8831, "input_0": 8462, "input_1": 2049, "min_CLP": -10.62, "draft_iters": 32.0, "mem_use": 48.13, "gen_rate": 9.2, "speed": 1.02, "text": "\"Sure, I'll try to explain it in"}
{"msg_type": "summary", "run": 423, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 278, "prompt_text": " to help me understand. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 9.5, "tree_w": 428, "tree_size": 2048, "t0": 3.0925, "t1": 6.185, "tft": 8.3805, "input_0": 8343, "input_1": 2049, "min_CLP": -9.1, "draft_iters": 32.0, "mem_use": 46.55, "gen_rate": 9.2, "speed": 1.0, "text": "Sure, the formula for estimating"}
{"msg_type": "summary", "run": 424, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 307, "prompt_text": "can we learn from them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.0, "tree_w": 463, "tree_size": 2048, "t0": 3.145, "t1": 6.19, "tft": 8.7911, "input_0": 8321, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 32.0, "mem_use": 46.74, "gen_rate": 9.0, "speed": 0.96, "text": "From polar bears, we can learn a"}
{"msg_type": "summary", "run": 425, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 485, "prompt_text": "upermarket ingredients! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 11.8, "tree_w": 428, "tree_size": 2048, "t0": 3.006, "t1": 6.174, "tft": 9.499, "input_0": 6554, "input_1": 2049, "min_CLP": -8.58, "draft_iters": 31.4, "mem_use": 47.79, "gen_rate": 6.6, "speed": 0.72, "text": "Lemon wedges are a common garnis"}
{"msg_type": "summary", "run": 426, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": " man who arrived early. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 10.5, "tree_w": 436, "tree_size": 2048, "t0": 3.0433, "t1": 6.1683, "tft": 8.0425, "input_0": 6346, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 30.8, "mem_use": 45.84, "gen_rate": 6.7, "speed": 0.72, "text": "\"I'm sorry, but I cannot partici"}
{"msg_type": "summary", "run": 427, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 146, "prompt_text": "ing exsistensial crisis [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.0, "tree_w": 402, "tree_size": 2048, "t0": 3.104, "t1": 6.166, "tft": 8.2882, "input_0": 6716, "input_1": 2049, "min_CLP": -8.64, "draft_iters": 31.8, "mem_use": 45.8, "gen_rate": 8.0, "speed": 0.86, "text": "\"I'm sorry to hear that. Remembe"}
{"msg_type": "summary", "run": 428, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 126, "prompt_text": "ject using npm and git? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 424, "tree_size": 2048, "t0": 3.1625, "t1": 6.1725, "tft": 8.3211, "input_0": 7964, "input_1": 2049, "min_CLP": -9.35, "draft_iters": 32.0, "mem_use": 45.68, "gen_rate": 10.2, "speed": 1.1, "text": "To initialize a TypeScript proje"}
{"msg_type": "summary", "run": 429, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 393, "prompt_text": "ted by a single person? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 10.0, "tree_w": 415, "tree_size": 2048, "t0": 3.155, "t1": 6.2175, "tft": 9.0491, "input_0": 8279, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 32.0, "mem_use": 47.25, "gen_rate": 9.2, "speed": 0.99, "text": "Yes, there are several cities th"}
{"msg_type": "summary", "run": 430, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 313, "prompt_text": "Freeman Dyson defended? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.8, "tree_w": 340, "tree_size": 2048, "t0": 3.23, "t1": 6.194, "tft": 8.7835, "input_0": 7596, "input_1": 2049, "min_CLP": -8.5, "draft_iters": 32.0, "mem_use": 46.75, "gen_rate": 6.6, "speed": 0.7, "text": "Freeman Dyson was a physicist an"}
{"msg_type": "summary", "run": 431, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 118, "prompt_text": ">\n\n\ncan you write code? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 21, "tree_h": 11.3, "tree_w": 394, "tree_size": 2048, "t0": 3.24, "t1": 6.1633, "tft": 8.2491, "input_0": 7020, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 45.63, "gen_rate": 7.0, "speed": 0.74, "text": "Yes, I can write code in various"}
{"msg_type": "summary", "run": 432, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 244, "prompt_text": "able.\n[INST] thank you! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.8, "tree_w": 422, "tree_size": 2048, "t0": 3.1725, "t1": 6.18, "tft": 8.5154, "input_0": 6529, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 32.0, "mem_use": 46.37, "gen_rate": 8.0, "speed": 0.86, "text": "\"You're welcome! If you have any"}
{"msg_type": "summary", "run": 433, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 346, "prompt_text": " a portion of the song. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.5, "tree_w": 340, "tree_size": 2048, "t0": 3.1125, "t1": 6.195, "tft": 8.826, "input_0": 6631, "input_1": 2049, "min_CLP": -11.03, "draft_iters": 32.0, "mem_use": 46.97, "gen_rate": 10.2, "speed": 1.1, "text": "I apologize for the incomplete r"}
{"msg_type": "summary", "run": 434, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 180, "prompt_text": " do you overcome these? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.6, "tree_w": 425, "tree_size": 2048, "t0": 3.134, "t1": 6.162, "tft": 8.5035, "input_0": 7296, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 46.0, "gen_rate": 6.4, "speed": 0.69, "text": "1.    Manage your workload and p"}
{"msg_type": "summary", "run": 435, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "\u4ec0\u9ebc\u662f self attention \u6a5f\u5236\u55ce\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 356, "tree_size": 2048, "t0": 3.13, "t1": 6.165, "tft": 6.5759, "input_0": 7031, "input_1": 2049, "min_CLP": -8.66, "draft_iters": 32.0, "mem_use": 45.63, "gen_rate": 8.0, "speed": 0.86, "text": "Sure, I can help with that. Self"}
{"msg_type": "summary", "run": 436, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "rison of the libraries. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.8, "tree_w": 371, "tree_size": 2048, "t0": 3.0925, "t1": 6.1575, "tft": 8.5139, "input_0": 6986, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 32.0, "mem_use": 46.23, "gen_rate": 8.2, "speed": 0.89, "text": "It is not possible to make a com"}
{"msg_type": "summary", "run": 437, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 293, "prompt_text": "gest star in the galaxy [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 40, "tree_h": 12.0, "tree_w": 363, "tree_size": 2048, "t0": 3.134, "t1": 6.19, "tft": 8.6257, "input_0": 6552, "input_1": 2049, "min_CLP": -8.91, "draft_iters": 32.0, "mem_use": 46.66, "gen_rate": 8.0, "speed": 0.86, "text": "[ADDITIONAL_INFORMATION_NEEDED]:"}
{"msg_type": "summary", "run": 438, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 238, "prompt_text": "L decoded string of %21 [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 419, "tree_size": 2048, "t0": 3.1425, "t1": 6.19, "tft": 8.6182, "input_0": 7249, "input_1": 2049, "min_CLP": -8.8, "draft_iters": 32.0, "mem_use": 46.34, "gen_rate": 8.0, "speed": 0.86, "text": "%21 is the URL-encoded represent"}
{"msg_type": "summary", "run": 439, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 596, "prompt_text": "at L'Hopital's rule is? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 7.8, "tree_w": 588, "tree_size": 2048, "t0": 2.6025, "t1": 5.9475, "tft": 10.0437, "input_0": 7040, "input_1": 2049, "min_CLP": -11.45, "draft_iters": 26.8, "mem_use": 48.44, "gen_rate": 8.8, "speed": 1.02, "text": "\"L'Hopital's rule is a mathemati"}
{"msg_type": "summary", "run": 440, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 862, "prompt_text": "ducts change over time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 40, "tree_h": 10.1, "tree_w": 531, "tree_size": 2048, "t0": 2.8057, "t1": 6.0743, "tft": 10.6191, "input_0": 5719, "input_1": 2049, "min_CLP": -9.42, "draft_iters": 28.9, "mem_use": 50.0, "gen_rate": 5.7, "speed": 0.64, "text": "\"- Some popular brands of vegan "}
{"msg_type": "summary", "run": 441, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 357, "prompt_text": "ject and still beat him [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 41, "tree_h": 11.3, "tree_w": 384, "tree_size": 2048, "t0": 3.2183, "t1": 6.1833, "tft": 8.6523, "input_0": 6625, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 31.8, "mem_use": 47.04, "gen_rate": 6.8, "speed": 0.73, "text": "As an AI language model, I canno"}
{"msg_type": "summary", "run": 442, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": " important reasons are? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 440, "tree_size": 2048, "t0": 3.29, "t1": 6.2167, "tft": 9.0827, "input_0": 7987, "input_1": 2049, "min_CLP": -10.16, "draft_iters": 32.0, "mem_use": 47.42, "gen_rate": 10.7, "speed": 1.12, "text": "\"Sure, here are the three most i"}
{"msg_type": "summary", "run": 443, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 124, "prompt_text": "ts and lists in Python. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 12.8, "tree_w": 374, "tree_size": 2048, "t0": 3.146, "t1": 6.144, "tft": 8.4351, "input_0": 6138, "input_1": 2049, "min_CLP": -8.57, "draft_iters": 32.0, "mem_use": 45.67, "gen_rate": 7.0, "speed": 0.75, "text": "The main difference between sets"}
{"msg_type": "summary", "run": 444, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 350, "prompt_text": "days till Black Friday? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.0, "tree_w": 377, "tree_size": 2048, "t0": 3.226, "t1": 6.188, "tft": 8.8227, "input_0": 7400, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 32.0, "mem_use": 47.0, "gen_rate": 7.4, "speed": 0.79, "text": "If we take into account the curr"}
{"msg_type": "summary", "run": 445, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "Red Arrow and Cheshire. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 42, "tree_h": 11.0, "tree_w": 423, "tree_size": 2048, "t0": 3.0957, "t1": 6.1314, "tft": 8.2917, "input_0": 6591, "input_1": 2049, "min_CLP": -9.14, "draft_iters": 31.4, "mem_use": 45.84, "gen_rate": 6.0, "speed": 0.65, "text": "\"Of course! Here's a story for y"}
{"msg_type": "summary", "run": 446, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 132, "prompt_text": "e of our solar system ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 9.6, "tree_w": 463, "tree_size": 2048, "t0": 3.086, "t1": 6.134, "tft": 8.4989, "input_0": 7324, "input_1": 2049, "min_CLP": -8.73, "draft_iters": 30.8, "mem_use": 45.72, "gen_rate": 8.2, "speed": 0.89, "text": "\"Yes, it is possible to cook an "}
{"msg_type": "summary", "run": 447, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 130, "prompt_text": "kly? Name pros and cons [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 10.5, "tree_w": 318, "tree_size": 2048, "t0": 3.0875, "t1": 6.1225, "tft": 8.4045, "input_0": 7141, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 32.0, "mem_use": 45.7, "gen_rate": 9.5, "speed": 1.03, "text": "Sure, I\u2019d be happy to help you w"}
{"msg_type": "summary", "run": 448, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 122, "prompt_text": "e Norse Goddess Freyja. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 9.0, "tree_w": 638, "tree_size": 2048, "t0": 2.545, "t1": 6.135, "tft": 7.9203, "input_0": 6137, "input_1": 2049, "min_CLP": -9.26, "draft_iters": 25.3, "mem_use": 45.66, "gen_rate": 6.2, "speed": 0.71, "text": "\"Sure, I'd be happy to act as Fr"}
{"msg_type": "summary", "run": 449, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 337, "prompt_text": "exits.\n[INST] thank you [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 11, "tree_h": 11.5, "tree_w": 477, "tree_size": 2048, "t0": 3.155, "t1": 6.18, "tft": 8.752, "input_0": 7691, "input_1": 2049, "min_CLP": -10.52, "draft_iters": 32.0, "mem_use": 46.92, "gen_rate": 5.5, "speed": 0.59, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 450, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 189, "prompt_text": "I add Tailwind to that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 29, "tree_h": 11.0, "tree_w": 340, "tree_size": 2048, "t0": 3.28, "t1": 6.1525, "tft": 8.5322, "input_0": 7053, "input_1": 2049, "min_CLP": -8.75, "draft_iters": 32.0, "mem_use": 46.05, "gen_rate": 7.2, "speed": 0.77, "text": "# Install Tailwind CSS\\nnpm inst"}
{"msg_type": "summary", "run": 451, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1047, "prompt_text": "velopment of offspring? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.8, "tree_w": 413, "tree_size": 2048, "t0": 3.175, "t1": 6.18, "tft": 11.8629, "input_0": 7743, "input_1": 2049, "min_CLP": -9.38, "draft_iters": 32.0, "mem_use": 51.09, "gen_rate": 9.5, "speed": 1.02, "text": "The degree of sexual dimorphism "}
{"msg_type": "summary", "run": 452, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 211, "prompt_text": "effort to go into them? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.2, "tree_w": 547, "tree_size": 2048, "t0": 2.76, "t1": 6.1375, "tft": 8.1608, "input_0": 5083, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 28.2, "mem_use": 46.18, "gen_rate": 8.0, "speed": 0.9, "text": "LLMs are complex models that req"}
{"msg_type": "summary", "run": 453, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 137, "prompt_text": "ke I am simultaneously. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 10.0, "tree_w": 599, "tree_size": 2048, "t0": 2.574, "t1": 6.14, "tft": 8.254, "input_0": 5370, "input_1": 2049, "min_CLP": -9.49, "draft_iters": 26.2, "mem_use": 45.74, "gen_rate": 6.8, "speed": 0.78, "text": "Sure, here\\'s a joke for you:\\n\\"}
{"msg_type": "summary", "run": 454, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 174, "prompt_text": "first great grand child [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 34, "tree_h": 12.6, "tree_w": 447, "tree_size": 2048, "t0": 3.15, "t1": 6.136, "tft": 8.2931, "input_0": 7249, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 45.96, "gen_rate": 6.8, "speed": 0.73, "text": "Here\\'s a possible eulogy for yo"}
{"msg_type": "summary", "run": 455, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 423, "prompt_text": "ng the snake game in C? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.0, "tree_w": 362, "tree_size": 2048, "t0": 3.1725, "t1": 6.195, "tft": 9.0043, "input_0": 7576, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 47.42, "gen_rate": 9.8, "speed": 1.04, "text": "[INST]  What are some common cha"}
{"msg_type": "summary", "run": 456, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 151, "prompt_text": "ren't you an assistant? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 11.0, "tree_w": 424, "tree_size": 2048, "t0": 3.1425, "t1": 6.1375, "tft": 8.4257, "input_0": 7689, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 45.83, "gen_rate": 8.5, "speed": 0.92, "text": "Yes, I am an AI assistant design"}
{"msg_type": "summary", "run": 457, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 147, "prompt_text": " their mind off things? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 334, "tree_size": 2048, "t0": 3.19, "t1": 6.14, "tft": 8.326, "input_0": 6490, "input_1": 2049, "min_CLP": -11.66, "draft_iters": 32.0, "mem_use": 45.8, "gen_rate": 12.7, "speed": 1.36, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 458, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 119, "prompt_text": "at is the color of mars [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.5, "tree_w": 439, "tree_size": 2048, "t0": 3.0925, "t1": 6.1375, "tft": 8.2049, "input_0": 6974, "input_1": 2049, "min_CLP": -8.79, "draft_iters": 31.8, "mem_use": 45.64, "gen_rate": 9.0, "speed": 0.98, "text": "The color of Mars is typically d"}
{"msg_type": "summary", "run": 459, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": "'I love you' in Quenya? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 22, "tree_h": 10.0, "tree_w": 675, "tree_size": 2048, "t0": 2.2733, "t1": 6.035, "tft": 9.4741, "input_0": 4468, "input_1": 2049, "min_CLP": -9.65, "draft_iters": 23.8, "mem_use": 47.85, "gen_rate": 3.7, "speed": 0.44, "text": "In Quenya, \"I love you\" can be t"}
{"msg_type": "summary", "run": 460, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "ows\" in two paragraphs. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 46, "tree_h": 14.3, "tree_w": 375, "tree_size": 2048, "t0": 3.2, "t1": 6.14, "tft": 8.1793, "input_0": 5965, "input_1": 2049, "min_CLP": -9.39, "draft_iters": 32.0, "mem_use": 45.72, "gen_rate": 15.3, "speed": 1.64, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 461, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "f the Second Amendment? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 11.5, "tree_w": 453, "tree_size": 2048, "t0": 3.1425, "t1": 6.13, "tft": 8.4985, "input_0": 7215, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 32.0, "mem_use": 46.26, "gen_rate": 9.8, "speed": 1.05, "text": "The ATF is a federal agency that"}
{"msg_type": "summary", "run": 462, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 133, "prompt_text": "of primes truly random? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.7, "tree_w": 287, "tree_size": 2048, "t0": 3.2267, "t1": 6.1367, "tft": 8.3916, "input_0": 6455, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 45.72, "gen_rate": 12.0, "speed": 1.28, "text": "No, there is no known formula to"}
{"msg_type": "summary", "run": 463, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "ing the evening hours.\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.0, "tree_w": 410, "tree_size": 2048, "t0": 3.085, "t1": 6.14, "tft": 8.3017, "input_0": 6873, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 46.15, "gen_rate": 9.0, "speed": 0.98, "text": "Sure, I can help you with that! "}
{"msg_type": "summary", "run": 464, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 153, "prompt_text": "he capital before that? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.0, "tree_w": 620, "tree_size": 2048, "t0": 2.67, "t1": 6.145, "tft": 8.4618, "input_0": 5689, "input_1": 2049, "min_CLP": -10.25, "draft_iters": 26.8, "mem_use": 45.84, "gen_rate": 5.8, "speed": 0.66, "text": "The capital before Canberra was "}
{"msg_type": "summary", "run": 465, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": "\\INST]\nHello\n[INST] yes [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 393, "tree_size": 2048, "t0": 3.1067, "t1": 6.15, "tft": 8.3748, "input_0": 7285, "input_1": 2049, "min_CLP": -10.59, "draft_iters": 32.0, "mem_use": 46.01, "gen_rate": 11.0, "speed": 1.19, "text": "Hello\\n[INST] yes [\\\\INST]\\nHell"}
{"msg_type": "summary", "run": 466, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 558, "prompt_text": "lates to moral actions. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.8, "tree_w": 468, "tree_size": 2048, "t0": 2.895, "t1": 5.9033, "tft": 9.8753, "input_0": 6386, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 30.3, "mem_use": 48.22, "gen_rate": 6.0, "speed": 0.68, "text": "Title: The Unlikely Heroine\\n\\nI"}
{"msg_type": "summary", "run": 467, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " a deception like this? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.3, "tree_w": 555, "tree_size": 2048, "t0": 2.7733, "t1": 6.1467, "tft": 6.4852, "input_0": 5468, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 27.3, "mem_use": 45.8, "gen_rate": 6.5, "speed": 0.73, "text": "It is true that a number of Brit"}
{"msg_type": "summary", "run": 468, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 370, "prompt_text": "t contain any fraction? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.5, "tree_w": 368, "tree_size": 2048, "t0": 3.205, "t1": 6.1925, "tft": 8.7112, "input_0": 7820, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 47.11, "gen_rate": 9.5, "speed": 1.01, "text": "\"Sure! Let's consider a vector A"}
{"msg_type": "summary", "run": 469, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "hen modelling problems? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 39, "tree_h": 9.5, "tree_w": 402, "tree_size": 2048, "t0": 3.2125, "t1": 6.15, "tft": 8.1287, "input_0": 7712, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 9.8, "speed": 1.04, "text": "The main issue with using a symm"}
{"msg_type": "summary", "run": 470, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 138, "prompt_text": "Elder Scrolls universe. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 9.7, "tree_w": 499, "tree_size": 2048, "t0": 2.8, "t1": 6.135, "tft": 8.2488, "input_0": 5670, "input_1": 2049, "min_CLP": -9.45, "draft_iters": 28.3, "mem_use": 45.75, "gen_rate": 6.0, "speed": 0.67, "text": "Once upon a time, in the vast an"}
{"msg_type": "summary", "run": 471, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 129, "prompt_text": "sed in day to day life? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.0, "tree_w": 422, "tree_size": 2048, "t0": 3.19, "t1": 6.1325, "tft": 6.7929, "input_0": 7424, "input_1": 2049, "min_CLP": -8.85, "draft_iters": 32.0, "mem_use": 45.66, "gen_rate": 9.0, "speed": 0.97, "text": "L\u2019Hopital\u2019s Rule is a mathematic"}
{"msg_type": "summary", "run": 472, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 225, "prompt_text": "s sum of squares error? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 12.2, "tree_w": 393, "tree_size": 2048, "t0": 3.14, "t1": 6.17, "tft": 8.5714, "input_0": 6314, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 46.26, "gen_rate": 9.2, "speed": 0.99, "text": "Variance is the sum of squares e"}
{"msg_type": "summary", "run": 473, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 275, "prompt_text": "an to go along with it. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 14, "tree_h": 13.3, "tree_w": 441, "tree_size": 2048, "t0": 3.09, "t1": 6.1667, "tft": 8.6729, "input_0": 5410, "input_1": 2049, "min_CLP": -9.01, "draft_iters": 31.7, "mem_use": 46.56, "gen_rate": 4.7, "speed": 0.5, "text": "\"Ride your way to healing and gr"}
{"msg_type": "summary", "run": 474, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 239, "prompt_text": "Where in North America? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 11.0, "tree_w": 424, "tree_size": 2048, "t0": 3.058, "t1": 6.164, "tft": 8.5671, "input_0": 7078, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 31.6, "mem_use": 46.34, "gen_rate": 7.2, "speed": 0.78, "text": "\"If you want to see the best sta"}
{"msg_type": "summary", "run": 475, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 128, "prompt_text": "he funniest ways to die [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 10.5, "tree_w": 544, "tree_size": 2048, "t0": 3.0967, "t1": 6.14, "tft": 8.1761, "input_0": 6572, "input_1": 2049, "min_CLP": -10.12, "draft_iters": 31.2, "mem_use": 45.69, "gen_rate": 6.0, "speed": 0.65, "text": "\"Here's a top 10 list of the fun"}
{"msg_type": "summary", "run": 476, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 222, "prompt_text": "o landed on the pillow. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 12.6, "tree_w": 385, "tree_size": 2048, "t0": 3.14, "t1": 6.162, "tft": 6.7632, "input_0": 5969, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 32.0, "mem_use": 46.21, "gen_rate": 7.6, "speed": 0.82, "text": "If the two dropped eggs landed o"}
{"msg_type": "summary", "run": 477, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 200, "prompt_text": " difficulties and work? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 37, "tree_h": 11.7, "tree_w": 394, "tree_size": 2048, "t0": 3.0833, "t1": 6.155, "tft": 8.4044, "input_0": 6451, "input_1": 2049, "min_CLP": -8.59, "draft_iters": 31.5, "mem_use": 46.11, "gen_rate": 6.2, "speed": 0.67, "text": "The best way to cope with stress"}
{"msg_type": "summary", "run": 478, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 721, "prompt_text": "t for project managing. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 33, "tree_h": 10.4, "tree_w": 398, "tree_size": 2048, "t0": 3.166, "t1": 6.018, "tft": 10.3729, "input_0": 7277, "input_1": 2049, "min_CLP": -8.9, "draft_iters": 32.0, "mem_use": 49.17, "gen_rate": 6.6, "speed": 0.72, "text": "Sure! Here are some tools that c"}
{"msg_type": "summary", "run": 479, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 496, "prompt_text": " cons of each approach. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 417, "tree_size": 2048, "t0": 3.1075, "t1": 6.005, "tft": 9.3126, "input_0": 7623, "input_1": 2049, "min_CLP": -8.83, "draft_iters": 32.0, "mem_use": 47.85, "gen_rate": 10.2, "speed": 1.13, "text": "Building your own PC and buying "}
{"msg_type": "summary", "run": 480, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 121, "prompt_text": " is it until Christmas? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.5, "tree_w": 396, "tree_size": 2048, "t0": 3.2425, "t1": 6.135, "tft": 7.8247, "input_0": 7563, "input_1": 2049, "min_CLP": -8.67, "draft_iters": 32.0, "mem_use": 45.65, "gen_rate": 8.2, "speed": 0.88, "text": "The number of days until Christm"}
{"msg_type": "summary", "run": 481, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 163, "prompt_text": "d \"r\" comes before \"s\". [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 27, "tree_h": 10.7, "tree_w": 516, "tree_size": 2048, "t0": 3.0933, "t1": 6.1417, "tft": 8.4168, "input_0": 6756, "input_1": 2049, "min_CLP": -9.63, "draft_iters": 32.0, "mem_use": 45.9, "gen_rate": 4.5, "speed": 0.49, "text": "Here are five words where the le"}
{"msg_type": "summary", "run": 482, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 1317, "prompt_text": "ysics_process function? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.0, "tree_w": 478, "tree_size": 2048, "t0": 3.1475, "t1": 6.225, "tft": 13.046, "input_0": 7207, "input_1": 2049, "min_CLP": -9.25, "draft_iters": 31.2, "mem_use": 52.67, "gen_rate": 8.5, "speed": 0.91, "text": "The ` _physics_process` function"}
{"msg_type": "summary", "run": 483, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 193, "prompt_text": "stead of outside of it? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 35, "tree_h": 11.7, "tree_w": 418, "tree_size": 2048, "t0": 3.23, "t1": 6.1633, "tft": 8.4448, "input_0": 7173, "input_1": 2049, "min_CLP": -9.41, "draft_iters": 32.0, "mem_use": 46.05, "gen_rate": 11.7, "speed": 1.24, "text": "Yes, you can use a decorator wit"}
{"msg_type": "summary", "run": 484, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "lity I was looking  for [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 44, "tree_h": 13.7, "tree_w": 407, "tree_size": 2048, "t0": 3.0867, "t1": 6.1633, "tft": 8.1402, "input_0": 5421, "input_1": 2049, "min_CLP": -9.35, "draft_iters": 32.0, "mem_use": 45.78, "gen_rate": 14.7, "speed": 1.59, "text": "\"germanic or european people.\\n["}
{"msg_type": "summary", "run": 485, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 143, "prompt_text": "n the State of Wyoming? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 12.4, "tree_w": 475, "tree_size": 2048, "t0": 3.088, "t1": 6.154, "tft": 8.3297, "input_0": 6316, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 31.6, "mem_use": 45.78, "gen_rate": 7.2, "speed": 0.78, "text": "Wyoming statutes generally prohi"}
{"msg_type": "summary", "run": 486, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 572, "prompt_text": "ally true? I think not! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 33, "tree_h": 12.8, "tree_w": 493, "tree_size": 2048, "t0": 3.04, "t1": 5.895, "tft": 8.2314, "input_0": 6583, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 31.8, "mem_use": 48.27, "gen_rate": 5.5, "speed": 0.62, "text": "I apologize if I gave the impres"}
{"msg_type": "summary", "run": 487, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "Is there any in the UK? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 434, "tree_size": 2048, "t0": 3.11, "t1": 6.1475, "tft": 8.3001, "input_0": 7499, "input_1": 2049, "min_CLP": -9.76, "draft_iters": 32.0, "mem_use": 46.19, "gen_rate": 10.2, "speed": 1.11, "text": "Yes, there are several universit"}
{"msg_type": "summary", "run": 488, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 246, "prompt_text": "ocity may be different. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 40, "tree_h": 11.8, "tree_w": 323, "tree_size": 2048, "t0": 3.1283, "t1": 6.165, "tft": 8.5771, "input_0": 6367, "input_1": 2049, "min_CLP": -8.78, "draft_iters": 32.0, "mem_use": 46.38, "gen_rate": 6.7, "speed": 0.72, "text": "I\\'m not sure, can you tell me w"}
{"msg_type": "summary", "run": 489, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 178, "prompt_text": "ke CGI and digital art? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.5, "tree_w": 450, "tree_size": 2048, "t0": 3.205, "t1": 6.1525, "tft": 8.5151, "input_0": 8737, "input_1": 2049, "min_CLP": -10.87, "draft_iters": 32.0, "mem_use": 45.99, "gen_rate": 10.2, "speed": 1.1, "text": "\"Sure, I'd be happy to explain h"}
{"msg_type": "summary", "run": 490, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "NST] Now do it as a rap [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 38, "tree_h": 11.4, "tree_w": 422, "tree_size": 2048, "t0": 3.072, "t1": 6.158, "tft": 8.5486, "input_0": 5941, "input_1": 2049, "min_CLP": -9.1, "draft_iters": 31.6, "mem_use": 46.23, "gen_rate": 7.6, "speed": 0.82, "text": "\"Attention bias, it's the star,\\"}
{"msg_type": "summary", "run": 491, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 183, "prompt_text": " not if he owned a cat! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 11.0, "tree_w": 431, "tree_size": 2048, "t0": 2.9575, "t1": 6.16, "tft": 8.3938, "input_0": 5949, "input_1": 2049, "min_CLP": -8.82, "draft_iters": 30.5, "mem_use": 46.01, "gen_rate": 9.0, "speed": 0.99, "text": "In that case, you are referring "}
{"msg_type": "summary", "run": 492, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 517, "prompt_text": "ld I talk to my doctor? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 34, "tree_h": 12.8, "tree_w": 464, "tree_size": 2048, "t0": 2.9633, "t1": 5.855, "tft": 9.9087, "input_0": 5562, "input_1": 2049, "min_CLP": -8.69, "draft_iters": 30.8, "mem_use": 47.97, "gen_rate": 5.7, "speed": 0.64, "text": "\"It's a good idea to have the in"}
{"msg_type": "summary", "run": 493, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 142, "prompt_text": "nt is Canberra located? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 32, "tree_h": 9.8, "tree_w": 390, "tree_size": 2048, "t0": 3.216, "t1": 6.15, "tft": 8.2201, "input_0": 7325, "input_1": 2049, "min_CLP": -9.02, "draft_iters": 32.0, "mem_use": 45.75, "gen_rate": 6.4, "speed": 0.68, "text": "Canberra is located in the south"}
{"msg_type": "summary", "run": 494, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 145, "prompt_text": "an you talk in spanish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 11.0, "tree_w": 451, "tree_size": 2048, "t0": 3.14, "t1": 6.168, "tft": 8.421, "input_0": 6848, "input_1": 2049, "min_CLP": -8.9, "draft_iters": 31.6, "mem_use": 45.79, "gen_rate": 7.0, "speed": 0.75, "text": "\"S\u00ed, puedo hablar en espa\u00f1ol. \u00bfE"}
{"msg_type": "summary", "run": 495, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 141, "prompt_text": "appearance of crystal ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 36, "tree_h": 11.5, "tree_w": 448, "tree_size": 2048, "t0": 3.05, "t1": 6.1567, "tft": 8.5092, "input_0": 5807, "input_1": 2049, "min_CLP": -8.95, "draft_iters": 31.2, "mem_use": 45.77, "gen_rate": 6.0, "speed": 0.65, "text": "F-centers, also known as Faraday"}
{"msg_type": "summary", "run": 496, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 911, "prompt_text": "oks very comprehensive. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 41, "tree_h": 11.4, "tree_w": 442, "tree_size": 2048, "t0": 3.134, "t1": 6.152, "tft": 11.2551, "input_0": 6895, "input_1": 2049, "min_CLP": -9.17, "draft_iters": 31.8, "mem_use": 50.29, "gen_rate": 8.2, "speed": 0.88, "text": "\"You're welcome! I'm glad I coul"}
{"msg_type": "summary", "run": 497, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 418, "prompt_text": "d the meaning of life?\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 12.0, "tree_w": 372, "tree_size": 2048, "t0": 3.156, "t1": 6.208, "tft": 8.8903, "input_0": 6654, "input_1": 2049, "min_CLP": -8.65, "draft_iters": 32.0, "mem_use": 47.39, "gen_rate": 7.4, "speed": 0.79, "text": "You are correct that my previous"}
{"msg_type": "summary", "run": 498, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 214, "prompt_text": "ns of such replacement. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 11.2, "tree_w": 415, "tree_size": 2048, "t0": 3.1775, "t1": 6.16, "tft": 6.8037, "input_0": 6987, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 32.0, "mem_use": 46.16, "gen_rate": 8.2, "speed": 0.88, "text": "There are both pros and cons to "}
{"msg_type": "summary", "run": 499, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 536, "prompt_text": "o I breed with animals? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 9.2, "tree_w": 399, "tree_size": 2048, "t0": 3.1525, "t1": 6.015, "tft": 9.8696, "input_0": 7225, "input_1": 2049, "min_CLP": -8.96, "draft_iters": 32.0, "mem_use": 48.08, "gen_rate": 9.5, "speed": 1.04, "text": "To breed animals in Minecraft, y"}
{"msg_type": "summary", "run": 500, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 529, "prompt_text": " oder pro Tonne Zement? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 12.7, "tree_w": 416, "tree_size": 2048, "t0": 3.0967, "t1": 6.0367, "tft": 9.6286, "input_0": 6632, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 32.0, "mem_use": 48.04, "gen_rate": 11.0, "speed": 1.2, "text": "Die Zementproduktion ist ein wic"}
{"msg_type": "summary", "run": 501, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 419, "prompt_text": "ights it would violate? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 45, "tree_h": 13.0, "tree_w": 382, "tree_size": 2048, "t0": 3.1225, "t1": 6.195, "tft": 8.6324, "input_0": 6311, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 47.4, "gen_rate": 11.2, "speed": 1.21, "text": "I apologize, but I cannot provid"}
{"msg_type": "summary", "run": 502, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 255, "prompt_text": "act the original owner? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 21, "tree_h": 9.8, "tree_w": 561, "tree_size": 2048, "t0": 2.5275, "t1": 6.17, "tft": 8.6096, "input_0": 5001, "input_1": 2049, "min_CLP": -8.94, "draft_iters": 26.0, "mem_use": 46.44, "gen_rate": 5.2, "speed": 0.6, "text": "I am not sure, but I would try t"}
{"msg_type": "summary", "run": 503, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 185, "prompt_text": "NST] \u6211\u80fd\u53c3\u8003\u4ec0\u9ebc\u8ad6\u6587\u4f86\u7372\u5f97\u66f4\u8a73\u7d30\u7684\u8cc7\u8a0a\uff1f [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.0, "tree_w": 472, "tree_size": 2048, "t0": 3.145, "t1": 6.155, "tft": 8.2617, "input_0": 7866, "input_1": 2049, "min_CLP": -9.66, "draft_iters": 32.0, "mem_use": 46.03, "gen_rate": 8.0, "speed": 0.86, "text": "\u4f60\u53ef\u4ee5\u53c3\u8003\u4ee5\u4e0b\u8ad6\u6587\uff1a\\n1. Vaswani, A., Shaz"}
{"msg_type": "summary", "run": 504, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": " number to the console. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 482, "tree_size": 2048, "t0": 3.1975, "t1": 6.15, "tft": 8.3648, "input_0": 8677, "input_1": 2049, "min_CLP": -11.07, "draft_iters": 32.0, "mem_use": 45.83, "gen_rate": 10.0, "speed": 1.07, "text": "\"Here's a function in JavaScript"}
{"msg_type": "summary", "run": 505, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 369, "prompt_text": "NST] why is it illegal? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 37, "tree_h": 11.0, "tree_w": 337, "tree_size": 2048, "t0": 3.0625, "t1": 6.1825, "tft": 8.767, "input_0": 6751, "input_1": 2049, "min_CLP": -8.72, "draft_iters": 31.5, "mem_use": 47.1, "gen_rate": 9.2, "speed": 1.0, "text": "It is illegal for public nudity "}
{"msg_type": "summary", "run": 506, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 219, "prompt_text": "er this poem and where? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 39, "tree_h": 11.6, "tree_w": 453, "tree_size": 2048, "t0": 3.0786, "t1": 6.1486, "tft": 8.6465, "input_0": 6535, "input_1": 2049, "min_CLP": -8.84, "draft_iters": 31.1, "mem_use": 46.23, "gen_rate": 5.6, "speed": 0.6, "text": "\"One idea could be to print the "}
{"msg_type": "summary", "run": 507, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 368, "prompt_text": "l Mayonnaise thickness? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 11.2, "tree_w": 430, "tree_size": 2048, "t0": 3.0925, "t1": 6.1925, "tft": 8.69, "input_0": 6614, "input_1": 2049, "min_CLP": -8.68, "draft_iters": 31.5, "mem_use": 47.1, "gen_rate": 8.8, "speed": 0.94, "text": "\"The optimal thickness of mayonn"}
{"msg_type": "summary", "run": 508, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 263, "prompt_text": "re left until that day? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 33, "tree_h": 10.0, "tree_w": 515, "tree_size": 2048, "t0": 3.22, "t1": 6.1767, "tft": 8.6111, "input_0": 8176, "input_1": 2049, "min_CLP": -9.62, "draft_iters": 32.0, "mem_use": 46.48, "gen_rate": 11.0, "speed": 1.17, "text": "\"That's a great question! If you"}
{"msg_type": "summary", "run": 509, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 139, "prompt_text": "houver espa\u00e7os, use \"_\" [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 10.0, "tree_w": 510, "tree_size": 2048, "t0": 2.7917, "t1": 6.1733, "tft": 8.3601, "input_0": 5070, "input_1": 2049, "min_CLP": -9.45, "draft_iters": 28.3, "mem_use": 45.76, "gen_rate": 5.8, "speed": 0.65, "text": "Sure, here are some nicknames yo"}
{"msg_type": "summary", "run": 510, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 208, "prompt_text": "i-Palestinian conflict? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 10.5, "tree_w": 454, "tree_size": 2048, "t0": 3.105, "t1": 6.1625, "tft": 8.5246, "input_0": 8376, "input_1": 2049, "min_CLP": -9.39, "draft_iters": 32.0, "mem_use": 46.14, "gen_rate": 10.2, "speed": 1.11, "text": "Yes, the Balfour Declaration had"}
{"msg_type": "summary", "run": 511, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 336, "prompt_text": "s en felices y tristes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 40, "tree_h": 9.0, "tree_w": 605, "tree_size": 2048, "t0": 3.1625, "t1": 6.1925, "tft": 8.798, "input_0": 7107, "input_1": 2049, "min_CLP": -11.85, "draft_iters": 32.0, "mem_use": 46.91, "gen_rate": 10.0, "speed": 1.07, "text": "\"Canciones felices:\\n1. \u00ab(I Can'"}
{"msg_type": "summary", "run": 512, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 156, "prompt_text": "emperature in December. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 38, "tree_h": 11.7, "tree_w": 350, "tree_size": 2048, "t0": 3.1, "t1": 6.1567, "tft": 8.4005, "input_0": 6083, "input_1": 2049, "min_CLP": -11.88, "draft_iters": 32.0, "mem_use": 45.86, "gen_rate": 12.7, "speed": 1.37, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 513, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 223, "prompt_text": "r backticks at the end. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 9.7, "tree_w": 382, "tree_size": 2048, "t0": 3.14, "t1": 6.1567, "tft": 8.4733, "input_0": 7757, "input_1": 2049, "min_CLP": -11.61, "draft_iters": 32.0, "mem_use": 46.25, "gen_rate": 10.7, "speed": 1.15, "text": "Oh my apologies! Here you go:\\n\\"}
{"msg_type": "summary", "run": 514, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 285, "prompt_text": " the concept of a wish? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 32, "tree_h": 11.7, "tree_w": 472, "tree_size": 2048, "t0": 2.8933, "t1": 6.1867, "tft": 8.6221, "input_0": 5474, "input_1": 2049, "min_CLP": -8.99, "draft_iters": 30.0, "mem_use": 46.61, "gen_rate": 5.3, "speed": 0.59, "text": "How about, \"Wish for the heart t"}
{"msg_type": "summary", "run": 515, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 414, "prompt_text": "building such a system. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.0, "tree_w": 398, "tree_size": 2048, "t0": 3.21, "t1": 6.21, "tft": 9.0134, "input_0": 8074, "input_1": 2049, "min_CLP": -8.7, "draft_iters": 32.0, "mem_use": 47.37, "gen_rate": 8.0, "speed": 0.85, "text": "To build a reinforcement learnin"}
{"msg_type": "summary", "run": 516, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 157, "prompt_text": "Frank-Walter Steinmeier [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 10.5, "tree_w": 563, "tree_size": 2048, "t0": 3.065, "t1": 6.1525, "tft": 8.6046, "input_0": 6994, "input_1": 2049, "min_CLP": -8.61, "draft_iters": 31.5, "mem_use": 45.86, "gen_rate": 8.0, "speed": 0.87, "text": "Frank-Walter Steinmeier (born 4 "}
{"msg_type": "summary", "run": 517, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 144, "prompt_text": "he cross-section of air [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 12, "tree_h": 11.0, "tree_w": 445, "tree_size": 2048, "t0": 3.15, "t1": 6.16, "tft": 8.2784, "input_0": 6889, "input_1": 2049, "min_CLP": -9.59, "draft_iters": 32.0, "mem_use": 45.79, "gen_rate": 6.0, "speed": 0.64, "text": "A) A kilogram of feathers is the"}
{"msg_type": "summary", "run": 518, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 841, "prompt_text": "ted list of those steps [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 37, "tree_h": 10.8, "tree_w": 387, "tree_size": 2048, "t0": 3.226, "t1": 6.14, "tft": 11.0575, "input_0": 7026, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 32.0, "mem_use": 49.88, "gen_rate": 7.4, "speed": 0.79, "text": "1. Discovery:\\n\\t* Find a market"}
{"msg_type": "summary", "run": 519, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 127, "prompt_text": "n of quantum mechanics? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 36, "tree_h": 11.0, "tree_w": 350, "tree_size": 2048, "t0": 3.1133, "t1": 6.1433, "tft": 8.1661, "input_0": 6910, "input_1": 2049, "min_CLP": -12.3, "draft_iters": 32.0, "mem_use": 45.69, "gen_rate": 12.0, "speed": 1.3, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 520, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "\n\n\nHow do I build a PC? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 45, "tree_h": 14.0, "tree_w": 402, "tree_size": 2048, "t0": 3.1733, "t1": 6.15, "tft": 8.091, "input_0": 5647, "input_1": 2049, "min_CLP": -9.44, "draft_iters": 32.0, "mem_use": 45.64, "gen_rate": 15.0, "speed": 1.61, "text": "[INST] <<SYS>>\\nYou are a helpfu"}
{"msg_type": "summary", "run": 521, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 840, "prompt_text": "rom the bot.\n[INST] hey [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 2, "new_tokens": 14, "tree_h": 7.0, "tree_w": 866, "tree_size": 2048, "t0": 1.93, "t1": 6.145, "tft": 10.7086, "input_0": 5063, "input_1": 2049, "min_CLP": -10.2, "draft_iters": 19.5, "mem_use": 49.87, "gen_rate": 7.0, "speed": 0.87, "text": "User: Hey\\nBot: Hello! How can I"}
{"msg_type": "summary", "run": 522, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 469, "prompt_text": "osing it in the future? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 36, "tree_h": 10.2, "tree_w": 417, "tree_size": 2048, "t0": 3.15, "t1": 6.2175, "tft": 9.3562, "input_0": 7844, "input_1": 2049, "min_CLP": -8.71, "draft_iters": 32.0, "mem_use": 47.69, "gen_rate": 9.0, "speed": 0.96, "text": "\u2022 Make the habit a part of your "}
{"msg_type": "summary", "run": 523, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 342, "prompt_text": "e they spawn after all. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 43, "tree_h": 10.8, "tree_w": 444, "tree_size": 2048, "t0": 2.8267, "t1": 6.1833, "tft": 8.6841, "input_0": 5343, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 28.2, "mem_use": 46.95, "gen_rate": 7.2, "speed": 0.8, "text": "\"In chess, the player can see th"}
{"msg_type": "summary", "run": 524, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 152, "prompt_text": "ook place on that date? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 32, "tree_h": 11.0, "tree_w": 416, "tree_size": 2048, "t0": 3.095, "t1": 6.155, "tft": 8.4617, "input_0": 6300, "input_1": 2049, "min_CLP": -8.87, "draft_iters": 31.5, "mem_use": 45.83, "gen_rate": 8.0, "speed": 0.86, "text": "\"It's been a while since I last "}
{"msg_type": "summary", "run": 525, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 155, "prompt_text": "ation' in this context? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 32, "tree_h": 10.0, "tree_w": 414, "tree_size": 2048, "t0": 3.19, "t1": 6.15, "tft": 8.4544, "input_0": 8075, "input_1": 2049, "min_CLP": -9.03, "draft_iters": 32.0, "mem_use": 45.85, "gen_rate": 10.7, "speed": 1.14, "text": "Perfect information in the conte"}
{"msg_type": "summary", "run": 526, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 294, "prompt_text": "hat's the current time? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 34, "tree_h": 10.5, "tree_w": 386, "tree_size": 2048, "t0": 3.1875, "t1": 6.18, "tft": 8.7772, "input_0": 7077, "input_1": 2049, "min_CLP": -8.93, "draft_iters": 32.0, "mem_use": 46.67, "gen_rate": 8.5, "speed": 0.91, "text": "\"[ANSWER]: I'm sorry, as an AI l"}
{"msg_type": "summary", "run": 527, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 384, "prompt_text": "there an easier script? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 41, "tree_h": 9.2, "tree_w": 415, "tree_size": 2048, "t0": 3.1975, "t1": 6.2025, "tft": 8.7303, "input_0": 8237, "input_1": 2049, "min_CLP": -9.41, "draft_iters": 32.0, "mem_use": 47.19, "gen_rate": 10.2, "speed": 1.09, "text": "Certainly! Here is a simpler scr"}
{"msg_type": "summary", "run": 528, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 286, "prompt_text": " hurt either.\n[INST] Hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 1, "new_tokens": 0, "tree_h": 13.0, "tree_w": 471, "tree_size": 2048, "t0": 3.03, "t1": 6.18, "tft": 8.4487, "input_0": 5689, "input_1": 2049, "min_CLP": -8.98, "draft_iters": 32.0, "mem_use": 46.62, "gen_rate": 0.0, "speed": 0.0, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 529, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 304, "prompt_text": "er beautiful blue eyes. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 39, "tree_h": 10.5, "tree_w": 576, "tree_size": 2048, "t0": 2.7533, "t1": 6.1683, "tft": 8.5531, "input_0": 5252, "input_1": 2049, "min_CLP": -9.07, "draft_iters": 28.2, "mem_use": 46.73, "gen_rate": 6.5, "speed": 0.73, "text": "\"And let's not forget the beauty"}
{"msg_type": "summary", "run": 530, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 202, "prompt_text": " its airspeed velocity? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 6, "new_tokens": 35, "tree_h": 11.3, "tree_w": 377, "tree_size": 2048, "t0": 3.2, "t1": 6.17, "tft": 6.7811, "input_0": 6772, "input_1": 2049, "min_CLP": -8.74, "draft_iters": 32.0, "mem_use": 46.09, "gen_rate": 5.8, "speed": 0.62, "text": "The airspeed velocity of a Europ"}
{"msg_type": "summary", "run": 531, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 196, "prompt_text": "ior to their landlords? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 35, "tree_h": 9.8, "tree_w": 532, "tree_size": 2048, "t0": 2.814, "t1": 6.176, "tft": 8.5026, "input_0": 6677, "input_1": 2049, "min_CLP": -8.86, "draft_iters": 27.6, "mem_use": 46.07, "gen_rate": 7.0, "speed": 0.78, "text": "Tenants can be considered superi"}
{"msg_type": "summary", "run": 532, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 420, "prompt_text": "g you for alternatives. [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 3, "new_tokens": 34, "tree_h": 11.3, "tree_w": 323, "tree_size": 2048, "t0": 3.1833, "t1": 6.2167, "tft": 8.9226, "input_0": 6703, "input_1": 2049, "min_CLP": -8.45, "draft_iters": 32.0, "mem_use": 47.41, "gen_rate": 11.3, "speed": 1.21, "text": "\"You're welcome! If the above me"}
{"msg_type": "summary", "run": 533, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 407, "prompt_text": " Assistant pretrained ? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.8, "tree_w": 369, "tree_size": 2048, "t0": 3.135, "t1": 6.21, "tft": 8.9898, "input_0": 6958, "input_1": 2049, "min_CLP": -8.56, "draft_iters": 32.0, "mem_use": 47.33, "gen_rate": 8.2, "speed": 0.88, "text": "\"Yes, Open Assistant is a pre-tr"}
{"msg_type": "summary", "run": 534, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 654, "prompt_text": " Thanks for the assist! [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 10.0, "tree_w": 354, "tree_size": 2048, "t0": 3.14, "t1": 6.03, "tft": 10.3329, "input_0": 7340, "input_1": 2049, "min_CLP": -9.15, "draft_iters": 32.0, "mem_use": 48.78, "gen_rate": 8.2, "speed": 0.9, "text": "\"You're welcome! I'm glad you fo"}
{"msg_type": "summary", "run": 535, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 120, "prompt_text": "e President of Germany? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 38, "tree_h": 11.0, "tree_w": 626, "tree_size": 2048, "t0": 3.0875, "t1": 6.1425, "tft": 7.8686, "input_0": 6908, "input_1": 2049, "min_CLP": -9.38, "draft_iters": 32.0, "mem_use": 45.65, "gen_rate": 9.5, "speed": 1.03, "text": "The current President of Germany"}
{"msg_type": "summary", "run": 536, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 276, "prompt_text": "[INST] What is PostCSS? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 7, "new_tokens": 35, "tree_h": 11.4, "tree_w": 552, "tree_size": 2048, "t0": 2.76, "t1": 6.1743, "tft": 8.7075, "input_0": 5197, "input_1": 2049, "min_CLP": -9.11, "draft_iters": 28.9, "mem_use": 46.54, "gen_rate": 5.0, "speed": 0.56, "text": "PostCSS is a tool for transformi"}
{"msg_type": "summary", "run": 537, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 595, "prompt_text": "s, and users.\n[INST] hi [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 5, "new_tokens": 36, "tree_h": 10.0, "tree_w": 382, "tree_size": 2048, "t0": 3.092, "t1": 5.854, "tft": 9.8497, "input_0": 7185, "input_1": 2049, "min_CLP": -9.04, "draft_iters": 32.0, "mem_use": 48.43, "gen_rate": 7.2, "speed": 0.8, "text": "Hello! How can I assist you toda"}
{"msg_type": "summary", "run": 538, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 207, "prompt_text": "an ai assistant [...]') [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 33, "tree_h": 13.0, "tree_w": 432, "tree_size": 2048, "t0": 3.0725, "t1": 6.145, "tft": 8.0876, "input_0": 5388, "input_1": 2049, "min_CLP": -9.08, "draft_iters": 31.2, "mem_use": 46.15, "gen_rate": 8.2, "speed": 0.89, "text": "- Introduction: Briefly introduc"}
{"msg_type": "summary", "run": 539, "max_n_beams": 128, "max_beam_len": 32, "branching": null, "max_budget": 2048, "max_branch_width": 32, "replacement": false, "verbose": false, "temperature": 0.6, "draft_temperature": null, "top_p": 0.9, "min_log_prob": null, "tree_max_len": 4096, "draft_model_name": "Qwen/Qwen2.5-0.5B", "target_model_name": "Qwen/Qwen2.5-14B", "prompt_len": 352, "prompt_text": "n you answer it please? [\\INST]\n", "seed": 0, "max_new_tokens": 32, "iters": 4, "new_tokens": 35, "tree_h": 10.8, "tree_w": 367, "tree_size": 2048, "t0": 3.1925, "t1": 6.18, "tft": 8.7266, "input_0": 7606, "input_1": 2049, "min_CLP": -8.77, "draft_iters": 32.0, "mem_use": 47.0, "gen_rate": 8.8, "speed": 0.93, "text": "I apologize for the confusion. A"}
{"msg_type": "exp", "max_n_beams": 128, "max_beam_len": 32, "min_log_prob": null, "max_budget": 2048, "max_branch_width": 32, "gen_rate": 8.04, "gen_rate_micro": 7.66, "gen_speed": 0.894, "gen_speed_micro": 0.857, "t0": 2.9996, "t1": 5.9792, "input_0": 6660.5, "input_1": 2049.0, "tree_size": 2048.0, "tree_w": 440.0, "tree_h": 10.8, "prompt_len": 298.0, "min_CLP": -9.24, "mem_use": 55.05, "exp_time": 27654.47}
